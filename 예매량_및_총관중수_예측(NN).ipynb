{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow 의 DNN 을 사용한 총관중 예측 모델 \n",
    "- 모델 자체는 복잡하지 않음\n",
    "- Tensorflow 연습하기에 좋음. 여러 테크닉이 있음 \n",
    "- 성능은 글쎄..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# plt.style.use('ggplot')\n",
    "from sklearn import metrics  \n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "plt.rcParams['font.family'] = 'NanumGothic'\n",
    "# plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = 'Ubuntu'\n",
    "plt.rcParams['font.monospace'] = 'Ubuntu Mono'\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 13\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['legend.fontsize'] = 11\n",
    "plt.rcParams['figure.titlesize'] = 13 \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os_sep = os.sep \n",
    "home = os.path.expanduser(\"~\")   # home = os.getenv(\"HOME\")\n",
    "np.random.seed(42)\n",
    "\n",
    "sys.path.append(os.path.join(home, 'Google_Sync', 'Dev_Exercise', 'utils'))\n",
    "from tf_utils import *  \n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('3.6.6 | packaged by conda-forge | (default, Jul 26 2018, 09:53:17) \\n[GCC 4.8.2 20140120 (Red Hat 4.8.2-15)]',\n",
       " '1.11.0',\n",
       " '0.20.0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version, tf.__version__, sk.__version__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>경기일자</th>\n",
       "      <th>KIA</th>\n",
       "      <th>LG</th>\n",
       "      <th>NC</th>\n",
       "      <th>SK</th>\n",
       "      <th>키움</th>\n",
       "      <th>두산</th>\n",
       "      <th>롯데</th>\n",
       "      <th>삼성</th>\n",
       "      <th>한화</th>\n",
       "      <th>...</th>\n",
       "      <th>전체_d2</th>\n",
       "      <th>전체_d3</th>\n",
       "      <th>전체_d4</th>\n",
       "      <th>전체_d5</th>\n",
       "      <th>전체_d6</th>\n",
       "      <th>전체_d7</th>\n",
       "      <th>전체_d8</th>\n",
       "      <th>전체_d9</th>\n",
       "      <th>전체_d10</th>\n",
       "      <th>전체_d11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>2018-09-29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>482</td>\n",
       "      <td>316</td>\n",
       "      <td>189</td>\n",
       "      <td>99</td>\n",
       "      <td>60</td>\n",
       "      <td>130</td>\n",
       "      <td>161</td>\n",
       "      <td>286</td>\n",
       "      <td>666</td>\n",
       "      <td>1052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>288</td>\n",
       "      <td>355</td>\n",
       "      <td>239</td>\n",
       "      <td>133</td>\n",
       "      <td>58</td>\n",
       "      <td>97</td>\n",
       "      <td>123</td>\n",
       "      <td>133</td>\n",
       "      <td>359</td>\n",
       "      <td>806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>2018-10-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>85</td>\n",
       "      <td>125</td>\n",
       "      <td>129</td>\n",
       "      <td>154</td>\n",
       "      <td>182</td>\n",
       "      <td>138</td>\n",
       "      <td>148</td>\n",
       "      <td>231</td>\n",
       "      <td>336</td>\n",
       "      <td>581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>2018-10-09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>288</td>\n",
       "      <td>313</td>\n",
       "      <td>229</td>\n",
       "      <td>192</td>\n",
       "      <td>202</td>\n",
       "      <td>212</td>\n",
       "      <td>251</td>\n",
       "      <td>402</td>\n",
       "      <td>903</td>\n",
       "      <td>1714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>2018-10-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>246</td>\n",
       "      <td>259</td>\n",
       "      <td>256</td>\n",
       "      <td>157</td>\n",
       "      <td>168</td>\n",
       "      <td>116</td>\n",
       "      <td>125</td>\n",
       "      <td>131</td>\n",
       "      <td>351</td>\n",
       "      <td>1128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          경기일자  KIA  LG  NC  SK  키움  두산  롯데  삼성  한화   ...    전체_d2  전체_d3  \\\n",
       "256 2018-09-29    0   0   0   0   0   0   1   0   0   ...      482    316   \n",
       "257 2018-09-30    0   0   0   0   0   0   1   0   0   ...      288    355   \n",
       "258 2018-10-06    0   0   0   0   0   0   0   1   0   ...       85    125   \n",
       "259 2018-10-09    0   0   0   0   0   0   0   0   1   ...      288    313   \n",
       "260 2018-10-12    0   0   0   0   0   0   0   0   0   ...      246    259   \n",
       "\n",
       "     전체_d4  전체_d5  전체_d6  전체_d7  전체_d8  전체_d9  전체_d10  전체_d11  \n",
       "256    189     99     60    130    161    286     666    1052  \n",
       "257    239    133     58     97    123    133     359     806  \n",
       "258    129    154    182    138    148    231     336     581  \n",
       "259    229    192    202    212    251    402     903    1714  \n",
       "260    256    157    168    116    125    131     351    1128  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫째 열 '경기일자'를 datetime 타입으로 변환 \n",
    "data = pd.read_excel('./train_data(2015-2018).xlsx', parse_dates=[0])  \n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 탐색분석  : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 261 entries, 0 to 260\n",
      "Data columns (total 83 columns):\n",
      "경기일자      261 non-null datetime64[ns]\n",
      "KIA       261 non-null int64\n",
      "LG        261 non-null int64\n",
      "NC        261 non-null int64\n",
      "SK        261 non-null int64\n",
      "키움        261 non-null int64\n",
      "두산        261 non-null int64\n",
      "롯데        261 non-null int64\n",
      "삼성        261 non-null int64\n",
      "한화        261 non-null int64\n",
      "월         261 non-null int64\n",
      "화         261 non-null int64\n",
      "수         261 non-null int64\n",
      "목         261 non-null int64\n",
      "금         261 non-null int64\n",
      "토         261 non-null int64\n",
      "일         261 non-null int64\n",
      "공휴일       261 non-null int64\n",
      "1루        261 non-null int64\n",
      "3루        261 non-null int64\n",
      "외야        261 non-null int64\n",
      "중앙        261 non-null int64\n",
      "총관중수      261 non-null int64\n",
      "1루_d0     261 non-null int64\n",
      "1루_d1     261 non-null int64\n",
      "1루_d2     261 non-null int64\n",
      "1루_d3     261 non-null int64\n",
      "1루_d4     261 non-null int64\n",
      "1루_d5     261 non-null int64\n",
      "1루_d6     261 non-null int64\n",
      "1루_d7     261 non-null int64\n",
      "1루_d8     261 non-null int64\n",
      "1루_d9     261 non-null int64\n",
      "1루_d10    261 non-null int64\n",
      "1루_d11    261 non-null int64\n",
      "3루_d0     261 non-null int64\n",
      "3루_d1     261 non-null int64\n",
      "3루_d2     261 non-null int64\n",
      "3루_d3     261 non-null int64\n",
      "3루_d4     261 non-null int64\n",
      "3루_d5     261 non-null int64\n",
      "3루_d6     261 non-null int64\n",
      "3루_d7     261 non-null int64\n",
      "3루_d8     261 non-null int64\n",
      "3루_d9     261 non-null int64\n",
      "3루_d10    261 non-null int64\n",
      "3루_d11    261 non-null int64\n",
      "외야_d0     261 non-null int64\n",
      "외야_d1     261 non-null int64\n",
      "외야_d2     261 non-null int64\n",
      "외야_d3     261 non-null int64\n",
      "외야_d4     261 non-null int64\n",
      "외야_d5     261 non-null int64\n",
      "외야_d6     261 non-null int64\n",
      "외야_d7     261 non-null int64\n",
      "외야_d8     261 non-null int64\n",
      "외야_d9     261 non-null int64\n",
      "외야_d10    261 non-null int64\n",
      "외야_d11    261 non-null int64\n",
      "중앙_d0     261 non-null int64\n",
      "중앙_d1     261 non-null int64\n",
      "중앙_d2     261 non-null int64\n",
      "중앙_d3     261 non-null int64\n",
      "중앙_d4     261 non-null int64\n",
      "중앙_d5     261 non-null int64\n",
      "중앙_d6     261 non-null int64\n",
      "중앙_d7     261 non-null int64\n",
      "중앙_d8     261 non-null int64\n",
      "중앙_d9     261 non-null int64\n",
      "중앙_d10    261 non-null int64\n",
      "중앙_d11    261 non-null int64\n",
      "전체_d0     261 non-null int64\n",
      "전체_d1     261 non-null int64\n",
      "전체_d2     261 non-null int64\n",
      "전체_d3     261 non-null int64\n",
      "전체_d4     261 non-null int64\n",
      "전체_d5     261 non-null int64\n",
      "전체_d6     261 non-null int64\n",
      "전체_d7     261 non-null int64\n",
      "전체_d8     261 non-null int64\n",
      "전체_d9     261 non-null int64\n",
      "전체_d10    261 non-null int64\n",
      "전체_d11    261 non-null int64\n",
      "dtypes: datetime64[ns](1), int64(82)\n",
      "memory usage: 169.3 KB\n"
     ]
    }
   ],
   "source": [
    "# data.describe(include=\"all\")\n",
    "data.info()\n",
    "# data.경기일자.dtype   #  dtype('<M8[ns]') : datetime64[ns] 타입 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# np.mean(pd.concat( (train.총관중수, train.loc[:, '전체_d0':'전체_d11']), axis=1).values, axis=0)\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.plot(np.mean( data.loc[:, '전체_d0':'전체_d11'].values, axis=0), c='b', label='전체')\n",
    "plt.plot(np.mean( data.loc[:, '1루_d0':'1루_d11'].values, axis=0), c='r', label='1루')\n",
    "plt.plot(np.mean( data.loc[:, '3루_d0':'3루_d11'].values, axis=0), c='cyan', label='3루')\n",
    "plt.plot(np.mean( data.loc[:, '외야_d0':'외야_d11'].values, axis=0), c='g', label='외야')\n",
    "plt.plot(np.mean( data.loc[:, '중앙_d0':'중앙_d11'].values, axis=0), c='orange', label='중앙')\n",
    "plt.grid()\n",
    "plt.legend(loc=\"best\", fontsize=14)\n",
    "plt.ylabel(\"예매량\")\n",
    "plt.xlabel(\"예매일\")\n",
    "plt.title(\"평균 예매량\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 만들기 - 총관중 예측\n",
    "- Feature 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_base = data.loc[:,'KIA':'공휴일']        # 변하지 않는 X \n",
    "reserve = data.loc[:,'전체_d0':'전체_d11']    # 예매량: 입력과 target 역할 \n",
    "reserve = reserve.iloc[:,::-1]        # 예매량: why reverse the order\n",
    "\n",
    "X =  pd.concat([X_base, reserve], axis=1)   # 총관중 input features \n",
    "y_total = data['총관중수']            # 총관중 target/label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델들 만들기\n",
    "- `_d11` : 예매 첫날 (경기전 12일) 예매량\n",
    "- `_d0` : 예매 마지막날 (경기 전날) 예매량  \n",
    "    \n",
    "    \n",
    "        \n",
    "- 예매가 진행됨에 따라, 예매일 이후 날들에 대한 예매 예측 모델들을 만들어 dictionary 넣는다 \n",
    "- 0'th day : 예매 시작 전,   1'th day : 예매 하루 후, ....  11'th day : 예매 11일 끝난 후 \n",
    "- `y_model` : 총 관중 예측 모델\n",
    "- `reserve_model` : 예매량 예측 모델    \n",
    "   \n",
    "   \n",
    "- y_models : list of 12 models for y(총관중수) prediction \n",
    "  - input : X & progressive 예약 상황 \n",
    "  - dict_y_models : dictionary pointing to the `y_models`\n",
    "  - `y_model_0` : 예매 시작 전 총관중 예측 모델\n",
    "  - `y_model_5` : 예매 5일 지난 시점 총관중 예측 모델   \n",
    "  \n",
    "     \n",
    "- reserve_models  : list of models for reservation prediction for remaining days\n",
    "  - input : X & progressive 예약 상황 \n",
    "  - `dic_reserve_models` : dictionary pointing to the appropriate reserve models\n",
    "  - `res_model_0_0` : reserve_model prediction done at 0'th day, predicting first day reservation\n",
    "  - `res_model_3_7` : reserve_model prediction done at 3'th day(after 3'rd day rerservation is over), and                               predicting 8'th day reservation\n",
    "  - `res_model_11_11` : 예매 시작 11일차 실적을 갖고 마지막 12일차 예매량 예측  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['KIA', 'LG', 'NC', 'SK', '키움', '두산', '롯데', '삼성', '한화', '월', '화', '수',\n",
       "       '목', '금', '토', '일', '공휴일', '전체_d11', '전체_d10', '전체_d9', '전체_d8',\n",
       "       '전체_d7', '전체_d6', '전체_d5', '전체_d4', '전체_d3', '전체_d2', '전체_d1', '전체_d0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>경기일자</th>\n",
       "      <th>KIA</th>\n",
       "      <th>LG</th>\n",
       "      <th>NC</th>\n",
       "      <th>SK</th>\n",
       "      <th>키움</th>\n",
       "      <th>두산</th>\n",
       "      <th>롯데</th>\n",
       "      <th>삼성</th>\n",
       "      <th>한화</th>\n",
       "      <th>...</th>\n",
       "      <th>전체_d2</th>\n",
       "      <th>전체_d3</th>\n",
       "      <th>전체_d4</th>\n",
       "      <th>전체_d5</th>\n",
       "      <th>전체_d6</th>\n",
       "      <th>전체_d7</th>\n",
       "      <th>전체_d8</th>\n",
       "      <th>전체_d9</th>\n",
       "      <th>전체_d10</th>\n",
       "      <th>전체_d11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>281</td>\n",
       "      <td>321</td>\n",
       "      <td>213</td>\n",
       "      <td>256</td>\n",
       "      <td>208</td>\n",
       "      <td>231</td>\n",
       "      <td>248</td>\n",
       "      <td>440</td>\n",
       "      <td>1573</td>\n",
       "      <td>2607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>2017-10-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>378</td>\n",
       "      <td>369</td>\n",
       "      <td>253</td>\n",
       "      <td>211</td>\n",
       "      <td>229</td>\n",
       "      <td>247</td>\n",
       "      <td>259</td>\n",
       "      <td>301</td>\n",
       "      <td>1092</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>511</td>\n",
       "      <td>390</td>\n",
       "      <td>398</td>\n",
       "      <td>356</td>\n",
       "      <td>278</td>\n",
       "      <td>254</td>\n",
       "      <td>190</td>\n",
       "      <td>246</td>\n",
       "      <td>784</td>\n",
       "      <td>1775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>2018-03-30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>175</td>\n",
       "      <td>144</td>\n",
       "      <td>187</td>\n",
       "      <td>109</td>\n",
       "      <td>115</td>\n",
       "      <td>138</td>\n",
       "      <td>131</td>\n",
       "      <td>168</td>\n",
       "      <td>595</td>\n",
       "      <td>1123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>376</td>\n",
       "      <td>382</td>\n",
       "      <td>325</td>\n",
       "      <td>392</td>\n",
       "      <td>305</td>\n",
       "      <td>226</td>\n",
       "      <td>187</td>\n",
       "      <td>324</td>\n",
       "      <td>904</td>\n",
       "      <td>1404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          경기일자  KIA  LG  NC  SK  키움  두산  롯데  삼성  한화   ...    전체_d2  전체_d3  \\\n",
       "186 2017-10-01    1   0   0   0   0   0   0   0   0   ...      281    321   \n",
       "187 2017-10-02    1   0   0   0   0   0   0   0   0   ...      378    369   \n",
       "188 2017-10-03    1   0   0   0   0   0   0   0   0   ...      511    390   \n",
       "189 2018-03-30    0   0   0   0   0   1   0   0   0   ...      175    144   \n",
       "190 2018-03-31    0   0   0   0   0   1   0   0   0   ...      376    382   \n",
       "\n",
       "     전체_d4  전체_d5  전체_d6  전체_d7  전체_d8  전체_d9  전체_d10  전체_d11  \n",
       "186    213    256    208    231    248    440    1573    2607  \n",
       "187    253    211    229    247    259    301    1092    1995  \n",
       "188    398    356    278    254    190    246     784    1775  \n",
       "189    187    109    115    138    131    168     595    1123  \n",
       "190    325    392    305    226    187    324     904    1404  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[186:191]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net 총관중  모델 : 예매 시작 전 부터 예매 진행됨에 따른 ...\n",
    "- training set : 2015~2017, 3년 경기 \n",
    "- validation set :  2018 년 경기 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((189, 29), (72, 29), (189,), (72,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_2018 = 189    # 2018 start index of X \n",
    "X_train, X_test = X[:start_2018], X[start_2018:]\n",
    "y_train, y_test = y_total[:start_2018], y_total[start_2018:]   # y_total : 경기 당 총관중 \n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NeuralNetRegressor(X_train, y_train, X_test, y_test, n_epochs=10000, model_id='total') :\n",
    "    '''\n",
    "    features : numpy float ndarray.  Design matrix \n",
    "    targets : numpy float vector\n",
    "    model_id : integer or string \n",
    "    \n",
    "    구조 : Tensorflow 사용 \n",
    "    - 5개의 fully connected (dense) layer.  \n",
    "    - 2개의 drop out layer\n",
    "    - activation function : SELU\n",
    "    - Cost(Loss) : MSE\n",
    "    - Early stopping 조건 : 정해진 epoch 횟수에 Validation cost 감소가 없을 때 \n",
    "    - 학습 모델 저장 : 지정된 './models_log ' directory 에 \n",
    "    '''\n",
    "    \n",
    "    row_size, col_size = X_train.shape\n",
    "    \n",
    "    # ---------  Tensorflow Computational Graph Construction ---------\n",
    "    \n",
    "    reset_graph()\n",
    "    \n",
    "    he_init = tf.initializers.he_uniform()\n",
    "    selu_init = tf.variance_scaling_initializer(scale=1.0, mode='fan_in')\n",
    "\n",
    "    act_func = tf.nn.selu\n",
    "    ker_init = selu_init\n",
    "\n",
    "    X = tf.placeholder(tf.float32, shape=(None, col_size), name=\"X\")\n",
    "    y = tf.placeholder(tf.float32, shape=(None), name=\"y\")\n",
    "    training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "    \n",
    "    with tf.name_scope(\"hidden\"):\n",
    "        fc1 = tf.layers.dense(inputs=X, units=col_size*2, activation=act_func, \n",
    "                              kernel_initializer=ker_init, name=\"fc1\")  \n",
    "        # fc1_drop = tf.layers.dropout(fc1, 0.5, training=training)\n",
    "\n",
    "        fc2 = tf.layers.dense(fc1, col_size*2, activation=act_func, \n",
    "                              kernel_initializer=ker_init, name=\"fc2\") \n",
    "        fc2_drop = tf.layers.dropout(fc2, 0.25, training=training)\n",
    "        \n",
    "        fc3 = tf.layers.dense(fc2_drop, col_size, activation=act_func, \n",
    "                      kernel_initializer=ker_init, name=\"fc3\") \n",
    "\n",
    "        fc4 = tf.layers.dense(fc3, col_size, activation=act_func,\n",
    "                              kernel_initializer=ker_init, name=\"fc4\")\n",
    "        fc4_drop = tf.layers.dropout(fc4, 0.2, training=training)\n",
    "        \n",
    "        fc5 = tf.layers.dense(fc4_drop, int(col_size*0.5), activation=act_func,\n",
    "                              kernel_initializer=ker_init, name=\"fc5\")\n",
    "    \n",
    "    output = tf.layers.dense(fc5, 1, kernel_initializer=ker_init, name=\"output\")\n",
    "    \n",
    "    with tf.name_scope(\"train\"):\n",
    "        loss = tf.reduce_mean(tf.square(output - y), name=\"loss\")  # loss : MSE\n",
    "        optimizer = tf.train.AdamOptimizer(0.0015)\n",
    "        training_op = optimizer.minimize(loss) \n",
    "        \n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    # -----  Computational Graph 완성 ---------\n",
    "    \n",
    "    best_loss = np.infty\n",
    "    check_interval = 10\n",
    "    checks_since_last_progress = 0\n",
    "    max_checks_without_progress = 1000\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        init.run() \n",
    "        for epoch in range(n_epochs):\n",
    "            # print(\"Epoch %d\"%epoch)          \n",
    "            sess.run(training_op, feed_dict={X:X_train, y:y_train, training:True} )\n",
    "            \n",
    "            if epoch % check_interval == 0 : \n",
    "                loss_value_train = sess.run(loss, feed_dict={X:X_train, y:y_train} )\n",
    "                loss_value_validation = sess.run(loss, feed_dict={X:X_test, y:y_test} )\n",
    "                print(\"Model_{}_{} \\t loss_train = {} \\t loss_valid = {} \".format(model_id,\n",
    "                                    epoch, loss_value_train, loss_value_validation) )\n",
    "                                                \n",
    "                if loss_value_validation < best_loss : \n",
    "                    best_loss = loss_value_validation\n",
    "                    checks_since_last_progress = 0\n",
    "                    \n",
    "                    y_model_key = 'y_model_' + str(model_id)\n",
    "                    path = os.path.join('models_log', y_model_key)\n",
    "                    save_path = saver.save(sess, path) \n",
    "                else :\n",
    "                    checks_since_last_progress += 1   # increment at each check  \n",
    "            \n",
    "            if checks_since_last_progress > max_checks_without_progress: \n",
    "                print(\"Early stopping!\") \n",
    "                break \n",
    "    for op in (X, y, loss, training_op, output):\n",
    "        tf.add_to_collection(\"my_important_ops\", op)\n",
    "    \n",
    "    return save_path \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['KIA', 'LG', 'NC', 'SK', '키움', '두산', '롯데', '삼성', '한화', '월', '화', '수',\n",
       "       '목', '금', '토', '일', '공휴일', '전체_d11', '전체_d10', '전체_d9', '전체_d8',\n",
       "       '전체_d7', '전체_d6', '전체_d5', '전체_d4', '전체_d3', '전체_d2', '전체_d1', '전체_d0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예매 전 부터 시작해 예매일 마다 총관중 예측 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_0_0 \t loss_train = 119493408.0 \t loss_valid = 104556416.0 \n",
      "Model_0_10 \t loss_train = 119429848.0 \t loss_valid = 104495392.0 \n",
      "Model_0_20 \t loss_train = 119339768.0 \t loss_valid = 104410232.0 \n",
      "Model_0_30 \t loss_train = 119212832.0 \t loss_valid = 104291352.0 \n",
      "Model_0_40 \t loss_train = 119027664.0 \t loss_valid = 104117312.0 \n",
      "Model_0_50 \t loss_train = 118725408.0 \t loss_valid = 103832760.0 \n",
      "Model_0_60 \t loss_train = 118206616.0 \t loss_valid = 103343896.0 \n",
      "Model_0_70 \t loss_train = 117294912.0 \t loss_valid = 102484144.0 \n",
      "Model_0_80 \t loss_train = 115694320.0 \t loss_valid = 100974128.0 \n",
      "Model_0_90 \t loss_train = 112954688.0 \t loss_valid = 98389312.0 \n",
      "Model_0_100 \t loss_train = 108414176.0 \t loss_valid = 94111024.0 \n",
      "Model_0_110 \t loss_train = 101224544.0 \t loss_valid = 87360856.0 \n",
      "Model_0_120 \t loss_train = 90460336.0 \t loss_valid = 77324576.0 \n",
      "Model_0_130 \t loss_train = 75704744.0 \t loss_valid = 63742680.0 \n",
      "Model_0_140 \t loss_train = 57913120.0 \t loss_valid = 47781536.0 \n",
      "Model_0_150 \t loss_train = 40800076.0 \t loss_valid = 33332496.0 \n",
      "Model_0_160 \t loss_train = 30523254.0 \t loss_valid = 26288800.0 \n",
      "Model_0_170 \t loss_train = 28620604.0 \t loss_valid = 26670136.0 \n",
      "Model_0_180 \t loss_train = 28565366.0 \t loss_valid = 26734396.0 \n",
      "Model_0_190 \t loss_train = 28589798.0 \t loss_valid = 26055322.0 \n",
      "Model_0_200 \t loss_train = 28780678.0 \t loss_valid = 25794984.0 \n",
      "Model_0_210 \t loss_train = 28813164.0 \t loss_valid = 25721084.0 \n",
      "Model_0_220 \t loss_train = 28713772.0 \t loss_valid = 25695858.0 \n",
      "Model_0_230 \t loss_train = 28598190.0 \t loss_valid = 25688430.0 \n",
      "Model_0_240 \t loss_train = 28478396.0 \t loss_valid = 25709594.0 \n",
      "Model_0_250 \t loss_train = 28413604.0 \t loss_valid = 25704822.0 \n",
      "Model_0_260 \t loss_train = 28412844.0 \t loss_valid = 25650818.0 \n",
      "Model_0_270 \t loss_train = 28425880.0 \t loss_valid = 25597244.0 \n",
      "Model_0_280 \t loss_train = 28415336.0 \t loss_valid = 25567536.0 \n",
      "Model_0_290 \t loss_train = 28432566.0 \t loss_valid = 25530940.0 \n",
      "Model_0_300 \t loss_train = 28391698.0 \t loss_valid = 25529310.0 \n",
      "Model_0_310 \t loss_train = 28348492.0 \t loss_valid = 25530852.0 \n",
      "Model_0_320 \t loss_train = 28356216.0 \t loss_valid = 25505964.0 \n",
      "Model_0_330 \t loss_train = 28360102.0 \t loss_valid = 25485786.0 \n",
      "Model_0_340 \t loss_train = 28297698.0 \t loss_valid = 25508732.0 \n",
      "Model_0_350 \t loss_train = 28299150.0 \t loss_valid = 25492002.0 \n",
      "Model_0_360 \t loss_train = 28347622.0 \t loss_valid = 25447376.0 \n",
      "Model_0_370 \t loss_train = 28335740.0 \t loss_valid = 25440914.0 \n",
      "Model_0_380 \t loss_train = 28273452.0 \t loss_valid = 25470016.0 \n",
      "Model_0_390 \t loss_train = 28283588.0 \t loss_valid = 25454376.0 \n",
      "Model_0_400 \t loss_train = 28339176.0 \t loss_valid = 25415152.0 \n",
      "Model_0_410 \t loss_train = 28317534.0 \t loss_valid = 25419094.0 \n",
      "Model_0_420 \t loss_train = 28259100.0 \t loss_valid = 25447116.0 \n",
      "Model_0_430 \t loss_train = 28248756.0 \t loss_valid = 25449642.0 \n",
      "Model_0_440 \t loss_train = 28211638.0 \t loss_valid = 25473336.0 \n",
      "Model_0_450 \t loss_train = 28230424.0 \t loss_valid = 25449988.0 \n",
      "Model_0_460 \t loss_train = 28282350.0 \t loss_valid = 25409116.0 \n",
      "Model_0_470 \t loss_train = 28321838.0 \t loss_valid = 25384246.0 \n",
      "Model_0_480 \t loss_train = 28274650.0 \t loss_valid = 25401708.0 \n",
      "Model_0_490 \t loss_train = 28206900.0 \t loss_valid = 25443700.0 \n",
      "Model_0_500 \t loss_train = 28211516.0 \t loss_valid = 25437706.0 \n",
      "Model_0_510 \t loss_train = 28210474.0 \t loss_valid = 25435598.0 \n",
      "Model_0_520 \t loss_train = 28216538.0 \t loss_valid = 25424454.0 \n",
      "Model_0_530 \t loss_train = 28262326.0 \t loss_valid = 25389986.0 \n",
      "Model_0_540 \t loss_train = 28282810.0 \t loss_valid = 25376704.0 \n",
      "Model_0_550 \t loss_train = 28227918.0 \t loss_valid = 25406102.0 \n",
      "Model_0_560 \t loss_train = 28208502.0 \t loss_valid = 25417122.0 \n",
      "Model_0_570 \t loss_train = 28255540.0 \t loss_valid = 25382032.0 \n",
      "Model_0_580 \t loss_train = 28249566.0 \t loss_valid = 25381162.0 \n",
      "Model_0_590 \t loss_train = 28263264.0 \t loss_valid = 25372716.0 \n",
      "Model_0_600 \t loss_train = 28230648.0 \t loss_valid = 25388856.0 \n",
      "Model_0_610 \t loss_train = 28262686.0 \t loss_valid = 25367906.0 \n",
      "Model_0_620 \t loss_train = 28258156.0 \t loss_valid = 25367048.0 \n",
      "Model_0_630 \t loss_train = 28183620.0 \t loss_valid = 25412048.0 \n",
      "Model_0_640 \t loss_train = 28194688.0 \t loss_valid = 25401866.0 \n",
      "Model_0_650 \t loss_train = 28235670.0 \t loss_valid = 25372374.0 \n",
      "Model_0_660 \t loss_train = 28218988.0 \t loss_valid = 25378544.0 \n",
      "Model_0_670 \t loss_train = 28236860.0 \t loss_valid = 25364906.0 \n",
      "Model_0_680 \t loss_train = 28162658.0 \t loss_valid = 25413424.0 \n",
      "Model_0_690 \t loss_train = 28152574.0 \t loss_valid = 25419282.0 \n",
      "Model_0_700 \t loss_train = 28263932.0 \t loss_valid = 25345180.0 \n",
      "Model_0_710 \t loss_train = 28242712.0 \t loss_valid = 25354072.0 \n",
      "Model_0_720 \t loss_train = 28185496.0 \t loss_valid = 25387676.0 \n",
      "Model_0_730 \t loss_train = 28165270.0 \t loss_valid = 25402134.0 \n",
      "Model_0_740 \t loss_train = 28195522.0 \t loss_valid = 25378284.0 \n",
      "Model_0_750 \t loss_train = 28212444.0 \t loss_valid = 25367278.0 \n",
      "Model_0_760 \t loss_train = 28192914.0 \t loss_valid = 25377814.0 \n",
      "Model_0_770 \t loss_train = 28221230.0 \t loss_valid = 25359432.0 \n",
      "Model_0_780 \t loss_train = 28260854.0 \t loss_valid = 25339070.0 \n",
      "Model_0_790 \t loss_train = 28205174.0 \t loss_valid = 25364668.0 \n",
      "Model_0_800 \t loss_train = 28174928.0 \t loss_valid = 25383256.0 \n",
      "Model_0_810 \t loss_train = 28270140.0 \t loss_valid = 25332936.0 \n",
      "Model_0_820 \t loss_train = 28189976.0 \t loss_valid = 25370296.0 \n",
      "Model_0_830 \t loss_train = 28178204.0 \t loss_valid = 25377568.0 \n",
      "Model_0_840 \t loss_train = 28211046.0 \t loss_valid = 25356194.0 \n",
      "Model_0_850 \t loss_train = 28200038.0 \t loss_valid = 25360396.0 \n",
      "Model_0_860 \t loss_train = 28177260.0 \t loss_valid = 25372426.0 \n",
      "Model_0_870 \t loss_train = 28210378.0 \t loss_valid = 25350340.0 \n",
      "Model_0_880 \t loss_train = 28209614.0 \t loss_valid = 25349410.0 \n",
      "Model_0_890 \t loss_train = 28160380.0 \t loss_valid = 25378664.0 \n",
      "Model_0_900 \t loss_train = 28164156.0 \t loss_valid = 25374240.0 \n",
      "Model_0_910 \t loss_train = 28210252.0 \t loss_valid = 25344294.0 \n",
      "Model_0_920 \t loss_train = 28220450.0 \t loss_valid = 25338116.0 \n",
      "Model_0_930 \t loss_train = 28130310.0 \t loss_valid = 25397056.0 \n",
      "Model_0_940 \t loss_train = 28145878.0 \t loss_valid = 25382410.0 \n",
      "Model_0_950 \t loss_train = 28311812.0 \t loss_valid = 25305484.0 \n",
      "Model_0_960 \t loss_train = 28162266.0 \t loss_valid = 25367034.0 \n",
      "Model_0_970 \t loss_train = 28106338.0 \t loss_valid = 25415142.0 \n",
      "Model_0_980 \t loss_train = 28225132.0 \t loss_valid = 25330548.0 \n",
      "Model_0_990 \t loss_train = 28300536.0 \t loss_valid = 25305098.0 \n",
      "Model_0_1000 \t loss_train = 28145540.0 \t loss_valid = 25375340.0 \n",
      "Model_0_1010 \t loss_train = 28232188.0 \t loss_valid = 25324736.0 \n",
      "Model_0_1020 \t loss_train = 28191704.0 \t loss_valid = 25343562.0 \n",
      "Model_0_1030 \t loss_train = 28113098.0 \t loss_valid = 25402314.0 \n",
      "Model_0_1040 \t loss_train = 28146984.0 \t loss_valid = 25372090.0 \n",
      "Model_0_1050 \t loss_train = 28152402.0 \t loss_valid = 25365910.0 \n",
      "Model_0_1060 \t loss_train = 28171318.0 \t loss_valid = 25351716.0 \n",
      "Model_0_1070 \t loss_train = 28148626.0 \t loss_valid = 25364932.0 \n",
      "Model_0_1080 \t loss_train = 28134860.0 \t loss_valid = 25374686.0 \n",
      "Model_0_1090 \t loss_train = 28224688.0 \t loss_valid = 25322342.0 \n",
      "Model_0_1100 \t loss_train = 28202364.0 \t loss_valid = 25332076.0 \n",
      "Model_0_1110 \t loss_train = 28169088.0 \t loss_valid = 25348670.0 \n",
      "Model_0_1120 \t loss_train = 28133398.0 \t loss_valid = 25371780.0 \n",
      "Model_0_1130 \t loss_train = 28155074.0 \t loss_valid = 25353976.0 \n",
      "Model_0_1140 \t loss_train = 28164002.0 \t loss_valid = 25347802.0 \n",
      "Model_0_1150 \t loss_train = 28156834.0 \t loss_valid = 25352474.0 \n",
      "Model_0_1160 \t loss_train = 28120816.0 \t loss_valid = 25378194.0 \n",
      "Model_0_1170 \t loss_train = 28119716.0 \t loss_valid = 25377226.0 \n",
      "Model_0_1180 \t loss_train = 28188386.0 \t loss_valid = 25329562.0 \n",
      "Model_0_1190 \t loss_train = 28251174.0 \t loss_valid = 25303434.0 \n",
      "Model_0_1200 \t loss_train = 28147742.0 \t loss_valid = 25352336.0 \n",
      "Model_0_1210 \t loss_train = 28144298.0 \t loss_valid = 25354090.0 \n",
      "Model_0_1220 \t loss_train = 28151644.0 \t loss_valid = 25347934.0 \n",
      "Model_0_1230 \t loss_train = 28190610.0 \t loss_valid = 25325008.0 \n",
      "Model_0_1240 \t loss_train = 28103146.0 \t loss_valid = 25385882.0 \n",
      "Model_0_1250 \t loss_train = 28148664.0 \t loss_valid = 25347402.0 \n",
      "Model_0_1260 \t loss_train = 28083664.0 \t loss_valid = 25404820.0 \n",
      "Model_0_1270 \t loss_train = 28152534.0 \t loss_valid = 25343340.0 \n",
      "Model_0_1280 \t loss_train = 28275544.0 \t loss_valid = 25291454.0 \n",
      "Model_0_1290 \t loss_train = 28109622.0 \t loss_valid = 25375752.0 \n",
      "Model_0_1300 \t loss_train = 28112806.0 \t loss_valid = 25372702.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_0_1310 \t loss_train = 28231138.0 \t loss_valid = 25303744.0 \n",
      "Model_0_1320 \t loss_train = 28116850.0 \t loss_valid = 25367646.0 \n",
      "Model_0_1330 \t loss_train = 28130554.0 \t loss_valid = 25355682.0 \n",
      "Model_0_1340 \t loss_train = 28187086.0 \t loss_valid = 25319902.0 \n",
      "Model_0_1350 \t loss_train = 28162398.0 \t loss_valid = 25332678.0 \n",
      "Model_0_1360 \t loss_train = 28113386.0 \t loss_valid = 25367356.0 \n",
      "Model_0_1370 \t loss_train = 28163414.0 \t loss_valid = 25331320.0 \n",
      "Model_0_1380 \t loss_train = 28159940.0 \t loss_valid = 25332728.0 \n",
      "Model_0_1390 \t loss_train = 28203946.0 \t loss_valid = 25309216.0 \n",
      "Model_0_1400 \t loss_train = 28248984.0 \t loss_valid = 25292480.0 \n",
      "Model_0_1410 \t loss_train = 28103902.0 \t loss_valid = 25370296.0 \n",
      "Model_0_1420 \t loss_train = 28129440.0 \t loss_valid = 25348438.0 \n",
      "Model_0_1430 \t loss_train = 28135062.0 \t loss_valid = 25343756.0 \n",
      "Model_0_1440 \t loss_train = 28166166.0 \t loss_valid = 25323792.0 \n",
      "Model_0_1450 \t loss_train = 28122360.0 \t loss_valid = 25353130.0 \n",
      "Model_0_1460 \t loss_train = 28111060.0 \t loss_valid = 25362564.0 \n",
      "Model_0_1470 \t loss_train = 28143240.0 \t loss_valid = 25336986.0 \n",
      "Model_0_1480 \t loss_train = 28145614.0 \t loss_valid = 25335760.0 \n",
      "Model_0_1490 \t loss_train = 28199374.0 \t loss_valid = 25307708.0 \n",
      "Model_0_1500 \t loss_train = 28085628.0 \t loss_valid = 25388112.0 \n",
      "Model_0_1510 \t loss_train = 28079778.0 \t loss_valid = 25395124.0 \n",
      "Model_0_1520 \t loss_train = 28196176.0 \t loss_valid = 25309040.0 \n",
      "Model_0_1530 \t loss_train = 28150454.0 \t loss_valid = 25333018.0 \n",
      "Model_0_1540 \t loss_train = 28123666.0 \t loss_valid = 25351668.0 \n",
      "Model_0_1550 \t loss_train = 28100346.0 \t loss_valid = 25371764.0 \n",
      "Model_0_1560 \t loss_train = 28075516.0 \t loss_valid = 25397710.0 \n",
      "Model_0_1570 \t loss_train = 28142206.0 \t loss_valid = 25335668.0 \n",
      "Model_0_1580 \t loss_train = 28154674.0 \t loss_valid = 25326958.0 \n",
      "Model_0_1590 \t loss_train = 28192236.0 \t loss_valid = 25307238.0 \n",
      "Model_0_1600 \t loss_train = 28067714.0 \t loss_valid = 25405158.0 \n",
      "Model_0_1610 \t loss_train = 28196932.0 \t loss_valid = 25305614.0 \n",
      "Model_0_1620 \t loss_train = 28276854.0 \t loss_valid = 25280708.0 \n",
      "Model_0_1630 \t loss_train = 28111180.0 \t loss_valid = 25358320.0 \n",
      "Model_0_1640 \t loss_train = 28184322.0 \t loss_valid = 25309682.0 \n",
      "Model_0_1650 \t loss_train = 28213442.0 \t loss_valid = 25296554.0 \n",
      "Model_0_1660 \t loss_train = 28135332.0 \t loss_valid = 25336198.0 \n",
      "Model_0_1670 \t loss_train = 28075226.0 \t loss_valid = 25390874.0 \n",
      "Model_0_1680 \t loss_train = 28084750.0 \t loss_valid = 25379334.0 \n",
      "Model_0_1690 \t loss_train = 28137258.0 \t loss_valid = 25333192.0 \n",
      "Model_0_1700 \t loss_train = 28106864.0 \t loss_valid = 25356630.0 \n",
      "Model_0_1710 \t loss_train = 28131116.0 \t loss_valid = 25336574.0 \n",
      "Model_0_1720 \t loss_train = 28053988.0 \t loss_valid = 25417220.0 \n",
      "Model_0_1730 \t loss_train = 28178560.0 \t loss_valid = 25308156.0 \n",
      "Model_0_1740 \t loss_train = 28194240.0 \t loss_valid = 25300822.0 \n",
      "Model_0_1750 \t loss_train = 28128130.0 \t loss_valid = 25337620.0 \n",
      "Model_0_1760 \t loss_train = 28115418.0 \t loss_valid = 25347498.0 \n",
      "Model_0_1770 \t loss_train = 28123130.0 \t loss_valid = 25341082.0 \n",
      "Model_0_1780 \t loss_train = 28121348.0 \t loss_valid = 25341926.0 \n",
      "Model_0_1790 \t loss_train = 28056662.0 \t loss_valid = 25410842.0 \n",
      "Model_0_1800 \t loss_train = 28123148.0 \t loss_valid = 25340272.0 \n",
      "Model_0_1810 \t loss_train = 28089734.0 \t loss_valid = 25370534.0 \n",
      "Model_0_1820 \t loss_train = 28122960.0 \t loss_valid = 25340852.0 \n",
      "Model_0_1830 \t loss_train = 28206536.0 \t loss_valid = 25294684.0 \n",
      "Model_0_1840 \t loss_train = 28159778.0 \t loss_valid = 25316116.0 \n",
      "Model_0_1850 \t loss_train = 28063762.0 \t loss_valid = 25400790.0 \n",
      "Model_0_1860 \t loss_train = 28066198.0 \t loss_valid = 25398064.0 \n",
      "Model_0_1870 \t loss_train = 28188150.0 \t loss_valid = 25302572.0 \n",
      "Model_0_1880 \t loss_train = 28118884.0 \t loss_valid = 25343980.0 \n",
      "Model_0_1890 \t loss_train = 28063328.0 \t loss_valid = 25401718.0 \n",
      "Model_0_1900 \t loss_train = 28136254.0 \t loss_valid = 25330890.0 \n",
      "Model_0_1910 \t loss_train = 28208266.0 \t loss_valid = 25293732.0 \n",
      "Model_0_1920 \t loss_train = 28067030.0 \t loss_valid = 25396754.0 \n",
      "Model_0_1930 \t loss_train = 28065916.0 \t loss_valid = 25398284.0 \n",
      "Model_0_1940 \t loss_train = 28095914.0 \t loss_valid = 25363266.0 \n",
      "Model_0_1950 \t loss_train = 28054200.0 \t loss_valid = 25414004.0 \n",
      "Model_0_1960 \t loss_train = 28138510.0 \t loss_valid = 25328666.0 \n",
      "Model_0_1970 \t loss_train = 28085906.0 \t loss_valid = 25373686.0 \n",
      "Model_0_1980 \t loss_train = 28106264.0 \t loss_valid = 25353304.0 \n",
      "Model_0_1990 \t loss_train = 28144194.0 \t loss_valid = 25324156.0 \n",
      "Model_0_2000 \t loss_train = 28083264.0 \t loss_valid = 25374896.0 \n",
      "Model_0_2010 \t loss_train = 28123498.0 \t loss_valid = 25337628.0 \n",
      "Model_0_2020 \t loss_train = 28077586.0 \t loss_valid = 25380766.0 \n",
      "Model_0_2030 \t loss_train = 28132034.0 \t loss_valid = 25330866.0 \n",
      "Model_0_2040 \t loss_train = 28120960.0 \t loss_valid = 25338844.0 \n",
      "Model_0_2050 \t loss_train = 28130562.0 \t loss_valid = 25331504.0 \n",
      "Model_0_2060 \t loss_train = 28056692.0 \t loss_valid = 25407356.0 \n",
      "Model_0_2070 \t loss_train = 28117488.0 \t loss_valid = 25341392.0 \n",
      "Model_0_2080 \t loss_train = 28118798.0 \t loss_valid = 25340198.0 \n",
      "Model_0_2090 \t loss_train = 28094604.0 \t loss_valid = 25361586.0 \n",
      "Model_0_2100 \t loss_train = 28072886.0 \t loss_valid = 25385752.0 \n",
      "Model_0_2110 \t loss_train = 28098680.0 \t loss_valid = 25358566.0 \n",
      "Model_0_2120 \t loss_train = 28123870.0 \t loss_valid = 25337896.0 \n",
      "Model_0_2130 \t loss_train = 28038284.0 \t loss_valid = 25440996.0 \n",
      "Model_0_2140 \t loss_train = 28103798.0 \t loss_valid = 25354252.0 \n",
      "Model_0_2150 \t loss_train = 28094874.0 \t loss_valid = 25362572.0 \n",
      "Model_0_2160 \t loss_train = 28066108.0 \t loss_valid = 25395926.0 \n",
      "Model_0_2170 \t loss_train = 28072406.0 \t loss_valid = 25388812.0 \n",
      "Model_0_2180 \t loss_train = 28133080.0 \t loss_valid = 25331910.0 \n",
      "Model_0_2190 \t loss_train = 28177116.0 \t loss_valid = 25305746.0 \n",
      "Model_0_2200 \t loss_train = 28074050.0 \t loss_valid = 25387320.0 \n",
      "Model_0_2210 \t loss_train = 28118828.0 \t loss_valid = 25342276.0 \n",
      "Model_0_2220 \t loss_train = 28086898.0 \t loss_valid = 25371666.0 \n",
      "Model_0_2230 \t loss_train = 28129986.0 \t loss_valid = 25332852.0 \n",
      "Model_0_2240 \t loss_train = 28057030.0 \t loss_valid = 25408996.0 \n",
      "Model_0_2250 \t loss_train = 28112286.0 \t loss_valid = 25346828.0 \n",
      "Model_0_2260 \t loss_train = 28087254.0 \t loss_valid = 25370914.0 \n",
      "Model_0_2270 \t loss_train = 28110308.0 \t loss_valid = 25348670.0 \n",
      "Model_0_2280 \t loss_train = 28092534.0 \t loss_valid = 25365564.0 \n",
      "Model_0_2290 \t loss_train = 28099136.0 \t loss_valid = 25358950.0 \n",
      "Model_0_2300 \t loss_train = 28139346.0 \t loss_valid = 25326566.0 \n",
      "Model_0_2310 \t loss_train = 28100220.0 \t loss_valid = 25358258.0 \n",
      "Model_0_2320 \t loss_train = 28079584.0 \t loss_valid = 25380008.0 \n",
      "Model_0_2330 \t loss_train = 28149306.0 \t loss_valid = 25319950.0 \n",
      "Model_0_2340 \t loss_train = 28098360.0 \t loss_valid = 25359368.0 \n",
      "Model_0_2350 \t loss_train = 28092530.0 \t loss_valid = 25365140.0 \n",
      "Model_0_2360 \t loss_train = 28119890.0 \t loss_valid = 25340496.0 \n",
      "Model_0_2370 \t loss_train = 28107200.0 \t loss_valid = 25351174.0 \n",
      "Model_0_2380 \t loss_train = 28089420.0 \t loss_valid = 25368390.0 \n",
      "Model_0_2390 \t loss_train = 28034060.0 \t loss_valid = 25450206.0 \n",
      "Model_0_2400 \t loss_train = 28103188.0 \t loss_valid = 25354992.0 \n",
      "Model_0_2410 \t loss_train = 28101856.0 \t loss_valid = 25356424.0 \n",
      "Model_0_2420 \t loss_train = 28073098.0 \t loss_valid = 25386642.0 \n",
      "Model_0_2430 \t loss_train = 28105158.0 \t loss_valid = 25352008.0 \n",
      "Model_0_2440 \t loss_train = 28112890.0 \t loss_valid = 25345188.0 \n",
      "Model_0_2450 \t loss_train = 28059356.0 \t loss_valid = 25403794.0 \n",
      "Model_0_2460 \t loss_train = 28127018.0 \t loss_valid = 25333110.0 \n",
      "Model_0_2470 \t loss_train = 28097014.0 \t loss_valid = 25358504.0 \n",
      "Model_0_2480 \t loss_train = 28058324.0 \t loss_valid = 25404346.0 \n",
      "Model_0_2490 \t loss_train = 28119636.0 \t loss_valid = 25338378.0 \n",
      "Model_0_2500 \t loss_train = 28097556.0 \t loss_valid = 25357662.0 \n",
      "Model_0_2510 \t loss_train = 28111192.0 \t loss_valid = 25345382.0 \n",
      "Model_0_2520 \t loss_train = 28088442.0 \t loss_valid = 25367254.0 \n",
      "Model_0_2530 \t loss_train = 28073498.0 \t loss_valid = 25384780.0 \n",
      "Model_0_2540 \t loss_train = 28105850.0 \t loss_valid = 25350440.0 \n",
      "Model_0_2550 \t loss_train = 28100598.0 \t loss_valid = 25355138.0 \n",
      "Model_0_2560 \t loss_train = 28077828.0 \t loss_valid = 25378938.0 \n",
      "Model_0_2570 \t loss_train = 28090428.0 \t loss_valid = 25365056.0 \n",
      "Model_0_2580 \t loss_train = 28085786.0 \t loss_valid = 25370182.0 \n",
      "Model_0_2590 \t loss_train = 28077996.0 \t loss_valid = 25378968.0 \n",
      "Model_0_2600 \t loss_train = 28077430.0 \t loss_valid = 25379340.0 \n",
      "Model_0_2610 \t loss_train = 28162232.0 \t loss_valid = 25309964.0 \n",
      "Model_0_2620 \t loss_train = 28165702.0 \t loss_valid = 25307908.0 \n",
      "Model_0_2630 \t loss_train = 28068528.0 \t loss_valid = 25390212.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_0_2640 \t loss_train = 28083922.0 \t loss_valid = 25371706.0 \n",
      "Model_0_2650 \t loss_train = 28157966.0 \t loss_valid = 25312304.0 \n",
      "Model_0_2660 \t loss_train = 28068728.0 \t loss_valid = 25390084.0 \n",
      "Model_0_2670 \t loss_train = 28051248.0 \t loss_valid = 25415030.0 \n",
      "Model_0_2680 \t loss_train = 28267796.0 \t loss_valid = 25270166.0 \n",
      "Model_0_2690 \t loss_train = 28089634.0 \t loss_valid = 25365304.0 \n",
      "Model_0_2700 \t loss_train = 28035178.0 \t loss_valid = 25444326.0 \n",
      "Model_0_2710 \t loss_train = 28136720.0 \t loss_valid = 25325534.0 \n",
      "Model_0_2720 \t loss_train = 28078396.0 \t loss_valid = 25378084.0 \n",
      "Model_0_2730 \t loss_train = 28119406.0 \t loss_valid = 25338286.0 \n",
      "Model_0_2740 \t loss_train = 28109682.0 \t loss_valid = 25346542.0 \n",
      "Model_0_2750 \t loss_train = 28073266.0 \t loss_valid = 25384720.0 \n",
      "Model_0_2760 \t loss_train = 28079166.0 \t loss_valid = 25377264.0 \n",
      "Model_0_2770 \t loss_train = 28076656.0 \t loss_valid = 25380384.0 \n",
      "Model_0_2780 \t loss_train = 28066390.0 \t loss_valid = 25393876.0 \n",
      "Model_0_2790 \t loss_train = 28105512.0 \t loss_valid = 25351512.0 \n",
      "Model_0_2800 \t loss_train = 28059920.0 \t loss_valid = 25403834.0 \n",
      "Model_0_2810 \t loss_train = 28090178.0 \t loss_valid = 25366676.0 \n",
      "Model_0_2820 \t loss_train = 28069304.0 \t loss_valid = 25391034.0 \n",
      "Model_0_2830 \t loss_train = 28100364.0 \t loss_valid = 25356346.0 \n",
      "Model_0_2840 \t loss_train = 28144470.0 \t loss_valid = 25321596.0 \n",
      "Model_0_2850 \t loss_train = 28073954.0 \t loss_valid = 25385120.0 \n",
      "Model_0_2860 \t loss_train = 28065472.0 \t loss_valid = 25396370.0 \n",
      "Model_0_2870 \t loss_train = 28112960.0 \t loss_valid = 25345522.0 \n",
      "Model_0_2880 \t loss_train = 28119062.0 \t loss_valid = 25340852.0 \n",
      "Model_0_2890 \t loss_train = 28080946.0 \t loss_valid = 25377864.0 \n",
      "Model_0_2900 \t loss_train = 28208938.0 \t loss_valid = 25289228.0 \n",
      "Model_0_2910 \t loss_train = 28042734.0 \t loss_valid = 25434674.0 \n",
      "Model_0_2920 \t loss_train = 28101842.0 \t loss_valid = 25357080.0 \n",
      "Model_0_2930 \t loss_train = 28123808.0 \t loss_valid = 25337944.0 \n",
      "Model_0_2940 \t loss_train = 28132760.0 \t loss_valid = 25330780.0 \n",
      "Model_0_2950 \t loss_train = 28025686.0 \t loss_valid = 25470166.0 \n",
      "Model_0_2960 \t loss_train = 28202220.0 \t loss_valid = 25291978.0 \n",
      "Model_0_2970 \t loss_train = 28078366.0 \t loss_valid = 25381474.0 \n",
      "Model_0_2980 \t loss_train = 28112420.0 \t loss_valid = 25346494.0 \n",
      "Model_0_2990 \t loss_train = 28093050.0 \t loss_valid = 25363986.0 \n",
      "Model_0_3000 \t loss_train = 28044678.0 \t loss_valid = 25428346.0 \n",
      "Model_0_3010 \t loss_train = 28159808.0 \t loss_valid = 25311546.0 \n",
      "Model_0_3020 \t loss_train = 28159096.0 \t loss_valid = 25311872.0 \n",
      "Model_0_3030 \t loss_train = 28071774.0 \t loss_valid = 25387366.0 \n",
      "Model_0_3040 \t loss_train = 28091044.0 \t loss_valid = 25365144.0 \n",
      "Model_0_3050 \t loss_train = 28072568.0 \t loss_valid = 25386788.0 \n",
      "Model_0_3060 \t loss_train = 28025426.0 \t loss_valid = 25469272.0 \n",
      "Model_0_3070 \t loss_train = 28134906.0 \t loss_valid = 25328492.0 \n",
      "Model_0_3080 \t loss_train = 28117954.0 \t loss_valid = 25341308.0 \n",
      "Model_0_3090 \t loss_train = 28051648.0 \t loss_valid = 25416986.0 \n",
      "Model_0_3100 \t loss_train = 28130240.0 \t loss_valid = 25331084.0 \n",
      "Model_0_3110 \t loss_train = 28111478.0 \t loss_valid = 25346036.0 \n",
      "Model_0_3120 \t loss_train = 28044802.0 \t loss_valid = 25428996.0 \n",
      "Model_0_3130 \t loss_train = 28270764.0 \t loss_valid = 25269590.0 \n",
      "Model_0_3140 \t loss_train = 28080400.0 \t loss_valid = 25377328.0 \n",
      "Model_0_3150 \t loss_train = 28086176.0 \t loss_valid = 25371016.0 \n",
      "Model_0_3160 \t loss_train = 28159078.0 \t loss_valid = 25312614.0 \n",
      "Model_0_3170 \t loss_train = 28097044.0 \t loss_valid = 25360154.0 \n",
      "Model_0_3180 \t loss_train = 28045754.0 \t loss_valid = 25427058.0 \n",
      "Model_0_3190 \t loss_train = 28091120.0 \t loss_valid = 25365422.0 \n",
      "Model_0_3200 \t loss_train = 28040786.0 \t loss_valid = 25435502.0 \n",
      "Model_0_3210 \t loss_train = 28064768.0 \t loss_valid = 25397512.0 \n",
      "Model_0_3220 \t loss_train = 28099916.0 \t loss_valid = 25356942.0 \n",
      "Model_0_3230 \t loss_train = 28107752.0 \t loss_valid = 25349146.0 \n",
      "Model_0_3240 \t loss_train = 28120094.0 \t loss_valid = 25338522.0 \n",
      "Model_0_3250 \t loss_train = 28105798.0 \t loss_valid = 25350238.0 \n",
      "Model_0_3260 \t loss_train = 28060800.0 \t loss_valid = 25401464.0 \n",
      "Model_0_3270 \t loss_train = 28130944.0 \t loss_valid = 25329668.0 \n",
      "Model_0_3280 \t loss_train = 28067124.0 \t loss_valid = 25392258.0 \n",
      "Model_0_3290 \t loss_train = 28103306.0 \t loss_valid = 25352078.0 \n",
      "Model_0_3300 \t loss_train = 28087058.0 \t loss_valid = 25368340.0 \n",
      "Model_0_3310 \t loss_train = 28135600.0 \t loss_valid = 25326288.0 \n",
      "Model_0_3320 \t loss_train = 28093412.0 \t loss_valid = 25362218.0 \n",
      "Model_0_3330 \t loss_train = 28058872.0 \t loss_valid = 25404676.0 \n",
      "Model_0_3340 \t loss_train = 28149134.0 \t loss_valid = 25317598.0 \n",
      "Model_0_3350 \t loss_train = 28060174.0 \t loss_valid = 25402776.0 \n",
      "Model_0_3360 \t loss_train = 28119790.0 \t loss_valid = 25338264.0 \n",
      "Model_0_3370 \t loss_train = 28113934.0 \t loss_valid = 25342992.0 \n",
      "Model_0_3380 \t loss_train = 28057224.0 \t loss_valid = 25406562.0 \n",
      "Model_0_3390 \t loss_train = 28142914.0 \t loss_valid = 25321260.0 \n",
      "Model_0_3400 \t loss_train = 28092914.0 \t loss_valid = 25362056.0 \n",
      "Model_0_3410 \t loss_train = 28130984.0 \t loss_valid = 25328884.0 \n",
      "Model_0_3420 \t loss_train = 28071628.0 \t loss_valid = 25385300.0 \n",
      "Model_0_3430 \t loss_train = 28046796.0 \t loss_valid = 25421556.0 \n",
      "Model_0_3440 \t loss_train = 28143294.0 \t loss_valid = 25320056.0 \n",
      "Model_0_3450 \t loss_train = 28074642.0 \t loss_valid = 25382102.0 \n",
      "Model_0_3460 \t loss_train = 28140544.0 \t loss_valid = 25322202.0 \n",
      "Model_0_3470 \t loss_train = 28039386.0 \t loss_valid = 25436058.0 \n",
      "Model_0_3480 \t loss_train = 28177794.0 \t loss_valid = 25300736.0 \n",
      "Model_0_3490 \t loss_train = 28101366.0 \t loss_valid = 25353510.0 \n",
      "Model_0_3500 \t loss_train = 28041056.0 \t loss_valid = 25432836.0 \n",
      "Model_0_3510 \t loss_train = 28145230.0 \t loss_valid = 25319248.0 \n",
      "Model_0_3520 \t loss_train = 28115680.0 \t loss_valid = 25340630.0 \n",
      "Model_0_3530 \t loss_train = 28065548.0 \t loss_valid = 25393718.0 \n",
      "Model_0_3540 \t loss_train = 28058544.0 \t loss_valid = 25404250.0 \n",
      "Model_0_3550 \t loss_train = 28043526.0 \t loss_valid = 25429192.0 \n",
      "Model_0_3560 \t loss_train = 28103576.0 \t loss_valid = 25352380.0 \n",
      "Model_0_3570 \t loss_train = 28065076.0 \t loss_valid = 25396086.0 \n",
      "Model_0_3580 \t loss_train = 28091130.0 \t loss_valid = 25364850.0 \n",
      "Model_0_3590 \t loss_train = 28072524.0 \t loss_valid = 25385800.0 \n",
      "Model_0_3600 \t loss_train = 28037596.0 \t loss_valid = 25440188.0 \n",
      "Model_0_3610 \t loss_train = 28256626.0 \t loss_valid = 25272418.0 \n",
      "Model_0_3620 \t loss_train = 28108298.0 \t loss_valid = 25347904.0 \n",
      "Model_0_3630 \t loss_train = 28051000.0 \t loss_valid = 25416734.0 \n",
      "Model_0_3640 \t loss_train = 28088034.0 \t loss_valid = 25368228.0 \n",
      "Model_0_3650 \t loss_train = 28072352.0 \t loss_valid = 25386266.0 \n",
      "Model_0_3660 \t loss_train = 28053338.0 \t loss_valid = 25412526.0 \n",
      "Model_0_3670 \t loss_train = 28110312.0 \t loss_valid = 25345968.0 \n",
      "Model_0_3680 \t loss_train = 28095476.0 \t loss_valid = 25359392.0 \n",
      "Model_0_3690 \t loss_train = 28058126.0 \t loss_valid = 25404324.0 \n",
      "Model_0_3700 \t loss_train = 28078578.0 \t loss_valid = 25377298.0 \n",
      "Model_0_3710 \t loss_train = 28104524.0 \t loss_valid = 25350418.0 \n",
      "Model_0_3720 \t loss_train = 28050696.0 \t loss_valid = 25416096.0 \n",
      "Model_0_3730 \t loss_train = 28160138.0 \t loss_valid = 25310518.0 \n",
      "Model_0_3740 \t loss_train = 28016174.0 \t loss_valid = 25491444.0 \n",
      "Model_0_3750 \t loss_train = 28079174.0 \t loss_valid = 25377122.0 \n",
      "Model_0_3760 \t loss_train = 28141746.0 \t loss_valid = 25321440.0 \n",
      "Model_0_3770 \t loss_train = 28091290.0 \t loss_valid = 25363276.0 \n",
      "Model_0_3780 \t loss_train = 28136176.0 \t loss_valid = 25324638.0 \n",
      "Model_0_3790 \t loss_train = 28035712.0 \t loss_valid = 25441972.0 \n",
      "Model_0_3800 \t loss_train = 28116344.0 \t loss_valid = 25339228.0 \n",
      "Model_0_3810 \t loss_train = 28068238.0 \t loss_valid = 25389146.0 \n",
      "Model_0_3820 \t loss_train = 28087442.0 \t loss_valid = 25366208.0 \n",
      "Model_0_3830 \t loss_train = 28080344.0 \t loss_valid = 25374348.0 \n",
      "Model_0_3840 \t loss_train = 28054968.0 \t loss_valid = 25408136.0 \n",
      "Model_0_3850 \t loss_train = 28145020.0 \t loss_valid = 25318490.0 \n",
      "Model_0_3860 \t loss_train = 28063198.0 \t loss_valid = 25396356.0 \n",
      "Model_0_3870 \t loss_train = 28079854.0 \t loss_valid = 25375672.0 \n",
      "Model_0_3880 \t loss_train = 28078022.0 \t loss_valid = 25377568.0 \n",
      "Model_0_3890 \t loss_train = 28047136.0 \t loss_valid = 25421048.0 \n",
      "Model_0_3900 \t loss_train = 28061350.0 \t loss_valid = 25398878.0 \n",
      "Model_0_3910 \t loss_train = 28066668.0 \t loss_valid = 25391718.0 \n",
      "Model_0_3920 \t loss_train = 28061860.0 \t loss_valid = 25398168.0 \n",
      "Model_0_3930 \t loss_train = 28041806.0 \t loss_valid = 25430318.0 \n",
      "Model_0_3940 \t loss_train = 28073104.0 \t loss_valid = 25383330.0 \n",
      "Model_0_3950 \t loss_train = 28100856.0 \t loss_valid = 25353400.0 \n",
      "Model_0_3960 \t loss_train = 28036918.0 \t loss_valid = 25439748.0 \n",
      "Model_0_3970 \t loss_train = 28124372.0 \t loss_valid = 25333052.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_0_3980 \t loss_train = 28064272.0 \t loss_valid = 25394388.0 \n",
      "Model_0_3990 \t loss_train = 28081390.0 \t loss_valid = 25373008.0 \n",
      "Model_0_4000 \t loss_train = 28165238.0 \t loss_valid = 25306244.0 \n",
      "Model_0_4010 \t loss_train = 28108028.0 \t loss_valid = 25346188.0 \n",
      "Model_0_4020 \t loss_train = 28037930.0 \t loss_valid = 25437240.0 \n",
      "Model_0_4030 \t loss_train = 28083386.0 \t loss_valid = 25370980.0 \n",
      "Model_0_4040 \t loss_train = 28051638.0 \t loss_valid = 25413246.0 \n",
      "Model_0_4050 \t loss_train = 28083712.0 \t loss_valid = 25370826.0 \n",
      "Model_0_4060 \t loss_train = 28067824.0 \t loss_valid = 25390770.0 \n",
      "Model_0_4070 \t loss_train = 28067036.0 \t loss_valid = 25392048.0 \n",
      "Model_0_4080 \t loss_train = 28123514.0 \t loss_valid = 25334382.0 \n",
      "Model_0_4090 \t loss_train = 28058896.0 \t loss_valid = 25403050.0 \n",
      "Model_0_4100 \t loss_train = 28099376.0 \t loss_valid = 25354914.0 \n",
      "Model_0_4110 \t loss_train = 28141578.0 \t loss_valid = 25321024.0 \n",
      "Model_0_4120 \t loss_train = 28025636.0 \t loss_valid = 25464362.0 \n",
      "Model_0_4130 \t loss_train = 28145052.0 \t loss_valid = 25318584.0 \n",
      "Model_0_4140 \t loss_train = 28070708.0 \t loss_valid = 25386360.0 \n",
      "Model_0_4150 \t loss_train = 28146628.0 \t loss_valid = 25317364.0 \n",
      "Model_0_4160 \t loss_train = 28069926.0 \t loss_valid = 25387002.0 \n",
      "Model_0_4170 \t loss_train = 28038140.0 \t loss_valid = 25436758.0 \n",
      "Model_0_4180 \t loss_train = 28158246.0 \t loss_valid = 25310118.0 \n",
      "Model_0_4190 \t loss_train = 28048956.0 \t loss_valid = 25417340.0 \n",
      "Model_0_4200 \t loss_train = 28049526.0 \t loss_valid = 25416506.0 \n",
      "Model_0_4210 \t loss_train = 28133330.0 \t loss_valid = 25326248.0 \n",
      "Model_0_4220 \t loss_train = 28071572.0 \t loss_valid = 25384736.0 \n",
      "Model_0_4230 \t loss_train = 28158248.0 \t loss_valid = 25310196.0 \n",
      "Model_0_4240 \t loss_train = 28055778.0 \t loss_valid = 25406748.0 \n",
      "Model_0_4250 \t loss_train = 28128492.0 \t loss_valid = 25329894.0 \n",
      "Model_0_4260 \t loss_train = 28060468.0 \t loss_valid = 25400262.0 \n",
      "Model_0_4270 \t loss_train = 28089786.0 \t loss_valid = 25364270.0 \n",
      "Model_0_4280 \t loss_train = 28096160.0 \t loss_valid = 25358056.0 \n",
      "Model_0_4290 \t loss_train = 28124170.0 \t loss_valid = 25333706.0 \n",
      "Model_0_4300 \t loss_train = 28061494.0 \t loss_valid = 25399134.0 \n",
      "Model_0_4310 \t loss_train = 28078162.0 \t loss_valid = 25377622.0 \n",
      "Model_0_4320 \t loss_train = 28049140.0 \t loss_valid = 25418464.0 \n",
      "Model_0_4330 \t loss_train = 28081996.0 \t loss_valid = 25373632.0 \n",
      "Model_0_4340 \t loss_train = 28042140.0 \t loss_valid = 25431370.0 \n",
      "Model_0_4350 \t loss_train = 28080204.0 \t loss_valid = 25375880.0 \n",
      "Model_0_4360 \t loss_train = 28067244.0 \t loss_valid = 25392502.0 \n",
      "Model_0_4370 \t loss_train = 28151214.0 \t loss_valid = 25315550.0 \n",
      "Model_0_4380 \t loss_train = 28026698.0 \t loss_valid = 25461994.0 \n",
      "Model_0_4390 \t loss_train = 28089170.0 \t loss_valid = 25364434.0 \n",
      "Model_0_4400 \t loss_train = 28095720.0 \t loss_valid = 25357520.0 \n",
      "Model_0_4410 \t loss_train = 28028152.0 \t loss_valid = 25457638.0 \n",
      "Model_0_4420 \t loss_train = 28168162.0 \t loss_valid = 25304882.0 \n",
      "Model_0_4430 \t loss_train = 28015508.0 \t loss_valid = 25490540.0 \n",
      "Model_0_4440 \t loss_train = 28117712.0 \t loss_valid = 25337938.0 \n",
      "Model_0_4450 \t loss_train = 28020810.0 \t loss_valid = 25476138.0 \n",
      "Model_0_4460 \t loss_train = 28086226.0 \t loss_valid = 25367814.0 \n",
      "Model_0_4470 \t loss_train = 28084906.0 \t loss_valid = 25369156.0 \n",
      "Model_0_4480 \t loss_train = 28060164.0 \t loss_valid = 25400020.0 \n",
      "Model_0_4490 \t loss_train = 28231818.0 \t loss_valid = 25278558.0 \n",
      "Model_0_4500 \t loss_train = 28071604.0 \t loss_valid = 25384956.0 \n",
      "Model_0_4510 \t loss_train = 28021642.0 \t loss_valid = 25474210.0 \n",
      "Model_0_4520 \t loss_train = 28111192.0 \t loss_valid = 25344094.0 \n",
      "Model_0_4530 \t loss_train = 28100690.0 \t loss_valid = 25353548.0 \n",
      "Model_0_4540 \t loss_train = 28040022.0 \t loss_valid = 25433234.0 \n",
      "Model_0_4550 \t loss_train = 28042140.0 \t loss_valid = 25428812.0 \n",
      "Model_0_4560 \t loss_train = 28107720.0 \t loss_valid = 25346676.0 \n",
      "Model_0_4570 \t loss_train = 28065286.0 \t loss_valid = 25393250.0 \n",
      "Model_0_4580 \t loss_train = 28022064.0 \t loss_valid = 25473210.0 \n",
      "Model_0_4590 \t loss_train = 28157544.0 \t loss_valid = 25312516.0 \n",
      "Model_0_4600 \t loss_train = 28027292.0 \t loss_valid = 25461940.0 \n",
      "Model_0_4610 \t loss_train = 28199868.0 \t loss_valid = 25292420.0 \n",
      "Model_0_4620 \t loss_train = 28035690.0 \t loss_valid = 25444376.0 \n",
      "Model_0_4630 \t loss_train = 28119122.0 \t loss_valid = 25339256.0 \n",
      "Model_0_4640 \t loss_train = 28111782.0 \t loss_valid = 25345200.0 \n",
      "Model_0_4650 \t loss_train = 28044890.0 \t loss_valid = 25426568.0 \n",
      "Model_0_4660 \t loss_train = 28082724.0 \t loss_valid = 25373532.0 \n",
      "Model_0_4670 \t loss_train = 28087074.0 \t loss_valid = 25369224.0 \n",
      "Model_0_4680 \t loss_train = 28013540.0 \t loss_valid = 25499980.0 \n",
      "Model_0_4690 \t loss_train = 28136286.0 \t loss_valid = 25327124.0 \n",
      "Model_0_4700 \t loss_train = 28034588.0 \t loss_valid = 25446502.0 \n",
      "Model_0_4710 \t loss_train = 28184946.0 \t loss_valid = 25299000.0 \n",
      "Model_0_4720 \t loss_train = 28042124.0 \t loss_valid = 25431766.0 \n",
      "Model_0_4730 \t loss_train = 28060666.0 \t loss_valid = 25401626.0 \n",
      "Model_0_4740 \t loss_train = 28103512.0 \t loss_valid = 25352786.0 \n",
      "Model_0_4750 \t loss_train = 28043308.0 \t loss_valid = 25431214.0 \n",
      "Model_0_4760 \t loss_train = 28050338.0 \t loss_valid = 25420538.0 \n",
      "Model_0_4770 \t loss_train = 28076096.0 \t loss_valid = 25383340.0 \n",
      "Model_0_4780 \t loss_train = 28093406.0 \t loss_valid = 25363660.0 \n",
      "Model_0_4790 \t loss_train = 28055410.0 \t loss_valid = 25411678.0 \n",
      "Model_0_4800 \t loss_train = 28130130.0 \t loss_valid = 25332836.0 \n",
      "Model_0_4810 \t loss_train = 28081510.0 \t loss_valid = 25377032.0 \n",
      "Model_0_4820 \t loss_train = 28095300.0 \t loss_valid = 25361352.0 \n",
      "Model_0_4830 \t loss_train = 28090830.0 \t loss_valid = 25365978.0 \n",
      "Model_0_4840 \t loss_train = 28076818.0 \t loss_valid = 25380974.0 \n",
      "Model_0_4850 \t loss_train = 28052416.0 \t loss_valid = 25414618.0 \n",
      "Model_0_4860 \t loss_train = 28174418.0 \t loss_valid = 25304766.0 \n",
      "Model_0_4870 \t loss_train = 28036134.0 \t loss_valid = 25443458.0 \n",
      "Model_0_4880 \t loss_train = 28130502.0 \t loss_valid = 25332216.0 \n",
      "Model_0_4890 \t loss_train = 28027022.0 \t loss_valid = 25465666.0 \n",
      "Model_0_4900 \t loss_train = 28102520.0 \t loss_valid = 25357246.0 \n",
      "Model_0_4910 \t loss_train = 28055486.0 \t loss_valid = 25413438.0 \n",
      "Model_0_4920 \t loss_train = 28110826.0 \t loss_valid = 25351082.0 \n",
      "Model_0_4930 \t loss_train = 28048374.0 \t loss_valid = 25424874.0 \n",
      "Model_0_4940 \t loss_train = 28141218.0 \t loss_valid = 25328662.0 \n",
      "Model_0_4950 \t loss_train = 28038812.0 \t loss_valid = 25441474.0 \n",
      "Model_0_4960 \t loss_train = 28091816.0 \t loss_valid = 25367706.0 \n",
      "Model_0_4970 \t loss_train = 28114644.0 \t loss_valid = 25346870.0 \n",
      "Model_0_4980 \t loss_train = 28017720.0 \t loss_valid = 25490836.0 \n",
      "Model_0_4990 \t loss_train = 28107498.0 \t loss_valid = 25351676.0 \n",
      "Model_0_5000 \t loss_train = 28070670.0 \t loss_valid = 25389980.0 \n",
      "Model_0_5010 \t loss_train = 28089676.0 \t loss_valid = 25367928.0 \n",
      "Model_0_5020 \t loss_train = 28138992.0 \t loss_valid = 25327982.0 \n",
      "Model_0_5030 \t loss_train = 28034148.0 \t loss_valid = 25449838.0 \n",
      "Model_0_5040 \t loss_train = 28048134.0 \t loss_valid = 25424598.0 \n",
      "Model_0_5050 \t loss_train = 28079324.0 \t loss_valid = 25382482.0 \n",
      "Model_0_5060 \t loss_train = 28059586.0 \t loss_valid = 25407398.0 \n",
      "Model_0_5070 \t loss_train = 28116980.0 \t loss_valid = 25346502.0 \n",
      "Model_0_5080 \t loss_train = 28127644.0 \t loss_valid = 25340904.0 \n",
      "Model_0_5090 \t loss_train = 28008024.0 \t loss_valid = 25532262.0 \n",
      "Model_0_5100 \t loss_train = 28119100.0 \t loss_valid = 25344642.0 \n",
      "Model_0_5110 \t loss_train = 28021964.0 \t loss_valid = 25478468.0 \n",
      "Model_0_5120 \t loss_train = 28146654.0 \t loss_valid = 25323382.0 \n",
      "Model_0_5130 \t loss_train = 28037010.0 \t loss_valid = 25444422.0 \n",
      "Model_0_5140 \t loss_train = 28028782.0 \t loss_valid = 25460084.0 \n",
      "Model_0_5150 \t loss_train = 28111268.0 \t loss_valid = 25347904.0 \n",
      "Model_0_5160 \t loss_train = 27999752.0 \t loss_valid = 25562760.0 \n",
      "Model_0_5170 \t loss_train = 28157116.0 \t loss_valid = 25318564.0 \n",
      "Model_0_5180 \t loss_train = 28065432.0 \t loss_valid = 25400196.0 \n",
      "Model_0_5190 \t loss_train = 28110236.0 \t loss_valid = 25351228.0 \n",
      "Model_0_5200 \t loss_train = 28061604.0 \t loss_valid = 25406426.0 \n",
      "Model_0_5210 \t loss_train = 28148698.0 \t loss_valid = 25324804.0 \n",
      "Model_0_5220 \t loss_train = 28043776.0 \t loss_valid = 25434790.0 \n",
      "Model_0_5230 \t loss_train = 28048648.0 \t loss_valid = 25424388.0 \n",
      "Model_0_5240 \t loss_train = 28171992.0 \t loss_valid = 25309354.0 \n",
      "Model_0_5250 \t loss_train = 28028078.0 \t loss_valid = 25460142.0 \n",
      "Model_0_5260 \t loss_train = 28120928.0 \t loss_valid = 25338736.0 \n",
      "Model_0_5270 \t loss_train = 28009528.0 \t loss_valid = 25513048.0 \n",
      "Model_0_5280 \t loss_train = 28144924.0 \t loss_valid = 25322652.0 \n",
      "Model_0_5290 \t loss_train = 28061536.0 \t loss_valid = 25400506.0 \n",
      "Model_0_5300 \t loss_train = 28031218.0 \t loss_valid = 25451750.0 \n",
      "Model_0_5310 \t loss_train = 28119994.0 \t loss_valid = 25339414.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_0_5320 \t loss_train = 28086424.0 \t loss_valid = 25369808.0 \n",
      "Model_0_5330 \t loss_train = 28006750.0 \t loss_valid = 25521038.0 \n",
      "Model_0_5340 \t loss_train = 28114142.0 \t loss_valid = 25344268.0 \n",
      "Model_0_5350 \t loss_train = 28030778.0 \t loss_valid = 25455012.0 \n",
      "Model_0_5360 \t loss_train = 28116090.0 \t loss_valid = 25345214.0 \n",
      "Model_0_5370 \t loss_train = 28038466.0 \t loss_valid = 25439360.0 \n",
      "Model_0_5380 \t loss_train = 28082458.0 \t loss_valid = 25376494.0 \n",
      "Model_0_5390 \t loss_train = 28096398.0 \t loss_valid = 25361816.0 \n",
      "Model_0_5400 \t loss_train = 28044508.0 \t loss_valid = 25429438.0 \n",
      "Model_0_5410 \t loss_train = 28055400.0 \t loss_valid = 25414444.0 \n",
      "Model_0_5420 \t loss_train = 28112144.0 \t loss_valid = 25353520.0 \n",
      "Model_0_5430 \t loss_train = 28086736.0 \t loss_valid = 25379316.0 \n",
      "Model_0_5440 \t loss_train = 28070716.0 \t loss_valid = 25397852.0 \n",
      "Model_0_5450 \t loss_train = 28110470.0 \t loss_valid = 25351426.0 \n",
      "Model_0_5460 \t loss_train = 28070874.0 \t loss_valid = 25391454.0 \n",
      "Model_0_5470 \t loss_train = 28129282.0 \t loss_valid = 25336720.0 \n",
      "Model_0_5480 \t loss_train = 28076414.0 \t loss_valid = 25388184.0 \n",
      "Model_0_5490 \t loss_train = 28114876.0 \t loss_valid = 25352280.0 \n",
      "Model_0_5500 \t loss_train = 28110462.0 \t loss_valid = 25355242.0 \n",
      "Model_0_5510 \t loss_train = 28012368.0 \t loss_valid = 25510706.0 \n",
      "Model_0_5520 \t loss_train = 28132722.0 \t loss_valid = 25341160.0 \n",
      "Model_0_5530 \t loss_train = 28057856.0 \t loss_valid = 25413052.0 \n",
      "Model_0_5540 \t loss_train = 28083884.0 \t loss_valid = 25378548.0 \n",
      "Model_0_5550 \t loss_train = 28091312.0 \t loss_valid = 25370106.0 \n",
      "Model_0_5560 \t loss_train = 28044540.0 \t loss_valid = 25432462.0 \n",
      "Model_0_5570 \t loss_train = 28074816.0 \t loss_valid = 25388374.0 \n",
      "Model_0_5580 \t loss_train = 28031682.0 \t loss_valid = 25457380.0 \n",
      "Model_0_5590 \t loss_train = 28225290.0 \t loss_valid = 25289842.0 \n",
      "Model_0_5600 \t loss_train = 28025998.0 \t loss_valid = 25467164.0 \n",
      "Model_0_5610 \t loss_train = 28113658.0 \t loss_valid = 25347850.0 \n",
      "Model_0_5620 \t loss_train = 28053138.0 \t loss_valid = 25417868.0 \n",
      "Model_0_5630 \t loss_train = 28060236.0 \t loss_valid = 25408980.0 \n",
      "Model_0_5640 \t loss_train = 28103056.0 \t loss_valid = 25361016.0 \n",
      "Model_0_5650 \t loss_train = 28064706.0 \t loss_valid = 25404450.0 \n",
      "Model_0_5660 \t loss_train = 28189584.0 \t loss_valid = 25305082.0 \n",
      "Model_0_5670 \t loss_train = 28000382.0 \t loss_valid = 25561078.0 \n",
      "Model_0_5680 \t loss_train = 28102222.0 \t loss_valid = 25364132.0 \n",
      "Model_0_5690 \t loss_train = 28092832.0 \t loss_valid = 25371228.0 \n",
      "Model_0_5700 \t loss_train = 28081770.0 \t loss_valid = 25381320.0 \n",
      "Model_0_5710 \t loss_train = 28134482.0 \t loss_valid = 25333598.0 \n",
      "Model_0_5720 \t loss_train = 28098076.0 \t loss_valid = 25363382.0 \n",
      "Model_0_5730 \t loss_train = 28022466.0 \t loss_valid = 25480610.0 \n",
      "Model_0_5740 \t loss_train = 28088748.0 \t loss_valid = 25374238.0 \n",
      "Model_0_5750 \t loss_train = 28094528.0 \t loss_valid = 25369660.0 \n",
      "Model_0_5760 \t loss_train = 28063778.0 \t loss_valid = 25406758.0 \n",
      "Model_0_5770 \t loss_train = 28028198.0 \t loss_valid = 25471950.0 \n",
      "Model_0_5780 \t loss_train = 28021574.0 \t loss_valid = 25486200.0 \n",
      "Model_0_5790 \t loss_train = 28061168.0 \t loss_valid = 25407002.0 \n",
      "Model_0_5800 \t loss_train = 27999516.0 \t loss_valid = 25564220.0 \n",
      "Model_0_5810 \t loss_train = 28242232.0 \t loss_valid = 25289772.0 \n",
      "Model_0_5820 \t loss_train = 28030676.0 \t loss_valid = 25467954.0 \n",
      "Model_0_5830 \t loss_train = 28089518.0 \t loss_valid = 25376878.0 \n",
      "Model_0_5840 \t loss_train = 28089436.0 \t loss_valid = 25372864.0 \n",
      "Model_0_5850 \t loss_train = 28035270.0 \t loss_valid = 25452126.0 \n",
      "Model_0_5860 \t loss_train = 28158390.0 \t loss_valid = 25321028.0 \n",
      "Model_0_5870 \t loss_train = 28181724.0 \t loss_valid = 25309044.0 \n",
      "Model_0_5880 \t loss_train = 28005878.0 \t loss_valid = 25534302.0 \n",
      "Model_0_5890 \t loss_train = 27999898.0 \t loss_valid = 25558532.0 \n",
      "Model_0_5900 \t loss_train = 28229892.0 \t loss_valid = 25288686.0 \n",
      "Model_0_5910 \t loss_train = 27991798.0 \t loss_valid = 25681508.0 \n",
      "Model_0_5920 \t loss_train = 28118770.0 \t loss_valid = 25346014.0 \n",
      "Model_0_5930 \t loss_train = 28152216.0 \t loss_valid = 25324702.0 \n",
      "Model_0_5940 \t loss_train = 28034728.0 \t loss_valid = 25452700.0 \n",
      "Model_0_5950 \t loss_train = 28065102.0 \t loss_valid = 25401586.0 \n",
      "Model_0_5960 \t loss_train = 28133334.0 \t loss_valid = 25334858.0 \n",
      "Model_0_5970 \t loss_train = 28025678.0 \t loss_valid = 25471728.0 \n",
      "Model_0_5980 \t loss_train = 28116440.0 \t loss_valid = 25348870.0 \n",
      "Model_0_5990 \t loss_train = 28057244.0 \t loss_valid = 25412686.0 \n",
      "Model_0_6000 \t loss_train = 28044946.0 \t loss_valid = 25430164.0 \n",
      "Model_0_6010 \t loss_train = 28170616.0 \t loss_valid = 25314362.0 \n",
      "Model_0_6020 \t loss_train = 28029530.0 \t loss_valid = 25465110.0 \n",
      "Model_0_6030 \t loss_train = 28032866.0 \t loss_valid = 25457052.0 \n",
      "Model_0_6040 \t loss_train = 28127722.0 \t loss_valid = 25340290.0 \n",
      "Model_0_6050 \t loss_train = 28095220.0 \t loss_valid = 25367514.0 \n",
      "Model_0_6060 \t loss_train = 28027166.0 \t loss_valid = 25472978.0 \n",
      "Model_0_6070 \t loss_train = 28115820.0 \t loss_valid = 25352504.0 \n",
      "Model_0_6080 \t loss_train = 28065582.0 \t loss_valid = 25403538.0 \n",
      "Model_0_6090 \t loss_train = 28112080.0 \t loss_valid = 25351984.0 \n",
      "Model_0_6100 \t loss_train = 28011890.0 \t loss_valid = 25511150.0 \n",
      "Model_0_6110 \t loss_train = 28047718.0 \t loss_valid = 25427400.0 \n",
      "Model_0_6120 \t loss_train = 28183654.0 \t loss_valid = 25306466.0 \n",
      "Model_0_6130 \t loss_train = 28028140.0 \t loss_valid = 25468150.0 \n",
      "Model_0_6140 \t loss_train = 28123108.0 \t loss_valid = 25343378.0 \n",
      "Model_0_6150 \t loss_train = 28025306.0 \t loss_valid = 25476684.0 \n",
      "Model_0_6160 \t loss_train = 28103768.0 \t loss_valid = 25362264.0 \n",
      "Model_0_6170 \t loss_train = 28010680.0 \t loss_valid = 25522858.0 \n",
      "Model_0_6180 \t loss_train = 28049196.0 \t loss_valid = 25431210.0 \n",
      "Model_0_6190 \t loss_train = 28049988.0 \t loss_valid = 25429106.0 \n",
      "Model_0_6200 \t loss_train = 28029998.0 \t loss_valid = 25471902.0 \n",
      "Model_0_6210 \t loss_train = 28110028.0 \t loss_valid = 25355118.0 \n",
      "Model_0_6220 \t loss_train = 28029890.0 \t loss_valid = 25462790.0 \n",
      "Model_0_6230 \t loss_train = 28029920.0 \t loss_valid = 25462642.0 \n",
      "Model_0_6240 \t loss_train = 28086202.0 \t loss_valid = 25379416.0 \n",
      "Model_0_6250 \t loss_train = 28083882.0 \t loss_valid = 25380536.0 \n",
      "Model_0_6260 \t loss_train = 28049204.0 \t loss_valid = 25427376.0 \n",
      "Model_0_6270 \t loss_train = 28109706.0 \t loss_valid = 25354214.0 \n",
      "Model_0_6280 \t loss_train = 28164134.0 \t loss_valid = 25313464.0 \n",
      "Model_0_6290 \t loss_train = 28040756.0 \t loss_valid = 25437276.0 \n",
      "Model_0_6300 \t loss_train = 28134000.0 \t loss_valid = 25333312.0 \n",
      "Model_0_6310 \t loss_train = 28025466.0 \t loss_valid = 25474590.0 \n",
      "Model_0_6320 \t loss_train = 28155658.0 \t loss_valid = 25322402.0 \n",
      "Model_0_6330 \t loss_train = 28010286.0 \t loss_valid = 25521654.0 \n",
      "Model_0_6340 \t loss_train = 28030782.0 \t loss_valid = 25460870.0 \n",
      "Model_0_6350 \t loss_train = 28144378.0 \t loss_valid = 25325618.0 \n",
      "Model_0_6360 \t loss_train = 28021150.0 \t loss_valid = 25483226.0 \n",
      "Model_0_6370 \t loss_train = 28055176.0 \t loss_valid = 25417664.0 \n",
      "Model_0_6380 \t loss_train = 28047616.0 \t loss_valid = 25427128.0 \n",
      "Model_0_6390 \t loss_train = 28087578.0 \t loss_valid = 25372570.0 \n",
      "Model_0_6400 \t loss_train = 28062148.0 \t loss_valid = 25404360.0 \n",
      "Model_0_6410 \t loss_train = 28014692.0 \t loss_valid = 25496738.0 \n",
      "Model_0_6420 \t loss_train = 28093832.0 \t loss_valid = 25362470.0 \n",
      "Model_0_6430 \t loss_train = 28027292.0 \t loss_valid = 25463380.0 \n",
      "Model_0_6440 \t loss_train = 28136266.0 \t loss_valid = 25328814.0 \n",
      "Model_0_6450 \t loss_train = 28041202.0 \t loss_valid = 25433230.0 \n",
      "Model_0_6460 \t loss_train = 27995612.0 \t loss_valid = 25579040.0 \n",
      "Model_0_6470 \t loss_train = 28159444.0 \t loss_valid = 25314144.0 \n",
      "Model_0_6480 \t loss_train = 28071948.0 \t loss_valid = 25386668.0 \n",
      "Model_0_6490 \t loss_train = 28052146.0 \t loss_valid = 25412926.0 \n",
      "Model_0_6500 \t loss_train = 28080980.0 \t loss_valid = 25375956.0 \n",
      "Model_0_6510 \t loss_train = 28062412.0 \t loss_valid = 25401986.0 \n",
      "Model_0_6520 \t loss_train = 28015474.0 \t loss_valid = 25497694.0 \n",
      "Model_0_6530 \t loss_train = 28042916.0 \t loss_valid = 25433634.0 \n",
      "Model_0_6540 \t loss_train = 28075210.0 \t loss_valid = 25385482.0 \n",
      "Model_0_6550 \t loss_train = 28038258.0 \t loss_valid = 25445974.0 \n",
      "Model_0_6560 \t loss_train = 28060500.0 \t loss_valid = 25407956.0 \n",
      "Model_0_6570 \t loss_train = 28117874.0 \t loss_valid = 25342986.0 \n",
      "Model_0_6580 \t loss_train = 28028082.0 \t loss_valid = 25462630.0 \n",
      "Model_0_6590 \t loss_train = 28016270.0 \t loss_valid = 25496632.0 \n",
      "Model_0_6600 \t loss_train = 28045622.0 \t loss_valid = 25431148.0 \n",
      "Model_0_6610 \t loss_train = 28034572.0 \t loss_valid = 25451792.0 \n",
      "Model_0_6620 \t loss_train = 28071604.0 \t loss_valid = 25388142.0 \n",
      "Model_0_6630 \t loss_train = 28107276.0 \t loss_valid = 25348934.0 \n",
      "Model_0_6640 \t loss_train = 28046640.0 \t loss_valid = 25423100.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_0_6650 \t loss_train = 28013644.0 \t loss_valid = 25503084.0 \n",
      "Model_0_6660 \t loss_train = 28133642.0 \t loss_valid = 25334238.0 \n",
      "Model_0_6670 \t loss_train = 28057386.0 \t loss_valid = 25416082.0 \n",
      "Model_0_6680 \t loss_train = 28079904.0 \t loss_valid = 25387728.0 \n",
      "Model_0_6690 \t loss_train = 28086636.0 \t loss_valid = 25378192.0 \n",
      "Model_0_6700 \t loss_train = 28085916.0 \t loss_valid = 25377726.0 \n",
      "Model_0_6710 \t loss_train = 28039366.0 \t loss_valid = 25445906.0 \n",
      "Model_0_6720 \t loss_train = 28062474.0 \t loss_valid = 25404208.0 \n",
      "Model_0_6730 \t loss_train = 28062320.0 \t loss_valid = 25401838.0 \n",
      "Model_0_6740 \t loss_train = 28002770.0 \t loss_valid = 25544038.0 \n",
      "Model_0_6750 \t loss_train = 28120544.0 \t loss_valid = 25340756.0 \n",
      "Model_0_6760 \t loss_train = 28060706.0 \t loss_valid = 25406116.0 \n",
      "Model_0_6770 \t loss_train = 28052922.0 \t loss_valid = 25418628.0 \n",
      "Model_0_6780 \t loss_train = 28012806.0 \t loss_valid = 25509448.0 \n",
      "Model_0_6790 \t loss_train = 28093320.0 \t loss_valid = 25363266.0 \n",
      "Model_0_6800 \t loss_train = 28095732.0 \t loss_valid = 25360396.0 \n",
      "Model_0_6810 \t loss_train = 28001814.0 \t loss_valid = 25550180.0 \n",
      "Model_0_6820 \t loss_train = 28045062.0 \t loss_valid = 25428386.0 \n",
      "Model_0_6830 \t loss_train = 28065646.0 \t loss_valid = 25396504.0 \n",
      "Model_0_6840 \t loss_train = 28019778.0 \t loss_valid = 25484924.0 \n",
      "Model_0_6850 \t loss_train = 28059928.0 \t loss_valid = 25404738.0 \n",
      "Model_0_6860 \t loss_train = 28004722.0 \t loss_valid = 25536474.0 \n",
      "Model_0_6870 \t loss_train = 28127502.0 \t loss_valid = 25331894.0 \n",
      "Model_0_6880 \t loss_train = 28091568.0 \t loss_valid = 25364090.0 \n",
      "Model_0_6890 \t loss_train = 28014946.0 \t loss_valid = 25502762.0 \n",
      "Model_0_6900 \t loss_train = 28114428.0 \t loss_valid = 25344712.0 \n",
      "Model_0_6910 \t loss_train = 28064020.0 \t loss_valid = 25398870.0 \n",
      "Model_0_6920 \t loss_train = 28065578.0 \t loss_valid = 25399976.0 \n",
      "Model_0_6930 \t loss_train = 28020898.0 \t loss_valid = 25493900.0 \n",
      "Model_0_6940 \t loss_train = 28063960.0 \t loss_valid = 25408604.0 \n",
      "Model_0_6950 \t loss_train = 28077212.0 \t loss_valid = 25385400.0 \n",
      "Model_0_6960 \t loss_train = 28051602.0 \t loss_valid = 25421236.0 \n",
      "Model_0_6970 \t loss_train = 28044304.0 \t loss_valid = 25438942.0 \n",
      "Model_0_6980 \t loss_train = 28058856.0 \t loss_valid = 25414716.0 \n",
      "Model_0_6990 \t loss_train = 28020960.0 \t loss_valid = 25488292.0 \n",
      "Model_0_7000 \t loss_train = 28096876.0 \t loss_valid = 25361840.0 \n",
      "Model_0_7010 \t loss_train = 28043464.0 \t loss_valid = 25432588.0 \n",
      "Model_0_7020 \t loss_train = 27995268.0 \t loss_valid = 25589362.0 \n",
      "Model_0_7030 \t loss_train = 28072018.0 \t loss_valid = 25388206.0 \n",
      "Model_0_7040 \t loss_train = 27999616.0 \t loss_valid = 25558748.0 \n",
      "Model_0_7050 \t loss_train = 28033974.0 \t loss_valid = 25447952.0 \n",
      "Model_0_7060 \t loss_train = 28087874.0 \t loss_valid = 25369408.0 \n",
      "Model_0_7070 \t loss_train = 28076110.0 \t loss_valid = 25384210.0 \n",
      "Model_0_7080 \t loss_train = 27991026.0 \t loss_valid = 25642762.0 \n",
      "Model_0_7090 \t loss_train = 28038406.0 \t loss_valid = 25441774.0 \n",
      "Model_0_7100 \t loss_train = 28110716.0 \t loss_valid = 25349650.0 \n",
      "Model_0_7110 \t loss_train = 28020540.0 \t loss_valid = 25490814.0 \n",
      "Model_0_7120 \t loss_train = 28218014.0 \t loss_valid = 25286130.0 \n",
      "Model_0_7130 \t loss_train = 27993884.0 \t loss_valid = 25607632.0 \n",
      "Model_0_7140 \t loss_train = 28056350.0 \t loss_valid = 25410506.0 \n",
      "Model_0_7150 \t loss_train = 28039276.0 \t loss_valid = 25437488.0 \n",
      "Model_0_7160 \t loss_train = 28072258.0 \t loss_valid = 25385226.0 \n",
      "Model_0_7170 \t loss_train = 28038976.0 \t loss_valid = 25436562.0 \n",
      "Model_0_7180 \t loss_train = 28015832.0 \t loss_valid = 25491896.0 \n",
      "Model_0_7190 \t loss_train = 28082024.0 \t loss_valid = 25373810.0 \n",
      "Model_0_7200 \t loss_train = 28029868.0 \t loss_valid = 25455398.0 \n",
      "Model_0_7210 \t loss_train = 28093080.0 \t loss_valid = 25359532.0 \n",
      "Model_0_7220 \t loss_train = 27996156.0 \t loss_valid = 25577462.0 \n",
      "Model_0_7230 \t loss_train = 28043460.0 \t loss_valid = 25424242.0 \n",
      "Model_0_7240 \t loss_train = 28184300.0 \t loss_valid = 25294068.0 \n",
      "Model_0_7250 \t loss_train = 28027294.0 \t loss_valid = 25459518.0 \n",
      "Model_0_7260 \t loss_train = 28094816.0 \t loss_valid = 25356718.0 \n",
      "Model_0_7270 \t loss_train = 28023110.0 \t loss_valid = 25468862.0 \n",
      "Model_0_7280 \t loss_train = 28028974.0 \t loss_valid = 25455666.0 \n",
      "Model_0_7290 \t loss_train = 28034262.0 \t loss_valid = 25444658.0 \n",
      "Model_0_7300 \t loss_train = 28036570.0 \t loss_valid = 25439824.0 \n",
      "Model_0_7310 \t loss_train = 28068584.0 \t loss_valid = 25391512.0 \n",
      "Model_0_7320 \t loss_train = 28013170.0 \t loss_valid = 25511252.0 \n",
      "Model_0_7330 \t loss_train = 28050520.0 \t loss_valid = 25424226.0 \n",
      "Model_0_7340 \t loss_train = 28046004.0 \t loss_valid = 25428398.0 \n",
      "Model_0_7350 \t loss_train = 28079658.0 \t loss_valid = 25378680.0 \n",
      "Model_0_7360 \t loss_train = 27990980.0 \t loss_valid = 25634678.0 \n",
      "Model_0_7370 \t loss_train = 28043320.0 \t loss_valid = 25430086.0 \n",
      "Model_0_7380 \t loss_train = 28044486.0 \t loss_valid = 25428084.0 \n",
      "Model_0_7390 \t loss_train = 28023524.0 \t loss_valid = 25472222.0 \n",
      "Model_0_7400 \t loss_train = 27993982.0 \t loss_valid = 25596058.0 \n",
      "Model_0_7410 \t loss_train = 28154418.0 \t loss_valid = 25313106.0 \n",
      "Model_0_7420 \t loss_train = 27999618.0 \t loss_valid = 25563770.0 \n",
      "Model_0_7430 \t loss_train = 28015662.0 \t loss_valid = 25500210.0 \n",
      "Model_0_7440 \t loss_train = 28054702.0 \t loss_valid = 25414148.0 \n",
      "Model_0_7450 \t loss_train = 28049396.0 \t loss_valid = 25422634.0 \n",
      "Model_0_7460 \t loss_train = 28002768.0 \t loss_valid = 25544346.0 \n",
      "Model_0_7470 \t loss_train = 28058090.0 \t loss_valid = 25405740.0 \n",
      "Model_0_7480 \t loss_train = 28058988.0 \t loss_valid = 25406872.0 \n",
      "Model_0_7490 \t loss_train = 28051840.0 \t loss_valid = 25419908.0 \n",
      "Model_0_7500 \t loss_train = 28021102.0 \t loss_valid = 25483040.0 \n",
      "Model_0_7510 \t loss_train = 28060094.0 \t loss_valid = 25404418.0 \n",
      "Model_0_7520 \t loss_train = 28046964.0 \t loss_valid = 25421940.0 \n",
      "Model_0_7530 \t loss_train = 28048292.0 \t loss_valid = 25419760.0 \n",
      "Model_0_7540 \t loss_train = 28030594.0 \t loss_valid = 25456164.0 \n",
      "Model_0_7550 \t loss_train = 28070694.0 \t loss_valid = 25388240.0 \n",
      "Model_0_7560 \t loss_train = 28097626.0 \t loss_valid = 25358042.0 \n",
      "Model_0_7570 \t loss_train = 28004774.0 \t loss_valid = 25534780.0 \n",
      "Model_0_7580 \t loss_train = 28068394.0 \t loss_valid = 25392096.0 \n",
      "Model_0_7590 \t loss_train = 28034772.0 \t loss_valid = 25447154.0 \n",
      "Model_0_7600 \t loss_train = 28076496.0 \t loss_valid = 25381312.0 \n",
      "Model_0_7610 \t loss_train = 27994646.0 \t loss_valid = 25600364.0 \n",
      "Model_0_7620 \t loss_train = 28078876.0 \t loss_valid = 25382422.0 \n",
      "Model_0_7630 \t loss_train = 28018394.0 \t loss_valid = 25493460.0 \n",
      "Model_0_7640 \t loss_train = 28035718.0 \t loss_valid = 25445922.0 \n",
      "Model_0_7650 \t loss_train = 28039082.0 \t loss_valid = 25438212.0 \n",
      "Model_0_7660 \t loss_train = 28040702.0 \t loss_valid = 25435140.0 \n",
      "Model_0_7670 \t loss_train = 28041124.0 \t loss_valid = 25433604.0 \n",
      "Model_0_7680 \t loss_train = 28004476.0 \t loss_valid = 25532330.0 \n",
      "Model_0_7690 \t loss_train = 28081244.0 \t loss_valid = 25374810.0 \n",
      "Model_0_7700 \t loss_train = 28015548.0 \t loss_valid = 25497098.0 \n",
      "Model_0_7710 \t loss_train = 28078800.0 \t loss_valid = 25382292.0 \n",
      "Model_0_7720 \t loss_train = 28036858.0 \t loss_valid = 25447604.0 \n",
      "Model_0_7730 \t loss_train = 28025824.0 \t loss_valid = 25468438.0 \n",
      "Model_0_7740 \t loss_train = 28066700.0 \t loss_valid = 25393396.0 \n",
      "Model_0_7750 \t loss_train = 28016006.0 \t loss_valid = 25492408.0 \n",
      "Model_0_7760 \t loss_train = 28022478.0 \t loss_valid = 25475508.0 \n",
      "Model_0_7770 \t loss_train = 28042458.0 \t loss_valid = 25432628.0 \n",
      "Model_0_7780 \t loss_train = 28018410.0 \t loss_valid = 25487574.0 \n",
      "Model_0_7790 \t loss_train = 28028492.0 \t loss_valid = 25462274.0 \n",
      "Model_0_7800 \t loss_train = 28042876.0 \t loss_valid = 25432582.0 \n",
      "Model_0_7810 \t loss_train = 28025142.0 \t loss_valid = 25471102.0 \n",
      "Model_0_7820 \t loss_train = 28036634.0 \t loss_valid = 25449094.0 \n",
      "Model_0_7830 \t loss_train = 28009952.0 \t loss_valid = 25524742.0 \n",
      "Model_0_7840 \t loss_train = 28053216.0 \t loss_valid = 25424614.0 \n",
      "Model_0_7850 \t loss_train = 28050906.0 \t loss_valid = 25425330.0 \n",
      "Model_0_7860 \t loss_train = 28045694.0 \t loss_valid = 25431764.0 \n",
      "Model_0_7870 \t loss_train = 28043114.0 \t loss_valid = 25436124.0 \n",
      "Model_0_7880 \t loss_train = 28012686.0 \t loss_valid = 25509112.0 \n",
      "Model_0_7890 \t loss_train = 28038128.0 \t loss_valid = 25442868.0 \n",
      "Model_0_7900 \t loss_train = 28053544.0 \t loss_valid = 25414308.0 \n",
      "Model_0_7910 \t loss_train = 28031286.0 \t loss_valid = 25453648.0 \n",
      "Model_0_7920 \t loss_train = 28043196.0 \t loss_valid = 25428944.0 \n",
      "Model_0_7930 \t loss_train = 28084930.0 \t loss_valid = 25369866.0 \n",
      "Model_0_7940 \t loss_train = 28010152.0 \t loss_valid = 25511662.0 \n",
      "Model_0_7950 \t loss_train = 28025988.0 \t loss_valid = 25465450.0 \n",
      "Model_0_7960 \t loss_train = 28015780.0 \t loss_valid = 25493064.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_0_7970 \t loss_train = 28073136.0 \t loss_valid = 25384602.0 \n",
      "Model_0_7980 \t loss_train = 28013224.0 \t loss_valid = 25502770.0 \n",
      "Model_0_7990 \t loss_train = 28038550.0 \t loss_valid = 25441482.0 \n",
      "Model_0_8000 \t loss_train = 28022570.0 \t loss_valid = 25478076.0 \n",
      "Model_0_8010 \t loss_train = 28031006.0 \t loss_valid = 25457746.0 \n",
      "Model_0_8020 \t loss_train = 28089354.0 \t loss_valid = 25368964.0 \n",
      "Model_0_8030 \t loss_train = 28027332.0 \t loss_valid = 25466494.0 \n",
      "Model_0_8040 \t loss_train = 28050300.0 \t loss_valid = 25419092.0 \n",
      "Model_0_8050 \t loss_train = 28041866.0 \t loss_valid = 25432746.0 \n",
      "Model_0_8060 \t loss_train = 28037152.0 \t loss_valid = 25440630.0 \n",
      "Model_0_8070 \t loss_train = 28054342.0 \t loss_valid = 25410136.0 \n",
      "Model_0_8080 \t loss_train = 28028294.0 \t loss_valid = 25459828.0 \n",
      "Model_0_8090 \t loss_train = 28020860.0 \t loss_valid = 25480106.0 \n",
      "Model_0_8100 \t loss_train = 28048898.0 \t loss_valid = 25419304.0 \n",
      "Model_0_8110 \t loss_train = 28064334.0 \t loss_valid = 25395242.0 \n",
      "Model_0_8120 \t loss_train = 28011650.0 \t loss_valid = 25506180.0 \n",
      "Model_0_8130 \t loss_train = 28052784.0 \t loss_valid = 25414232.0 \n",
      "Model_0_8140 \t loss_train = 28028874.0 \t loss_valid = 25462178.0 \n",
      "Model_0_8150 \t loss_train = 28063044.0 \t loss_valid = 25403168.0 \n",
      "Model_0_8160 \t loss_train = 28025880.0 \t loss_valid = 25471042.0 \n",
      "Model_0_8170 \t loss_train = 28013170.0 \t loss_valid = 25505414.0 \n",
      "Model_0_8180 \t loss_train = 28045260.0 \t loss_valid = 25428688.0 \n",
      "Model_0_8190 \t loss_train = 28016806.0 \t loss_valid = 25492110.0 \n",
      "Model_0_8200 \t loss_train = 28025126.0 \t loss_valid = 25469970.0 \n",
      "Model_0_8210 \t loss_train = 28045944.0 \t loss_valid = 25428070.0 \n",
      "Model_0_8220 \t loss_train = 28021564.0 \t loss_valid = 25483426.0 \n",
      "Model_0_8230 \t loss_train = 28023756.0 \t loss_valid = 25477772.0 \n",
      "Model_0_8240 \t loss_train = 28020418.0 \t loss_valid = 25486892.0 \n",
      "Model_0_8250 \t loss_train = 28054744.0 \t loss_valid = 25416994.0 \n",
      "Model_0_8260 \t loss_train = 28002274.0 \t loss_valid = 25553480.0 \n",
      "Model_0_8270 \t loss_train = 28056748.0 \t loss_valid = 25414610.0 \n",
      "Model_0_8280 \t loss_train = 28021046.0 \t loss_valid = 25486762.0 \n",
      "Model_0_8290 \t loss_train = 28011782.0 \t loss_valid = 25512312.0 \n",
      "Model_0_8300 \t loss_train = 28053722.0 \t loss_valid = 25415294.0 \n",
      "Model_0_8310 \t loss_train = 28036690.0 \t loss_valid = 25444658.0 \n",
      "Model_0_8320 \t loss_train = 28028180.0 \t loss_valid = 25462014.0 \n",
      "Model_0_8330 \t loss_train = 28034812.0 \t loss_valid = 25447120.0 \n",
      "Model_0_8340 \t loss_train = 28021052.0 \t loss_valid = 25479452.0 \n",
      "Model_0_8350 \t loss_train = 28020336.0 \t loss_valid = 25481600.0 \n",
      "Model_0_8360 \t loss_train = 28059602.0 \t loss_valid = 25404792.0 \n",
      "Model_0_8370 \t loss_train = 28014104.0 \t loss_valid = 25501750.0 \n",
      "Model_0_8380 \t loss_train = 28064056.0 \t loss_valid = 25400286.0 \n",
      "Model_0_8390 \t loss_train = 28034868.0 \t loss_valid = 25452066.0 \n",
      "Model_0_8400 \t loss_train = 28015592.0 \t loss_valid = 25502128.0 \n",
      "Model_0_8410 \t loss_train = 28047088.0 \t loss_valid = 25430988.0 \n",
      "Model_0_8420 \t loss_train = 28014880.0 \t loss_valid = 25506828.0 \n",
      "Model_0_8430 \t loss_train = 28062092.0 \t loss_valid = 25408432.0 \n",
      "Model_0_8440 \t loss_train = 28030646.0 \t loss_valid = 25463944.0 \n",
      "Model_0_8450 \t loss_train = 28010464.0 \t loss_valid = 25519688.0 \n",
      "Model_0_8460 \t loss_train = 28057164.0 \t loss_valid = 25413196.0 \n",
      "Model_0_8470 \t loss_train = 28012116.0 \t loss_valid = 25512192.0 \n",
      "Model_0_8480 \t loss_train = 28022176.0 \t loss_valid = 25481514.0 \n",
      "Model_0_8490 \t loss_train = 28045396.0 \t loss_valid = 25430866.0 \n",
      "Model_0_8500 \t loss_train = 28028606.0 \t loss_valid = 25465024.0 \n",
      "Model_0_8510 \t loss_train = 28076406.0 \t loss_valid = 25385996.0 \n",
      "Model_0_8520 \t loss_train = 28011254.0 \t loss_valid = 25514562.0 \n",
      "Model_0_8530 \t loss_train = 28040816.0 \t loss_valid = 25440708.0 \n",
      "Model_0_8540 \t loss_train = 28043380.0 \t loss_valid = 25435638.0 \n",
      "Model_0_8550 \t loss_train = 28037600.0 \t loss_valid = 25447348.0 \n",
      "Model_0_8560 \t loss_train = 28026896.0 \t loss_valid = 25471500.0 \n",
      "Model_0_8570 \t loss_train = 28013644.0 \t loss_valid = 25509420.0 \n",
      "Model_0_8580 \t loss_train = 28064088.0 \t loss_valid = 25404908.0 \n",
      "Model_0_8590 \t loss_train = 28004352.0 \t loss_valid = 25541952.0 \n",
      "Model_0_8600 \t loss_train = 28081480.0 \t loss_valid = 25379912.0 \n",
      "Model_0_8610 \t loss_train = 28025460.0 \t loss_valid = 25473704.0 \n",
      "Model_0_8620 \t loss_train = 28015540.0 \t loss_valid = 25501722.0 \n",
      "Model_0_8630 \t loss_train = 28061416.0 \t loss_valid = 25407510.0 \n",
      "Model_0_8640 \t loss_train = 28027464.0 \t loss_valid = 25470860.0 \n",
      "Model_0_8650 \t loss_train = 28055308.0 \t loss_valid = 25415490.0 \n",
      "Model_0_8660 \t loss_train = 28007962.0 \t loss_valid = 25524056.0 \n",
      "Model_0_8670 \t loss_train = 28054994.0 \t loss_valid = 25412438.0 \n",
      "Model_0_8680 \t loss_train = 28007016.0 \t loss_valid = 25525202.0 \n",
      "Model_0_8690 \t loss_train = 28029956.0 \t loss_valid = 25458910.0 \n",
      "Model_0_8700 \t loss_train = 28031540.0 \t loss_valid = 25456138.0 \n",
      "Model_0_8710 \t loss_train = 28062544.0 \t loss_valid = 25401642.0 \n",
      "Model_0_8720 \t loss_train = 28010842.0 \t loss_valid = 25512514.0 \n",
      "Model_0_8730 \t loss_train = 28078330.0 \t loss_valid = 25380536.0 \n",
      "Model_0_8740 \t loss_train = 28005636.0 \t loss_valid = 25531676.0 \n",
      "Model_0_8750 \t loss_train = 28063670.0 \t loss_valid = 25399862.0 \n",
      "Model_0_8760 \t loss_train = 27998942.0 \t loss_valid = 25564162.0 \n",
      "Model_0_8770 \t loss_train = 28071604.0 \t loss_valid = 25389628.0 \n",
      "Model_0_8780 \t loss_train = 28013530.0 \t loss_valid = 25503216.0 \n",
      "Model_0_8790 \t loss_train = 28021660.0 \t loss_valid = 25479480.0 \n",
      "Model_0_8800 \t loss_train = 28037256.0 \t loss_valid = 25443392.0 \n",
      "Model_0_8810 \t loss_train = 28025940.0 \t loss_valid = 25468258.0 \n",
      "Model_0_8820 \t loss_train = 28015546.0 \t loss_valid = 25496216.0 \n",
      "Model_0_8830 \t loss_train = 28051598.0 \t loss_valid = 25417966.0 \n",
      "Model_0_8840 \t loss_train = 28036958.0 \t loss_valid = 25445544.0 \n",
      "Model_0_8850 \t loss_train = 28062712.0 \t loss_valid = 25401882.0 \n",
      "Model_0_8860 \t loss_train = 28036506.0 \t loss_valid = 25445906.0 \n",
      "Model_0_8870 \t loss_train = 28055184.0 \t loss_valid = 25412554.0 \n",
      "Model_0_8880 \t loss_train = 28029884.0 \t loss_valid = 25460160.0 \n",
      "Model_0_8890 \t loss_train = 28013796.0 \t loss_valid = 25502444.0 \n",
      "Model_0_8900 \t loss_train = 28023982.0 \t loss_valid = 25473226.0 \n",
      "Model_0_8910 \t loss_train = 28053600.0 \t loss_valid = 25414854.0 \n",
      "Model_0_8920 \t loss_train = 27996992.0 \t loss_valid = 25574918.0 \n",
      "Model_0_8930 \t loss_train = 28043280.0 \t loss_valid = 25433278.0 \n",
      "Model_0_8940 \t loss_train = 28000250.0 \t loss_valid = 25557502.0 \n",
      "Model_0_8950 \t loss_train = 28021790.0 \t loss_valid = 25480428.0 \n",
      "Model_0_8960 \t loss_train = 28035956.0 \t loss_valid = 25447500.0 \n",
      "Model_0_8970 \t loss_train = 28017888.0 \t loss_valid = 25491286.0 \n",
      "Model_0_8980 \t loss_train = 28025568.0 \t loss_valid = 25470346.0 \n",
      "Model_0_8990 \t loss_train = 28004088.0 \t loss_valid = 25538526.0 \n",
      "Model_0_9000 \t loss_train = 28037916.0 \t loss_valid = 25443610.0 \n",
      "Model_0_9010 \t loss_train = 28055744.0 \t loss_valid = 25412794.0 \n",
      "Model_0_9020 \t loss_train = 28009106.0 \t loss_valid = 25519386.0 \n",
      "Model_0_9030 \t loss_train = 28042212.0 \t loss_valid = 25435334.0 \n",
      "Model_0_9040 \t loss_train = 28039704.0 \t loss_valid = 25440176.0 \n",
      "Model_0_9050 \t loss_train = 27996830.0 \t loss_valid = 25577958.0 \n",
      "Model_0_9060 \t loss_train = 28043864.0 \t loss_valid = 25434006.0 \n",
      "Model_0_9070 \t loss_train = 28015184.0 \t loss_valid = 25500476.0 \n",
      "Model_0_9080 \t loss_train = 28025594.0 \t loss_valid = 25472098.0 \n",
      "Model_0_9090 \t loss_train = 28024062.0 \t loss_valid = 25475170.0 \n",
      "Model_0_9100 \t loss_train = 28033462.0 \t loss_valid = 25453872.0 \n",
      "Model_0_9110 \t loss_train = 28025208.0 \t loss_valid = 25474664.0 \n",
      "Model_0_9120 \t loss_train = 28016820.0 \t loss_valid = 25499752.0 \n",
      "Model_0_9130 \t loss_train = 28024074.0 \t loss_valid = 25480590.0 \n",
      "Model_0_9140 \t loss_train = 28019620.0 \t loss_valid = 25491320.0 \n",
      "Model_0_9150 \t loss_train = 28025160.0 \t loss_valid = 25474896.0 \n",
      "Model_0_9160 \t loss_train = 28024646.0 \t loss_valid = 25474700.0 \n",
      "Model_0_9170 \t loss_train = 28011824.0 \t loss_valid = 25510466.0 \n",
      "Model_0_9180 \t loss_train = 28058812.0 \t loss_valid = 25407892.0 \n",
      "Model_0_9190 \t loss_train = 28021484.0 \t loss_valid = 25480760.0 \n",
      "Model_0_9200 \t loss_train = 28030984.0 \t loss_valid = 25457272.0 \n",
      "Model_0_9210 \t loss_train = 28011358.0 \t loss_valid = 25509822.0 \n",
      "Model_0_9220 \t loss_train = 28054024.0 \t loss_valid = 25413720.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_0_9230 \t loss_train = 27998500.0 \t loss_valid = 25565308.0 \n",
      "Model_0_9240 \t loss_train = 28025662.0 \t loss_valid = 25469798.0 \n",
      "Model_0_9250 \t loss_train = 28034228.0 \t loss_valid = 25450402.0 \n",
      "Model_0_9260 \t loss_train = 28000694.0 \t loss_valid = 25553480.0 \n",
      "Model_0_9270 \t loss_train = 28079164.0 \t loss_valid = 25379922.0 \n",
      "Model_0_9280 \t loss_train = 28004900.0 \t loss_valid = 25535232.0 \n",
      "Model_0_9290 \t loss_train = 28056820.0 \t loss_valid = 25410528.0 \n",
      "Model_0_9300 \t loss_train = 28022676.0 \t loss_valid = 25477556.0 \n",
      "Model_0_9310 \t loss_train = 28034500.0 \t loss_valid = 25450364.0 \n",
      "Model_0_9320 \t loss_train = 28020574.0 \t loss_valid = 25484056.0 \n",
      "Model_0_9330 \t loss_train = 28019632.0 \t loss_valid = 25488116.0 \n",
      "Model_0_9340 \t loss_train = 28008682.0 \t loss_valid = 25524058.0 \n",
      "Model_0_9350 \t loss_train = 28007454.0 \t loss_valid = 25527406.0 \n",
      "Model_0_9360 \t loss_train = 28044036.0 \t loss_valid = 25433168.0 \n",
      "Model_0_9370 \t loss_train = 28031464.0 \t loss_valid = 25457930.0 \n",
      "Model_0_9380 \t loss_train = 27992494.0 \t loss_valid = 25612146.0 \n",
      "Model_0_9390 \t loss_train = 28035520.0 \t loss_valid = 25448448.0 \n",
      "Model_0_9400 \t loss_train = 28027648.0 \t loss_valid = 25465062.0 \n",
      "Model_0_9410 \t loss_train = 28042124.0 \t loss_valid = 25435530.0 \n",
      "Model_0_9420 \t loss_train = 28032436.0 \t loss_valid = 25455358.0 \n",
      "Model_0_9430 \t loss_train = 28018966.0 \t loss_valid = 25488402.0 \n",
      "Model_0_9440 \t loss_train = 28015252.0 \t loss_valid = 25498860.0 \n",
      "Model_0_9450 \t loss_train = 28005082.0 \t loss_valid = 25535274.0 \n",
      "Model_0_9460 \t loss_train = 28022938.0 \t loss_valid = 25477394.0 \n",
      "Model_0_9470 \t loss_train = 28025566.0 \t loss_valid = 25470496.0 \n",
      "Model_0_9480 \t loss_train = 28010016.0 \t loss_valid = 25515718.0 \n",
      "Model_0_9490 \t loss_train = 28041950.0 \t loss_valid = 25435392.0 \n",
      "Model_0_9500 \t loss_train = 28012422.0 \t loss_valid = 25508050.0 \n",
      "Model_0_9510 \t loss_train = 28028152.0 \t loss_valid = 25465748.0 \n",
      "Model_0_9520 \t loss_train = 28029398.0 \t loss_valid = 25463880.0 \n",
      "Model_0_9530 \t loss_train = 28047298.0 \t loss_valid = 25428438.0 \n",
      "Model_0_9540 \t loss_train = 28012684.0 \t loss_valid = 25508788.0 \n",
      "Model_0_9550 \t loss_train = 28055502.0 \t loss_valid = 25413336.0 \n",
      "Model_0_9560 \t loss_train = 27999872.0 \t loss_valid = 25559296.0 \n",
      "Model_0_9570 \t loss_train = 28027426.0 \t loss_valid = 25466326.0 \n",
      "Model_0_9580 \t loss_train = 28017168.0 \t loss_valid = 25493124.0 \n",
      "Model_0_9590 \t loss_train = 28010774.0 \t loss_valid = 25513476.0 \n",
      "Model_0_9600 \t loss_train = 28047852.0 \t loss_valid = 25425372.0 \n",
      "Model_0_9610 \t loss_train = 28014094.0 \t loss_valid = 25502422.0 \n",
      "Model_0_9620 \t loss_train = 28021484.0 \t loss_valid = 25481488.0 \n",
      "Model_0_9630 \t loss_train = 28062548.0 \t loss_valid = 25402606.0 \n",
      "Model_0_9640 \t loss_train = 27993990.0 \t loss_valid = 25597820.0 \n",
      "Model_0_9650 \t loss_train = 28034322.0 \t loss_valid = 25451584.0 \n",
      "Model_0_9660 \t loss_train = 28066948.0 \t loss_valid = 25396454.0 \n",
      "Model_0_9670 \t loss_train = 28000218.0 \t loss_valid = 25557832.0 \n",
      "Model_0_9680 \t loss_train = 28051784.0 \t loss_valid = 25419192.0 \n",
      "Model_0_9690 \t loss_train = 28020076.0 \t loss_valid = 25485090.0 \n",
      "Model_0_9700 \t loss_train = 28007894.0 \t loss_valid = 25524234.0 \n",
      "Model_0_9710 \t loss_train = 28027134.0 \t loss_valid = 25467580.0 \n",
      "Model_0_9720 \t loss_train = 28035390.0 \t loss_valid = 25449378.0 \n",
      "Model_0_9730 \t loss_train = 28023698.0 \t loss_valid = 25475834.0 \n",
      "Model_0_9740 \t loss_train = 28035526.0 \t loss_valid = 25448602.0 \n",
      "Model_0_9750 \t loss_train = 28015886.0 \t loss_valid = 25497024.0 \n",
      "Model_0_9760 \t loss_train = 28012018.0 \t loss_valid = 25509622.0 \n",
      "Model_0_9770 \t loss_train = 28034004.0 \t loss_valid = 25452892.0 \n",
      "Model_0_9780 \t loss_train = 28009812.0 \t loss_valid = 25518972.0 \n",
      "Model_0_9790 \t loss_train = 28017608.0 \t loss_valid = 25494096.0 \n",
      "Model_0_9800 \t loss_train = 28038118.0 \t loss_valid = 25445420.0 \n",
      "Model_0_9810 \t loss_train = 28005084.0 \t loss_valid = 25537232.0 \n",
      "Model_0_9820 \t loss_train = 28018772.0 \t loss_valid = 25490252.0 \n",
      "Model_0_9830 \t loss_train = 28007128.0 \t loss_valid = 25527928.0 \n",
      "Model_0_9840 \t loss_train = 28024458.0 \t loss_valid = 25474528.0 \n",
      "Model_0_9850 \t loss_train = 28018620.0 \t loss_valid = 25489686.0 \n",
      "Model_0_9860 \t loss_train = 28036608.0 \t loss_valid = 25446554.0 \n",
      "Model_0_9870 \t loss_train = 28031010.0 \t loss_valid = 25457592.0 \n",
      "Model_0_9880 \t loss_train = 28001234.0 \t loss_valid = 25551430.0 \n",
      "Model_0_9890 \t loss_train = 28023998.0 \t loss_valid = 25474428.0 \n",
      "Model_0_9900 \t loss_train = 28023924.0 \t loss_valid = 25474912.0 \n",
      "Model_0_9910 \t loss_train = 28013476.0 \t loss_valid = 25504628.0 \n",
      "Model_0_9920 \t loss_train = 28041776.0 \t loss_valid = 25436516.0 \n",
      "Model_0_9930 \t loss_train = 28011780.0 \t loss_valid = 25510310.0 \n",
      "Model_0_9940 \t loss_train = 28010226.0 \t loss_valid = 25515238.0 \n",
      "Model_0_9950 \t loss_train = 28022560.0 \t loss_valid = 25477726.0 \n",
      "Model_0_9960 \t loss_train = 28023742.0 \t loss_valid = 25474052.0 \n",
      "Model_0_9970 \t loss_train = 28042778.0 \t loss_valid = 25432792.0 \n",
      "Model_0_9980 \t loss_train = 28017026.0 \t loss_valid = 25491954.0 \n",
      "Model_0_9990 \t loss_train = 28024386.0 \t loss_valid = 25471950.0 \n",
      "Model_0_10000 \t loss_train = 28021528.0 \t loss_valid = 25479180.0 \n",
      "Model_0_10010 \t loss_train = 28022684.0 \t loss_valid = 25476258.0 \n",
      "Model_0_10020 \t loss_train = 27997620.0 \t loss_valid = 25570642.0 \n",
      "Model_0_10030 \t loss_train = 28041494.0 \t loss_valid = 25436128.0 \n",
      "Model_0_10040 \t loss_train = 28034430.0 \t loss_valid = 25450618.0 \n",
      "Model_0_10050 \t loss_train = 28031892.0 \t loss_valid = 25456116.0 \n",
      "Model_0_10060 \t loss_train = 28023058.0 \t loss_valid = 25476868.0 \n",
      "Model_0_10070 \t loss_train = 28030122.0 \t loss_valid = 25460028.0 \n",
      "Model_0_10080 \t loss_train = 28019128.0 \t loss_valid = 25487496.0 \n",
      "Model_0_10090 \t loss_train = 28020502.0 \t loss_valid = 25484054.0 \n",
      "Model_0_10100 \t loss_train = 28019414.0 \t loss_valid = 25487138.0 \n",
      "Model_0_10110 \t loss_train = 28020948.0 \t loss_valid = 25482778.0 \n",
      "Model_0_10120 \t loss_train = 28046800.0 \t loss_valid = 25427394.0 \n",
      "Model_0_10130 \t loss_train = 28015304.0 \t loss_valid = 25498484.0 \n",
      "Model_0_10140 \t loss_train = 28012230.0 \t loss_valid = 25507998.0 \n",
      "Model_0_10150 \t loss_train = 27999384.0 \t loss_valid = 25560840.0 \n",
      "Model_0_10160 \t loss_train = 28044308.0 \t loss_valid = 25430990.0 \n",
      "Model_0_10170 \t loss_train = 28057206.0 \t loss_valid = 25410066.0 \n",
      "Model_0_10180 \t loss_train = 27998198.0 \t loss_valid = 25567790.0 \n",
      "Model_0_10190 \t loss_train = 28016972.0 \t loss_valid = 25492606.0 \n",
      "Model_0_10200 \t loss_train = 28037834.0 \t loss_valid = 25442706.0 \n",
      "Model_0_10210 \t loss_train = 28026478.0 \t loss_valid = 25467626.0 \n",
      "Model_0_10220 \t loss_train = 27998588.0 \t loss_valid = 25565128.0 \n",
      "Model_0_10230 \t loss_train = 28029378.0 \t loss_valid = 25460966.0 \n",
      "Model_0_10240 \t loss_train = 28034038.0 \t loss_valid = 25450786.0 \n",
      "Model_0_10250 \t loss_train = 28010512.0 \t loss_valid = 25513254.0 \n",
      "Model_0_10260 \t loss_train = 28015020.0 \t loss_valid = 25498206.0 \n",
      "Model_0_10270 \t loss_train = 28015764.0 \t loss_valid = 25495966.0 \n",
      "Model_0_10280 \t loss_train = 28013972.0 \t loss_valid = 25501422.0 \n",
      "Model_0_10290 \t loss_train = 28030222.0 \t loss_valid = 25458720.0 \n",
      "Model_0_10300 \t loss_train = 28018244.0 \t loss_valid = 25489148.0 \n",
      "Model_0_10310 \t loss_train = 28017056.0 \t loss_valid = 25492722.0 \n",
      "Model_0_10320 \t loss_train = 28007000.0 \t loss_valid = 25526278.0 \n",
      "Model_0_10330 \t loss_train = 28002338.0 \t loss_valid = 25546202.0 \n",
      "Model_0_10340 \t loss_train = 28022058.0 \t loss_valid = 25478682.0 \n",
      "Model_0_10350 \t loss_train = 28025414.0 \t loss_valid = 25469984.0 \n",
      "Model_0_10360 \t loss_train = 28003920.0 \t loss_valid = 25538300.0 \n",
      "Model_0_10370 \t loss_train = 28049750.0 \t loss_valid = 25420684.0 \n",
      "Model_0_10380 \t loss_train = 28007908.0 \t loss_valid = 25522234.0 \n",
      "Model_0_10390 \t loss_train = 28029672.0 \t loss_valid = 25459720.0 \n",
      "Model_0_10400 \t loss_train = 28055634.0 \t loss_valid = 25411474.0 \n",
      "Model_0_10410 \t loss_train = 28024664.0 \t loss_valid = 25471792.0 \n",
      "Model_0_10420 \t loss_train = 28011936.0 \t loss_valid = 25507944.0 \n",
      "Model_0_10430 \t loss_train = 28032020.0 \t loss_valid = 25454070.0 \n",
      "Model_0_10440 \t loss_train = 28012532.0 \t loss_valid = 25505194.0 \n",
      "Model_0_10450 \t loss_train = 28046966.0 \t loss_valid = 25424798.0 \n",
      "Model_0_10460 \t loss_train = 28040630.0 \t loss_valid = 25436264.0 \n",
      "Model_0_10470 \t loss_train = 28015746.0 \t loss_valid = 25494940.0 \n",
      "Model_0_10480 \t loss_train = 28017884.0 \t loss_valid = 25488746.0 \n",
      "Model_0_10490 \t loss_train = 28019968.0 \t loss_valid = 25483234.0 \n",
      "Model_0_10500 \t loss_train = 28001958.0 \t loss_valid = 25546868.0 \n",
      "Model_0_10510 \t loss_train = 28011950.0 \t loss_valid = 25507768.0 \n",
      "Model_0_10520 \t loss_train = 28021580.0 \t loss_valid = 25479608.0 \n",
      "Model_0_10530 \t loss_train = 28013718.0 \t loss_valid = 25502520.0 \n",
      "Model_0_10540 \t loss_train = 28031204.0 \t loss_valid = 25456754.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_0_10550 \t loss_train = 28001020.0 \t loss_valid = 25552784.0 \n",
      "Model_0_10560 \t loss_train = 28033626.0 \t loss_valid = 25451660.0 \n",
      "Model_0_10570 \t loss_train = 28017642.0 \t loss_valid = 25490966.0 \n",
      "Model_0_10580 \t loss_train = 28016098.0 \t loss_valid = 25495314.0 \n",
      "Model_0_10590 \t loss_train = 28024974.0 \t loss_valid = 25471122.0 \n",
      "Model_0_10600 \t loss_train = 27996750.0 \t loss_valid = 25576716.0 \n",
      "Model_0_10610 \t loss_train = 28006860.0 \t loss_valid = 25526652.0 \n",
      "Model_0_10620 \t loss_train = 28045154.0 \t loss_valid = 25428856.0 \n",
      "Model_0_10630 \t loss_train = 28026896.0 \t loss_valid = 25466330.0 \n",
      "Model_0_10640 \t loss_train = 28012418.0 \t loss_valid = 25507050.0 \n",
      "Model_0_10650 \t loss_train = 28027804.0 \t loss_valid = 25465024.0 \n",
      "Model_0_10660 \t loss_train = 28001490.0 \t loss_valid = 25550950.0 \n",
      "Model_0_10670 \t loss_train = 28025448.0 \t loss_valid = 25471124.0 \n",
      "Model_0_10680 \t loss_train = 28027220.0 \t loss_valid = 25467060.0 \n",
      "Model_0_10690 \t loss_train = 28003432.0 \t loss_valid = 25541922.0 \n",
      "Model_0_10700 \t loss_train = 28019396.0 \t loss_valid = 25486236.0 \n",
      "Model_0_10710 \t loss_train = 28027098.0 \t loss_valid = 25466410.0 \n",
      "Model_0_10720 \t loss_train = 28015214.0 \t loss_valid = 25498226.0 \n",
      "Model_0_10730 \t loss_train = 28033398.0 \t loss_valid = 25452416.0 \n",
      "Model_0_10740 \t loss_train = 28021228.0 \t loss_valid = 25481384.0 \n",
      "Model_0_10750 \t loss_train = 28011380.0 \t loss_valid = 25510886.0 \n",
      "Model_0_10760 \t loss_train = 28028644.0 \t loss_valid = 25463186.0 \n",
      "Model_0_10770 \t loss_train = 28015668.0 \t loss_valid = 25497136.0 \n",
      "Model_0_10780 \t loss_train = 28015044.0 \t loss_valid = 25499086.0 \n",
      "Model_0_10790 \t loss_train = 28016106.0 \t loss_valid = 25496096.0 \n",
      "Model_0_10800 \t loss_train = 28025372.0 \t loss_valid = 25471150.0 \n",
      "Model_0_10810 \t loss_train = 28024956.0 \t loss_valid = 25472304.0 \n",
      "Model_0_10820 \t loss_train = 28009342.0 \t loss_valid = 25518390.0 \n",
      "Model_0_10830 \t loss_train = 28016412.0 \t loss_valid = 25495254.0 \n",
      "Model_0_10840 \t loss_train = 28014388.0 \t loss_valid = 25501466.0 \n",
      "Model_0_10850 \t loss_train = 28005344.0 \t loss_valid = 25533942.0 \n",
      "Model_0_10860 \t loss_train = 28022688.0 \t loss_valid = 25478024.0 \n",
      "Model_0_10870 \t loss_train = 28026842.0 \t loss_valid = 25467404.0 \n",
      "Model_0_10880 \t loss_train = 28028746.0 \t loss_valid = 25462770.0 \n",
      "Model_0_10890 \t loss_train = 28032730.0 \t loss_valid = 25453708.0 \n",
      "Model_0_10900 \t loss_train = 28039468.0 \t loss_valid = 25439788.0 \n",
      "Model_0_10910 \t loss_train = 28016788.0 \t loss_valid = 25493456.0 \n",
      "Model_0_10920 \t loss_train = 28004298.0 \t loss_valid = 25537540.0 \n",
      "Model_0_10930 \t loss_train = 28011008.0 \t loss_valid = 25511702.0 \n",
      "Model_0_10940 \t loss_train = 28019990.0 \t loss_valid = 25484004.0 \n",
      "Model_0_10950 \t loss_train = 28012928.0 \t loss_valid = 25504936.0 \n",
      "Model_0_10960 \t loss_train = 28030764.0 \t loss_valid = 25457300.0 \n",
      "Model_0_10970 \t loss_train = 28022512.0 \t loss_valid = 25476974.0 \n",
      "Model_0_10980 \t loss_train = 28024064.0 \t loss_valid = 25473030.0 \n",
      "Model_0_10990 \t loss_train = 28017122.0 \t loss_valid = 25491762.0 \n",
      "Model_0_11000 \t loss_train = 28012924.0 \t loss_valid = 25504644.0 \n",
      "Model_0_11010 \t loss_train = 28019814.0 \t loss_valid = 25484012.0 \n",
      "Model_0_11020 \t loss_train = 28024672.0 \t loss_valid = 25471334.0 \n",
      "Model_0_11030 \t loss_train = 28010870.0 \t loss_valid = 25511548.0 \n",
      "Model_0_11040 \t loss_train = 28010114.0 \t loss_valid = 25514094.0 \n",
      "Model_0_11050 \t loss_train = 28021744.0 \t loss_valid = 25478960.0 \n",
      "Model_0_11060 \t loss_train = 28013698.0 \t loss_valid = 25502324.0 \n",
      "Model_0_11070 \t loss_train = 28000316.0 \t loss_valid = 25555660.0 \n",
      "Model_0_11080 \t loss_train = 28012608.0 \t loss_valid = 25506174.0 \n",
      "Model_0_11090 \t loss_train = 28031024.0 \t loss_valid = 25457096.0 \n",
      "Model_0_11100 \t loss_train = 28015168.0 \t loss_valid = 25498242.0 \n",
      "Model_0_11110 \t loss_train = 27996680.0 \t loss_valid = 25577010.0 \n",
      "Model_0_11120 \t loss_train = 28020812.0 \t loss_valid = 25482476.0 \n",
      "Model_0_11130 \t loss_train = 28028498.0 \t loss_valid = 25463498.0 \n",
      "Model_0_11140 \t loss_train = 28021054.0 \t loss_valid = 25482138.0 \n",
      "Model_0_11150 \t loss_train = 28023844.0 \t loss_valid = 25474926.0 \n",
      "Model_0_11160 \t loss_train = 28015408.0 \t loss_valid = 25498514.0 \n",
      "Model_0_11170 \t loss_train = 28023242.0 \t loss_valid = 25476506.0 \n",
      "Model_0_11180 \t loss_train = 28011020.0 \t loss_valid = 25512628.0 \n",
      "Model_0_11190 \t loss_train = 28010730.0 \t loss_valid = 25513722.0 \n",
      "Model_0_11200 \t loss_train = 28009628.0 \t loss_valid = 25517498.0 \n",
      "Model_0_11210 \t loss_train = 28026448.0 \t loss_valid = 25468094.0 \n",
      "Model_0_11220 \t loss_train = 28016930.0 \t loss_valid = 25493268.0 \n",
      "Model_0_11230 \t loss_train = 28008030.0 \t loss_valid = 25522656.0 \n",
      "Model_0_11240 \t loss_train = 28022604.0 \t loss_valid = 25476984.0 \n",
      "Model_0_11250 \t loss_train = 28014968.0 \t loss_valid = 25498452.0 \n",
      "Model_0_11260 \t loss_train = 28015684.0 \t loss_valid = 25496204.0 \n",
      "Model_0_11270 \t loss_train = 28015580.0 \t loss_valid = 25496474.0 \n",
      "Model_0_11280 \t loss_train = 28020160.0 \t loss_valid = 25483214.0 \n",
      "Model_0_11290 \t loss_train = 28018274.0 \t loss_valid = 25488440.0 \n",
      "Model_0_11300 \t loss_train = 28021772.0 \t loss_valid = 25478784.0 \n",
      "Model_0_11310 \t loss_train = 28028160.0 \t loss_valid = 25462816.0 \n",
      "Model_0_11320 \t loss_train = 28013260.0 \t loss_valid = 25503378.0 \n",
      "Model_0_11330 \t loss_train = 28016912.0 \t loss_valid = 25492070.0 \n",
      "Model_0_11340 \t loss_train = 28012830.0 \t loss_valid = 25504676.0 \n",
      "Model_0_11350 \t loss_train = 28032454.0 \t loss_valid = 25452860.0 \n",
      "Model_0_11360 \t loss_train = 28008508.0 \t loss_valid = 25519500.0 \n",
      "Model_0_11370 \t loss_train = 28021026.0 \t loss_valid = 25480188.0 \n",
      "Model_0_11380 \t loss_train = 28010690.0 \t loss_valid = 25511528.0 \n",
      "Model_0_11390 \t loss_train = 28015974.0 \t loss_valid = 25494484.0 \n",
      "Model_0_11400 \t loss_train = 28010270.0 \t loss_valid = 25512978.0 \n",
      "Model_0_11410 \t loss_train = 28011496.0 \t loss_valid = 25508730.0 \n",
      "Model_0_11420 \t loss_train = 28010252.0 \t loss_valid = 25512992.0 \n",
      "Model_0_11430 \t loss_train = 28027560.0 \t loss_valid = 25463616.0 \n",
      "Model_0_11440 \t loss_train = 28025028.0 \t loss_valid = 25469712.0 \n",
      "Model_0_11450 \t loss_train = 28014054.0 \t loss_valid = 25500258.0 \n",
      "Model_0_11460 \t loss_train = 28012202.0 \t loss_valid = 25506222.0 \n",
      "Model_0_11470 \t loss_train = 28020964.0 \t loss_valid = 25480106.0 \n",
      "Model_0_11480 \t loss_train = 28019940.0 \t loss_valid = 25482832.0 \n",
      "Model_0_11490 \t loss_train = 28002208.0 \t loss_valid = 25545266.0 \n",
      "Model_0_11500 \t loss_train = 28023404.0 \t loss_valid = 25473660.0 \n",
      "Model_0_11510 \t loss_train = 28037476.0 \t loss_valid = 25441962.0 \n",
      "Model_0_11520 \t loss_train = 28032356.0 \t loss_valid = 25452608.0 \n",
      "Model_0_11530 \t loss_train = 28009544.0 \t loss_valid = 25515248.0 \n",
      "Model_0_11540 \t loss_train = 28019584.0 \t loss_valid = 25483716.0 \n",
      "Model_0_11550 \t loss_train = 28017496.0 \t loss_valid = 25489600.0 \n",
      "Model_0_11560 \t loss_train = 28010120.0 \t loss_valid = 25513096.0 \n",
      "Model_0_11570 \t loss_train = 28004448.0 \t loss_valid = 25535036.0 \n",
      "Model_0_11580 \t loss_train = 28005450.0 \t loss_valid = 25530790.0 \n",
      "Model_0_11590 \t loss_train = 28014094.0 \t loss_valid = 25499796.0 \n",
      "Model_0_11600 \t loss_train = 28038132.0 \t loss_valid = 25440494.0 \n",
      "Model_0_11610 \t loss_train = 28025186.0 \t loss_valid = 25468954.0 \n",
      "Model_0_11620 \t loss_train = 28009540.0 \t loss_valid = 25515008.0 \n",
      "Model_0_11630 \t loss_train = 28014776.0 \t loss_valid = 25497596.0 \n",
      "Model_0_11640 \t loss_train = 28031304.0 \t loss_valid = 25454690.0 \n",
      "Model_0_11650 \t loss_train = 28022544.0 \t loss_valid = 25475594.0 \n",
      "Model_0_11660 \t loss_train = 28005006.0 \t loss_valid = 25532490.0 \n",
      "Model_0_11670 \t loss_train = 28014468.0 \t loss_valid = 25498496.0 \n",
      "Model_0_11680 \t loss_train = 28022874.0 \t loss_valid = 25474694.0 \n",
      "Model_0_11690 \t loss_train = 28006656.0 \t loss_valid = 25525742.0 \n",
      "Model_0_11700 \t loss_train = 28018990.0 \t loss_valid = 25485090.0 \n",
      "Model_0_11710 \t loss_train = 28013224.0 \t loss_valid = 25502394.0 \n",
      "Model_0_11720 \t loss_train = 28002260.0 \t loss_valid = 25544574.0 \n",
      "Model_0_11730 \t loss_train = 28011298.0 \t loss_valid = 25508792.0 \n",
      "Model_0_11740 \t loss_train = 28023358.0 \t loss_valid = 25473442.0 \n",
      "Model_0_11750 \t loss_train = 28006542.0 \t loss_valid = 25526208.0 \n",
      "Model_0_11760 \t loss_train = 28002338.0 \t loss_valid = 25544220.0 \n",
      "Model_0_11770 \t loss_train = 28015562.0 \t loss_valid = 25495094.0 \n",
      "Model_0_11780 \t loss_train = 28018186.0 \t loss_valid = 25487372.0 \n",
      "Model_0_11790 \t loss_train = 28015126.0 \t loss_valid = 25496412.0 \n",
      "Model_0_11800 \t loss_train = 28006088.0 \t loss_valid = 25527976.0 \n",
      "Model_0_11810 \t loss_train = 28010270.0 \t loss_valid = 25512312.0 \n",
      "Model_0_11820 \t loss_train = 28035942.0 \t loss_valid = 25444740.0 \n",
      "Model_0_11830 \t loss_train = 28040942.0 \t loss_valid = 25434914.0 \n",
      "Model_0_11840 \t loss_train = 28017712.0 \t loss_valid = 25488698.0 \n",
      "Model_0_11850 \t loss_train = 27999770.0 \t loss_valid = 25556906.0 \n",
      "Model_0_11860 \t loss_train = 28003534.0 \t loss_valid = 25538700.0 \n",
      "Model_0_11870 \t loss_train = 28024242.0 \t loss_valid = 25471128.0 \n",
      "Model_0_11880 \t loss_train = 28026250.0 \t loss_valid = 25466188.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_0_11890 \t loss_train = 28004972.0 \t loss_valid = 25532502.0 \n",
      "Model_0_11900 \t loss_train = 28008226.0 \t loss_valid = 25519636.0 \n",
      "Model_0_11910 \t loss_train = 28021176.0 \t loss_valid = 25479028.0 \n",
      "Model_0_11920 \t loss_train = 28039068.0 \t loss_valid = 25438428.0 \n",
      "Model_0_11930 \t loss_train = 28012778.0 \t loss_valid = 25503706.0 \n",
      "Model_0_11940 \t loss_train = 28005210.0 \t loss_valid = 25531406.0 \n",
      "Model_0_11950 \t loss_train = 28011016.0 \t loss_valid = 25509572.0 \n",
      "Model_0_11960 \t loss_train = 28004012.0 \t loss_valid = 25536490.0 \n",
      "Model_0_11970 \t loss_train = 28017580.0 \t loss_valid = 25488940.0 \n",
      "Model_0_11980 \t loss_train = 28013162.0 \t loss_valid = 25502422.0 \n",
      "Model_0_11990 \t loss_train = 28010374.0 \t loss_valid = 25511786.0 \n",
      "Model_0_12000 \t loss_train = 28002778.0 \t loss_valid = 25541998.0 \n",
      "Model_0_12010 \t loss_train = 28005112.0 \t loss_valid = 25531806.0 \n",
      "Model_0_12020 \t loss_train = 28014528.0 \t loss_valid = 25498106.0 \n",
      "Model_0_12030 \t loss_train = 28008254.0 \t loss_valid = 25519452.0 \n",
      "Model_0_12040 \t loss_train = 28013756.0 \t loss_valid = 25500542.0 \n",
      "Model_0_12050 \t loss_train = 28019428.0 \t loss_valid = 25483736.0 \n",
      "Model_0_12060 \t loss_train = 28003920.0 \t loss_valid = 25536916.0 \n",
      "Model_0_12070 \t loss_train = 28012106.0 \t loss_valid = 25505916.0 \n",
      "Model_0_12080 \t loss_train = 28037810.0 \t loss_valid = 25440882.0 \n",
      "Model_0_12090 \t loss_train = 28011164.0 \t loss_valid = 25509076.0 \n",
      "Model_0_12100 \t loss_train = 28002956.0 \t loss_valid = 25541180.0 \n",
      "Model_0_12110 \t loss_train = 28011144.0 \t loss_valid = 25509126.0 \n",
      "Model_0_12120 \t loss_train = 28011902.0 \t loss_valid = 25506554.0 \n",
      "Model_0_12130 \t loss_train = 28012090.0 \t loss_valid = 25505916.0 \n",
      "Model_0_12140 \t loss_train = 28016594.0 \t loss_valid = 25491806.0 \n",
      "Model_0_12150 \t loss_train = 28011178.0 \t loss_valid = 25508988.0 \n",
      "Model_0_12160 \t loss_train = 28014050.0 \t loss_valid = 25499562.0 \n",
      "Model_0_12170 \t loss_train = 28011240.0 \t loss_valid = 25508782.0 \n",
      "Model_0_12180 \t loss_train = 28014902.0 \t loss_valid = 25496920.0 \n",
      "Model_0_12190 \t loss_train = 28016762.0 \t loss_valid = 25491310.0 \n",
      "Model_0_12200 \t loss_train = 28006678.0 \t loss_valid = 25525450.0 \n",
      "Model_0_12210 \t loss_train = 27998754.0 \t loss_valid = 25562288.0 \n",
      "Model_0_12220 \t loss_train = 28021064.0 \t loss_valid = 25479248.0 \n",
      "Model_0_12230 \t loss_train = 28011214.0 \t loss_valid = 25508872.0 \n",
      "Model_0_12240 \t loss_train = 28002582.0 \t loss_valid = 25542872.0 \n",
      "Model_0_12250 \t loss_train = 28024346.0 \t loss_valid = 25470742.0 \n",
      "Model_0_12260 \t loss_train = 28019910.0 \t loss_valid = 25482358.0 \n",
      "Model_0_12270 \t loss_train = 28017614.0 \t loss_valid = 25488826.0 \n",
      "Model_0_12280 \t loss_train = 28011196.0 \t loss_valid = 25508944.0 \n",
      "Model_0_12290 \t loss_train = 28009126.0 \t loss_valid = 25516206.0 \n",
      "Model_0_12300 \t loss_train = 28010142.0 \t loss_valid = 25512558.0 \n",
      "Model_0_12310 \t loss_train = 28013852.0 \t loss_valid = 25500178.0 \n",
      "Model_0_12320 \t loss_train = 28006342.0 \t loss_valid = 25526772.0 \n",
      "Model_0_12330 \t loss_train = 28007772.0 \t loss_valid = 25521222.0 \n",
      "Model_0_12340 \t loss_train = 28014436.0 \t loss_valid = 25498352.0 \n",
      "Model_0_12350 \t loss_train = 28006514.0 \t loss_valid = 25526080.0 \n",
      "Model_0_12360 \t loss_train = 28012384.0 \t loss_valid = 25504922.0 \n",
      "Model_0_12370 \t loss_train = 28007164.0 \t loss_valid = 25523536.0 \n",
      "Model_0_12380 \t loss_train = 28022674.0 \t loss_valid = 25474996.0 \n",
      "Model_0_12390 \t loss_train = 28014618.0 \t loss_valid = 25497802.0 \n",
      "Model_0_12400 \t loss_train = 27999648.0 \t loss_valid = 25557380.0 \n",
      "Model_0_12410 \t loss_train = 28001710.0 \t loss_valid = 25546964.0 \n",
      "Model_0_12420 \t loss_train = 28023968.0 \t loss_valid = 25471678.0 \n",
      "Model_0_12430 \t loss_train = 28016744.0 \t loss_valid = 25491332.0 \n",
      "Model_0_12440 \t loss_train = 28009394.0 \t loss_valid = 25515202.0 \n",
      "Model_0_12450 \t loss_train = 28011424.0 \t loss_valid = 25508108.0 \n",
      "Model_0_12460 \t loss_train = 28006700.0 \t loss_valid = 25525310.0 \n",
      "Model_0_12470 \t loss_train = 28011132.0 \t loss_valid = 25509098.0 \n",
      "Model_0_12480 \t loss_train = 28017272.0 \t loss_valid = 25489758.0 \n",
      "Model_0_12490 \t loss_train = 28021860.0 \t loss_valid = 25477064.0 \n",
      "Model_0_12500 \t loss_train = 28011378.0 \t loss_valid = 25508250.0 \n",
      "Model_0_12510 \t loss_train = 28015702.0 \t loss_valid = 25494416.0 \n",
      "Model_0_12520 \t loss_train = 28012510.0 \t loss_valid = 25504464.0 \n",
      "Model_0_12530 \t loss_train = 28002878.0 \t loss_valid = 25541408.0 \n",
      "Model_0_12540 \t loss_train = 28013046.0 \t loss_valid = 25502674.0 \n",
      "Model_0_12550 \t loss_train = 28009966.0 \t loss_valid = 25513092.0 \n",
      "Model_0_12560 \t loss_train = 28017280.0 \t loss_valid = 25489684.0 \n",
      "Model_0_12570 \t loss_train = 28008194.0 \t loss_valid = 25519514.0 \n",
      "Model_0_12580 \t loss_train = 28010296.0 \t loss_valid = 25511914.0 \n",
      "Model_0_12590 \t loss_train = 28018882.0 \t loss_valid = 25485104.0 \n",
      "Model_0_12600 \t loss_train = 27998140.0 \t loss_valid = 25565632.0 \n",
      "Model_0_12610 \t loss_train = 28001438.0 \t loss_valid = 25548156.0 \n",
      "Model_0_12620 \t loss_train = 28023128.0 \t loss_valid = 25473706.0 \n",
      "Model_0_12630 \t loss_train = 28028210.0 \t loss_valid = 25461302.0 \n",
      "Model_0_12640 \t loss_train = 28001024.0 \t loss_valid = 25550166.0 \n",
      "Model_0_12650 \t loss_train = 27999084.0 \t loss_valid = 25560314.0 \n",
      "Model_0_12660 \t loss_train = 28003692.0 \t loss_valid = 25537732.0 \n",
      "Model_0_12670 \t loss_train = 28011540.0 \t loss_valid = 25507628.0 \n",
      "Model_0_12680 \t loss_train = 28009862.0 \t loss_valid = 25513424.0 \n",
      "Model_0_12690 \t loss_train = 28007806.0 \t loss_valid = 25520940.0 \n",
      "Model_0_12700 \t loss_train = 28014426.0 \t loss_valid = 25498238.0 \n",
      "Model_0_12710 \t loss_train = 28022404.0 \t loss_valid = 25475546.0 \n",
      "Model_0_12720 \t loss_train = 28018466.0 \t loss_valid = 25486220.0 \n",
      "Model_0_12730 \t loss_train = 28000446.0 \t loss_valid = 25553034.0 \n",
      "Model_0_12740 \t loss_train = 28011284.0 \t loss_valid = 25508438.0 \n",
      "Model_0_12750 \t loss_train = 28019374.0 \t loss_valid = 25483660.0 \n",
      "Model_0_12760 \t loss_train = 28013270.0 \t loss_valid = 25501866.0 \n",
      "Model_0_12770 \t loss_train = 28008046.0 \t loss_valid = 25519990.0 \n",
      "Model_0_12780 \t loss_train = 28012248.0 \t loss_valid = 25505200.0 \n",
      "Model_0_12790 \t loss_train = 28017524.0 \t loss_valid = 25488898.0 \n",
      "Model_0_12800 \t loss_train = 28003780.0 \t loss_valid = 25537262.0 \n",
      "Model_0_12810 \t loss_train = 28010308.0 \t loss_valid = 25511782.0 \n",
      "Model_0_12820 \t loss_train = 28012216.0 \t loss_valid = 25505290.0 \n",
      "Model_0_12830 \t loss_train = 28016702.0 \t loss_valid = 25491266.0 \n",
      "Model_0_12840 \t loss_train = 28002870.0 \t loss_valid = 25541296.0 \n",
      "Model_0_12850 \t loss_train = 28006558.0 \t loss_valid = 25525684.0 \n",
      "Model_0_12860 \t loss_train = 28000300.0 \t loss_valid = 25553718.0 \n",
      "Model_0_12870 \t loss_train = 28016644.0 \t loss_valid = 25491424.0 \n",
      "Model_0_12880 \t loss_train = 28008584.0 \t loss_valid = 25517942.0 \n",
      "Model_0_12890 \t loss_train = 28007046.0 \t loss_valid = 25523750.0 \n",
      "Model_0_12900 \t loss_train = 28017008.0 \t loss_valid = 25490356.0 \n",
      "Model_0_12910 \t loss_train = 28019878.0 \t loss_valid = 25482226.0 \n",
      "Model_0_12920 \t loss_train = 28009130.0 \t loss_valid = 25515960.0 \n",
      "Model_0_12930 \t loss_train = 28009658.0 \t loss_valid = 25514044.0 \n",
      "Model_0_12940 \t loss_train = 28001882.0 \t loss_valid = 25545876.0 \n",
      "Model_0_12950 \t loss_train = 27999316.0 \t loss_valid = 25558900.0 \n",
      "Model_0_12960 \t loss_train = 28016288.0 \t loss_valid = 25492466.0 \n",
      "Model_0_12970 \t loss_train = 28035008.0 \t loss_valid = 25446284.0 \n",
      "Model_0_12980 \t loss_train = 28018916.0 \t loss_valid = 25484866.0 \n",
      "Model_0_12990 \t loss_train = 28010990.0 \t loss_valid = 25509364.0 \n",
      "Model_0_13000 \t loss_train = 28016732.0 \t loss_valid = 25491140.0 \n",
      "Model_0_13010 \t loss_train = 28010176.0 \t loss_valid = 25512196.0 \n",
      "Model_0_13020 \t loss_train = 28005062.0 \t loss_valid = 25531718.0 \n",
      "Model_0_13030 \t loss_train = 28018612.0 \t loss_valid = 25485716.0 \n",
      "Model_0_13040 \t loss_train = 28003710.0 \t loss_valid = 25537498.0 \n",
      "Model_0_13050 \t loss_train = 27999950.0 \t loss_valid = 25555504.0 \n",
      "Model_0_13060 \t loss_train = 28005768.0 \t loss_valid = 25528802.0 \n",
      "Model_0_13070 \t loss_train = 28005590.0 \t loss_valid = 25529540.0 \n",
      "Model_0_13080 \t loss_train = 28000428.0 \t loss_valid = 25553036.0 \n",
      "Model_0_13090 \t loss_train = 28007662.0 \t loss_valid = 25521374.0 \n",
      "Model_0_13100 \t loss_train = 28017478.0 \t loss_valid = 25488972.0 \n",
      "Model_0_13110 \t loss_train = 28001104.0 \t loss_valid = 25549638.0 \n",
      "Model_0_13120 \t loss_train = 28005090.0 \t loss_valid = 25531616.0 \n",
      "Model_0_13130 \t loss_train = 28013814.0 \t loss_valid = 25500072.0 \n",
      "Model_0_13140 \t loss_train = 28003930.0 \t loss_valid = 25536542.0 \n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_1_0 \t loss_train = 119448136.0 \t loss_valid = 104476344.0 \n",
      "Model_1_10 \t loss_train = 118586720.0 \t loss_valid = 103244976.0 \n",
      "Model_1_20 \t loss_train = 116971320.0 \t loss_valid = 100859408.0 \n",
      "Model_1_30 \t loss_train = 113551576.0 \t loss_valid = 95848648.0 \n",
      "Model_1_40 \t loss_train = 106943312.0 \t loss_valid = 86429776.0 \n",
      "Model_1_50 \t loss_train = 95261096.0 \t loss_valid = 71125008.0 \n",
      "Model_1_60 \t loss_train = 80854528.0 \t loss_valid = 58447044.0 \n",
      "Model_1_70 \t loss_train = 77299216.0 \t loss_valid = 70882240.0 \n",
      "Model_1_80 \t loss_train = 76516440.0 \t loss_valid = 63360476.0 \n",
      "Model_1_90 \t loss_train = 77004168.0 \t loss_valid = 59353828.0 \n",
      "Model_1_100 \t loss_train = 76295232.0 \t loss_valid = 60153604.0 \n",
      "Model_1_110 \t loss_train = 75474592.0 \t loss_valid = 62876792.0 \n",
      "Model_1_120 \t loss_train = 75232736.0 \t loss_valid = 61417496.0 \n",
      "Model_1_130 \t loss_train = 74978832.0 \t loss_valid = 60259876.0 \n",
      "Model_1_140 \t loss_train = 74340672.0 \t loss_valid = 61155820.0 \n",
      "Model_1_150 \t loss_train = 73831496.0 \t loss_valid = 61312052.0 \n",
      "Model_1_160 \t loss_train = 73357576.0 \t loss_valid = 60502716.0 \n",
      "Model_1_170 \t loss_train = 73128880.0 \t loss_valid = 58349056.0 \n",
      "Model_1_180 \t loss_train = 72082712.0 \t loss_valid = 60735164.0 \n",
      "Model_1_190 \t loss_train = 71859232.0 \t loss_valid = 57194244.0 \n",
      "Model_1_200 \t loss_train = 70884000.0 \t loss_valid = 57051656.0 \n",
      "Model_1_210 \t loss_train = 69541816.0 \t loss_valid = 58515132.0 \n",
      "Model_1_220 \t loss_train = 68448920.0 \t loss_valid = 56355304.0 \n",
      "Model_1_230 \t loss_train = 66921492.0 \t loss_valid = 55409412.0 \n",
      "Model_1_240 \t loss_train = 64967424.0 \t loss_valid = 54579888.0 \n",
      "Model_1_250 \t loss_train = 62688648.0 \t loss_valid = 52180488.0 \n",
      "Model_1_260 \t loss_train = 59708712.0 \t loss_valid = 50090940.0 \n",
      "Model_1_270 \t loss_train = 55938536.0 \t loss_valid = 49045492.0 \n",
      "Model_1_280 \t loss_train = 51497068.0 \t loss_valid = 43032388.0 \n",
      "Model_1_290 \t loss_train = 46076492.0 \t loss_valid = 38503132.0 \n",
      "Model_1_300 \t loss_train = 39931764.0 \t loss_valid = 34625752.0 \n",
      "Model_1_310 \t loss_train = 34528600.0 \t loss_valid = 30123064.0 \n",
      "Model_1_320 \t loss_train = 30862790.0 \t loss_valid = 26457224.0 \n",
      "Model_1_330 \t loss_train = 28712826.0 \t loss_valid = 25393232.0 \n",
      "Model_1_340 \t loss_train = 28105214.0 \t loss_valid = 25399924.0 \n",
      "Model_1_350 \t loss_train = 28142198.0 \t loss_valid = 25377110.0 \n",
      "Model_1_360 \t loss_train = 28227382.0 \t loss_valid = 25299520.0 \n",
      "Model_1_370 \t loss_train = 28290600.0 \t loss_valid = 25267368.0 \n",
      "Model_1_380 \t loss_train = 28477596.0 \t loss_valid = 25279976.0 \n",
      "Model_1_390 \t loss_train = 28386428.0 \t loss_valid = 25260438.0 \n",
      "Model_1_400 \t loss_train = 28251614.0 \t loss_valid = 25311408.0 \n",
      "Model_1_410 \t loss_train = 28231000.0 \t loss_valid = 25326192.0 \n",
      "Model_1_420 \t loss_train = 28374342.0 \t loss_valid = 25273898.0 \n",
      "Model_1_430 \t loss_train = 28601286.0 \t loss_valid = 25349624.0 \n",
      "Model_1_440 \t loss_train = 28243882.0 \t loss_valid = 25287912.0 \n",
      "Model_1_450 \t loss_train = 28546810.0 \t loss_valid = 25321432.0 \n",
      "Model_1_460 \t loss_train = 28293162.0 \t loss_valid = 25289200.0 \n",
      "Model_1_470 \t loss_train = 28176080.0 \t loss_valid = 25392826.0 \n",
      "Model_1_480 \t loss_train = 28222766.0 \t loss_valid = 25314808.0 \n",
      "Model_1_490 \t loss_train = 28211798.0 \t loss_valid = 25330012.0 \n",
      "Model_1_500 \t loss_train = 28153030.0 \t loss_valid = 25472958.0 \n",
      "Model_1_510 \t loss_train = 28215052.0 \t loss_valid = 25312998.0 \n",
      "Model_1_520 \t loss_train = 28207996.0 \t loss_valid = 25303720.0 \n",
      "Model_1_530 \t loss_train = 28088974.0 \t loss_valid = 25436000.0 \n",
      "Model_1_540 \t loss_train = 28223870.0 \t loss_valid = 25280586.0 \n",
      "Model_1_550 \t loss_train = 28236970.0 \t loss_valid = 25305002.0 \n",
      "Model_1_560 \t loss_train = 28257180.0 \t loss_valid = 25289298.0 \n",
      "Model_1_570 \t loss_train = 28149350.0 \t loss_valid = 25365266.0 \n",
      "Model_1_580 \t loss_train = 28609272.0 \t loss_valid = 25384154.0 \n",
      "Model_1_590 \t loss_train = 28339450.0 \t loss_valid = 25264716.0 \n",
      "Model_1_600 \t loss_train = 28111210.0 \t loss_valid = 25428126.0 \n",
      "Model_1_610 \t loss_train = 28078660.0 \t loss_valid = 25575478.0 \n",
      "Model_1_620 \t loss_train = 28245552.0 \t loss_valid = 25285598.0 \n",
      "Model_1_630 \t loss_train = 28318894.0 \t loss_valid = 25274958.0 \n",
      "Model_1_640 \t loss_train = 28380716.0 \t loss_valid = 25265468.0 \n",
      "Model_1_650 \t loss_train = 28226384.0 \t loss_valid = 25301656.0 \n",
      "Model_1_660 \t loss_train = 28153918.0 \t loss_valid = 25457744.0 \n",
      "Model_1_670 \t loss_train = 28228276.0 \t loss_valid = 25369026.0 \n",
      "Model_1_680 \t loss_train = 28186958.0 \t loss_valid = 25365932.0 \n",
      "Model_1_690 \t loss_train = 28592540.0 \t loss_valid = 25381574.0 \n",
      "Model_1_700 \t loss_train = 28543726.0 \t loss_valid = 25356648.0 \n",
      "Model_1_710 \t loss_train = 28109126.0 \t loss_valid = 25445448.0 \n",
      "Model_1_720 \t loss_train = 28178470.0 \t loss_valid = 25315036.0 \n",
      "Model_1_730 \t loss_train = 28173432.0 \t loss_valid = 25308572.0 \n",
      "Model_1_740 \t loss_train = 28176830.0 \t loss_valid = 25313570.0 \n",
      "Model_1_750 \t loss_train = 28398484.0 \t loss_valid = 25264244.0 \n",
      "Model_1_760 \t loss_train = 28174432.0 \t loss_valid = 25385836.0 \n",
      "Model_1_770 \t loss_train = 28126628.0 \t loss_valid = 25478916.0 \n",
      "Model_1_780 \t loss_train = 28464710.0 \t loss_valid = 25273876.0 \n",
      "Model_1_790 \t loss_train = 28216138.0 \t loss_valid = 25287570.0 \n",
      "Model_1_800 \t loss_train = 28146188.0 \t loss_valid = 25420022.0 \n",
      "Model_1_810 \t loss_train = 28240804.0 \t loss_valid = 25308848.0 \n",
      "Model_1_820 \t loss_train = 28413072.0 \t loss_valid = 25267060.0 \n",
      "Model_1_830 \t loss_train = 28140224.0 \t loss_valid = 25349108.0 \n",
      "Model_1_840 \t loss_train = 28173798.0 \t loss_valid = 25297186.0 \n",
      "Model_1_850 \t loss_train = 28241820.0 \t loss_valid = 25272700.0 \n",
      "Model_1_860 \t loss_train = 28202590.0 \t loss_valid = 25291818.0 \n",
      "Model_1_870 \t loss_train = 28286424.0 \t loss_valid = 25264242.0 \n",
      "Model_1_880 \t loss_train = 28187268.0 \t loss_valid = 25337106.0 \n",
      "Model_1_890 \t loss_train = 28187018.0 \t loss_valid = 25359940.0 \n",
      "Model_1_900 \t loss_train = 28239754.0 \t loss_valid = 25281884.0 \n",
      "Model_1_910 \t loss_train = 28152410.0 \t loss_valid = 25345024.0 \n",
      "Model_1_920 \t loss_train = 28084728.0 \t loss_valid = 25563222.0 \n",
      "Model_1_930 \t loss_train = 28209390.0 \t loss_valid = 25282084.0 \n",
      "Model_1_940 \t loss_train = 28167512.0 \t loss_valid = 25309880.0 \n",
      "Model_1_950 \t loss_train = 28204474.0 \t loss_valid = 25300494.0 \n",
      "Model_1_960 \t loss_train = 28243398.0 \t loss_valid = 25273562.0 \n",
      "Model_1_970 \t loss_train = 28158718.0 \t loss_valid = 25367420.0 \n",
      "Model_1_980 \t loss_train = 28211964.0 \t loss_valid = 25330912.0 \n",
      "Model_1_990 \t loss_train = 28538002.0 \t loss_valid = 25324752.0 \n",
      "Model_1_1000 \t loss_train = 28243790.0 \t loss_valid = 25271182.0 \n",
      "Model_1_1010 \t loss_train = 28133820.0 \t loss_valid = 25377650.0 \n",
      "Model_1_1020 \t loss_train = 28548790.0 \t loss_valid = 25311022.0 \n",
      "Model_1_1030 \t loss_train = 28376704.0 \t loss_valid = 25261858.0 \n",
      "Model_1_1040 \t loss_train = 28076998.0 \t loss_valid = 25610584.0 \n",
      "Model_1_1050 \t loss_train = 28122456.0 \t loss_valid = 25331458.0 \n",
      "Model_1_1060 \t loss_train = 28135268.0 \t loss_valid = 25363552.0 \n",
      "Model_1_1070 \t loss_train = 28165302.0 \t loss_valid = 25316356.0 \n",
      "Model_1_1080 \t loss_train = 28176062.0 \t loss_valid = 25310540.0 \n",
      "Model_1_1090 \t loss_train = 28200544.0 \t loss_valid = 25301312.0 \n",
      "Model_1_1100 \t loss_train = 28150560.0 \t loss_valid = 25351134.0 \n",
      "Model_1_1110 \t loss_train = 28346786.0 \t loss_valid = 25264908.0 \n",
      "Model_1_1120 \t loss_train = 28192872.0 \t loss_valid = 25294588.0 \n",
      "Model_1_1130 \t loss_train = 28135804.0 \t loss_valid = 25494050.0 \n",
      "Model_1_1140 \t loss_train = 28188526.0 \t loss_valid = 25325264.0 \n",
      "Model_1_1150 \t loss_train = 28450008.0 \t loss_valid = 25283954.0 \n",
      "Model_1_1160 \t loss_train = 28118156.0 \t loss_valid = 25372032.0 \n",
      "Model_1_1170 \t loss_train = 28126354.0 \t loss_valid = 25357074.0 \n",
      "Model_1_1180 \t loss_train = 28299700.0 \t loss_valid = 25261956.0 \n",
      "Model_1_1190 \t loss_train = 28228808.0 \t loss_valid = 25278196.0 \n",
      "Model_1_1200 \t loss_train = 28226292.0 \t loss_valid = 25274606.0 \n",
      "Model_1_1210 \t loss_train = 28223304.0 \t loss_valid = 25275332.0 \n",
      "Model_1_1220 \t loss_train = 28119450.0 \t loss_valid = 25429044.0 \n",
      "Model_1_1230 \t loss_train = 28111048.0 \t loss_valid = 25384258.0 \n",
      "Model_1_1240 \t loss_train = 28172736.0 \t loss_valid = 25319450.0 \n",
      "Model_1_1250 \t loss_train = 28421440.0 \t loss_valid = 25266508.0 \n",
      "Model_1_1260 \t loss_train = 28081022.0 \t loss_valid = 25780966.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_1_1270 \t loss_train = 28286108.0 \t loss_valid = 25274406.0 \n",
      "Model_1_1280 \t loss_train = 28182934.0 \t loss_valid = 25303390.0 \n",
      "Model_1_1290 \t loss_train = 28137058.0 \t loss_valid = 25323802.0 \n",
      "Model_1_1300 \t loss_train = 28143722.0 \t loss_valid = 25333858.0 \n",
      "Model_1_1310 \t loss_train = 28179102.0 \t loss_valid = 25324390.0 \n",
      "Model_1_1320 \t loss_train = 28164038.0 \t loss_valid = 25307348.0 \n",
      "Model_1_1330 \t loss_train = 28185240.0 \t loss_valid = 25291870.0 \n",
      "Model_1_1340 \t loss_train = 28201756.0 \t loss_valid = 25286906.0 \n",
      "Model_1_1350 \t loss_train = 28175956.0 \t loss_valid = 25319364.0 \n",
      "Model_1_1360 \t loss_train = 28120990.0 \t loss_valid = 25358790.0 \n",
      "Model_1_1370 \t loss_train = 28281096.0 \t loss_valid = 25269576.0 \n",
      "Model_1_1380 \t loss_train = 28453820.0 \t loss_valid = 25286070.0 \n",
      "Model_1_1390 \t loss_train = 28173766.0 \t loss_valid = 25354878.0 \n",
      "Model_1_1400 \t loss_train = 28167006.0 \t loss_valid = 25430118.0 \n",
      "Model_1_1410 \t loss_train = 28299858.0 \t loss_valid = 25268116.0 \n",
      "Model_1_1420 \t loss_train = 28146454.0 \t loss_valid = 25334464.0 \n",
      "Model_1_1430 \t loss_train = 28261290.0 \t loss_valid = 25272272.0 \n",
      "Model_1_1440 \t loss_train = 28181962.0 \t loss_valid = 25331782.0 \n",
      "Model_1_1450 \t loss_train = 28280268.0 \t loss_valid = 25264884.0 \n",
      "Model_1_1460 \t loss_train = 28240524.0 \t loss_valid = 25269860.0 \n",
      "Model_1_1470 \t loss_train = 28127802.0 \t loss_valid = 25423372.0 \n",
      "Model_1_1480 \t loss_train = 28355258.0 \t loss_valid = 25256192.0 \n",
      "Model_1_1490 \t loss_train = 28204220.0 \t loss_valid = 25335080.0 \n",
      "Model_1_1500 \t loss_train = 28159818.0 \t loss_valid = 25309398.0 \n",
      "Model_1_1510 \t loss_train = 28113990.0 \t loss_valid = 25347222.0 \n",
      "Model_1_1520 \t loss_train = 28183148.0 \t loss_valid = 25303100.0 \n",
      "Model_1_1530 \t loss_train = 28073534.0 \t loss_valid = 25438594.0 \n",
      "Model_1_1540 \t loss_train = 28261030.0 \t loss_valid = 25268014.0 \n",
      "Model_1_1550 \t loss_train = 28280050.0 \t loss_valid = 25278008.0 \n",
      "Model_1_1560 \t loss_train = 28107746.0 \t loss_valid = 25380856.0 \n",
      "Model_1_1570 \t loss_train = 28230324.0 \t loss_valid = 25286498.0 \n",
      "Model_1_1580 \t loss_train = 28174056.0 \t loss_valid = 25294646.0 \n",
      "Model_1_1590 \t loss_train = 28110004.0 \t loss_valid = 25374590.0 \n",
      "Model_1_1600 \t loss_train = 28198392.0 \t loss_valid = 25289684.0 \n",
      "Model_1_1610 \t loss_train = 28102642.0 \t loss_valid = 25590518.0 \n",
      "Model_1_1620 \t loss_train = 28333318.0 \t loss_valid = 25256278.0 \n",
      "Model_1_1630 \t loss_train = 28179168.0 \t loss_valid = 25291688.0 \n",
      "Model_1_1640 \t loss_train = 28077736.0 \t loss_valid = 25373790.0 \n",
      "Model_1_1650 \t loss_train = 28165530.0 \t loss_valid = 25314376.0 \n",
      "Model_1_1660 \t loss_train = 28237446.0 \t loss_valid = 25273302.0 \n",
      "Model_1_1670 \t loss_train = 28166776.0 \t loss_valid = 25390614.0 \n",
      "Model_1_1680 \t loss_train = 28182692.0 \t loss_valid = 25348728.0 \n",
      "Model_1_1690 \t loss_train = 28173320.0 \t loss_valid = 25301432.0 \n",
      "Model_1_1700 \t loss_train = 28087450.0 \t loss_valid = 25420954.0 \n",
      "Model_1_1710 \t loss_train = 28156942.0 \t loss_valid = 25368080.0 \n",
      "Model_1_1720 \t loss_train = 28264688.0 \t loss_valid = 25266122.0 \n",
      "Model_1_1730 \t loss_train = 28252946.0 \t loss_valid = 25267950.0 \n",
      "Model_1_1740 \t loss_train = 28072796.0 \t loss_valid = 25490218.0 \n",
      "Model_1_1750 \t loss_train = 28159070.0 \t loss_valid = 25326234.0 \n",
      "Model_1_1760 \t loss_train = 28254942.0 \t loss_valid = 25268856.0 \n",
      "Model_1_1770 \t loss_train = 28329994.0 \t loss_valid = 25279424.0 \n",
      "Model_1_1780 \t loss_train = 28128268.0 \t loss_valid = 25358446.0 \n",
      "Model_1_1790 \t loss_train = 28369030.0 \t loss_valid = 25281438.0 \n",
      "Model_1_1800 \t loss_train = 28205080.0 \t loss_valid = 25282774.0 \n",
      "Model_1_1810 \t loss_train = 28166102.0 \t loss_valid = 25333160.0 \n",
      "Model_1_1820 \t loss_train = 28344256.0 \t loss_valid = 25256682.0 \n",
      "Model_1_1830 \t loss_train = 28157972.0 \t loss_valid = 25305912.0 \n",
      "Model_1_1840 \t loss_train = 28254070.0 \t loss_valid = 25268656.0 \n",
      "Model_1_1850 \t loss_train = 28116278.0 \t loss_valid = 25357796.0 \n",
      "Model_1_1860 \t loss_train = 28179286.0 \t loss_valid = 25292706.0 \n",
      "Model_1_1870 \t loss_train = 28238348.0 \t loss_valid = 25272160.0 \n",
      "Model_1_1880 \t loss_train = 28077542.0 \t loss_valid = 25498024.0 \n",
      "Model_1_1890 \t loss_train = 28224082.0 \t loss_valid = 25276496.0 \n",
      "Model_1_1900 \t loss_train = 28086370.0 \t loss_valid = 25427882.0 \n",
      "Model_1_1910 \t loss_train = 28163384.0 \t loss_valid = 25335874.0 \n",
      "Model_1_1920 \t loss_train = 28224846.0 \t loss_valid = 25277168.0 \n",
      "Model_1_1930 \t loss_train = 28289546.0 \t loss_valid = 25260370.0 \n",
      "Model_1_1940 \t loss_train = 28240466.0 \t loss_valid = 25270974.0 \n",
      "Model_1_1950 \t loss_train = 28172514.0 \t loss_valid = 25322670.0 \n",
      "Model_1_1960 \t loss_train = 28357092.0 \t loss_valid = 25260262.0 \n",
      "Model_1_1970 \t loss_train = 28081644.0 \t loss_valid = 25476334.0 \n",
      "Model_1_1980 \t loss_train = 28299330.0 \t loss_valid = 25257388.0 \n",
      "Model_1_1990 \t loss_train = 28265792.0 \t loss_valid = 25266512.0 \n",
      "Model_1_2000 \t loss_train = 28117278.0 \t loss_valid = 25358956.0 \n",
      "Model_1_2010 \t loss_train = 28310914.0 \t loss_valid = 25257356.0 \n",
      "Model_1_2020 \t loss_train = 28394628.0 \t loss_valid = 25253762.0 \n",
      "Model_1_2030 \t loss_train = 28077730.0 \t loss_valid = 25414998.0 \n",
      "Model_1_2040 \t loss_train = 28325050.0 \t loss_valid = 25262316.0 \n",
      "Model_1_2050 \t loss_train = 28221162.0 \t loss_valid = 25280888.0 \n",
      "Model_1_2060 \t loss_train = 28243736.0 \t loss_valid = 25268372.0 \n",
      "Model_1_2070 \t loss_train = 28293650.0 \t loss_valid = 25272630.0 \n",
      "Model_1_2080 \t loss_train = 28079418.0 \t loss_valid = 25399340.0 \n",
      "Model_1_2090 \t loss_train = 28153014.0 \t loss_valid = 25389556.0 \n",
      "Model_1_2100 \t loss_train = 28640588.0 \t loss_valid = 25311112.0 \n",
      "Model_1_2110 \t loss_train = 28075402.0 \t loss_valid = 25613940.0 \n",
      "Model_1_2120 \t loss_train = 28197898.0 \t loss_valid = 25284148.0 \n",
      "Model_1_2130 \t loss_train = 28236198.0 \t loss_valid = 25274554.0 \n",
      "Model_1_2140 \t loss_train = 28229100.0 \t loss_valid = 25274942.0 \n",
      "Model_1_2150 \t loss_train = 28124212.0 \t loss_valid = 25395342.0 \n",
      "Model_1_2160 \t loss_train = 28328970.0 \t loss_valid = 25256460.0 \n",
      "Model_1_2170 \t loss_train = 28085878.0 \t loss_valid = 25475768.0 \n",
      "Model_1_2180 \t loss_train = 28125898.0 \t loss_valid = 25347048.0 \n",
      "Model_1_2190 \t loss_train = 28157014.0 \t loss_valid = 25318354.0 \n",
      "Model_1_2200 \t loss_train = 28274782.0 \t loss_valid = 25266748.0 \n",
      "Model_1_2210 \t loss_train = 28114654.0 \t loss_valid = 25357136.0 \n",
      "Model_1_2220 \t loss_train = 28275912.0 \t loss_valid = 25265914.0 \n",
      "Model_1_2230 \t loss_train = 28172866.0 \t loss_valid = 25327048.0 \n",
      "Model_1_2240 \t loss_train = 28203942.0 \t loss_valid = 25283828.0 \n",
      "Model_1_2250 \t loss_train = 28379758.0 \t loss_valid = 25325220.0 \n",
      "Model_1_2260 \t loss_train = 28066988.0 \t loss_valid = 25454238.0 \n",
      "Model_1_2270 \t loss_train = 28285388.0 \t loss_valid = 25259586.0 \n",
      "Model_1_2280 \t loss_train = 28170940.0 \t loss_valid = 25302722.0 \n",
      "Model_1_2290 \t loss_train = 28143268.0 \t loss_valid = 25378290.0 \n",
      "Model_1_2300 \t loss_train = 28433936.0 \t loss_valid = 25272876.0 \n",
      "Model_1_2310 \t loss_train = 28093928.0 \t loss_valid = 25352482.0 \n",
      "Model_1_2320 \t loss_train = 28133086.0 \t loss_valid = 25315156.0 \n",
      "Model_1_2330 \t loss_train = 28192622.0 \t loss_valid = 25281944.0 \n",
      "Model_1_2340 \t loss_train = 28152962.0 \t loss_valid = 25302276.0 \n",
      "Model_1_2350 \t loss_train = 28160572.0 \t loss_valid = 25333008.0 \n",
      "Model_1_2360 \t loss_train = 28250656.0 \t loss_valid = 25266076.0 \n",
      "Model_1_2370 \t loss_train = 28098946.0 \t loss_valid = 25398432.0 \n",
      "Model_1_2380 \t loss_train = 28169392.0 \t loss_valid = 25305598.0 \n",
      "Model_1_2390 \t loss_train = 28148324.0 \t loss_valid = 25371200.0 \n",
      "Model_1_2400 \t loss_train = 28233736.0 \t loss_valid = 25270048.0 \n",
      "Model_1_2410 \t loss_train = 28253496.0 \t loss_valid = 25267906.0 \n",
      "Model_1_2420 \t loss_train = 28106092.0 \t loss_valid = 25358984.0 \n",
      "Model_1_2430 \t loss_train = 28188108.0 \t loss_valid = 25329248.0 \n",
      "Model_1_2440 \t loss_train = 28152582.0 \t loss_valid = 25319042.0 \n",
      "Model_1_2450 \t loss_train = 28185460.0 \t loss_valid = 25292984.0 \n",
      "Model_1_2460 \t loss_train = 28136330.0 \t loss_valid = 25321750.0 \n",
      "Model_1_2470 \t loss_train = 28237248.0 \t loss_valid = 25296274.0 \n",
      "Model_1_2480 \t loss_train = 28195572.0 \t loss_valid = 25391996.0 \n",
      "Model_1_2490 \t loss_train = 28048308.0 \t loss_valid = 25591646.0 \n",
      "Model_1_2500 \t loss_train = 28370996.0 \t loss_valid = 25291962.0 \n",
      "Model_1_2510 \t loss_train = 28101344.0 \t loss_valid = 25348712.0 \n",
      "Model_1_2520 \t loss_train = 28154344.0 \t loss_valid = 25321160.0 \n",
      "Model_1_2530 \t loss_train = 28319078.0 \t loss_valid = 25261452.0 \n",
      "Model_1_2540 \t loss_train = 28075530.0 \t loss_valid = 25432440.0 \n",
      "Model_1_2550 \t loss_train = 28193966.0 \t loss_valid = 25284482.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_1_2560 \t loss_train = 28165782.0 \t loss_valid = 25304698.0 \n",
      "Model_1_2570 \t loss_train = 28288878.0 \t loss_valid = 25264976.0 \n",
      "Model_1_2580 \t loss_train = 28316806.0 \t loss_valid = 25254588.0 \n",
      "Model_1_2590 \t loss_train = 28098874.0 \t loss_valid = 25367556.0 \n",
      "Model_1_2600 \t loss_train = 28200058.0 \t loss_valid = 25283260.0 \n",
      "Model_1_2610 \t loss_train = 28090698.0 \t loss_valid = 25360522.0 \n",
      "Model_1_2620 \t loss_train = 28218600.0 \t loss_valid = 25298090.0 \n",
      "Model_1_2630 \t loss_train = 28139484.0 \t loss_valid = 25392346.0 \n",
      "Model_1_2640 \t loss_train = 28219922.0 \t loss_valid = 25277136.0 \n",
      "Model_1_2650 \t loss_train = 28070278.0 \t loss_valid = 25496316.0 \n",
      "Model_1_2660 \t loss_train = 28252498.0 \t loss_valid = 25276240.0 \n",
      "Model_1_2670 \t loss_train = 28112510.0 \t loss_valid = 25331248.0 \n",
      "Model_1_2680 \t loss_train = 28084366.0 \t loss_valid = 25429844.0 \n",
      "Model_1_2690 \t loss_train = 28211878.0 \t loss_valid = 25284222.0 \n",
      "Model_1_2700 \t loss_train = 28162560.0 \t loss_valid = 25317760.0 \n",
      "Model_1_2710 \t loss_train = 28105428.0 \t loss_valid = 25378384.0 \n",
      "Model_1_2720 \t loss_train = 28180998.0 \t loss_valid = 25293628.0 \n",
      "Model_1_2730 \t loss_train = 28063778.0 \t loss_valid = 25440432.0 \n",
      "Model_1_2740 \t loss_train = 28174548.0 \t loss_valid = 25292230.0 \n",
      "Model_1_2750 \t loss_train = 28220248.0 \t loss_valid = 25276132.0 \n",
      "Model_1_2760 \t loss_train = 28229198.0 \t loss_valid = 25271234.0 \n",
      "Model_1_2770 \t loss_train = 28188992.0 \t loss_valid = 25286196.0 \n",
      "Model_1_2780 \t loss_train = 28177170.0 \t loss_valid = 25294062.0 \n",
      "Model_1_2790 \t loss_train = 28112226.0 \t loss_valid = 25337270.0 \n",
      "Model_1_2800 \t loss_train = 28093124.0 \t loss_valid = 25359876.0 \n",
      "Model_1_2810 \t loss_train = 28221826.0 \t loss_valid = 25274966.0 \n",
      "Model_1_2820 \t loss_train = 28178932.0 \t loss_valid = 25291230.0 \n",
      "Model_1_2830 \t loss_train = 28207788.0 \t loss_valid = 25289394.0 \n",
      "Model_1_2840 \t loss_train = 28099294.0 \t loss_valid = 25360364.0 \n",
      "Model_1_2850 \t loss_train = 28244304.0 \t loss_valid = 25267354.0 \n",
      "Model_1_2860 \t loss_train = 28074702.0 \t loss_valid = 25520304.0 \n",
      "Model_1_2870 \t loss_train = 28388482.0 \t loss_valid = 25273928.0 \n",
      "Model_1_2880 \t loss_train = 28118190.0 \t loss_valid = 25333548.0 \n",
      "Model_1_2890 \t loss_train = 28174774.0 \t loss_valid = 25296644.0 \n",
      "Model_1_2900 \t loss_train = 28132132.0 \t loss_valid = 25365216.0 \n",
      "Model_1_2910 \t loss_train = 28130654.0 \t loss_valid = 25336548.0 \n",
      "Model_1_2920 \t loss_train = 28133292.0 \t loss_valid = 25345972.0 \n",
      "Model_1_2930 \t loss_train = 28157074.0 \t loss_valid = 25300234.0 \n",
      "Model_1_2940 \t loss_train = 28170884.0 \t loss_valid = 25301546.0 \n",
      "Model_1_2950 \t loss_train = 28145706.0 \t loss_valid = 25308630.0 \n",
      "Model_1_2960 \t loss_train = 28090298.0 \t loss_valid = 25362178.0 \n",
      "Model_1_2970 \t loss_train = 28215100.0 \t loss_valid = 25322578.0 \n",
      "Model_1_2980 \t loss_train = 28155286.0 \t loss_valid = 25378040.0 \n",
      "Model_1_2990 \t loss_train = 28278476.0 \t loss_valid = 25268730.0 \n",
      "Model_1_3000 \t loss_train = 28137780.0 \t loss_valid = 25314428.0 \n",
      "Model_1_3010 \t loss_train = 28066970.0 \t loss_valid = 25404832.0 \n",
      "Model_1_3020 \t loss_train = 28187748.0 \t loss_valid = 25285468.0 \n",
      "Model_1_3030 \t loss_train = 28089508.0 \t loss_valid = 25409518.0 \n",
      "Model_1_3040 \t loss_train = 28117836.0 \t loss_valid = 25394512.0 \n",
      "Model_1_3050 \t loss_train = 28431428.0 \t loss_valid = 25284166.0 \n",
      "Model_1_3060 \t loss_train = 28049900.0 \t loss_valid = 25439226.0 \n",
      "Model_1_3070 \t loss_train = 28191974.0 \t loss_valid = 25287728.0 \n",
      "Model_1_3080 \t loss_train = 28112586.0 \t loss_valid = 25340700.0 \n",
      "Model_1_3090 \t loss_train = 28211500.0 \t loss_valid = 25278084.0 \n",
      "Model_1_3100 \t loss_train = 28004230.0 \t loss_valid = 25580572.0 \n",
      "Model_1_3110 \t loss_train = 28243016.0 \t loss_valid = 25293934.0 \n",
      "Model_1_3120 \t loss_train = 28042390.0 \t loss_valid = 25442436.0 \n",
      "Model_1_3130 \t loss_train = 28323360.0 \t loss_valid = 25253390.0 \n",
      "Model_1_3140 \t loss_train = 28085418.0 \t loss_valid = 25433840.0 \n",
      "Model_1_3150 \t loss_train = 28144906.0 \t loss_valid = 25308064.0 \n",
      "Model_1_3160 \t loss_train = 28235178.0 \t loss_valid = 25270614.0 \n",
      "Model_1_3170 \t loss_train = 28142148.0 \t loss_valid = 25323134.0 \n",
      "Model_1_3180 \t loss_train = 28124192.0 \t loss_valid = 25322948.0 \n",
      "Model_1_3190 \t loss_train = 28147558.0 \t loss_valid = 25305790.0 \n",
      "Model_1_3200 \t loss_train = 28110800.0 \t loss_valid = 25367450.0 \n",
      "Model_1_3210 \t loss_train = 28188594.0 \t loss_valid = 25285986.0 \n",
      "Model_1_3220 \t loss_train = 28158944.0 \t loss_valid = 25300056.0 \n",
      "Model_1_3230 \t loss_train = 28119874.0 \t loss_valid = 25341934.0 \n",
      "Model_1_3240 \t loss_train = 28130312.0 \t loss_valid = 25378472.0 \n",
      "Model_1_3250 \t loss_train = 28232144.0 \t loss_valid = 25271374.0 \n",
      "Model_1_3260 \t loss_train = 28081544.0 \t loss_valid = 25361728.0 \n",
      "Model_1_3270 \t loss_train = 28148674.0 \t loss_valid = 25318748.0 \n",
      "Model_1_3280 \t loss_train = 28143332.0 \t loss_valid = 25311080.0 \n",
      "Model_1_3290 \t loss_train = 28133096.0 \t loss_valid = 25319458.0 \n",
      "Model_1_3300 \t loss_train = 28153948.0 \t loss_valid = 25310864.0 \n",
      "Model_1_3310 \t loss_train = 28149870.0 \t loss_valid = 25315182.0 \n",
      "Model_1_3320 \t loss_train = 28194922.0 \t loss_valid = 25286682.0 \n",
      "Model_1_3330 \t loss_train = 28068566.0 \t loss_valid = 25378636.0 \n",
      "Model_1_3340 \t loss_train = 28294440.0 \t loss_valid = 25260112.0 \n",
      "Model_1_3350 \t loss_train = 28057466.0 \t loss_valid = 25537152.0 \n",
      "Model_1_3360 \t loss_train = 28280718.0 \t loss_valid = 25262250.0 \n",
      "Model_1_3370 \t loss_train = 28069446.0 \t loss_valid = 25390024.0 \n",
      "Model_1_3380 \t loss_train = 28251984.0 \t loss_valid = 25270256.0 \n",
      "Model_1_3390 \t loss_train = 28085222.0 \t loss_valid = 25352528.0 \n",
      "Model_1_3400 \t loss_train = 28160160.0 \t loss_valid = 25298220.0 \n",
      "Model_1_3410 \t loss_train = 28097238.0 \t loss_valid = 25372518.0 \n",
      "Model_1_3420 \t loss_train = 28184864.0 \t loss_valid = 25294184.0 \n",
      "Model_1_3430 \t loss_train = 28043626.0 \t loss_valid = 25478416.0 \n",
      "Model_1_3440 \t loss_train = 28209298.0 \t loss_valid = 25277114.0 \n",
      "Model_1_3450 \t loss_train = 28138454.0 \t loss_valid = 25309150.0 \n",
      "Model_1_3460 \t loss_train = 28131304.0 \t loss_valid = 25339480.0 \n",
      "Model_1_3470 \t loss_train = 28137688.0 \t loss_valid = 25334392.0 \n",
      "Model_1_3480 \t loss_train = 28117800.0 \t loss_valid = 25345562.0 \n",
      "Model_1_3490 \t loss_train = 28146586.0 \t loss_valid = 25304360.0 \n",
      "Model_1_3500 \t loss_train = 28133186.0 \t loss_valid = 25316110.0 \n",
      "Model_1_3510 \t loss_train = 28210124.0 \t loss_valid = 25286382.0 \n",
      "Model_1_3520 \t loss_train = 28073448.0 \t loss_valid = 25381226.0 \n",
      "Model_1_3530 \t loss_train = 28209814.0 \t loss_valid = 25276470.0 \n",
      "Model_1_3540 \t loss_train = 28059224.0 \t loss_valid = 25448188.0 \n",
      "Model_1_3550 \t loss_train = 28174516.0 \t loss_valid = 25296554.0 \n",
      "Model_1_3560 \t loss_train = 28106936.0 \t loss_valid = 25387336.0 \n",
      "Model_1_3570 \t loss_train = 28185584.0 \t loss_valid = 25295334.0 \n",
      "Model_1_3580 \t loss_train = 28108562.0 \t loss_valid = 25330878.0 \n",
      "Model_1_3590 \t loss_train = 28180230.0 \t loss_valid = 25293106.0 \n",
      "Model_1_3600 \t loss_train = 28106904.0 \t loss_valid = 25375060.0 \n",
      "Model_1_3610 \t loss_train = 28171140.0 \t loss_valid = 25322756.0 \n",
      "Model_1_3620 \t loss_train = 28091990.0 \t loss_valid = 25378888.0 \n",
      "Model_1_3630 \t loss_train = 28159040.0 \t loss_valid = 25302942.0 \n",
      "Model_1_3640 \t loss_train = 28086968.0 \t loss_valid = 25404404.0 \n",
      "Model_1_3650 \t loss_train = 28119210.0 \t loss_valid = 25345410.0 \n",
      "Model_1_3660 \t loss_train = 28307280.0 \t loss_valid = 25255376.0 \n",
      "Model_1_3670 \t loss_train = 28100140.0 \t loss_valid = 25382972.0 \n",
      "Model_1_3680 \t loss_train = 28157276.0 \t loss_valid = 25317818.0 \n",
      "Model_1_3690 \t loss_train = 28075514.0 \t loss_valid = 25383370.0 \n",
      "Model_1_3700 \t loss_train = 28111448.0 \t loss_valid = 25333002.0 \n",
      "Model_1_3710 \t loss_train = 28203794.0 \t loss_valid = 25279712.0 \n",
      "Model_1_3720 \t loss_train = 28112872.0 \t loss_valid = 25338836.0 \n",
      "Model_1_3730 \t loss_train = 28197626.0 \t loss_valid = 25283512.0 \n",
      "Model_1_3740 \t loss_train = 28098778.0 \t loss_valid = 25344096.0 \n",
      "Model_1_3750 \t loss_train = 28122278.0 \t loss_valid = 25325580.0 \n",
      "Model_1_3760 \t loss_train = 28181306.0 \t loss_valid = 25301716.0 \n",
      "Model_1_3770 \t loss_train = 28113180.0 \t loss_valid = 25508648.0 \n",
      "Model_1_3780 \t loss_train = 28114314.0 \t loss_valid = 25363756.0 \n",
      "Model_1_3790 \t loss_train = 28166968.0 \t loss_valid = 25298388.0 \n",
      "Model_1_3800 \t loss_train = 28095674.0 \t loss_valid = 25364054.0 \n",
      "Model_1_3810 \t loss_train = 28176236.0 \t loss_valid = 25289834.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_1_3820 \t loss_train = 28131312.0 \t loss_valid = 25315340.0 \n",
      "Model_1_3830 \t loss_train = 28092826.0 \t loss_valid = 25369826.0 \n",
      "Model_1_3840 \t loss_train = 28177008.0 \t loss_valid = 25289810.0 \n",
      "Model_1_3850 \t loss_train = 28239046.0 \t loss_valid = 25279220.0 \n",
      "Model_1_3860 \t loss_train = 28067246.0 \t loss_valid = 25376282.0 \n",
      "Model_1_3870 \t loss_train = 28123206.0 \t loss_valid = 25324668.0 \n",
      "Model_1_3880 \t loss_train = 28132640.0 \t loss_valid = 25334664.0 \n",
      "Model_1_3890 \t loss_train = 28127028.0 \t loss_valid = 25327734.0 \n",
      "Model_1_3900 \t loss_train = 28122356.0 \t loss_valid = 25324256.0 \n",
      "Model_1_3910 \t loss_train = 28151240.0 \t loss_valid = 25307746.0 \n",
      "Model_1_3920 \t loss_train = 28092886.0 \t loss_valid = 25367646.0 \n",
      "Model_1_3930 \t loss_train = 28297642.0 \t loss_valid = 25256058.0 \n",
      "Model_1_3940 \t loss_train = 28042238.0 \t loss_valid = 25461792.0 \n",
      "Model_1_3950 \t loss_train = 28343178.0 \t loss_valid = 25262394.0 \n",
      "Model_1_3960 \t loss_train = 28008652.0 \t loss_valid = 25608366.0 \n",
      "Model_1_3970 \t loss_train = 28323692.0 \t loss_valid = 25253658.0 \n",
      "Model_1_3980 \t loss_train = 28025350.0 \t loss_valid = 25504536.0 \n",
      "Model_1_3990 \t loss_train = 28169534.0 \t loss_valid = 25293778.0 \n",
      "Model_1_4000 \t loss_train = 28081878.0 \t loss_valid = 25372896.0 \n",
      "Model_1_4010 \t loss_train = 28182666.0 \t loss_valid = 25297158.0 \n",
      "Model_1_4020 \t loss_train = 28140256.0 \t loss_valid = 25326218.0 \n",
      "Model_1_4030 \t loss_train = 28159048.0 \t loss_valid = 25309914.0 \n",
      "Model_1_4040 \t loss_train = 28066718.0 \t loss_valid = 25402196.0 \n",
      "Model_1_4050 \t loss_train = 28237270.0 \t loss_valid = 25276780.0 \n",
      "Model_1_4060 \t loss_train = 28054498.0 \t loss_valid = 25439940.0 \n",
      "Model_1_4070 \t loss_train = 28193418.0 \t loss_valid = 25283654.0 \n",
      "Model_1_4080 \t loss_train = 28049088.0 \t loss_valid = 25445396.0 \n",
      "Model_1_4090 \t loss_train = 28121426.0 \t loss_valid = 25352852.0 \n",
      "Model_1_4100 \t loss_train = 28117424.0 \t loss_valid = 25372554.0 \n",
      "Model_1_4110 \t loss_train = 28220174.0 \t loss_valid = 25280816.0 \n",
      "Model_1_4120 \t loss_train = 28171284.0 \t loss_valid = 25310896.0 \n",
      "Model_1_4130 \t loss_train = 28155940.0 \t loss_valid = 25316010.0 \n",
      "Model_1_4140 \t loss_train = 28109104.0 \t loss_valid = 25333614.0 \n",
      "Model_1_4150 \t loss_train = 28126052.0 \t loss_valid = 25326822.0 \n",
      "Model_1_4160 \t loss_train = 28196750.0 \t loss_valid = 25306740.0 \n",
      "Model_1_4170 \t loss_train = 28027846.0 \t loss_valid = 25465680.0 \n",
      "Model_1_4180 \t loss_train = 28172000.0 \t loss_valid = 25297604.0 \n",
      "Model_1_4190 \t loss_train = 28068570.0 \t loss_valid = 25379024.0 \n",
      "Model_1_4200 \t loss_train = 28192784.0 \t loss_valid = 25287654.0 \n",
      "Model_1_4210 \t loss_train = 28126552.0 \t loss_valid = 25362354.0 \n",
      "Model_1_4220 \t loss_train = 28181680.0 \t loss_valid = 25294886.0 \n",
      "Model_1_4230 \t loss_train = 28132794.0 \t loss_valid = 25316102.0 \n",
      "Model_1_4240 \t loss_train = 28036432.0 \t loss_valid = 25455228.0 \n",
      "Model_1_4250 \t loss_train = 28154748.0 \t loss_valid = 25333990.0 \n",
      "Model_1_4260 \t loss_train = 28072320.0 \t loss_valid = 25444318.0 \n",
      "Model_1_4270 \t loss_train = 28201844.0 \t loss_valid = 25291110.0 \n",
      "Model_1_4280 \t loss_train = 28029132.0 \t loss_valid = 25566072.0 \n",
      "Model_1_4290 \t loss_train = 28216314.0 \t loss_valid = 25280044.0 \n",
      "Model_1_4300 \t loss_train = 28124986.0 \t loss_valid = 25324702.0 \n",
      "Model_1_4310 \t loss_train = 28133090.0 \t loss_valid = 25320844.0 \n",
      "Model_1_4320 \t loss_train = 28215526.0 \t loss_valid = 25283530.0 \n",
      "Model_1_4330 \t loss_train = 28163662.0 \t loss_valid = 25303896.0 \n",
      "Model_1_4340 \t loss_train = 28174522.0 \t loss_valid = 25294348.0 \n",
      "Model_1_4350 \t loss_train = 28130906.0 \t loss_valid = 25318124.0 \n",
      "Model_1_4360 \t loss_train = 28150224.0 \t loss_valid = 25308072.0 \n",
      "Model_1_4370 \t loss_train = 28079106.0 \t loss_valid = 25383032.0 \n",
      "Model_1_4380 \t loss_train = 28197862.0 \t loss_valid = 25283580.0 \n",
      "Model_1_4390 \t loss_train = 28083618.0 \t loss_valid = 25374746.0 \n",
      "Model_1_4400 \t loss_train = 28126632.0 \t loss_valid = 25323998.0 \n",
      "Model_1_4410 \t loss_train = 28097628.0 \t loss_valid = 25350522.0 \n",
      "Model_1_4420 \t loss_train = 28103358.0 \t loss_valid = 25344476.0 \n",
      "Model_1_4430 \t loss_train = 28182286.0 \t loss_valid = 25298396.0 \n",
      "Model_1_4440 \t loss_train = 28084112.0 \t loss_valid = 25398294.0 \n",
      "Model_1_4450 \t loss_train = 28086526.0 \t loss_valid = 25378402.0 \n",
      "Model_1_4460 \t loss_train = 28112938.0 \t loss_valid = 25349540.0 \n",
      "Model_1_4470 \t loss_train = 28070856.0 \t loss_valid = 25396790.0 \n",
      "Model_1_4480 \t loss_train = 28293634.0 \t loss_valid = 25257572.0 \n",
      "Model_1_4490 \t loss_train = 28036862.0 \t loss_valid = 25484180.0 \n",
      "Model_1_4500 \t loss_train = 28145826.0 \t loss_valid = 25307792.0 \n",
      "Model_1_4510 \t loss_train = 28116376.0 \t loss_valid = 25345910.0 \n",
      "Model_1_4520 \t loss_train = 28181232.0 \t loss_valid = 25299108.0 \n",
      "Model_1_4530 \t loss_train = 28110270.0 \t loss_valid = 25375466.0 \n",
      "Model_1_4540 \t loss_train = 28245716.0 \t loss_valid = 25269968.0 \n",
      "Model_1_4550 \t loss_train = 28105508.0 \t loss_valid = 25338950.0 \n",
      "Model_1_4560 \t loss_train = 28040634.0 \t loss_valid = 25428974.0 \n",
      "Model_1_4570 \t loss_train = 28144274.0 \t loss_valid = 25317126.0 \n",
      "Model_1_4580 \t loss_train = 28069442.0 \t loss_valid = 25398044.0 \n",
      "Model_1_4590 \t loss_train = 28182436.0 \t loss_valid = 25293322.0 \n",
      "Model_1_4600 \t loss_train = 28041556.0 \t loss_valid = 25454220.0 \n",
      "Model_1_4610 \t loss_train = 28213702.0 \t loss_valid = 25277920.0 \n",
      "Model_1_4620 \t loss_train = 28016632.0 \t loss_valid = 25506228.0 \n",
      "Model_1_4630 \t loss_train = 28233960.0 \t loss_valid = 25271508.0 \n",
      "Model_1_4640 \t loss_train = 28035642.0 \t loss_valid = 25517124.0 \n",
      "Model_1_4650 \t loss_train = 28125562.0 \t loss_valid = 25373978.0 \n",
      "Model_1_4660 \t loss_train = 28156540.0 \t loss_valid = 25317748.0 \n",
      "Model_1_4670 \t loss_train = 28138812.0 \t loss_valid = 25313470.0 \n",
      "Model_1_4680 \t loss_train = 28148270.0 \t loss_valid = 25307826.0 \n",
      "Model_1_4690 \t loss_train = 28112792.0 \t loss_valid = 25346930.0 \n",
      "Model_1_4700 \t loss_train = 28068618.0 \t loss_valid = 25424260.0 \n",
      "Model_1_4710 \t loss_train = 28091638.0 \t loss_valid = 25386108.0 \n",
      "Model_1_4720 \t loss_train = 28098306.0 \t loss_valid = 25351022.0 \n",
      "Model_1_4730 \t loss_train = 28163428.0 \t loss_valid = 25301470.0 \n",
      "Model_1_4740 \t loss_train = 28102772.0 \t loss_valid = 25347494.0 \n",
      "Model_1_4750 \t loss_train = 28089900.0 \t loss_valid = 25365354.0 \n",
      "Model_1_4760 \t loss_train = 28128082.0 \t loss_valid = 25320790.0 \n",
      "Model_1_4770 \t loss_train = 28118786.0 \t loss_valid = 25327578.0 \n",
      "Model_1_4780 \t loss_train = 28130878.0 \t loss_valid = 25322102.0 \n",
      "Model_1_4790 \t loss_train = 28087008.0 \t loss_valid = 25380646.0 \n",
      "Model_1_4800 \t loss_train = 28117090.0 \t loss_valid = 25373364.0 \n",
      "Model_1_4810 \t loss_train = 28272658.0 \t loss_valid = 25262404.0 \n",
      "Model_1_4820 \t loss_train = 28034500.0 \t loss_valid = 25444218.0 \n",
      "Model_1_4830 \t loss_train = 28188028.0 \t loss_valid = 25288850.0 \n",
      "Model_1_4840 \t loss_train = 28135978.0 \t loss_valid = 25323950.0 \n",
      "Model_1_4850 \t loss_train = 28149596.0 \t loss_valid = 25325264.0 \n",
      "Model_1_4860 \t loss_train = 28157056.0 \t loss_valid = 25315320.0 \n",
      "Model_1_4870 \t loss_train = 28076022.0 \t loss_valid = 25384154.0 \n",
      "Model_1_4880 \t loss_train = 28101178.0 \t loss_valid = 25351086.0 \n",
      "Model_1_4890 \t loss_train = 28137038.0 \t loss_valid = 25323584.0 \n",
      "Model_1_4900 \t loss_train = 28143762.0 \t loss_valid = 25340496.0 \n",
      "Model_1_4910 \t loss_train = 28143806.0 \t loss_valid = 25333910.0 \n",
      "Model_1_4920 \t loss_train = 28043408.0 \t loss_valid = 25482660.0 \n",
      "Model_1_4930 \t loss_train = 28259394.0 \t loss_valid = 25266328.0 \n",
      "Model_1_4940 \t loss_train = 28080296.0 \t loss_valid = 25366296.0 \n",
      "Model_1_4950 \t loss_train = 28123818.0 \t loss_valid = 25331908.0 \n",
      "Model_1_4960 \t loss_train = 28162074.0 \t loss_valid = 25312848.0 \n",
      "Model_1_4970 \t loss_train = 28091602.0 \t loss_valid = 25379536.0 \n",
      "Model_1_4980 \t loss_train = 28162824.0 \t loss_valid = 25302454.0 \n",
      "Model_1_4990 \t loss_train = 28047616.0 \t loss_valid = 25411666.0 \n",
      "Model_1_5000 \t loss_train = 28188838.0 \t loss_valid = 25288106.0 \n",
      "Model_1_5010 \t loss_train = 28145206.0 \t loss_valid = 25314224.0 \n",
      "Model_1_5020 \t loss_train = 28126776.0 \t loss_valid = 25334554.0 \n",
      "Model_1_5030 \t loss_train = 28134822.0 \t loss_valid = 25318772.0 \n",
      "Model_1_5040 \t loss_train = 28069576.0 \t loss_valid = 25386300.0 \n",
      "Model_1_5050 \t loss_train = 28255072.0 \t loss_valid = 25269178.0 \n",
      "Model_1_5060 \t loss_train = 28040018.0 \t loss_valid = 25434244.0 \n",
      "Model_1_5070 \t loss_train = 28129976.0 \t loss_valid = 25334328.0 \n",
      "Model_1_5080 \t loss_train = 28087646.0 \t loss_valid = 25393886.0 \n",
      "Model_1_5090 \t loss_train = 28130092.0 \t loss_valid = 25331256.0 \n",
      "Model_1_5100 \t loss_train = 28053444.0 \t loss_valid = 25407644.0 \n",
      "Model_1_5110 \t loss_train = 28150736.0 \t loss_valid = 25320204.0 \n",
      "Model_1_5120 \t loss_train = 28044988.0 \t loss_valid = 25459832.0 \n",
      "Model_1_5130 \t loss_train = 28181070.0 \t loss_valid = 25290706.0 \n",
      "Model_1_5140 \t loss_train = 28102384.0 \t loss_valid = 25356104.0 \n",
      "Model_1_5150 \t loss_train = 28081496.0 \t loss_valid = 25395572.0 \n",
      "Model_1_5160 \t loss_train = 28078474.0 \t loss_valid = 25381050.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_1_5170 \t loss_train = 28145492.0 \t loss_valid = 25311720.0 \n",
      "Model_1_5180 \t loss_train = 28072558.0 \t loss_valid = 25403124.0 \n",
      "Model_1_5190 \t loss_train = 28039126.0 \t loss_valid = 25462706.0 \n",
      "Model_1_5200 \t loss_train = 28275028.0 \t loss_valid = 25261394.0 \n",
      "Model_1_5210 \t loss_train = 28010854.0 \t loss_valid = 25542946.0 \n",
      "Model_1_5220 \t loss_train = 28166284.0 \t loss_valid = 25302326.0 \n",
      "Model_1_5230 \t loss_train = 28083952.0 \t loss_valid = 25362780.0 \n",
      "Model_1_5240 \t loss_train = 28083366.0 \t loss_valid = 25359120.0 \n",
      "Model_1_5250 \t loss_train = 28080144.0 \t loss_valid = 25366842.0 \n",
      "Model_1_5260 \t loss_train = 28056746.0 \t loss_valid = 25412970.0 \n",
      "Model_1_5270 \t loss_train = 28208124.0 \t loss_valid = 25280260.0 \n",
      "Model_1_5280 \t loss_train = 28059584.0 \t loss_valid = 25396242.0 \n",
      "Model_1_5290 \t loss_train = 28157864.0 \t loss_valid = 25303182.0 \n",
      "Model_1_5300 \t loss_train = 28093040.0 \t loss_valid = 25350704.0 \n",
      "Model_1_5310 \t loss_train = 28147920.0 \t loss_valid = 25316954.0 \n",
      "Model_1_5320 \t loss_train = 28057540.0 \t loss_valid = 25438124.0 \n",
      "Model_1_5330 \t loss_train = 28155136.0 \t loss_valid = 25317516.0 \n",
      "Model_1_5340 \t loss_train = 28044604.0 \t loss_valid = 25446366.0 \n",
      "Model_1_5350 \t loss_train = 28137206.0 \t loss_valid = 25316926.0 \n",
      "Model_1_5360 \t loss_train = 28112494.0 \t loss_valid = 25337356.0 \n",
      "Model_1_5370 \t loss_train = 28112582.0 \t loss_valid = 25336078.0 \n",
      "Model_1_5380 \t loss_train = 28029686.0 \t loss_valid = 25439792.0 \n",
      "Model_1_5390 \t loss_train = 28203062.0 \t loss_valid = 25280272.0 \n",
      "Model_1_5400 \t loss_train = 28123756.0 \t loss_valid = 25344230.0 \n",
      "Model_1_5410 \t loss_train = 28068388.0 \t loss_valid = 25421188.0 \n",
      "Model_1_5420 \t loss_train = 28046898.0 \t loss_valid = 25442504.0 \n",
      "Model_1_5430 \t loss_train = 28139350.0 \t loss_valid = 25324466.0 \n",
      "Model_1_5440 \t loss_train = 28106410.0 \t loss_valid = 25372224.0 \n",
      "Model_1_5450 \t loss_train = 28093140.0 \t loss_valid = 25362960.0 \n",
      "Model_1_5460 \t loss_train = 28095216.0 \t loss_valid = 25347688.0 \n",
      "Model_1_5470 \t loss_train = 28100802.0 \t loss_valid = 25341578.0 \n",
      "Model_1_5480 \t loss_train = 28101172.0 \t loss_valid = 25342576.0 \n",
      "Model_1_5490 \t loss_train = 28139282.0 \t loss_valid = 25312936.0 \n",
      "Model_1_5500 \t loss_train = 28096882.0 \t loss_valid = 25378752.0 \n",
      "Model_1_5510 \t loss_train = 28135888.0 \t loss_valid = 25366958.0 \n",
      "Model_1_5520 \t loss_train = 28086366.0 \t loss_valid = 25414050.0 \n",
      "Model_1_5530 \t loss_train = 28088860.0 \t loss_valid = 25370148.0 \n",
      "Model_1_5540 \t loss_train = 28138192.0 \t loss_valid = 25313758.0 \n",
      "Model_1_5550 \t loss_train = 28074896.0 \t loss_valid = 25369104.0 \n",
      "Model_1_5560 \t loss_train = 28123184.0 \t loss_valid = 25329584.0 \n",
      "Model_1_5570 \t loss_train = 28106612.0 \t loss_valid = 25346682.0 \n",
      "Model_1_5580 \t loss_train = 28045302.0 \t loss_valid = 25419374.0 \n",
      "Model_1_5590 \t loss_train = 28285430.0 \t loss_valid = 25259600.0 \n",
      "Model_1_5600 \t loss_train = 28042964.0 \t loss_valid = 25444826.0 \n",
      "Model_1_5610 \t loss_train = 28139904.0 \t loss_valid = 25318970.0 \n",
      "Model_1_5620 \t loss_train = 28075420.0 \t loss_valid = 25379478.0 \n",
      "Model_1_5630 \t loss_train = 28155088.0 \t loss_valid = 25309130.0 \n",
      "Model_1_5640 \t loss_train = 28099884.0 \t loss_valid = 25354140.0 \n",
      "Model_1_5650 \t loss_train = 28118338.0 \t loss_valid = 25334338.0 \n",
      "Model_1_5660 \t loss_train = 28061234.0 \t loss_valid = 25393172.0 \n",
      "Model_1_5670 \t loss_train = 28203734.0 \t loss_valid = 25280724.0 \n",
      "Model_1_5680 \t loss_train = 28049626.0 \t loss_valid = 25410278.0 \n",
      "Model_1_5690 \t loss_train = 28130824.0 \t loss_valid = 25321234.0 \n",
      "Model_1_5700 \t loss_train = 28012978.0 \t loss_valid = 25500676.0 \n",
      "Model_1_5710 \t loss_train = 28183264.0 \t loss_valid = 25290916.0 \n",
      "Model_1_5720 \t loss_train = 28048854.0 \t loss_valid = 25419938.0 \n",
      "Model_1_5730 \t loss_train = 28187272.0 \t loss_valid = 25288912.0 \n",
      "Model_1_5740 \t loss_train = 28012402.0 \t loss_valid = 25496986.0 \n",
      "Model_1_5750 \t loss_train = 28172188.0 \t loss_valid = 25297608.0 \n",
      "Model_1_5760 \t loss_train = 28080292.0 \t loss_valid = 25380952.0 \n",
      "Model_1_5770 \t loss_train = 28116354.0 \t loss_valid = 25338158.0 \n",
      "Model_1_5780 \t loss_train = 28148600.0 \t loss_valid = 25316526.0 \n",
      "Model_1_5790 \t loss_train = 28169722.0 \t loss_valid = 25306004.0 \n",
      "Model_1_5800 \t loss_train = 28091518.0 \t loss_valid = 25364232.0 \n",
      "Model_1_5810 \t loss_train = 28077938.0 \t loss_valid = 25386454.0 \n",
      "Model_1_5820 \t loss_train = 28152964.0 \t loss_valid = 25310132.0 \n",
      "Model_1_5830 \t loss_train = 28111294.0 \t loss_valid = 25340746.0 \n",
      "Model_1_5840 \t loss_train = 28062082.0 \t loss_valid = 25411206.0 \n",
      "Model_1_5850 \t loss_train = 28081930.0 \t loss_valid = 25382552.0 \n",
      "Model_1_5860 \t loss_train = 28105300.0 \t loss_valid = 25346444.0 \n",
      "Model_1_5870 \t loss_train = 28061270.0 \t loss_valid = 25410236.0 \n",
      "Model_1_5880 \t loss_train = 28207752.0 \t loss_valid = 25288938.0 \n",
      "Model_1_5890 \t loss_train = 28059612.0 \t loss_valid = 25418746.0 \n",
      "Model_1_5900 \t loss_train = 28140584.0 \t loss_valid = 25317056.0 \n",
      "Model_1_5910 \t loss_train = 28107358.0 \t loss_valid = 25339680.0 \n",
      "Model_1_5920 \t loss_train = 28098360.0 \t loss_valid = 25354960.0 \n",
      "Model_1_5930 \t loss_train = 28036734.0 \t loss_valid = 25458240.0 \n",
      "Model_1_5940 \t loss_train = 28064118.0 \t loss_valid = 25400156.0 \n",
      "Model_1_5950 \t loss_train = 28123904.0 \t loss_valid = 25333744.0 \n",
      "Model_1_5960 \t loss_train = 28104290.0 \t loss_valid = 25345652.0 \n",
      "Model_1_5970 \t loss_train = 28112678.0 \t loss_valid = 25336310.0 \n",
      "Model_1_5980 \t loss_train = 28072360.0 \t loss_valid = 25392470.0 \n",
      "Model_1_5990 \t loss_train = 28090868.0 \t loss_valid = 25387874.0 \n",
      "Model_1_6000 \t loss_train = 28127790.0 \t loss_valid = 25354032.0 \n",
      "Model_1_6010 \t loss_train = 28021246.0 \t loss_valid = 25518762.0 \n",
      "Model_1_6020 \t loss_train = 28145420.0 \t loss_valid = 25313128.0 \n",
      "Model_1_6030 \t loss_train = 28055196.0 \t loss_valid = 25412034.0 \n",
      "Model_1_6040 \t loss_train = 28097622.0 \t loss_valid = 25365068.0 \n",
      "Model_1_6050 \t loss_train = 28107174.0 \t loss_valid = 25348898.0 \n",
      "Model_1_6060 \t loss_train = 28068470.0 \t loss_valid = 25394534.0 \n",
      "Model_1_6070 \t loss_train = 28111492.0 \t loss_valid = 25349602.0 \n",
      "Model_1_6080 \t loss_train = 28090976.0 \t loss_valid = 25362548.0 \n",
      "Model_1_6090 \t loss_train = 28125718.0 \t loss_valid = 25322012.0 \n",
      "Model_1_6100 \t loss_train = 28089910.0 \t loss_valid = 25359078.0 \n",
      "Model_1_6110 \t loss_train = 28133242.0 \t loss_valid = 25324274.0 \n",
      "Model_1_6120 \t loss_train = 28068518.0 \t loss_valid = 25404262.0 \n",
      "Model_1_6130 \t loss_train = 28052638.0 \t loss_valid = 25444302.0 \n",
      "Model_1_6140 \t loss_train = 28095120.0 \t loss_valid = 25362226.0 \n",
      "Model_1_6150 \t loss_train = 28076308.0 \t loss_valid = 25372714.0 \n",
      "Model_1_6160 \t loss_train = 28078264.0 \t loss_valid = 25373934.0 \n",
      "Model_1_6170 \t loss_train = 28140502.0 \t loss_valid = 25315688.0 \n",
      "Model_1_6180 \t loss_train = 28064408.0 \t loss_valid = 25390966.0 \n",
      "Model_1_6190 \t loss_train = 28158622.0 \t loss_valid = 25303552.0 \n",
      "Model_1_6200 \t loss_train = 28039850.0 \t loss_valid = 25458486.0 \n",
      "Model_1_6210 \t loss_train = 28203792.0 \t loss_valid = 25284850.0 \n",
      "Model_1_6220 \t loss_train = 28002724.0 \t loss_valid = 25555138.0 \n",
      "Model_1_6230 \t loss_train = 28197064.0 \t loss_valid = 25283160.0 \n",
      "Model_1_6240 \t loss_train = 28055124.0 \t loss_valid = 25398238.0 \n",
      "Model_1_6250 \t loss_train = 28202552.0 \t loss_valid = 25282318.0 \n",
      "Model_1_6260 \t loss_train = 28106040.0 \t loss_valid = 25341368.0 \n",
      "Model_1_6270 \t loss_train = 28053192.0 \t loss_valid = 25432132.0 \n",
      "Model_1_6280 \t loss_train = 28127116.0 \t loss_valid = 25335228.0 \n",
      "Model_1_6290 \t loss_train = 28156322.0 \t loss_valid = 25300400.0 \n",
      "Model_1_6300 \t loss_train = 28105982.0 \t loss_valid = 25338330.0 \n",
      "Model_1_6310 \t loss_train = 28131326.0 \t loss_valid = 25320306.0 \n",
      "Model_1_6320 \t loss_train = 28048216.0 \t loss_valid = 25427764.0 \n",
      "Model_1_6330 \t loss_train = 28170606.0 \t loss_valid = 25295036.0 \n",
      "Model_1_6340 \t loss_train = 28129668.0 \t loss_valid = 25319692.0 \n",
      "Model_1_6350 \t loss_train = 28080700.0 \t loss_valid = 25367142.0 \n",
      "Model_1_6360 \t loss_train = 28122394.0 \t loss_valid = 25333858.0 \n",
      "Model_1_6370 \t loss_train = 28162636.0 \t loss_valid = 25312376.0 \n",
      "Model_1_6380 \t loss_train = 28181680.0 \t loss_valid = 25291008.0 \n",
      "Model_1_6390 \t loss_train = 28061048.0 \t loss_valid = 25397738.0 \n",
      "Model_1_6400 \t loss_train = 28116466.0 \t loss_valid = 25346208.0 \n",
      "Model_1_6410 \t loss_train = 28022886.0 \t loss_valid = 25505444.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_1_6420 \t loss_train = 28143836.0 \t loss_valid = 25322016.0 \n",
      "Model_1_6430 \t loss_train = 28116402.0 \t loss_valid = 25336560.0 \n",
      "Model_1_6440 \t loss_train = 28083064.0 \t loss_valid = 25366502.0 \n",
      "Model_1_6450 \t loss_train = 28198060.0 \t loss_valid = 25283448.0 \n",
      "Model_1_6460 \t loss_train = 28110348.0 \t loss_valid = 25337832.0 \n",
      "Model_1_6470 \t loss_train = 28082870.0 \t loss_valid = 25375624.0 \n",
      "Model_1_6480 \t loss_train = 28070412.0 \t loss_valid = 25392700.0 \n",
      "Model_1_6490 \t loss_train = 28213140.0 \t loss_valid = 25279642.0 \n",
      "Model_1_6500 \t loss_train = 28055246.0 \t loss_valid = 25415782.0 \n",
      "Model_1_6510 \t loss_train = 28067432.0 \t loss_valid = 25390408.0 \n",
      "Model_1_6520 \t loss_train = 28145038.0 \t loss_valid = 25314364.0 \n",
      "Model_1_6530 \t loss_train = 28139522.0 \t loss_valid = 25316262.0 \n",
      "Model_1_6540 \t loss_train = 28090706.0 \t loss_valid = 25363286.0 \n",
      "Model_1_6550 \t loss_train = 28135422.0 \t loss_valid = 25324522.0 \n",
      "Model_1_6560 \t loss_train = 28120644.0 \t loss_valid = 25343142.0 \n",
      "Model_1_6570 \t loss_train = 28087214.0 \t loss_valid = 25372552.0 \n",
      "Model_1_6580 \t loss_train = 28172296.0 \t loss_valid = 25299104.0 \n",
      "Model_1_6590 \t loss_train = 28082002.0 \t loss_valid = 25368602.0 \n",
      "Model_1_6600 \t loss_train = 28151434.0 \t loss_valid = 25315210.0 \n",
      "Model_1_6610 \t loss_train = 28072944.0 \t loss_valid = 25399352.0 \n",
      "Model_1_6620 \t loss_train = 28101138.0 \t loss_valid = 25367578.0 \n",
      "Model_1_6630 \t loss_train = 28092872.0 \t loss_valid = 25382392.0 \n",
      "Model_1_6640 \t loss_train = 28118622.0 \t loss_valid = 25345780.0 \n",
      "Model_1_6650 \t loss_train = 28139354.0 \t loss_valid = 25323226.0 \n",
      "Model_1_6660 \t loss_train = 28119722.0 \t loss_valid = 25336866.0 \n",
      "Model_1_6670 \t loss_train = 28131664.0 \t loss_valid = 25326642.0 \n",
      "Model_1_6680 \t loss_train = 28095824.0 \t loss_valid = 25360756.0 \n",
      "Model_1_6690 \t loss_train = 28126376.0 \t loss_valid = 25335586.0 \n",
      "Model_1_6700 \t loss_train = 28147538.0 \t loss_valid = 25320018.0 \n",
      "Model_1_6710 \t loss_train = 28107074.0 \t loss_valid = 25351118.0 \n",
      "Model_1_6720 \t loss_train = 28091690.0 \t loss_valid = 25368376.0 \n",
      "Model_1_6730 \t loss_train = 28093340.0 \t loss_valid = 25362824.0 \n",
      "Model_1_6740 \t loss_train = 28056086.0 \t loss_valid = 25403376.0 \n",
      "Model_1_6750 \t loss_train = 28144422.0 \t loss_valid = 25311130.0 \n",
      "Model_1_6760 \t loss_train = 28090196.0 \t loss_valid = 25356386.0 \n",
      "Model_1_6770 \t loss_train = 28092000.0 \t loss_valid = 25359226.0 \n",
      "Model_1_6780 \t loss_train = 28090030.0 \t loss_valid = 25372764.0 \n",
      "Model_1_6790 \t loss_train = 28076154.0 \t loss_valid = 25384040.0 \n",
      "Model_1_6800 \t loss_train = 28086266.0 \t loss_valid = 25369128.0 \n",
      "Model_1_6810 \t loss_train = 28079150.0 \t loss_valid = 25372322.0 \n",
      "Model_1_6820 \t loss_train = 28105762.0 \t loss_valid = 25342566.0 \n",
      "Model_1_6830 \t loss_train = 28114424.0 \t loss_valid = 25336836.0 \n",
      "Model_1_6840 \t loss_train = 28103850.0 \t loss_valid = 25346624.0 \n",
      "Model_1_6850 \t loss_train = 28126562.0 \t loss_valid = 25324064.0 \n",
      "Model_1_6860 \t loss_train = 28071542.0 \t loss_valid = 25379644.0 \n",
      "Model_1_6870 \t loss_train = 28062416.0 \t loss_valid = 25391342.0 \n",
      "Model_1_6880 \t loss_train = 28180938.0 \t loss_valid = 25292672.0 \n",
      "Model_1_6890 \t loss_train = 28033052.0 \t loss_valid = 25460010.0 \n",
      "Model_1_6900 \t loss_train = 28129476.0 \t loss_valid = 25329652.0 \n",
      "Model_1_6910 \t loss_train = 28064822.0 \t loss_valid = 25409934.0 \n",
      "Model_1_6920 \t loss_train = 28191150.0 \t loss_valid = 25299812.0 \n",
      "Model_1_6930 \t loss_train = 28036162.0 \t loss_valid = 25461674.0 \n",
      "Model_1_6940 \t loss_train = 28134618.0 \t loss_valid = 25323192.0 \n",
      "Model_1_6950 \t loss_train = 28056626.0 \t loss_valid = 25398350.0 \n",
      "Model_1_6960 \t loss_train = 28068728.0 \t loss_valid = 25379194.0 \n",
      "Model_1_6970 \t loss_train = 28097456.0 \t loss_valid = 25345776.0 \n",
      "Model_1_6980 \t loss_train = 28094790.0 \t loss_valid = 25350886.0 \n",
      "Model_1_6990 \t loss_train = 28059054.0 \t loss_valid = 25400288.0 \n",
      "Model_1_7000 \t loss_train = 28072788.0 \t loss_valid = 25389504.0 \n",
      "Model_1_7010 \t loss_train = 28077144.0 \t loss_valid = 25378316.0 \n",
      "Model_1_7020 \t loss_train = 28042052.0 \t loss_valid = 25442526.0 \n",
      "Model_1_7030 \t loss_train = 28084234.0 \t loss_valid = 25376418.0 \n",
      "Model_1_7040 \t loss_train = 28091608.0 \t loss_valid = 25362654.0 \n",
      "Model_1_7050 \t loss_train = 28075674.0 \t loss_valid = 25384644.0 \n",
      "Model_1_7060 \t loss_train = 28103898.0 \t loss_valid = 25352384.0 \n",
      "Model_1_7070 \t loss_train = 28026916.0 \t loss_valid = 25479178.0 \n",
      "Model_1_7080 \t loss_train = 28090536.0 \t loss_valid = 25364032.0 \n",
      "Model_1_7090 \t loss_train = 28063734.0 \t loss_valid = 25394916.0 \n",
      "Model_1_7100 \t loss_train = 28084170.0 \t loss_valid = 25370046.0 \n",
      "Model_1_7110 \t loss_train = 28079516.0 \t loss_valid = 25371704.0 \n",
      "Model_1_7120 \t loss_train = 28068352.0 \t loss_valid = 25388126.0 \n",
      "Model_1_7130 \t loss_train = 28050994.0 \t loss_valid = 25420416.0 \n",
      "Model_1_7140 \t loss_train = 28062708.0 \t loss_valid = 25407762.0 \n",
      "Model_1_7150 \t loss_train = 28112586.0 \t loss_valid = 25348454.0 \n",
      "Model_1_7160 \t loss_train = 28037438.0 \t loss_valid = 25455108.0 \n",
      "Model_1_7170 \t loss_train = 28052702.0 \t loss_valid = 25422440.0 \n",
      "Model_1_7180 \t loss_train = 28084294.0 \t loss_valid = 25370228.0 \n",
      "Model_1_7190 \t loss_train = 28059992.0 \t loss_valid = 25395468.0 \n",
      "Model_1_7200 \t loss_train = 28139038.0 \t loss_valid = 25316308.0 \n",
      "Model_1_7210 \t loss_train = 28029418.0 \t loss_valid = 25463922.0 \n",
      "Model_1_7220 \t loss_train = 28094288.0 \t loss_valid = 25363408.0 \n",
      "Model_1_7230 \t loss_train = 28050354.0 \t loss_valid = 25420228.0 \n",
      "Model_1_7240 \t loss_train = 28077382.0 \t loss_valid = 25378614.0 \n",
      "Model_1_7250 \t loss_train = 28054750.0 \t loss_valid = 25409120.0 \n",
      "Model_1_7260 \t loss_train = 28082418.0 \t loss_valid = 25372828.0 \n",
      "Model_1_7270 \t loss_train = 28063774.0 \t loss_valid = 25402846.0 \n",
      "Model_1_7280 \t loss_train = 28075600.0 \t loss_valid = 25387934.0 \n",
      "Model_1_7290 \t loss_train = 28022704.0 \t loss_valid = 25486412.0 \n",
      "Model_1_7300 \t loss_train = 28106812.0 \t loss_valid = 25349278.0 \n",
      "Model_1_7310 \t loss_train = 28049482.0 \t loss_valid = 25422032.0 \n",
      "Model_1_7320 \t loss_train = 28096114.0 \t loss_valid = 25357206.0 \n",
      "Model_1_7330 \t loss_train = 28025000.0 \t loss_valid = 25465874.0 \n",
      "Model_1_7340 \t loss_train = 28110040.0 \t loss_valid = 25339592.0 \n",
      "Model_1_7350 \t loss_train = 28024716.0 \t loss_valid = 25462404.0 \n",
      "Model_1_7360 \t loss_train = 28063200.0 \t loss_valid = 25389242.0 \n",
      "Model_1_7370 \t loss_train = 28091132.0 \t loss_valid = 25354048.0 \n",
      "Model_1_7380 \t loss_train = 28052946.0 \t loss_valid = 25402826.0 \n",
      "Model_1_7390 \t loss_train = 28061198.0 \t loss_valid = 25389790.0 \n",
      "Model_1_7400 \t loss_train = 28075126.0 \t loss_valid = 25373180.0 \n",
      "Model_1_7410 \t loss_train = 28072008.0 \t loss_valid = 25377924.0 \n",
      "Model_1_7420 \t loss_train = 28080400.0 \t loss_valid = 25368354.0 \n",
      "Model_1_7430 \t loss_train = 28070984.0 \t loss_valid = 25379714.0 \n",
      "Model_1_7440 \t loss_train = 28060228.0 \t loss_valid = 25399352.0 \n",
      "Model_1_7450 \t loss_train = 28041856.0 \t loss_valid = 25438488.0 \n",
      "Model_1_7460 \t loss_train = 28056662.0 \t loss_valid = 25417612.0 \n",
      "Model_1_7470 \t loss_train = 28049712.0 \t loss_valid = 25434716.0 \n",
      "Model_1_7480 \t loss_train = 28074092.0 \t loss_valid = 25394408.0 \n",
      "Model_1_7490 \t loss_train = 28082516.0 \t loss_valid = 25377214.0 \n",
      "Model_1_7500 \t loss_train = 28036528.0 \t loss_valid = 25452332.0 \n",
      "Model_1_7510 \t loss_train = 28089396.0 \t loss_valid = 25371202.0 \n",
      "Model_1_7520 \t loss_train = 28031458.0 \t loss_valid = 25457898.0 \n",
      "Model_1_7530 \t loss_train = 28089348.0 \t loss_valid = 25362362.0 \n",
      "Model_1_7540 \t loss_train = 28080400.0 \t loss_valid = 25370052.0 \n",
      "Model_1_7550 \t loss_train = 28030690.0 \t loss_valid = 25446662.0 \n",
      "Model_1_7560 \t loss_train = 28095014.0 \t loss_valid = 25351834.0 \n",
      "Model_1_7570 \t loss_train = 28071688.0 \t loss_valid = 25381456.0 \n",
      "Model_1_7580 \t loss_train = 28037438.0 \t loss_valid = 25436330.0 \n",
      "Model_1_7590 \t loss_train = 28071386.0 \t loss_valid = 25380736.0 \n",
      "Model_1_7600 \t loss_train = 28038672.0 \t loss_valid = 25433106.0 \n",
      "Model_1_7610 \t loss_train = 28037710.0 \t loss_valid = 25437328.0 \n",
      "Model_1_7620 \t loss_train = 28090460.0 \t loss_valid = 25361016.0 \n",
      "Model_1_7630 \t loss_train = 28040422.0 \t loss_valid = 25430230.0 \n",
      "Model_1_7640 \t loss_train = 28073532.0 \t loss_valid = 25378496.0 \n",
      "Model_1_7650 \t loss_train = 28088846.0 \t loss_valid = 25359916.0 \n",
      "Model_1_7660 \t loss_train = 28074492.0 \t loss_valid = 25375854.0 \n",
      "Model_1_7670 \t loss_train = 28041062.0 \t loss_valid = 25428094.0 \n",
      "Model_1_7680 \t loss_train = 28045632.0 \t loss_valid = 25422998.0 \n",
      "Model_1_7690 \t loss_train = 28040500.0 \t loss_valid = 25435374.0 \n",
      "Model_1_7700 \t loss_train = 28033370.0 \t loss_valid = 25452570.0 \n",
      "Model_1_7710 \t loss_train = 28040810.0 \t loss_valid = 25436868.0 \n",
      "Model_1_7720 \t loss_train = 28042206.0 \t loss_valid = 25432572.0 \n",
      "Model_1_7730 \t loss_train = 28050814.0 \t loss_valid = 25415104.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_1_7740 \t loss_train = 28061772.0 \t loss_valid = 25396524.0 \n",
      "Model_1_7750 \t loss_train = 28059032.0 \t loss_valid = 25401234.0 \n",
      "Model_1_7760 \t loss_train = 28047586.0 \t loss_valid = 25415724.0 \n",
      "Model_1_7770 \t loss_train = 28082442.0 \t loss_valid = 25360174.0 \n",
      "Model_1_7780 \t loss_train = 28026258.0 \t loss_valid = 25463420.0 \n",
      "Model_1_7790 \t loss_train = 28062768.0 \t loss_valid = 25396054.0 \n",
      "Model_1_7800 \t loss_train = 28041578.0 \t loss_valid = 25428590.0 \n",
      "Model_1_7810 \t loss_train = 28055582.0 \t loss_valid = 25405406.0 \n",
      "Model_1_7820 \t loss_train = 28070550.0 \t loss_valid = 25391056.0 \n",
      "Model_1_7830 \t loss_train = 28021308.0 \t loss_valid = 25473810.0 \n",
      "Model_1_7840 \t loss_train = 28067828.0 \t loss_valid = 25384656.0 \n",
      "Model_1_7850 \t loss_train = 28074720.0 \t loss_valid = 25376238.0 \n",
      "Model_1_7860 \t loss_train = 28043476.0 \t loss_valid = 25423288.0 \n",
      "Model_1_7870 \t loss_train = 28029528.0 \t loss_valid = 25455034.0 \n",
      "Model_1_7880 \t loss_train = 28055192.0 \t loss_valid = 25407222.0 \n",
      "Model_1_7890 \t loss_train = 28058258.0 \t loss_valid = 25402288.0 \n",
      "Model_1_7900 \t loss_train = 28051866.0 \t loss_valid = 25413994.0 \n",
      "Model_1_7910 \t loss_train = 28061536.0 \t loss_valid = 25400956.0 \n",
      "Model_1_7920 \t loss_train = 28036546.0 \t loss_valid = 25443418.0 \n",
      "Model_1_7930 \t loss_train = 28054678.0 \t loss_valid = 25408562.0 \n",
      "Model_1_7940 \t loss_train = 28020330.0 \t loss_valid = 25478392.0 \n",
      "Model_1_7950 \t loss_train = 28020248.0 \t loss_valid = 25480294.0 \n",
      "Model_1_7960 \t loss_train = 28034082.0 \t loss_valid = 25453344.0 \n",
      "Model_1_7970 \t loss_train = 28034614.0 \t loss_valid = 25454672.0 \n",
      "Model_1_7980 \t loss_train = 28020492.0 \t loss_valid = 25484898.0 \n",
      "Model_1_7990 \t loss_train = 28073064.0 \t loss_valid = 25386552.0 \n",
      "Model_1_8000 \t loss_train = 28058834.0 \t loss_valid = 25403848.0 \n",
      "Model_1_8010 \t loss_train = 28018450.0 \t loss_valid = 25484886.0 \n",
      "Model_1_8020 \t loss_train = 28104654.0 \t loss_valid = 25348552.0 \n",
      "Model_1_8030 \t loss_train = 28042396.0 \t loss_valid = 25430128.0 \n",
      "Model_1_8040 \t loss_train = 28038286.0 \t loss_valid = 25438540.0 \n",
      "Model_1_8050 \t loss_train = 28065020.0 \t loss_valid = 25397394.0 \n",
      "Model_1_8060 \t loss_train = 28042830.0 \t loss_valid = 25435130.0 \n",
      "Model_1_8070 \t loss_train = 28017302.0 \t loss_valid = 25495910.0 \n",
      "Model_1_8080 \t loss_train = 28082758.0 \t loss_valid = 25377134.0 \n",
      "Model_1_8090 \t loss_train = 28019588.0 \t loss_valid = 25489846.0 \n",
      "Model_1_8100 \t loss_train = 28056496.0 \t loss_valid = 25411552.0 \n",
      "Model_1_8110 \t loss_train = 28042698.0 \t loss_valid = 25432206.0 \n",
      "Model_1_8120 \t loss_train = 28064688.0 \t loss_valid = 25393606.0 \n",
      "Model_1_8130 \t loss_train = 28066040.0 \t loss_valid = 25391864.0 \n",
      "Model_1_8140 \t loss_train = 28021966.0 \t loss_valid = 25477118.0 \n",
      "Model_1_8150 \t loss_train = 28037848.0 \t loss_valid = 25441028.0 \n",
      "Model_1_8160 \t loss_train = 28016384.0 \t loss_valid = 25494284.0 \n",
      "Model_1_8170 \t loss_train = 28062122.0 \t loss_valid = 25401184.0 \n",
      "Model_1_8180 \t loss_train = 28030410.0 \t loss_valid = 25457690.0 \n",
      "Model_1_8190 \t loss_train = 28037900.0 \t loss_valid = 25440286.0 \n",
      "Model_1_8200 \t loss_train = 28052452.0 \t loss_valid = 25411452.0 \n",
      "Model_1_8210 \t loss_train = 28010138.0 \t loss_valid = 25508944.0 \n",
      "Model_1_8220 \t loss_train = 28056346.0 \t loss_valid = 25404580.0 \n",
      "Model_1_8230 \t loss_train = 28033186.0 \t loss_valid = 25444882.0 \n",
      "Model_1_8240 \t loss_train = 28031842.0 \t loss_valid = 25449454.0 \n",
      "Model_1_8250 \t loss_train = 28047976.0 \t loss_valid = 25420430.0 \n",
      "Model_1_8260 \t loss_train = 28049540.0 \t loss_valid = 25418388.0 \n",
      "Model_1_8270 \t loss_train = 28039566.0 \t loss_valid = 25437510.0 \n",
      "Model_1_8280 \t loss_train = 28029402.0 \t loss_valid = 25460520.0 \n",
      "Model_1_8290 \t loss_train = 28060532.0 \t loss_valid = 25404500.0 \n",
      "Model_1_8300 \t loss_train = 28065992.0 \t loss_valid = 25397236.0 \n",
      "Model_1_8310 \t loss_train = 28018730.0 \t loss_valid = 25490318.0 \n",
      "Model_1_8320 \t loss_train = 28048608.0 \t loss_valid = 25426018.0 \n",
      "Model_1_8330 \t loss_train = 28010864.0 \t loss_valid = 25517812.0 \n",
      "Model_1_8340 \t loss_train = 28057050.0 \t loss_valid = 25413670.0 \n",
      "Model_1_8350 \t loss_train = 28061812.0 \t loss_valid = 25402402.0 \n",
      "Model_1_8360 \t loss_train = 28019622.0 \t loss_valid = 25482014.0 \n",
      "Model_1_8370 \t loss_train = 28044280.0 \t loss_valid = 25425486.0 \n",
      "Model_1_8380 \t loss_train = 28026608.0 \t loss_valid = 25461176.0 \n",
      "Model_1_8390 \t loss_train = 28028366.0 \t loss_valid = 25458164.0 \n",
      "Model_1_8400 \t loss_train = 28051958.0 \t loss_valid = 25413802.0 \n",
      "Model_1_8410 \t loss_train = 28024002.0 \t loss_valid = 25471008.0 \n",
      "Model_1_8420 \t loss_train = 28011652.0 \t loss_valid = 25506902.0 \n",
      "Model_1_8430 \t loss_train = 28059850.0 \t loss_valid = 25402146.0 \n",
      "Model_1_8440 \t loss_train = 28055958.0 \t loss_valid = 25407048.0 \n",
      "Model_1_8450 \t loss_train = 28038100.0 \t loss_valid = 25436518.0 \n",
      "Model_1_8460 \t loss_train = 28049016.0 \t loss_valid = 25417260.0 \n",
      "Model_1_8470 \t loss_train = 28026638.0 \t loss_valid = 25464032.0 \n",
      "Model_1_8480 \t loss_train = 28028442.0 \t loss_valid = 25458858.0 \n",
      "Model_1_8490 \t loss_train = 28003816.0 \t loss_valid = 25535374.0 \n",
      "Model_1_8500 \t loss_train = 28055382.0 \t loss_valid = 25409412.0 \n",
      "Model_1_8510 \t loss_train = 28029348.0 \t loss_valid = 25458600.0 \n",
      "Model_1_8520 \t loss_train = 28063230.0 \t loss_valid = 25398492.0 \n",
      "Model_1_8530 \t loss_train = 28014454.0 \t loss_valid = 25499594.0 \n",
      "Model_1_8540 \t loss_train = 28039704.0 \t loss_valid = 25438960.0 \n",
      "Model_1_8550 \t loss_train = 28056764.0 \t loss_valid = 25410496.0 \n",
      "Model_1_8560 \t loss_train = 28013928.0 \t loss_valid = 25504332.0 \n",
      "Model_1_8570 \t loss_train = 28058600.0 \t loss_valid = 25409810.0 \n",
      "Model_1_8580 \t loss_train = 28015232.0 \t loss_valid = 25500312.0 \n",
      "Model_1_8590 \t loss_train = 28049004.0 \t loss_valid = 25422402.0 \n",
      "Model_1_8600 \t loss_train = 28016314.0 \t loss_valid = 25493572.0 \n",
      "Model_1_8610 \t loss_train = 28035944.0 \t loss_valid = 25443540.0 \n",
      "Model_1_8620 \t loss_train = 28034964.0 \t loss_valid = 25450718.0 \n",
      "Model_1_8630 \t loss_train = 28004044.0 \t loss_valid = 25539740.0 \n",
      "Model_1_8640 \t loss_train = 28036806.0 \t loss_valid = 25444042.0 \n",
      "Model_1_8650 \t loss_train = 28017594.0 \t loss_valid = 25490370.0 \n",
      "Model_1_8660 \t loss_train = 28018058.0 \t loss_valid = 25487228.0 \n",
      "Model_1_8670 \t loss_train = 28059432.0 \t loss_valid = 25402010.0 \n",
      "Model_1_8680 \t loss_train = 28019790.0 \t loss_valid = 25478028.0 \n",
      "Model_1_8690 \t loss_train = 28065130.0 \t loss_valid = 25390892.0 \n",
      "Model_1_8700 \t loss_train = 28024126.0 \t loss_valid = 25467038.0 \n",
      "Model_1_8710 \t loss_train = 28034170.0 \t loss_valid = 25447212.0 \n",
      "Model_1_8720 \t loss_train = 28020500.0 \t loss_valid = 25482066.0 \n",
      "Model_1_8730 \t loss_train = 28012888.0 \t loss_valid = 25503192.0 \n",
      "Model_1_8740 \t loss_train = 28074834.0 \t loss_valid = 25380342.0 \n",
      "Model_1_8750 \t loss_train = 28018142.0 \t loss_valid = 25483134.0 \n",
      "Model_1_8760 \t loss_train = 28031428.0 \t loss_valid = 25449298.0 \n",
      "Model_1_8770 \t loss_train = 28045124.0 \t loss_valid = 25422988.0 \n",
      "Model_1_8780 \t loss_train = 28026614.0 \t loss_valid = 25462924.0 \n",
      "Model_1_8790 \t loss_train = 28029014.0 \t loss_valid = 25458672.0 \n",
      "Model_1_8800 \t loss_train = 28043760.0 \t loss_valid = 25429234.0 \n",
      "Model_1_8810 \t loss_train = 28013754.0 \t loss_valid = 25500556.0 \n",
      "Model_1_8820 \t loss_train = 28065814.0 \t loss_valid = 25394390.0 \n",
      "Model_1_8830 \t loss_train = 28014340.0 \t loss_valid = 25497252.0 \n",
      "Model_1_8840 \t loss_train = 28009254.0 \t loss_valid = 25515564.0 \n",
      "Model_1_8850 \t loss_train = 28057422.0 \t loss_valid = 25407124.0 \n",
      "Model_1_8860 \t loss_train = 28008448.0 \t loss_valid = 25521194.0 \n",
      "Model_1_8870 \t loss_train = 28025004.0 \t loss_valid = 25470278.0 \n",
      "Model_1_8880 \t loss_train = 28034450.0 \t loss_valid = 25447950.0 \n",
      "Model_1_8890 \t loss_train = 28049852.0 \t loss_valid = 25420650.0 \n",
      "Model_1_8900 \t loss_train = 28007916.0 \t loss_valid = 25524764.0 \n",
      "Model_1_8910 \t loss_train = 28043086.0 \t loss_valid = 25435310.0 \n",
      "Model_1_8920 \t loss_train = 28004748.0 \t loss_valid = 25537418.0 \n",
      "Model_1_8930 \t loss_train = 28021804.0 \t loss_valid = 25478166.0 \n",
      "Model_1_8940 \t loss_train = 28052960.0 \t loss_valid = 25413800.0 \n",
      "Model_1_8950 \t loss_train = 28008658.0 \t loss_valid = 25518144.0 \n",
      "Model_1_8960 \t loss_train = 28049268.0 \t loss_valid = 25420526.0 \n",
      "Model_1_8970 \t loss_train = 28025982.0 \t loss_valid = 25468678.0 \n",
      "Model_1_8980 \t loss_train = 28018070.0 \t loss_valid = 25491042.0 \n",
      "Model_1_8990 \t loss_train = 28042826.0 \t loss_valid = 25435316.0 \n",
      "Model_1_9000 \t loss_train = 28025950.0 \t loss_valid = 25470006.0 \n",
      "Model_1_9010 \t loss_train = 28048098.0 \t loss_valid = 25425212.0 \n",
      "Model_1_9020 \t loss_train = 28029734.0 \t loss_valid = 25462118.0 \n",
      "Model_1_9030 \t loss_train = 28013112.0 \t loss_valid = 25508630.0 \n",
      "Model_1_9040 \t loss_train = 28040320.0 \t loss_valid = 25439210.0 \n",
      "Model_1_9050 \t loss_train = 28013818.0 \t loss_valid = 25499588.0 \n",
      "Model_1_9060 \t loss_train = 28021100.0 \t loss_valid = 25479108.0 \n",
      "Model_1_9070 \t loss_train = 28012648.0 \t loss_valid = 25504548.0 \n",
      "Model_1_9080 \t loss_train = 28010756.0 \t loss_valid = 25512166.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_1_9090 \t loss_train = 28009160.0 \t loss_valid = 25518080.0 \n",
      "Model_1_9100 \t loss_train = 28032540.0 \t loss_valid = 25450174.0 \n",
      "Model_1_9110 \t loss_train = 28032082.0 \t loss_valid = 25448900.0 \n",
      "Model_1_9120 \t loss_train = 28011350.0 \t loss_valid = 25505908.0 \n",
      "Model_1_9130 \t loss_train = 28066280.0 \t loss_valid = 25392284.0 \n",
      "Model_1_9140 \t loss_train = 28018750.0 \t loss_valid = 25485800.0 \n",
      "Model_1_9150 \t loss_train = 28002800.0 \t loss_valid = 25545446.0 \n",
      "Model_1_9160 \t loss_train = 28022702.0 \t loss_valid = 25478118.0 \n",
      "Model_1_9170 \t loss_train = 28015658.0 \t loss_valid = 25498012.0 \n",
      "Model_1_9180 \t loss_train = 28024224.0 \t loss_valid = 25475040.0 \n",
      "Model_1_9190 \t loss_train = 28006014.0 \t loss_valid = 25530104.0 \n",
      "Model_1_9200 \t loss_train = 28014696.0 \t loss_valid = 25499110.0 \n",
      "Model_1_9210 \t loss_train = 28014318.0 \t loss_valid = 25502536.0 \n",
      "Model_1_9220 \t loss_train = 28011682.0 \t loss_valid = 25511756.0 \n",
      "Model_1_9230 \t loss_train = 28048872.0 \t loss_valid = 25421908.0 \n",
      "Model_1_9240 \t loss_train = 28000638.0 \t loss_valid = 25557642.0 \n",
      "Model_1_9250 \t loss_train = 28012140.0 \t loss_valid = 25507704.0 \n",
      "Model_1_9260 \t loss_train = 28008456.0 \t loss_valid = 25519736.0 \n",
      "Model_1_9270 \t loss_train = 28008966.0 \t loss_valid = 25517824.0 \n",
      "Model_1_9280 \t loss_train = 28029576.0 \t loss_valid = 25457622.0 \n",
      "Model_1_9290 \t loss_train = 28011558.0 \t loss_valid = 25505208.0 \n",
      "Model_1_9300 \t loss_train = 28034492.0 \t loss_valid = 25442320.0 \n",
      "Model_1_9310 \t loss_train = 28018806.0 \t loss_valid = 25481318.0 \n",
      "Model_1_9320 \t loss_train = 28000536.0 \t loss_valid = 25551164.0 \n",
      "Model_1_9330 \t loss_train = 28045910.0 \t loss_valid = 25424448.0 \n",
      "Model_1_9340 \t loss_train = 28022548.0 \t loss_valid = 25474624.0 \n",
      "Model_1_9350 \t loss_train = 28003532.0 \t loss_valid = 25540700.0 \n",
      "Model_1_9360 \t loss_train = 28036902.0 \t loss_valid = 25443638.0 \n",
      "Model_1_9370 \t loss_train = 28016230.0 \t loss_valid = 25494704.0 \n",
      "Model_1_9380 \t loss_train = 28014606.0 \t loss_valid = 25500096.0 \n",
      "Model_1_9390 \t loss_train = 28050062.0 \t loss_valid = 25420054.0 \n",
      "Model_1_9400 \t loss_train = 28007426.0 \t loss_valid = 25526762.0 \n",
      "Model_1_9410 \t loss_train = 28012476.0 \t loss_valid = 25507868.0 \n",
      "Model_1_9420 \t loss_train = 28023808.0 \t loss_valid = 25473952.0 \n",
      "Model_1_9430 \t loss_train = 28009826.0 \t loss_valid = 25514754.0 \n",
      "Model_1_9440 \t loss_train = 28029456.0 \t loss_valid = 25460666.0 \n",
      "Model_1_9450 \t loss_train = 28032052.0 \t loss_valid = 25456508.0 \n",
      "Model_1_9460 \t loss_train = 28024632.0 \t loss_valid = 25473520.0 \n",
      "Model_1_9470 \t loss_train = 28010608.0 \t loss_valid = 25510916.0 \n",
      "Model_1_9480 \t loss_train = 28027686.0 \t loss_valid = 25458246.0 \n",
      "Model_1_9490 \t loss_train = 28019492.0 \t loss_valid = 25479508.0 \n",
      "Model_1_9500 \t loss_train = 28024490.0 \t loss_valid = 25467000.0 \n",
      "Model_1_9510 \t loss_train = 28017940.0 \t loss_valid = 25486134.0 \n",
      "Model_1_9520 \t loss_train = 28023176.0 \t loss_valid = 25471576.0 \n",
      "Model_1_9530 \t loss_train = 28016728.0 \t loss_valid = 25488670.0 \n",
      "Model_1_9540 \t loss_train = 28018648.0 \t loss_valid = 25481314.0 \n",
      "Model_1_9550 \t loss_train = 28057370.0 \t loss_valid = 25399872.0 \n",
      "Model_1_9560 \t loss_train = 27999018.0 \t loss_valid = 25555440.0 \n",
      "Model_1_9570 \t loss_train = 28033062.0 \t loss_valid = 25446426.0 \n",
      "Model_1_9580 \t loss_train = 28014810.0 \t loss_valid = 25492432.0 \n",
      "Model_1_9590 \t loss_train = 28023006.0 \t loss_valid = 25470002.0 \n",
      "Model_1_9600 \t loss_train = 28063502.0 \t loss_valid = 25393924.0 \n",
      "Model_1_9610 \t loss_train = 28011006.0 \t loss_valid = 25503242.0 \n",
      "Model_1_9620 \t loss_train = 28017624.0 \t loss_valid = 25486364.0 \n",
      "Model_1_9630 \t loss_train = 28017860.0 \t loss_valid = 25488258.0 \n",
      "Model_1_9640 \t loss_train = 27997300.0 \t loss_valid = 25568862.0 \n",
      "Model_1_9650 \t loss_train = 28017066.0 \t loss_valid = 25485980.0 \n",
      "Model_1_9660 \t loss_train = 28007318.0 \t loss_valid = 25518570.0 \n",
      "Model_1_9670 \t loss_train = 28013444.0 \t loss_valid = 25500004.0 \n",
      "Model_1_9680 \t loss_train = 28023518.0 \t loss_valid = 25473456.0 \n",
      "Model_1_9690 \t loss_train = 28024944.0 \t loss_valid = 25469074.0 \n",
      "Model_1_9700 \t loss_train = 27999774.0 \t loss_valid = 25556078.0 \n",
      "Model_1_9710 \t loss_train = 28009854.0 \t loss_valid = 25510742.0 \n",
      "Model_1_9720 \t loss_train = 28026028.0 \t loss_valid = 25461756.0 \n",
      "Model_1_9730 \t loss_train = 27998376.0 \t loss_valid = 25558436.0 \n",
      "Model_1_9740 \t loss_train = 28029810.0 \t loss_valid = 25450926.0 \n",
      "Model_1_9750 \t loss_train = 28038726.0 \t loss_valid = 25435818.0 \n",
      "Model_1_9760 \t loss_train = 28005056.0 \t loss_valid = 25529634.0 \n",
      "Model_1_9770 \t loss_train = 28024728.0 \t loss_valid = 25464304.0 \n",
      "Model_1_9780 \t loss_train = 27998030.0 \t loss_valid = 25560014.0 \n",
      "Model_1_9790 \t loss_train = 28032356.0 \t loss_valid = 25448480.0 \n",
      "Model_1_9800 \t loss_train = 28015896.0 \t loss_valid = 25491934.0 \n",
      "Model_1_9810 \t loss_train = 28001146.0 \t loss_valid = 25549534.0 \n",
      "Model_1_9820 \t loss_train = 28008402.0 \t loss_valid = 25519012.0 \n",
      "Model_1_9830 \t loss_train = 28055212.0 \t loss_valid = 25409090.0 \n",
      "Model_1_9840 \t loss_train = 28002500.0 \t loss_valid = 25545160.0 \n",
      "Model_1_9850 \t loss_train = 28016796.0 \t loss_valid = 25494610.0 \n",
      "Model_1_9860 \t loss_train = 28015188.0 \t loss_valid = 25499846.0 \n",
      "Model_1_9870 \t loss_train = 28024118.0 \t loss_valid = 25473646.0 \n",
      "Model_1_9880 \t loss_train = 28004900.0 \t loss_valid = 25534574.0 \n",
      "Model_1_9890 \t loss_train = 28021664.0 \t loss_valid = 25481058.0 \n",
      "Model_1_9900 \t loss_train = 28026130.0 \t loss_valid = 25469526.0 \n",
      "Model_1_9910 \t loss_train = 27995330.0 \t loss_valid = 25587174.0 \n",
      "Model_1_9920 \t loss_train = 28024412.0 \t loss_valid = 25469284.0 \n",
      "Model_1_9930 \t loss_train = 28037166.0 \t loss_valid = 25438502.0 \n",
      "Model_1_9940 \t loss_train = 27995982.0 \t loss_valid = 25578638.0 \n",
      "Model_1_9950 \t loss_train = 28016230.0 \t loss_valid = 25495314.0 \n",
      "Model_1_9960 \t loss_train = 28018616.0 \t loss_valid = 25490160.0 \n",
      "Model_1_9970 \t loss_train = 28005648.0 \t loss_valid = 25534840.0 \n",
      "Model_1_9980 \t loss_train = 28022426.0 \t loss_valid = 25480324.0 \n",
      "Model_1_9990 \t loss_train = 28010862.0 \t loss_valid = 25509508.0 \n",
      "Model_1_10000 \t loss_train = 28012538.0 \t loss_valid = 25500822.0 \n",
      "Model_1_10010 \t loss_train = 28020702.0 \t loss_valid = 25477786.0 \n",
      "Model_1_10020 \t loss_train = 28012034.0 \t loss_valid = 25506858.0 \n",
      "Model_1_10030 \t loss_train = 28011486.0 \t loss_valid = 25510820.0 \n",
      "Model_1_10040 \t loss_train = 28006656.0 \t loss_valid = 25530198.0 \n",
      "Model_1_10050 \t loss_train = 28005854.0 \t loss_valid = 25532942.0 \n",
      "Model_1_10060 \t loss_train = 28010978.0 \t loss_valid = 25517742.0 \n",
      "Model_1_10070 \t loss_train = 28020394.0 \t loss_valid = 25492054.0 \n",
      "Model_1_10080 \t loss_train = 28013870.0 \t loss_valid = 25510404.0 \n",
      "Model_1_10090 \t loss_train = 28053170.0 \t loss_valid = 25417488.0 \n",
      "Model_1_10100 \t loss_train = 28026364.0 \t loss_valid = 25468254.0 \n",
      "Model_1_10110 \t loss_train = 27995058.0 \t loss_valid = 25586496.0 \n",
      "Model_1_10120 \t loss_train = 28021404.0 \t loss_valid = 25475494.0 \n",
      "Model_1_10130 \t loss_train = 28012696.0 \t loss_valid = 25501000.0 \n",
      "Model_1_10140 \t loss_train = 27999172.0 \t loss_valid = 25558728.0 \n",
      "Model_1_10150 \t loss_train = 28037042.0 \t loss_valid = 25440624.0 \n",
      "Model_1_10160 \t loss_train = 28001726.0 \t loss_valid = 25548112.0 \n",
      "Model_1_10170 \t loss_train = 28003222.0 \t loss_valid = 25545624.0 \n",
      "Model_1_10180 \t loss_train = 28017524.0 \t loss_valid = 25495232.0 \n",
      "Model_1_10190 \t loss_train = 28004046.0 \t loss_valid = 25540652.0 \n",
      "Model_1_10200 \t loss_train = 28007526.0 \t loss_valid = 25524170.0 \n",
      "Model_1_10210 \t loss_train = 28002664.0 \t loss_valid = 25543398.0 \n",
      "Model_1_10220 \t loss_train = 28039114.0 \t loss_valid = 25440066.0 \n",
      "Model_1_10230 \t loss_train = 28020850.0 \t loss_valid = 25481612.0 \n",
      "Model_1_10240 \t loss_train = 28016692.0 \t loss_valid = 25491152.0 \n",
      "Model_1_10250 \t loss_train = 28016722.0 \t loss_valid = 25492928.0 \n",
      "Model_1_10260 \t loss_train = 28008298.0 \t loss_valid = 25521170.0 \n",
      "Model_1_10270 \t loss_train = 28020258.0 \t loss_valid = 25478480.0 \n",
      "Model_1_10280 \t loss_train = 28008886.0 \t loss_valid = 25511298.0 \n",
      "Model_1_10290 \t loss_train = 28011780.0 \t loss_valid = 25501424.0 \n",
      "Model_1_10300 \t loss_train = 28006950.0 \t loss_valid = 25521026.0 \n",
      "Model_1_10310 \t loss_train = 28001980.0 \t loss_valid = 25543424.0 \n",
      "Model_1_10320 \t loss_train = 28009370.0 \t loss_valid = 25512352.0 \n",
      "Model_1_10330 \t loss_train = 28033676.0 \t loss_valid = 25446116.0 \n",
      "Model_1_10340 \t loss_train = 28007384.0 \t loss_valid = 25516582.0 \n",
      "Model_1_10350 \t loss_train = 27999740.0 \t loss_valid = 25549046.0 \n",
      "Model_1_10360 \t loss_train = 28019504.0 \t loss_valid = 25476110.0 \n",
      "Model_1_10370 \t loss_train = 27997200.0 \t loss_valid = 25564086.0 \n",
      "Model_1_10380 \t loss_train = 28019756.0 \t loss_valid = 25476534.0 \n",
      "Model_1_10390 \t loss_train = 28036214.0 \t loss_valid = 25438520.0 \n",
      "Model_1_10400 \t loss_train = 27994090.0 \t loss_valid = 25589118.0 \n",
      "Model_1_10410 \t loss_train = 28034396.0 \t loss_valid = 25444872.0 \n",
      "Model_1_10420 \t loss_train = 28002712.0 \t loss_valid = 25539824.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_1_10430 \t loss_train = 28024852.0 \t loss_valid = 25465572.0 \n",
      "Model_1_10440 \t loss_train = 28010538.0 \t loss_valid = 25508498.0 \n",
      "Model_1_10450 \t loss_train = 27995960.0 \t loss_valid = 25581300.0 \n",
      "Model_1_10460 \t loss_train = 28021172.0 \t loss_valid = 25482018.0 \n",
      "Model_1_10470 \t loss_train = 28004492.0 \t loss_valid = 25538258.0 \n",
      "Model_1_10480 \t loss_train = 28012006.0 \t loss_valid = 25508168.0 \n",
      "Model_1_10490 \t loss_train = 28011786.0 \t loss_valid = 25509092.0 \n",
      "Model_1_10500 \t loss_train = 28023180.0 \t loss_valid = 25475950.0 \n",
      "Model_1_10510 \t loss_train = 28008754.0 \t loss_valid = 25518990.0 \n",
      "Model_1_10520 \t loss_train = 28000602.0 \t loss_valid = 25555882.0 \n",
      "Model_1_10530 \t loss_train = 28012572.0 \t loss_valid = 25507754.0 \n",
      "Model_1_10540 \t loss_train = 28001048.0 \t loss_valid = 25554164.0 \n",
      "Model_1_10550 \t loss_train = 28021886.0 \t loss_valid = 25480130.0 \n",
      "Model_1_10560 \t loss_train = 27996904.0 \t loss_valid = 25578002.0 \n",
      "Model_1_10570 \t loss_train = 28006136.0 \t loss_valid = 25530116.0 \n",
      "Model_1_10580 \t loss_train = 28003968.0 \t loss_valid = 25537344.0 \n",
      "Model_1_10590 \t loss_train = 28027580.0 \t loss_valid = 25461924.0 \n",
      "Model_1_10600 \t loss_train = 28005722.0 \t loss_valid = 25529988.0 \n",
      "Model_1_10610 \t loss_train = 28023590.0 \t loss_valid = 25471098.0 \n",
      "Model_1_10620 \t loss_train = 28006874.0 \t loss_valid = 25520524.0 \n",
      "Model_1_10630 \t loss_train = 28008862.0 \t loss_valid = 25512436.0 \n",
      "Model_1_10640 \t loss_train = 28018916.0 \t loss_valid = 25478552.0 \n",
      "Model_1_10650 \t loss_train = 27991186.0 \t loss_valid = 25615680.0 \n",
      "Model_1_10660 \t loss_train = 28039042.0 \t loss_valid = 25431852.0 \n",
      "Model_1_10670 \t loss_train = 28003102.0 \t loss_valid = 25535466.0 \n",
      "Model_1_10680 \t loss_train = 28010370.0 \t loss_valid = 25508018.0 \n",
      "Model_1_10690 \t loss_train = 28009926.0 \t loss_valid = 25508950.0 \n",
      "Model_1_10700 \t loss_train = 28012494.0 \t loss_valid = 25501010.0 \n",
      "Model_1_10710 \t loss_train = 28008952.0 \t loss_valid = 25513198.0 \n",
      "Model_1_10720 \t loss_train = 28014806.0 \t loss_valid = 25493698.0 \n",
      "Model_1_10730 \t loss_train = 27998174.0 \t loss_valid = 25562576.0 \n",
      "Model_1_10740 \t loss_train = 28046210.0 \t loss_valid = 25422644.0 \n",
      "Model_1_10750 \t loss_train = 27994890.0 \t loss_valid = 25585818.0 \n",
      "Model_1_10760 \t loss_train = 28042622.0 \t loss_valid = 25429614.0 \n",
      "Model_1_10770 \t loss_train = 28003252.0 \t loss_valid = 25539992.0 \n",
      "Model_1_10780 \t loss_train = 28005820.0 \t loss_valid = 25527974.0 \n",
      "Model_1_10790 \t loss_train = 28009398.0 \t loss_valid = 25513362.0 \n",
      "Model_1_10800 \t loss_train = 27998196.0 \t loss_valid = 25564932.0 \n",
      "Model_1_10810 \t loss_train = 28018798.0 \t loss_valid = 25487226.0 \n",
      "Model_1_10820 \t loss_train = 28004026.0 \t loss_valid = 25538878.0 \n",
      "Model_1_10830 \t loss_train = 28010980.0 \t loss_valid = 25510458.0 \n",
      "Model_1_10840 \t loss_train = 28013244.0 \t loss_valid = 25504594.0 \n",
      "Model_1_10850 \t loss_train = 28005220.0 \t loss_valid = 25535838.0 \n",
      "Model_1_10860 \t loss_train = 28012490.0 \t loss_valid = 25506744.0 \n",
      "Model_1_10870 \t loss_train = 28009248.0 \t loss_valid = 25516728.0 \n",
      "Model_1_10880 \t loss_train = 27998558.0 \t loss_valid = 25561296.0 \n",
      "Model_1_10890 \t loss_train = 28001486.0 \t loss_valid = 25543642.0 \n",
      "Model_1_10900 \t loss_train = 28008440.0 \t loss_valid = 25514006.0 \n",
      "Model_1_10910 \t loss_train = 28009594.0 \t loss_valid = 25510484.0 \n",
      "Model_1_10920 \t loss_train = 28004150.0 \t loss_valid = 25534170.0 \n",
      "Model_1_10930 \t loss_train = 28017522.0 \t loss_valid = 25488318.0 \n",
      "Model_1_10940 \t loss_train = 28002428.0 \t loss_valid = 25546758.0 \n",
      "Model_1_10950 \t loss_train = 28011100.0 \t loss_valid = 25512768.0 \n",
      "Model_1_10960 \t loss_train = 27997044.0 \t loss_valid = 25575728.0 \n",
      "Model_1_10970 \t loss_train = 28008760.0 \t loss_valid = 25518890.0 \n",
      "Model_1_10980 \t loss_train = 28015082.0 \t loss_valid = 25495994.0 \n",
      "Model_1_10990 \t loss_train = 28012666.0 \t loss_valid = 25504170.0 \n",
      "Model_1_11000 \t loss_train = 28000096.0 \t loss_valid = 25558704.0 \n",
      "Model_1_11010 \t loss_train = 28008980.0 \t loss_valid = 25522658.0 \n",
      "Model_1_11020 \t loss_train = 28026016.0 \t loss_valid = 25472066.0 \n",
      "Model_1_11030 \t loss_train = 27992732.0 \t loss_valid = 25611194.0 \n",
      "Model_1_11040 \t loss_train = 28019760.0 \t loss_valid = 25485004.0 \n",
      "Model_1_11050 \t loss_train = 27999112.0 \t loss_valid = 25566436.0 \n",
      "Model_1_11060 \t loss_train = 27999828.0 \t loss_valid = 25565398.0 \n",
      "Model_1_11070 \t loss_train = 28010586.0 \t loss_valid = 25520364.0 \n",
      "Model_1_11080 \t loss_train = 28012426.0 \t loss_valid = 25511834.0 \n",
      "Model_1_11090 \t loss_train = 28007828.0 \t loss_valid = 25523694.0 \n",
      "Model_1_11100 \t loss_train = 28021558.0 \t loss_valid = 25478966.0 \n",
      "Model_1_11110 \t loss_train = 28005360.0 \t loss_valid = 25531136.0 \n",
      "Model_1_11120 \t loss_train = 28024230.0 \t loss_valid = 25468942.0 \n",
      "Model_1_11130 \t loss_train = 28001424.0 \t loss_valid = 25546056.0 \n",
      "Model_1_11140 \t loss_train = 28008920.0 \t loss_valid = 25515128.0 \n",
      "Model_1_11150 \t loss_train = 28022010.0 \t loss_valid = 25473564.0 \n",
      "Model_1_11160 \t loss_train = 27995096.0 \t loss_valid = 25583050.0 \n",
      "Model_1_11170 \t loss_train = 28004964.0 \t loss_valid = 25531826.0 \n",
      "Model_1_11180 \t loss_train = 28009452.0 \t loss_valid = 25518282.0 \n",
      "Model_1_11190 \t loss_train = 28010414.0 \t loss_valid = 25517888.0 \n",
      "Model_1_11200 \t loss_train = 28013808.0 \t loss_valid = 25506644.0 \n",
      "Model_1_11210 \t loss_train = 27992730.0 \t loss_valid = 25612344.0 \n",
      "Model_1_11220 \t loss_train = 28019408.0 \t loss_valid = 25487120.0 \n",
      "Model_1_11230 \t loss_train = 28014506.0 \t loss_valid = 25497518.0 \n",
      "Model_1_11240 \t loss_train = 27993882.0 \t loss_valid = 25594102.0 \n",
      "Model_1_11250 \t loss_train = 28009738.0 \t loss_valid = 25514198.0 \n",
      "Model_1_11260 \t loss_train = 28003772.0 \t loss_valid = 25547268.0 \n",
      "Model_1_11270 \t loss_train = 28008344.0 \t loss_valid = 25517224.0 \n",
      "Model_1_11280 \t loss_train = 28001086.0 \t loss_valid = 25545640.0 \n",
      "Model_1_11290 \t loss_train = 28000724.0 \t loss_valid = 25546022.0 \n",
      "Model_1_11300 \t loss_train = 27998848.0 \t loss_valid = 25556710.0 \n",
      "Model_1_11310 \t loss_train = 28025154.0 \t loss_valid = 25462736.0 \n",
      "Model_1_11320 \t loss_train = 27993876.0 \t loss_valid = 25589284.0 \n",
      "Model_1_11330 \t loss_train = 28006608.0 \t loss_valid = 25525260.0 \n",
      "Model_1_11340 \t loss_train = 28021726.0 \t loss_valid = 25479820.0 \n",
      "Model_1_11350 \t loss_train = 28004972.0 \t loss_valid = 25536248.0 \n",
      "Model_1_11360 \t loss_train = 27997182.0 \t loss_valid = 25576724.0 \n",
      "Model_1_11370 \t loss_train = 28010616.0 \t loss_valid = 25514166.0 \n",
      "Model_1_11380 \t loss_train = 28037534.0 \t loss_valid = 25446156.0 \n",
      "Model_1_11390 \t loss_train = 27996710.0 \t loss_valid = 25583802.0 \n",
      "Model_1_11400 \t loss_train = 28004006.0 \t loss_valid = 25544090.0 \n",
      "Model_1_11410 \t loss_train = 28015130.0 \t loss_valid = 25499644.0 \n",
      "Model_1_11420 \t loss_train = 28007210.0 \t loss_valid = 25524774.0 \n",
      "Model_1_11430 \t loss_train = 27998064.0 \t loss_valid = 25566336.0 \n",
      "Model_1_11440 \t loss_train = 27995804.0 \t loss_valid = 25587420.0 \n",
      "Model_1_11450 \t loss_train = 28026842.0 \t loss_valid = 25460894.0 \n",
      "Model_1_11460 \t loss_train = 27999226.0 \t loss_valid = 25555674.0 \n",
      "Model_1_11470 \t loss_train = 28009604.0 \t loss_valid = 25511924.0 \n",
      "Model_1_11480 \t loss_train = 28022286.0 \t loss_valid = 25475770.0 \n",
      "Model_1_11490 \t loss_train = 28012652.0 \t loss_valid = 25505536.0 \n",
      "Model_1_11500 \t loss_train = 27993040.0 \t loss_valid = 25605690.0 \n",
      "Model_1_11510 \t loss_train = 28044854.0 \t loss_valid = 25430468.0 \n",
      "Model_1_11520 \t loss_train = 27993352.0 \t loss_valid = 25604784.0 \n",
      "Model_1_11530 \t loss_train = 28004550.0 \t loss_valid = 25537410.0 \n",
      "Model_1_11540 \t loss_train = 28007916.0 \t loss_valid = 25524392.0 \n",
      "Model_1_11550 \t loss_train = 28017116.0 \t loss_valid = 25491656.0 \n",
      "Model_1_11560 \t loss_train = 27995052.0 \t loss_valid = 25584162.0 \n",
      "Model_1_11570 \t loss_train = 28004972.0 \t loss_valid = 25529744.0 \n",
      "Model_1_11580 \t loss_train = 28005798.0 \t loss_valid = 25526400.0 \n",
      "Model_1_11590 \t loss_train = 27996816.0 \t loss_valid = 25572138.0 \n",
      "Model_1_11600 \t loss_train = 28035258.0 \t loss_valid = 25445336.0 \n",
      "Model_1_11610 \t loss_train = 28013492.0 \t loss_valid = 25501392.0 \n",
      "Model_1_11620 \t loss_train = 27994394.0 \t loss_valid = 25591600.0 \n",
      "Model_1_11630 \t loss_train = 28003760.0 \t loss_valid = 25537976.0 \n",
      "Model_1_11640 \t loss_train = 27997886.0 \t loss_valid = 25568086.0 \n",
      "Model_1_11650 \t loss_train = 27997798.0 \t loss_valid = 25568496.0 \n",
      "Model_1_11660 \t loss_train = 28020706.0 \t loss_valid = 25483356.0 \n",
      "Model_1_11670 \t loss_train = 28011672.0 \t loss_valid = 25510358.0 \n",
      "Model_1_11680 \t loss_train = 28001028.0 \t loss_valid = 25551910.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_1_11690 \t loss_train = 28007384.0 \t loss_valid = 25522158.0 \n",
      "Model_1_11700 \t loss_train = 28015708.0 \t loss_valid = 25494322.0 \n",
      "Model_1_11710 \t loss_train = 27998162.0 \t loss_valid = 25568490.0 \n",
      "Model_1_11720 \t loss_train = 27997476.0 \t loss_valid = 25573566.0 \n",
      "Model_1_11730 \t loss_train = 28017122.0 \t loss_valid = 25491888.0 \n",
      "Model_1_11740 \t loss_train = 28007096.0 \t loss_valid = 25525580.0 \n",
      "Model_1_11750 \t loss_train = 27998232.0 \t loss_valid = 25564020.0 \n",
      "Model_1_11760 \t loss_train = 28019770.0 \t loss_valid = 25479012.0 \n",
      "Model_1_11770 \t loss_train = 28011584.0 \t loss_valid = 25503864.0 \n",
      "Model_1_11780 \t loss_train = 28007726.0 \t loss_valid = 25518776.0 \n",
      "Model_1_11790 \t loss_train = 28001204.0 \t loss_valid = 25547474.0 \n",
      "Model_1_11800 \t loss_train = 27992422.0 \t loss_valid = 25608204.0 \n",
      "Model_1_11810 \t loss_train = 28020050.0 \t loss_valid = 25484930.0 \n",
      "Model_1_11820 \t loss_train = 28027004.0 \t loss_valid = 25467814.0 \n",
      "Model_1_11830 \t loss_train = 27995988.0 \t loss_valid = 25584320.0 \n",
      "Model_1_11840 \t loss_train = 28003152.0 \t loss_valid = 25543906.0 \n",
      "Model_1_11850 \t loss_train = 28018660.0 \t loss_valid = 25487846.0 \n",
      "Model_1_11860 \t loss_train = 28004004.0 \t loss_valid = 25536794.0 \n",
      "Model_1_11870 \t loss_train = 28003450.0 \t loss_valid = 25536686.0 \n",
      "Model_1_11880 \t loss_train = 28007750.0 \t loss_valid = 25518054.0 \n",
      "Model_1_11890 \t loss_train = 28003392.0 \t loss_valid = 25534220.0 \n",
      "Model_1_11900 \t loss_train = 28009874.0 \t loss_valid = 25509222.0 \n",
      "Model_1_11910 \t loss_train = 27997220.0 \t loss_valid = 25568036.0 \n",
      "Model_1_11920 \t loss_train = 28005288.0 \t loss_valid = 25529766.0 \n",
      "Model_1_11930 \t loss_train = 28036396.0 \t loss_valid = 25445436.0 \n",
      "Model_1_11940 \t loss_train = 27995770.0 \t loss_valid = 25588444.0 \n",
      "Model_1_11950 \t loss_train = 28005288.0 \t loss_valid = 25539766.0 \n",
      "Model_1_11960 \t loss_train = 28011112.0 \t loss_valid = 25517346.0 \n",
      "Model_1_11970 \t loss_train = 28006092.0 \t loss_valid = 25535728.0 \n",
      "Model_1_11980 \t loss_train = 28003094.0 \t loss_valid = 25547666.0 \n",
      "Model_1_11990 \t loss_train = 28012290.0 \t loss_valid = 25509622.0 \n",
      "Model_1_12000 \t loss_train = 28015988.0 \t loss_valid = 25496564.0 \n",
      "Model_1_12010 \t loss_train = 27991822.0 \t loss_valid = 25617348.0 \n",
      "Model_1_12020 \t loss_train = 28005144.0 \t loss_valid = 25533990.0 \n",
      "Model_1_12030 \t loss_train = 28014600.0 \t loss_valid = 25500882.0 \n",
      "Model_1_12040 \t loss_train = 27996348.0 \t loss_valid = 25580470.0 \n",
      "Model_1_12050 \t loss_train = 28015716.0 \t loss_valid = 25497400.0 \n",
      "Model_1_12060 \t loss_train = 28004004.0 \t loss_valid = 25539976.0 \n",
      "Model_1_12070 \t loss_train = 27999158.0 \t loss_valid = 25563200.0 \n",
      "Model_1_12080 \t loss_train = 28014234.0 \t loss_valid = 25501430.0 \n",
      "Model_1_12090 \t loss_train = 28004642.0 \t loss_valid = 25536696.0 \n",
      "Model_1_12100 \t loss_train = 28001962.0 \t loss_valid = 25546886.0 \n",
      "Model_1_12110 \t loss_train = 28002570.0 \t loss_valid = 25543062.0 \n",
      "Model_1_12120 \t loss_train = 28021412.0 \t loss_valid = 25478426.0 \n",
      "Model_1_12130 \t loss_train = 27999044.0 \t loss_valid = 25559378.0 \n",
      "Model_1_12140 \t loss_train = 28009280.0 \t loss_valid = 25514296.0 \n",
      "Model_1_12150 \t loss_train = 28020230.0 \t loss_valid = 25479424.0 \n",
      "Model_1_12160 \t loss_train = 27992406.0 \t loss_valid = 25604464.0 \n",
      "Model_1_12170 \t loss_train = 28006876.0 \t loss_valid = 25521464.0 \n",
      "Model_1_12180 \t loss_train = 28018094.0 \t loss_valid = 25484602.0 \n",
      "Model_1_12190 \t loss_train = 28012090.0 \t loss_valid = 25501752.0 \n",
      "Model_1_12200 \t loss_train = 27999502.0 \t loss_valid = 25552398.0 \n",
      "Model_1_12210 \t loss_train = 28007936.0 \t loss_valid = 25514888.0 \n",
      "Model_1_12220 \t loss_train = 28011150.0 \t loss_valid = 25503536.0 \n",
      "Model_1_12230 \t loss_train = 28016836.0 \t loss_valid = 25486020.0 \n",
      "Model_1_12240 \t loss_train = 27992526.0 \t loss_valid = 25601682.0 \n",
      "Model_1_12250 \t loss_train = 28000288.0 \t loss_valid = 25548740.0 \n",
      "Model_1_12260 \t loss_train = 28013856.0 \t loss_valid = 25495932.0 \n",
      "Model_1_12270 \t loss_train = 28005078.0 \t loss_valid = 25528362.0 \n",
      "Model_1_12280 \t loss_train = 28017920.0 \t loss_valid = 25485078.0 \n",
      "Model_1_12290 \t loss_train = 28006422.0 \t loss_valid = 25522864.0 \n",
      "Model_1_12300 \t loss_train = 28007718.0 \t loss_valid = 25518298.0 \n",
      "Model_1_12310 \t loss_train = 28001788.0 \t loss_valid = 25543504.0 \n",
      "Model_1_12320 \t loss_train = 28001514.0 \t loss_valid = 25544436.0 \n",
      "Model_1_12330 \t loss_train = 27998330.0 \t loss_valid = 25562164.0 \n",
      "Model_1_12340 \t loss_train = 28021678.0 \t loss_valid = 25476462.0 \n",
      "Model_1_12350 \t loss_train = 28001696.0 \t loss_valid = 25545102.0 \n",
      "Model_1_12360 \t loss_train = 27992232.0 \t loss_valid = 25607504.0 \n",
      "Model_1_12370 \t loss_train = 28005412.0 \t loss_valid = 25528460.0 \n",
      "Model_1_12380 \t loss_train = 28027904.0 \t loss_valid = 25459686.0 \n",
      "Model_1_12390 \t loss_train = 28009420.0 \t loss_valid = 25511632.0 \n",
      "Model_1_12400 \t loss_train = 27994328.0 \t loss_valid = 25588160.0 \n",
      "Model_1_12410 \t loss_train = 28015796.0 \t loss_valid = 25491198.0 \n",
      "Model_1_12420 \t loss_train = 28005640.0 \t loss_valid = 25525922.0 \n",
      "Model_1_12430 \t loss_train = 27995134.0 \t loss_valid = 25581092.0 \n",
      "Model_1_12440 \t loss_train = 28018260.0 \t loss_valid = 25484486.0 \n",
      "Model_1_12450 \t loss_train = 28011008.0 \t loss_valid = 25506290.0 \n",
      "Model_1_12460 \t loss_train = 27994904.0 \t loss_valid = 25582358.0 \n",
      "Model_1_12470 \t loss_train = 28023770.0 \t loss_valid = 25467698.0 \n",
      "Model_1_12480 \t loss_train = 27996306.0 \t loss_valid = 25573014.0 \n",
      "Model_1_12490 \t loss_train = 28019134.0 \t loss_valid = 25482126.0 \n",
      "Model_1_12500 \t loss_train = 28015286.0 \t loss_valid = 25493674.0 \n",
      "Model_1_12510 \t loss_train = 28007256.0 \t loss_valid = 25520660.0 \n",
      "Model_1_12520 \t loss_train = 27999996.0 \t loss_valid = 25551502.0 \n",
      "Model_1_12530 \t loss_train = 28001258.0 \t loss_valid = 25544298.0 \n",
      "Model_1_12540 \t loss_train = 28036800.0 \t loss_valid = 25438988.0 \n",
      "Model_1_12550 \t loss_train = 27995000.0 \t loss_valid = 25580072.0 \n",
      "Model_1_12560 \t loss_train = 27993602.0 \t loss_valid = 25590098.0 \n",
      "Model_1_12570 \t loss_train = 28000344.0 \t loss_valid = 25547972.0 \n",
      "Model_1_12580 \t loss_train = 27994718.0 \t loss_valid = 25583636.0 \n",
      "Model_1_12590 \t loss_train = 28029556.0 \t loss_valid = 25457234.0 \n",
      "Model_1_12600 \t loss_train = 27990296.0 \t loss_valid = 25632822.0 \n",
      "Model_1_12610 \t loss_train = 27995810.0 \t loss_valid = 25579510.0 \n",
      "Model_1_12620 \t loss_train = 28020538.0 \t loss_valid = 25479932.0 \n",
      "Model_1_12630 \t loss_train = 28008352.0 \t loss_valid = 25517600.0 \n",
      "Model_1_12640 \t loss_train = 27998574.0 \t loss_valid = 25561164.0 \n",
      "Model_1_12650 \t loss_train = 28021270.0 \t loss_valid = 25477414.0 \n",
      "Model_1_12660 \t loss_train = 27997574.0 \t loss_valid = 25566570.0 \n",
      "Model_1_12670 \t loss_train = 27995722.0 \t loss_valid = 25578556.0 \n",
      "Model_1_12680 \t loss_train = 28000594.0 \t loss_valid = 25549970.0 \n",
      "Model_1_12690 \t loss_train = 27993868.0 \t loss_valid = 25590262.0 \n",
      "Model_1_12700 \t loss_train = 28002414.0 \t loss_valid = 25538802.0 \n",
      "Model_1_12710 \t loss_train = 28009776.0 \t loss_valid = 25509860.0 \n",
      "Model_1_12720 \t loss_train = 28003524.0 \t loss_valid = 25535178.0 \n",
      "Model_1_12730 \t loss_train = 28004278.0 \t loss_valid = 25532766.0 \n",
      "Model_1_12740 \t loss_train = 27996506.0 \t loss_valid = 25573622.0 \n",
      "Model_1_12750 \t loss_train = 28010340.0 \t loss_valid = 25511538.0 \n",
      "Model_1_12760 \t loss_train = 28001042.0 \t loss_valid = 25550224.0 \n",
      "Model_1_12770 \t loss_train = 28008180.0 \t loss_valid = 25521130.0 \n",
      "Model_1_12780 \t loss_train = 28007918.0 \t loss_valid = 25522688.0 \n",
      "Model_1_12790 \t loss_train = 27998360.0 \t loss_valid = 25567190.0 \n",
      "Model_1_12800 \t loss_train = 27995252.0 \t loss_valid = 25584770.0 \n",
      "Model_1_12810 \t loss_train = 28005316.0 \t loss_valid = 25530118.0 \n",
      "Model_1_12820 \t loss_train = 27998742.0 \t loss_valid = 25560814.0 \n",
      "Model_1_12830 \t loss_train = 27998144.0 \t loss_valid = 25563792.0 \n",
      "Model_1_12840 \t loss_train = 28019606.0 \t loss_valid = 25482422.0 \n",
      "Model_1_12850 \t loss_train = 27992596.0 \t loss_valid = 25605256.0 \n",
      "Model_1_12860 \t loss_train = 28008726.0 \t loss_valid = 25518310.0 \n",
      "Model_1_12870 \t loss_train = 28009050.0 \t loss_valid = 25518036.0 \n",
      "Model_1_12880 \t loss_train = 27991910.0 \t loss_valid = 25614194.0 \n",
      "Model_1_12890 \t loss_train = 28008532.0 \t loss_valid = 25519622.0 \n",
      "Model_1_12900 \t loss_train = 28021782.0 \t loss_valid = 25477922.0 \n",
      "Model_1_12910 \t loss_train = 27995114.0 \t loss_valid = 25584954.0 \n",
      "Model_1_12920 \t loss_train = 27996262.0 \t loss_valid = 25576052.0 \n",
      "Model_1_12930 \t loss_train = 27996592.0 \t loss_valid = 25573492.0 \n",
      "Model_1_12940 \t loss_train = 28017768.0 \t loss_valid = 25486990.0 \n",
      "Model_1_12950 \t loss_train = 28015958.0 \t loss_valid = 25492268.0 \n",
      "Model_1_12960 \t loss_train = 27994896.0 \t loss_valid = 25585374.0 \n",
      "Model_1_12970 \t loss_train = 28004256.0 \t loss_valid = 25534476.0 \n",
      "Model_1_12980 \t loss_train = 28006132.0 \t loss_valid = 25526414.0 \n",
      "Model_1_12990 \t loss_train = 28009324.0 \t loss_valid = 25515252.0 \n",
      "Model_1_13000 \t loss_train = 27999248.0 \t loss_valid = 25559978.0 \n",
      "Model_1_13010 \t loss_train = 28019158.0 \t loss_valid = 25485584.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_1_13020 \t loss_train = 28011174.0 \t loss_valid = 25511524.0 \n",
      "Model_1_13030 \t loss_train = 27996394.0 \t loss_valid = 25580644.0 \n",
      "Model_1_13040 \t loss_train = 28000062.0 \t loss_valid = 25560874.0 \n",
      "Model_1_13050 \t loss_train = 28002930.0 \t loss_valid = 25546138.0 \n",
      "Model_1_13060 \t loss_train = 28008658.0 \t loss_valid = 25521948.0 \n",
      "Model_1_13070 \t loss_train = 28004678.0 \t loss_valid = 25536790.0 \n",
      "Model_1_13080 \t loss_train = 28000210.0 \t loss_valid = 25555524.0 \n",
      "Model_1_13090 \t loss_train = 28002282.0 \t loss_valid = 25544296.0 \n",
      "Model_1_13100 \t loss_train = 27998398.0 \t loss_valid = 25564064.0 \n",
      "Model_1_13110 \t loss_train = 28011092.0 \t loss_valid = 25508444.0 \n",
      "Model_1_13120 \t loss_train = 27999652.0 \t loss_valid = 25556936.0 \n",
      "Model_1_13130 \t loss_train = 27998768.0 \t loss_valid = 25561598.0 \n",
      "Model_1_13140 \t loss_train = 28011302.0 \t loss_valid = 25507550.0 \n",
      "Early stopping!\n",
      "Model_2_0 \t loss_train = 119565416.0 \t loss_valid = 104564104.0 \n",
      "Model_2_10 \t loss_train = 117983104.0 \t loss_valid = 102430456.0 \n",
      "Model_2_20 \t loss_train = 114574408.0 \t loss_valid = 97921728.0 \n",
      "Model_2_30 \t loss_train = 106579144.0 \t loss_valid = 87455368.0 \n",
      "Model_2_40 \t loss_train = 90716704.0 \t loss_valid = 68716584.0 \n",
      "Model_2_50 \t loss_train = 73694808.0 \t loss_valid = 60312728.0 \n",
      "Model_2_60 \t loss_train = 72796184.0 \t loss_valid = 72587032.0 \n",
      "Model_2_70 \t loss_train = 72514400.0 \t loss_valid = 59889944.0 \n",
      "Model_2_80 \t loss_train = 71937312.0 \t loss_valid = 59589972.0 \n",
      "Model_2_90 \t loss_train = 70451296.0 \t loss_valid = 63231216.0 \n",
      "Model_2_100 \t loss_train = 70092992.0 \t loss_valid = 61348364.0 \n",
      "Model_2_110 \t loss_train = 69592000.0 \t loss_valid = 60826240.0 \n",
      "Model_2_120 \t loss_train = 69041864.0 \t loss_valid = 60730796.0 \n",
      "Model_2_130 \t loss_train = 68748864.0 \t loss_valid = 59226840.0 \n",
      "Model_2_140 \t loss_train = 68191760.0 \t loss_valid = 59418212.0 \n",
      "Model_2_150 \t loss_train = 67878352.0 \t loss_valid = 58595860.0 \n",
      "Model_2_160 \t loss_train = 67495848.0 \t loss_valid = 58149232.0 \n",
      "Model_2_170 \t loss_train = 67317840.0 \t loss_valid = 57169504.0 \n",
      "Model_2_180 \t loss_train = 66683368.0 \t loss_valid = 57531248.0 \n",
      "Model_2_190 \t loss_train = 66583484.0 \t loss_valid = 56103280.0 \n",
      "Model_2_200 \t loss_train = 65813248.0 \t loss_valid = 56256120.0 \n",
      "Model_2_210 \t loss_train = 65323724.0 \t loss_valid = 55602744.0 \n",
      "Model_2_220 \t loss_train = 64762124.0 \t loss_valid = 55160016.0 \n",
      "Model_2_230 \t loss_train = 64195440.0 \t loss_valid = 54358192.0 \n",
      "Model_2_240 \t loss_train = 63306768.0 \t loss_valid = 54023660.0 \n",
      "Model_2_250 \t loss_train = 62364596.0 \t loss_valid = 53200452.0 \n",
      "Model_2_260 \t loss_train = 61799680.0 \t loss_valid = 51477984.0 \n",
      "Model_2_270 \t loss_train = 60282472.0 \t loss_valid = 51959392.0 \n",
      "Model_2_280 \t loss_train = 59123284.0 \t loss_valid = 50319488.0 \n",
      "Model_2_290 \t loss_train = 57454984.0 \t loss_valid = 49120836.0 \n",
      "Model_2_300 \t loss_train = 55326128.0 \t loss_valid = 48655012.0 \n",
      "Model_2_310 \t loss_train = 52942328.0 \t loss_valid = 45832440.0 \n",
      "Model_2_320 \t loss_train = 49471752.0 \t loss_valid = 44231116.0 \n",
      "Model_2_330 \t loss_train = 45678060.0 \t loss_valid = 38997016.0 \n",
      "Model_2_340 \t loss_train = 40239396.0 \t loss_valid = 36269004.0 \n",
      "Model_2_350 \t loss_train = 35436776.0 \t loss_valid = 31450128.0 \n",
      "Model_2_360 \t loss_train = 31147996.0 \t loss_valid = 28164504.0 \n",
      "Model_2_370 \t loss_train = 29174744.0 \t loss_valid = 26299150.0 \n",
      "Model_2_380 \t loss_train = 28628266.0 \t loss_valid = 26004498.0 \n",
      "Model_2_390 \t loss_train = 28445438.0 \t loss_valid = 26028314.0 \n",
      "Model_2_400 \t loss_train = 28313376.0 \t loss_valid = 25820404.0 \n",
      "Model_2_410 \t loss_train = 28466306.0 \t loss_valid = 25739188.0 \n",
      "Model_2_420 \t loss_train = 28520510.0 \t loss_valid = 25615552.0 \n",
      "Model_2_430 \t loss_train = 28247706.0 \t loss_valid = 25880392.0 \n",
      "Model_2_440 \t loss_train = 29028332.0 \t loss_valid = 25777216.0 \n",
      "Model_2_450 \t loss_train = 28617072.0 \t loss_valid = 25571614.0 \n",
      "Model_2_460 \t loss_train = 28375628.0 \t loss_valid = 25648110.0 \n",
      "Model_2_470 \t loss_train = 28251218.0 \t loss_valid = 26158340.0 \n",
      "Model_2_480 \t loss_train = 28436102.0 \t loss_valid = 25502432.0 \n",
      "Model_2_490 \t loss_train = 28779714.0 \t loss_valid = 25607120.0 \n",
      "Model_2_500 \t loss_train = 28260400.0 \t loss_valid = 25793910.0 \n",
      "Model_2_510 \t loss_train = 28371528.0 \t loss_valid = 25535698.0 \n",
      "Model_2_520 \t loss_train = 28178976.0 \t loss_valid = 25861766.0 \n",
      "Model_2_530 \t loss_train = 28545798.0 \t loss_valid = 25479102.0 \n",
      "Model_2_540 \t loss_train = 28660402.0 \t loss_valid = 25550048.0 \n",
      "Model_2_550 \t loss_train = 28148994.0 \t loss_valid = 25717368.0 \n",
      "Model_2_560 \t loss_train = 28172440.0 \t loss_valid = 25659824.0 \n",
      "Model_2_570 \t loss_train = 28431342.0 \t loss_valid = 25434544.0 \n",
      "Model_2_580 \t loss_train = 28191766.0 \t loss_valid = 25454182.0 \n",
      "Model_2_590 \t loss_train = 28287074.0 \t loss_valid = 25441374.0 \n",
      "Model_2_600 \t loss_train = 28515296.0 \t loss_valid = 25435282.0 \n",
      "Model_2_610 \t loss_train = 28264070.0 \t loss_valid = 25949692.0 \n",
      "Model_2_620 \t loss_train = 28226390.0 \t loss_valid = 25539502.0 \n",
      "Model_2_630 \t loss_train = 28251526.0 \t loss_valid = 25547658.0 \n",
      "Model_2_640 \t loss_train = 28438240.0 \t loss_valid = 25422144.0 \n",
      "Model_2_650 \t loss_train = 28217676.0 \t loss_valid = 25444320.0 \n",
      "Model_2_660 \t loss_train = 28335774.0 \t loss_valid = 25400090.0 \n",
      "Model_2_670 \t loss_train = 28870408.0 \t loss_valid = 25593596.0 \n",
      "Model_2_680 \t loss_train = 28450022.0 \t loss_valid = 25468208.0 \n",
      "Model_2_690 \t loss_train = 28322884.0 \t loss_valid = 25408328.0 \n",
      "Model_2_700 \t loss_train = 28286618.0 \t loss_valid = 25478892.0 \n",
      "Model_2_710 \t loss_train = 28140868.0 \t loss_valid = 25662416.0 \n",
      "Model_2_720 \t loss_train = 28769668.0 \t loss_valid = 25481666.0 \n",
      "Model_2_730 \t loss_train = 28830564.0 \t loss_valid = 25527820.0 \n",
      "Model_2_740 \t loss_train = 28170646.0 \t loss_valid = 25857608.0 \n",
      "Model_2_750 \t loss_train = 28348044.0 \t loss_valid = 25356026.0 \n",
      "Model_2_760 \t loss_train = 28494016.0 \t loss_valid = 25345682.0 \n",
      "Model_2_770 \t loss_train = 28603798.0 \t loss_valid = 25364016.0 \n",
      "Model_2_780 \t loss_train = 28530758.0 \t loss_valid = 25366712.0 \n",
      "Model_2_790 \t loss_train = 28197502.0 \t loss_valid = 25472174.0 \n",
      "Model_2_800 \t loss_train = 28184310.0 \t loss_valid = 25407128.0 \n",
      "Model_2_810 \t loss_train = 28215162.0 \t loss_valid = 25454028.0 \n",
      "Model_2_820 \t loss_train = 28192054.0 \t loss_valid = 25622118.0 \n",
      "Model_2_830 \t loss_train = 28513032.0 \t loss_valid = 25327408.0 \n",
      "Model_2_840 \t loss_train = 28451020.0 \t loss_valid = 25326310.0 \n",
      "Model_2_850 \t loss_train = 28216264.0 \t loss_valid = 25373594.0 \n",
      "Model_2_860 \t loss_train = 28294922.0 \t loss_valid = 25379524.0 \n",
      "Model_2_870 \t loss_train = 28301718.0 \t loss_valid = 25346556.0 \n",
      "Model_2_880 \t loss_train = 28138712.0 \t loss_valid = 25505712.0 \n",
      "Model_2_890 \t loss_train = 28514026.0 \t loss_valid = 25346258.0 \n",
      "Model_2_900 \t loss_train = 28377002.0 \t loss_valid = 25330652.0 \n",
      "Model_2_910 \t loss_train = 28697366.0 \t loss_valid = 25380604.0 \n",
      "Model_2_920 \t loss_train = 28152450.0 \t loss_valid = 25447992.0 \n",
      "Model_2_930 \t loss_train = 28172854.0 \t loss_valid = 26047228.0 \n",
      "Model_2_940 \t loss_train = 28472274.0 \t loss_valid = 25334652.0 \n",
      "Model_2_950 \t loss_train = 28537898.0 \t loss_valid = 25411894.0 \n",
      "Model_2_960 \t loss_train = 28428574.0 \t loss_valid = 25331758.0 \n",
      "Model_2_970 \t loss_train = 28469764.0 \t loss_valid = 25331038.0 \n",
      "Model_2_980 \t loss_train = 28158850.0 \t loss_valid = 25504790.0 \n",
      "Model_2_990 \t loss_train = 28455758.0 \t loss_valid = 25305368.0 \n",
      "Model_2_1000 \t loss_train = 28269672.0 \t loss_valid = 25335464.0 \n",
      "Model_2_1010 \t loss_train = 28321292.0 \t loss_valid = 25340194.0 \n",
      "Model_2_1020 \t loss_train = 28295824.0 \t loss_valid = 25325610.0 \n",
      "Model_2_1030 \t loss_train = 28245992.0 \t loss_valid = 25439204.0 \n",
      "Model_2_1040 \t loss_train = 28689686.0 \t loss_valid = 25419306.0 \n",
      "Model_2_1050 \t loss_train = 28563478.0 \t loss_valid = 25392324.0 \n",
      "Model_2_1060 \t loss_train = 28146824.0 \t loss_valid = 25479744.0 \n",
      "Model_2_1070 \t loss_train = 28443230.0 \t loss_valid = 25325870.0 \n",
      "Model_2_1080 \t loss_train = 28578290.0 \t loss_valid = 25352088.0 \n",
      "Model_2_1090 \t loss_train = 28422938.0 \t loss_valid = 25329752.0 \n",
      "Model_2_1100 \t loss_train = 28557206.0 \t loss_valid = 25319116.0 \n",
      "Model_2_1110 \t loss_train = 28186534.0 \t loss_valid = 25460608.0 \n",
      "Model_2_1120 \t loss_train = 28205324.0 \t loss_valid = 25412010.0 \n",
      "Model_2_1130 \t loss_train = 28115940.0 \t loss_valid = 25695564.0 \n",
      "Model_2_1140 \t loss_train = 28654580.0 \t loss_valid = 25398076.0 \n",
      "Model_2_1150 \t loss_train = 28520214.0 \t loss_valid = 25320898.0 \n",
      "Model_2_1160 \t loss_train = 28683496.0 \t loss_valid = 25359160.0 \n",
      "Model_2_1170 \t loss_train = 28385622.0 \t loss_valid = 25310384.0 \n",
      "Model_2_1180 \t loss_train = 28321690.0 \t loss_valid = 25312348.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_2_1190 \t loss_train = 28321328.0 \t loss_valid = 25390528.0 \n",
      "Model_2_1200 \t loss_train = 28372126.0 \t loss_valid = 25310408.0 \n",
      "Model_2_1210 \t loss_train = 28654298.0 \t loss_valid = 25367782.0 \n",
      "Model_2_1220 \t loss_train = 28546886.0 \t loss_valid = 25295442.0 \n",
      "Model_2_1230 \t loss_train = 28331992.0 \t loss_valid = 25300566.0 \n",
      "Model_2_1240 \t loss_train = 28413372.0 \t loss_valid = 25289698.0 \n",
      "Model_2_1250 \t loss_train = 28572158.0 \t loss_valid = 25318042.0 \n",
      "Model_2_1260 \t loss_train = 28336486.0 \t loss_valid = 25337848.0 \n",
      "Model_2_1270 \t loss_train = 28351702.0 \t loss_valid = 25313194.0 \n",
      "Model_2_1280 \t loss_train = 28472030.0 \t loss_valid = 25325558.0 \n",
      "Model_2_1290 \t loss_train = 28654916.0 \t loss_valid = 25310558.0 \n",
      "Model_2_1300 \t loss_train = 28464074.0 \t loss_valid = 25289348.0 \n",
      "Model_2_1310 \t loss_train = 28206236.0 \t loss_valid = 25390076.0 \n",
      "Model_2_1320 \t loss_train = 28245578.0 \t loss_valid = 25393296.0 \n",
      "Model_2_1330 \t loss_train = 28965348.0 \t loss_valid = 25509566.0 \n",
      "Model_2_1340 \t loss_train = 28923248.0 \t loss_valid = 25469278.0 \n",
      "Model_2_1350 \t loss_train = 28510870.0 \t loss_valid = 25325782.0 \n",
      "Model_2_1360 \t loss_train = 28243982.0 \t loss_valid = 25443830.0 \n",
      "Model_2_1370 \t loss_train = 28533178.0 \t loss_valid = 25288638.0 \n",
      "Model_2_1380 \t loss_train = 28670986.0 \t loss_valid = 25330596.0 \n",
      "Model_2_1390 \t loss_train = 28858440.0 \t loss_valid = 25349948.0 \n",
      "Model_2_1400 \t loss_train = 28785496.0 \t loss_valid = 25332058.0 \n",
      "Model_2_1410 \t loss_train = 28886858.0 \t loss_valid = 25336980.0 \n",
      "Model_2_1420 \t loss_train = 28707648.0 \t loss_valid = 25304130.0 \n",
      "Model_2_1430 \t loss_train = 28977922.0 \t loss_valid = 25346912.0 \n",
      "Model_2_1440 \t loss_train = 28903936.0 \t loss_valid = 25359514.0 \n",
      "Model_2_1450 \t loss_train = 29190322.0 \t loss_valid = 25447358.0 \n",
      "Model_2_1460 \t loss_train = 28702898.0 \t loss_valid = 25303510.0 \n",
      "Model_2_1470 \t loss_train = 29206208.0 \t loss_valid = 25453964.0 \n",
      "Model_2_1480 \t loss_train = 28655844.0 \t loss_valid = 25323282.0 \n",
      "Model_2_1490 \t loss_train = 28580266.0 \t loss_valid = 25380224.0 \n",
      "Model_2_1500 \t loss_train = 29211904.0 \t loss_valid = 25563810.0 \n",
      "Model_2_1510 \t loss_train = 29110638.0 \t loss_valid = 25384850.0 \n",
      "Model_2_1520 \t loss_train = 28902520.0 \t loss_valid = 25306410.0 \n",
      "Model_2_1530 \t loss_train = 28641284.0 \t loss_valid = 25343298.0 \n",
      "Model_2_1540 \t loss_train = 29025116.0 \t loss_valid = 25350622.0 \n",
      "Model_2_1550 \t loss_train = 29455236.0 \t loss_valid = 25632774.0 \n",
      "Model_2_1560 \t loss_train = 29388030.0 \t loss_valid = 25609072.0 \n",
      "Model_2_1570 \t loss_train = 29368488.0 \t loss_valid = 25556822.0 \n",
      "Model_2_1580 \t loss_train = 28971584.0 \t loss_valid = 25347068.0 \n",
      "Model_2_1590 \t loss_train = 29206136.0 \t loss_valid = 25424074.0 \n",
      "Model_2_1600 \t loss_train = 29160256.0 \t loss_valid = 25385314.0 \n",
      "Model_2_1610 \t loss_train = 29236728.0 \t loss_valid = 25461600.0 \n",
      "Model_2_1620 \t loss_train = 29505818.0 \t loss_valid = 25636722.0 \n",
      "Model_2_1630 \t loss_train = 29706018.0 \t loss_valid = 25699146.0 \n",
      "Model_2_1640 \t loss_train = 30052596.0 \t loss_valid = 25989132.0 \n",
      "Model_2_1650 \t loss_train = 29123470.0 \t loss_valid = 25370698.0 \n",
      "Model_2_1660 \t loss_train = 29380130.0 \t loss_valid = 25481282.0 \n",
      "Model_2_1670 \t loss_train = 30182710.0 \t loss_valid = 25965596.0 \n",
      "Model_2_1680 \t loss_train = 29531522.0 \t loss_valid = 25597910.0 \n",
      "Model_2_1690 \t loss_train = 29554726.0 \t loss_valid = 25546188.0 \n",
      "Model_2_1700 \t loss_train = 29342798.0 \t loss_valid = 25421360.0 \n",
      "Model_2_1710 \t loss_train = 29182172.0 \t loss_valid = 25400646.0 \n",
      "Model_2_1720 \t loss_train = 29873952.0 \t loss_valid = 25720268.0 \n",
      "Model_2_1730 \t loss_train = 30262530.0 \t loss_valid = 26024098.0 \n",
      "Model_2_1740 \t loss_train = 30366068.0 \t loss_valid = 26146004.0 \n",
      "Model_2_1750 \t loss_train = 30633494.0 \t loss_valid = 26194196.0 \n",
      "Model_2_1760 \t loss_train = 29708990.0 \t loss_valid = 25621846.0 \n",
      "Model_2_1770 \t loss_train = 29573258.0 \t loss_valid = 25588212.0 \n",
      "Model_2_1780 \t loss_train = 30176520.0 \t loss_valid = 25885722.0 \n",
      "Model_2_1790 \t loss_train = 30267022.0 \t loss_valid = 25969288.0 \n",
      "Model_2_1800 \t loss_train = 30014746.0 \t loss_valid = 25746110.0 \n",
      "Model_2_1810 \t loss_train = 29591446.0 \t loss_valid = 25508580.0 \n",
      "Model_2_1820 \t loss_train = 30225442.0 \t loss_valid = 25932978.0 \n",
      "Model_2_1830 \t loss_train = 31149868.0 \t loss_valid = 26681442.0 \n",
      "Model_2_1840 \t loss_train = 31013652.0 \t loss_valid = 26476548.0 \n",
      "Model_2_1850 \t loss_train = 30037092.0 \t loss_valid = 25769842.0 \n",
      "Model_2_1860 \t loss_train = 30513262.0 \t loss_valid = 25977342.0 \n",
      "Model_2_1870 \t loss_train = 31022244.0 \t loss_valid = 26501462.0 \n",
      "Model_2_1880 \t loss_train = 30685932.0 \t loss_valid = 26196298.0 \n",
      "Model_2_1890 \t loss_train = 30730958.0 \t loss_valid = 26129038.0 \n",
      "Model_2_1900 \t loss_train = 30951078.0 \t loss_valid = 26411982.0 \n",
      "Model_2_1910 \t loss_train = 30686534.0 \t loss_valid = 26190348.0 \n",
      "Model_2_1920 \t loss_train = 30501592.0 \t loss_valid = 25939874.0 \n",
      "Model_2_1930 \t loss_train = 30510018.0 \t loss_valid = 26057716.0 \n",
      "Model_2_1940 \t loss_train = 30976356.0 \t loss_valid = 26294732.0 \n",
      "Model_2_1950 \t loss_train = 31290994.0 \t loss_valid = 26654442.0 \n",
      "Model_2_1960 \t loss_train = 31412220.0 \t loss_valid = 26789430.0 \n",
      "Model_2_1970 \t loss_train = 30679604.0 \t loss_valid = 26181474.0 \n",
      "Model_2_1980 \t loss_train = 31535984.0 \t loss_valid = 26719544.0 \n",
      "Model_2_1990 \t loss_train = 31576948.0 \t loss_valid = 26987602.0 \n",
      "Model_2_2000 \t loss_train = 30810848.0 \t loss_valid = 26117310.0 \n",
      "Model_2_2010 \t loss_train = 31166786.0 \t loss_valid = 26493210.0 \n",
      "Model_2_2020 \t loss_train = 31580650.0 \t loss_valid = 26743390.0 \n",
      "Model_2_2030 \t loss_train = 31079164.0 \t loss_valid = 26459438.0 \n",
      "Model_2_2040 \t loss_train = 31269146.0 \t loss_valid = 26574988.0 \n",
      "Model_2_2050 \t loss_train = 30837736.0 \t loss_valid = 26215518.0 \n",
      "Model_2_2060 \t loss_train = 31553982.0 \t loss_valid = 26780812.0 \n",
      "Model_2_2070 \t loss_train = 31935610.0 \t loss_valid = 27138294.0 \n",
      "Model_2_2080 \t loss_train = 31325026.0 \t loss_valid = 26611330.0 \n",
      "Model_2_2090 \t loss_train = 30939824.0 \t loss_valid = 26265060.0 \n",
      "Model_2_2100 \t loss_train = 30989658.0 \t loss_valid = 26225698.0 \n",
      "Model_2_2110 \t loss_train = 32209168.0 \t loss_valid = 27441212.0 \n",
      "Model_2_2120 \t loss_train = 32317044.0 \t loss_valid = 27548732.0 \n",
      "Model_2_2130 \t loss_train = 31755684.0 \t loss_valid = 27019542.0 \n",
      "Model_2_2140 \t loss_train = 32113884.0 \t loss_valid = 27208078.0 \n",
      "Model_2_2150 \t loss_train = 31684404.0 \t loss_valid = 26922186.0 \n",
      "Model_2_2160 \t loss_train = 31267668.0 \t loss_valid = 26461824.0 \n",
      "Model_2_2170 \t loss_train = 31820298.0 \t loss_valid = 27079054.0 \n",
      "Model_2_2180 \t loss_train = 31918026.0 \t loss_valid = 27028724.0 \n",
      "Model_2_2190 \t loss_train = 32679210.0 \t loss_valid = 27850976.0 \n",
      "Model_2_2200 \t loss_train = 32430712.0 \t loss_valid = 27478614.0 \n",
      "Model_2_2210 \t loss_train = 31708706.0 \t loss_valid = 26935966.0 \n",
      "Model_2_2220 \t loss_train = 31973040.0 \t loss_valid = 26953746.0 \n",
      "Model_2_2230 \t loss_train = 32401500.0 \t loss_valid = 27675174.0 \n",
      "Model_2_2240 \t loss_train = 32036190.0 \t loss_valid = 27026496.0 \n",
      "Model_2_2250 \t loss_train = 31931864.0 \t loss_valid = 27066032.0 \n",
      "Model_2_2260 \t loss_train = 32127144.0 \t loss_valid = 27307628.0 \n",
      "Model_2_2270 \t loss_train = 32051612.0 \t loss_valid = 27245074.0 \n",
      "Model_2_2280 \t loss_train = 31564820.0 \t loss_valid = 26656184.0 \n",
      "Model_2_2290 \t loss_train = 32325710.0 \t loss_valid = 27408614.0 \n",
      "Model_2_2300 \t loss_train = 31763320.0 \t loss_valid = 26944970.0 \n",
      "Model_2_2310 \t loss_train = 32390250.0 \t loss_valid = 27455770.0 \n",
      "Model_2_2320 \t loss_train = 32066476.0 \t loss_valid = 27143686.0 \n",
      "Model_2_2330 \t loss_train = 32184372.0 \t loss_valid = 27254480.0 \n",
      "Model_2_2340 \t loss_train = 31876894.0 \t loss_valid = 27004188.0 \n",
      "Model_2_2350 \t loss_train = 32205488.0 \t loss_valid = 27337712.0 \n",
      "Model_2_2360 \t loss_train = 32620280.0 \t loss_valid = 27831770.0 \n",
      "Model_2_2370 \t loss_train = 32305276.0 \t loss_valid = 27471184.0 \n",
      "Model_2_2380 \t loss_train = 32807754.0 \t loss_valid = 27653870.0 \n",
      "Model_2_2390 \t loss_train = 32172968.0 \t loss_valid = 27316938.0 \n",
      "Model_2_2400 \t loss_train = 32256466.0 \t loss_valid = 27410284.0 \n",
      "Model_2_2410 \t loss_train = 32568762.0 \t loss_valid = 27637416.0 \n",
      "Model_2_2420 \t loss_train = 32264638.0 \t loss_valid = 27373084.0 \n",
      "Model_2_2430 \t loss_train = 32747048.0 \t loss_valid = 27659564.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_2_2440 \t loss_train = 32601386.0 \t loss_valid = 27552408.0 \n",
      "Model_2_2450 \t loss_train = 32414934.0 \t loss_valid = 27524144.0 \n",
      "Model_2_2460 \t loss_train = 32281128.0 \t loss_valid = 27415160.0 \n",
      "Model_2_2470 \t loss_train = 32494988.0 \t loss_valid = 27433656.0 \n",
      "Model_2_2480 \t loss_train = 32171324.0 \t loss_valid = 27222622.0 \n",
      "Model_2_2490 \t loss_train = 32568448.0 \t loss_valid = 27572168.0 \n",
      "Model_2_2500 \t loss_train = 33139722.0 \t loss_valid = 28038656.0 \n",
      "Model_2_2510 \t loss_train = 32584784.0 \t loss_valid = 27537594.0 \n",
      "Model_2_2520 \t loss_train = 32604224.0 \t loss_valid = 27671338.0 \n",
      "Model_2_2530 \t loss_train = 32458104.0 \t loss_valid = 27448212.0 \n",
      "Model_2_2540 \t loss_train = 33681148.0 \t loss_valid = 28711440.0 \n",
      "Model_2_2550 \t loss_train = 33339366.0 \t loss_valid = 28362506.0 \n",
      "Model_2_2560 \t loss_train = 32769376.0 \t loss_valid = 27835888.0 \n",
      "Model_2_2570 \t loss_train = 32848304.0 \t loss_valid = 27746636.0 \n",
      "Model_2_2580 \t loss_train = 33020076.0 \t loss_valid = 27969758.0 \n",
      "Model_2_2590 \t loss_train = 32570598.0 \t loss_valid = 27627112.0 \n",
      "Model_2_2600 \t loss_train = 32757048.0 \t loss_valid = 27691358.0 \n",
      "Model_2_2610 \t loss_train = 33218182.0 \t loss_valid = 28161732.0 \n",
      "Model_2_2620 \t loss_train = 32110706.0 \t loss_valid = 27112414.0 \n",
      "Model_2_2630 \t loss_train = 32610700.0 \t loss_valid = 27552828.0 \n",
      "Model_2_2640 \t loss_train = 32648366.0 \t loss_valid = 27580182.0 \n",
      "Model_2_2650 \t loss_train = 33531348.0 \t loss_valid = 28481602.0 \n",
      "Model_2_2660 \t loss_train = 32797348.0 \t loss_valid = 27854348.0 \n",
      "Model_2_2670 \t loss_train = 32067088.0 \t loss_valid = 27117188.0 \n",
      "Model_2_2680 \t loss_train = 32537492.0 \t loss_valid = 27444976.0 \n",
      "Model_2_2690 \t loss_train = 32996804.0 \t loss_valid = 27906408.0 \n",
      "Model_2_2700 \t loss_train = 32744278.0 \t loss_valid = 27704248.0 \n",
      "Model_2_2710 \t loss_train = 33003010.0 \t loss_valid = 27828274.0 \n",
      "Model_2_2720 \t loss_train = 32782592.0 \t loss_valid = 27780984.0 \n",
      "Model_2_2730 \t loss_train = 32426210.0 \t loss_valid = 27422524.0 \n",
      "Model_2_2740 \t loss_train = 32830210.0 \t loss_valid = 27665904.0 \n",
      "Model_2_2750 \t loss_train = 33770576.0 \t loss_valid = 28731930.0 \n",
      "Model_2_2760 \t loss_train = 33001126.0 \t loss_valid = 28013514.0 \n",
      "Model_2_2770 \t loss_train = 32756368.0 \t loss_valid = 27536012.0 \n",
      "Model_2_2780 \t loss_train = 33168772.0 \t loss_valid = 28252300.0 \n",
      "Model_2_2790 \t loss_train = 33055320.0 \t loss_valid = 28019106.0 \n",
      "Model_2_2800 \t loss_train = 32197626.0 \t loss_valid = 27287284.0 \n",
      "Model_2_2810 \t loss_train = 33264980.0 \t loss_valid = 28161034.0 \n",
      "Model_2_2820 \t loss_train = 32957524.0 \t loss_valid = 27957500.0 \n",
      "Model_2_2830 \t loss_train = 33511428.0 \t loss_valid = 28489858.0 \n",
      "Model_2_2840 \t loss_train = 33436400.0 \t loss_valid = 28220454.0 \n",
      "Model_2_2850 \t loss_train = 33105960.0 \t loss_valid = 27965504.0 \n",
      "Model_2_2860 \t loss_train = 32938364.0 \t loss_valid = 27999270.0 \n",
      "Model_2_2870 \t loss_train = 33394952.0 \t loss_valid = 28292748.0 \n",
      "Model_2_2880 \t loss_train = 33742668.0 \t loss_valid = 28692442.0 \n",
      "Model_2_2890 \t loss_train = 33045048.0 \t loss_valid = 27963278.0 \n",
      "Model_2_2900 \t loss_train = 32667854.0 \t loss_valid = 27582618.0 \n",
      "Model_2_2910 \t loss_train = 33353778.0 \t loss_valid = 28316710.0 \n",
      "Model_2_2920 \t loss_train = 32960970.0 \t loss_valid = 27932416.0 \n",
      "Model_2_2930 \t loss_train = 33132118.0 \t loss_valid = 27994946.0 \n",
      "Model_2_2940 \t loss_train = 32901366.0 \t loss_valid = 27733696.0 \n",
      "Model_2_2950 \t loss_train = 33152770.0 \t loss_valid = 28043178.0 \n",
      "Model_2_2960 \t loss_train = 33235986.0 \t loss_valid = 28038608.0 \n",
      "Model_2_2970 \t loss_train = 32656192.0 \t loss_valid = 27785538.0 \n",
      "Model_2_2980 \t loss_train = 33071240.0 \t loss_valid = 27949828.0 \n",
      "Model_2_2990 \t loss_train = 32957338.0 \t loss_valid = 27890014.0 \n",
      "Model_2_3000 \t loss_train = 33473068.0 \t loss_valid = 28310360.0 \n",
      "Model_2_3010 \t loss_train = 33018938.0 \t loss_valid = 28020236.0 \n",
      "Model_2_3020 \t loss_train = 33233622.0 \t loss_valid = 28061180.0 \n",
      "Model_2_3030 \t loss_train = 33884644.0 \t loss_valid = 28797800.0 \n",
      "Model_2_3040 \t loss_train = 32983654.0 \t loss_valid = 27888912.0 \n",
      "Model_2_3050 \t loss_train = 33217642.0 \t loss_valid = 28093330.0 \n",
      "Model_2_3060 \t loss_train = 33622096.0 \t loss_valid = 28400776.0 \n",
      "Model_2_3070 \t loss_train = 33136646.0 \t loss_valid = 27968376.0 \n",
      "Model_2_3080 \t loss_train = 33310832.0 \t loss_valid = 28213260.0 \n",
      "Model_2_3090 \t loss_train = 33540350.0 \t loss_valid = 28335092.0 \n",
      "Model_2_3100 \t loss_train = 33043714.0 \t loss_valid = 28076958.0 \n",
      "Model_2_3110 \t loss_train = 32291340.0 \t loss_valid = 27204784.0 \n",
      "Model_2_3120 \t loss_train = 33226354.0 \t loss_valid = 28052638.0 \n",
      "Model_2_3130 \t loss_train = 33919700.0 \t loss_valid = 29007258.0 \n",
      "Model_2_3140 \t loss_train = 33018296.0 \t loss_valid = 27869180.0 \n",
      "Model_2_3150 \t loss_train = 32697190.0 \t loss_valid = 27643986.0 \n",
      "Model_2_3160 \t loss_train = 33125678.0 \t loss_valid = 27940688.0 \n",
      "Model_2_3170 \t loss_train = 32847364.0 \t loss_valid = 27549860.0 \n",
      "Model_2_3180 \t loss_train = 33669992.0 \t loss_valid = 28605428.0 \n",
      "Model_2_3190 \t loss_train = 33715936.0 \t loss_valid = 28632512.0 \n",
      "Model_2_3200 \t loss_train = 32745650.0 \t loss_valid = 27607126.0 \n",
      "Model_2_3210 \t loss_train = 34004968.0 \t loss_valid = 28748826.0 \n",
      "Model_2_3220 \t loss_train = 33761852.0 \t loss_valid = 28508716.0 \n",
      "Model_2_3230 \t loss_train = 33401600.0 \t loss_valid = 28244724.0 \n",
      "Model_2_3240 \t loss_train = 33566456.0 \t loss_valid = 28413068.0 \n",
      "Model_2_3250 \t loss_train = 33024266.0 \t loss_valid = 27868982.0 \n",
      "Model_2_3260 \t loss_train = 33659820.0 \t loss_valid = 28461730.0 \n",
      "Model_2_3270 \t loss_train = 33598752.0 \t loss_valid = 28494260.0 \n",
      "Model_2_3280 \t loss_train = 33143178.0 \t loss_valid = 27857424.0 \n",
      "Model_2_3290 \t loss_train = 33350006.0 \t loss_valid = 28106860.0 \n",
      "Model_2_3300 \t loss_train = 33748084.0 \t loss_valid = 28557556.0 \n",
      "Model_2_3310 \t loss_train = 33754688.0 \t loss_valid = 28557894.0 \n",
      "Model_2_3320 \t loss_train = 33803752.0 \t loss_valid = 28562474.0 \n",
      "Model_2_3330 \t loss_train = 34563348.0 \t loss_valid = 29441518.0 \n",
      "Model_2_3340 \t loss_train = 32908554.0 \t loss_valid = 27784072.0 \n",
      "Model_2_3350 \t loss_train = 33352762.0 \t loss_valid = 28226294.0 \n",
      "Model_2_3360 \t loss_train = 33825164.0 \t loss_valid = 28704654.0 \n",
      "Model_2_3370 \t loss_train = 33388838.0 \t loss_valid = 28204430.0 \n",
      "Model_2_3380 \t loss_train = 33619876.0 \t loss_valid = 28326552.0 \n",
      "Model_2_3390 \t loss_train = 33203534.0 \t loss_valid = 28045670.0 \n",
      "Model_2_3400 \t loss_train = 34139496.0 \t loss_valid = 28934274.0 \n",
      "Model_2_3410 \t loss_train = 33591296.0 \t loss_valid = 28351516.0 \n",
      "Model_2_3420 \t loss_train = 33170906.0 \t loss_valid = 27937738.0 \n",
      "Model_2_3430 \t loss_train = 33073056.0 \t loss_valid = 27742138.0 \n",
      "Model_2_3440 \t loss_train = 33893956.0 \t loss_valid = 28672670.0 \n",
      "Model_2_3450 \t loss_train = 33428078.0 \t loss_valid = 28207322.0 \n",
      "Model_2_3460 \t loss_train = 33740996.0 \t loss_valid = 28376632.0 \n",
      "Model_2_3470 \t loss_train = 33502104.0 \t loss_valid = 28275452.0 \n",
      "Model_2_3480 \t loss_train = 33493940.0 \t loss_valid = 28201054.0 \n",
      "Model_2_3490 \t loss_train = 34171948.0 \t loss_valid = 28846876.0 \n",
      "Model_2_3500 \t loss_train = 33302628.0 \t loss_valid = 28082940.0 \n",
      "Model_2_3510 \t loss_train = 33513336.0 \t loss_valid = 28274862.0 \n",
      "Model_2_3520 \t loss_train = 33992544.0 \t loss_valid = 28746966.0 \n",
      "Model_2_3530 \t loss_train = 34130128.0 \t loss_valid = 28838998.0 \n",
      "Model_2_3540 \t loss_train = 33450652.0 \t loss_valid = 28203982.0 \n",
      "Model_2_3550 \t loss_train = 33509696.0 \t loss_valid = 28116876.0 \n",
      "Model_2_3560 \t loss_train = 34436892.0 \t loss_valid = 29126880.0 \n",
      "Model_2_3570 \t loss_train = 34311596.0 \t loss_valid = 28963264.0 \n",
      "Model_2_3580 \t loss_train = 32605970.0 \t loss_valid = 27382404.0 \n",
      "Model_2_3590 \t loss_train = 33359874.0 \t loss_valid = 28021080.0 \n",
      "Model_2_3600 \t loss_train = 34201276.0 \t loss_valid = 28984828.0 \n",
      "Model_2_3610 \t loss_train = 33387492.0 \t loss_valid = 28115798.0 \n",
      "Model_2_3620 \t loss_train = 33736124.0 \t loss_valid = 28283712.0 \n",
      "Model_2_3630 \t loss_train = 34265172.0 \t loss_valid = 29070980.0 \n",
      "Model_2_3640 \t loss_train = 33792472.0 \t loss_valid = 28470652.0 \n",
      "Model_2_3650 \t loss_train = 32763568.0 \t loss_valid = 27633338.0 \n",
      "Model_2_3660 \t loss_train = 33349382.0 \t loss_valid = 28135224.0 \n",
      "Model_2_3670 \t loss_train = 34103012.0 \t loss_valid = 28812096.0 \n",
      "Model_2_3680 \t loss_train = 34545576.0 \t loss_valid = 29345564.0 \n",
      "Model_2_3690 \t loss_train = 33896672.0 \t loss_valid = 28503668.0 \n",
      "Model_2_3700 \t loss_train = 33570864.0 \t loss_valid = 28318082.0 \n",
      "Model_2_3710 \t loss_train = 32993318.0 \t loss_valid = 27733548.0 \n",
      "Model_2_3720 \t loss_train = 33875844.0 \t loss_valid = 28622792.0 \n",
      "Model_2_3730 \t loss_train = 33572752.0 \t loss_valid = 28576948.0 \n",
      "Model_2_3740 \t loss_train = 33758936.0 \t loss_valid = 28445642.0 \n",
      "Model_2_3750 \t loss_train = 33399194.0 \t loss_valid = 28124676.0 \n",
      "Model_2_3760 \t loss_train = 33891004.0 \t loss_valid = 28577192.0 \n",
      "Model_2_3770 \t loss_train = 34255432.0 \t loss_valid = 28957326.0 \n",
      "Model_2_3780 \t loss_train = 33951048.0 \t loss_valid = 28688570.0 \n",
      "Model_2_3790 \t loss_train = 33891408.0 \t loss_valid = 28647158.0 \n",
      "Model_2_3800 \t loss_train = 33604684.0 \t loss_valid = 28348306.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_2_3810 \t loss_train = 34308168.0 \t loss_valid = 28924080.0 \n",
      "Model_2_3820 \t loss_train = 34008880.0 \t loss_valid = 28864534.0 \n",
      "Model_2_3830 \t loss_train = 33749068.0 \t loss_valid = 28397000.0 \n",
      "Model_2_3840 \t loss_train = 33817492.0 \t loss_valid = 28496258.0 \n",
      "Model_2_3850 \t loss_train = 33968304.0 \t loss_valid = 28747388.0 \n",
      "Model_2_3860 \t loss_train = 34546172.0 \t loss_valid = 29184854.0 \n",
      "Model_2_3870 \t loss_train = 33993172.0 \t loss_valid = 28589820.0 \n",
      "Model_2_3880 \t loss_train = 33558232.0 \t loss_valid = 28338208.0 \n",
      "Model_2_3890 \t loss_train = 34206288.0 \t loss_valid = 28773900.0 \n",
      "Model_2_3900 \t loss_train = 33944776.0 \t loss_valid = 28566920.0 \n",
      "Model_2_3910 \t loss_train = 33244628.0 \t loss_valid = 28052126.0 \n",
      "Model_2_3920 \t loss_train = 33867564.0 \t loss_valid = 28517110.0 \n",
      "Model_2_3930 \t loss_train = 33905724.0 \t loss_valid = 28542296.0 \n",
      "Model_2_3940 \t loss_train = 34152952.0 \t loss_valid = 28843432.0 \n",
      "Model_2_3950 \t loss_train = 34162676.0 \t loss_valid = 28806628.0 \n",
      "Model_2_3960 \t loss_train = 34340396.0 \t loss_valid = 28896670.0 \n",
      "Model_2_3970 \t loss_train = 33595948.0 \t loss_valid = 28257464.0 \n",
      "Model_2_3980 \t loss_train = 35224436.0 \t loss_valid = 29886430.0 \n",
      "Model_2_3990 \t loss_train = 33865416.0 \t loss_valid = 28563272.0 \n",
      "Model_2_4000 \t loss_train = 34425536.0 \t loss_valid = 29089088.0 \n",
      "Model_2_4010 \t loss_train = 35153476.0 \t loss_valid = 29759190.0 \n",
      "Model_2_4020 \t loss_train = 33687472.0 \t loss_valid = 28305164.0 \n",
      "Model_2_4030 \t loss_train = 33747516.0 \t loss_valid = 28387344.0 \n",
      "Model_2_4040 \t loss_train = 34368436.0 \t loss_valid = 28852860.0 \n",
      "Model_2_4050 \t loss_train = 33975392.0 \t loss_valid = 28587014.0 \n",
      "Model_2_4060 \t loss_train = 34410556.0 \t loss_valid = 28950818.0 \n",
      "Model_2_4070 \t loss_train = 33911260.0 \t loss_valid = 28617222.0 \n",
      "Model_2_4080 \t loss_train = 33684304.0 \t loss_valid = 28237872.0 \n",
      "Model_2_4090 \t loss_train = 34678264.0 \t loss_valid = 29364114.0 \n",
      "Model_2_4100 \t loss_train = 33993424.0 \t loss_valid = 28581606.0 \n",
      "Model_2_4110 \t loss_train = 34254244.0 \t loss_valid = 28771388.0 \n",
      "Model_2_4120 \t loss_train = 33980552.0 \t loss_valid = 28480524.0 \n",
      "Model_2_4130 \t loss_train = 34392536.0 \t loss_valid = 28976634.0 \n",
      "Model_2_4140 \t loss_train = 34316612.0 \t loss_valid = 29011370.0 \n",
      "Model_2_4150 \t loss_train = 34486168.0 \t loss_valid = 28896860.0 \n",
      "Model_2_4160 \t loss_train = 33338128.0 \t loss_valid = 28047888.0 \n",
      "Model_2_4170 \t loss_train = 33724596.0 \t loss_valid = 28248968.0 \n",
      "Model_2_4180 \t loss_train = 34428376.0 \t loss_valid = 28969152.0 \n",
      "Model_2_4190 \t loss_train = 34612264.0 \t loss_valid = 29116028.0 \n",
      "Model_2_4200 \t loss_train = 34292320.0 \t loss_valid = 28788998.0 \n",
      "Model_2_4210 \t loss_train = 34241292.0 \t loss_valid = 28786774.0 \n",
      "Model_2_4220 \t loss_train = 33938184.0 \t loss_valid = 28528154.0 \n",
      "Model_2_4230 \t loss_train = 33669420.0 \t loss_valid = 28242306.0 \n",
      "Model_2_4240 \t loss_train = 34300672.0 \t loss_valid = 28951546.0 \n",
      "Model_2_4250 \t loss_train = 34260592.0 \t loss_valid = 28789280.0 \n",
      "Model_2_4260 \t loss_train = 34495376.0 \t loss_valid = 29091350.0 \n",
      "Model_2_4270 \t loss_train = 34811608.0 \t loss_valid = 29278572.0 \n",
      "Model_2_4280 \t loss_train = 35070908.0 \t loss_valid = 29621486.0 \n",
      "Model_2_4290 \t loss_train = 34490900.0 \t loss_valid = 29150338.0 \n",
      "Model_2_4300 \t loss_train = 33838388.0 \t loss_valid = 28366374.0 \n",
      "Model_2_4310 \t loss_train = 34578320.0 \t loss_valid = 29280692.0 \n",
      "Model_2_4320 \t loss_train = 34614720.0 \t loss_valid = 29285358.0 \n",
      "Model_2_4330 \t loss_train = 34687056.0 \t loss_valid = 29213690.0 \n",
      "Model_2_4340 \t loss_train = 34227004.0 \t loss_valid = 28781986.0 \n",
      "Model_2_4350 \t loss_train = 33696832.0 \t loss_valid = 28391614.0 \n",
      "Model_2_4360 \t loss_train = 34208092.0 \t loss_valid = 28691706.0 \n",
      "Model_2_4370 \t loss_train = 33747304.0 \t loss_valid = 28414650.0 \n",
      "Model_2_4380 \t loss_train = 34510248.0 \t loss_valid = 29012212.0 \n",
      "Model_2_4390 \t loss_train = 34711868.0 \t loss_valid = 29200176.0 \n",
      "Model_2_4400 \t loss_train = 34577304.0 \t loss_valid = 29079982.0 \n",
      "Model_2_4410 \t loss_train = 33792688.0 \t loss_valid = 28366340.0 \n",
      "Model_2_4420 \t loss_train = 34449976.0 \t loss_valid = 29016308.0 \n",
      "Model_2_4430 \t loss_train = 33797028.0 \t loss_valid = 28363514.0 \n",
      "Model_2_4440 \t loss_train = 34337692.0 \t loss_valid = 28997614.0 \n",
      "Model_2_4450 \t loss_train = 34515420.0 \t loss_valid = 29077010.0 \n",
      "Model_2_4460 \t loss_train = 34130212.0 \t loss_valid = 28792646.0 \n",
      "Model_2_4470 \t loss_train = 33950732.0 \t loss_valid = 28588980.0 \n",
      "Model_2_4480 \t loss_train = 34452024.0 \t loss_valid = 28952542.0 \n",
      "Model_2_4490 \t loss_train = 34898248.0 \t loss_valid = 29317936.0 \n",
      "Model_2_4500 \t loss_train = 34234916.0 \t loss_valid = 28842104.0 \n",
      "Model_2_4510 \t loss_train = 34420036.0 \t loss_valid = 29038336.0 \n",
      "Model_2_4520 \t loss_train = 34354820.0 \t loss_valid = 28799412.0 \n",
      "Model_2_4530 \t loss_train = 34034268.0 \t loss_valid = 28548956.0 \n",
      "Model_2_4540 \t loss_train = 35362088.0 \t loss_valid = 29780206.0 \n",
      "Model_2_4550 \t loss_train = 34889676.0 \t loss_valid = 29474842.0 \n",
      "Model_2_4560 \t loss_train = 34110152.0 \t loss_valid = 28585232.0 \n",
      "Model_2_4570 \t loss_train = 34605296.0 \t loss_valid = 29256514.0 \n",
      "Model_2_4580 \t loss_train = 35236700.0 \t loss_valid = 29875392.0 \n",
      "Model_2_4590 \t loss_train = 34961772.0 \t loss_valid = 29422340.0 \n",
      "Model_2_4600 \t loss_train = 34516560.0 \t loss_valid = 29103752.0 \n",
      "Model_2_4610 \t loss_train = 34060712.0 \t loss_valid = 28591916.0 \n",
      "Model_2_4620 \t loss_train = 34782072.0 \t loss_valid = 29276630.0 \n",
      "Model_2_4630 \t loss_train = 34803852.0 \t loss_valid = 29199928.0 \n",
      "Model_2_4640 \t loss_train = 34255456.0 \t loss_valid = 28750406.0 \n",
      "Model_2_4650 \t loss_train = 34108932.0 \t loss_valid = 28681980.0 \n",
      "Model_2_4660 \t loss_train = 34830152.0 \t loss_valid = 29325966.0 \n",
      "Model_2_4670 \t loss_train = 34601788.0 \t loss_valid = 29153802.0 \n",
      "Model_2_4680 \t loss_train = 34686420.0 \t loss_valid = 29170578.0 \n",
      "Model_2_4690 \t loss_train = 35317764.0 \t loss_valid = 29772996.0 \n",
      "Model_2_4700 \t loss_train = 34743308.0 \t loss_valid = 29211256.0 \n",
      "Model_2_4710 \t loss_train = 34470428.0 \t loss_valid = 28861292.0 \n",
      "Model_2_4720 \t loss_train = 34729444.0 \t loss_valid = 29362716.0 \n",
      "Model_2_4730 \t loss_train = 35534820.0 \t loss_valid = 30213802.0 \n",
      "Model_2_4740 \t loss_train = 34543092.0 \t loss_valid = 28977244.0 \n",
      "Model_2_4750 \t loss_train = 34825744.0 \t loss_valid = 29318330.0 \n",
      "Model_2_4760 \t loss_train = 35086948.0 \t loss_valid = 29523610.0 \n",
      "Model_2_4770 \t loss_train = 34173536.0 \t loss_valid = 28676940.0 \n",
      "Model_2_4780 \t loss_train = 35359088.0 \t loss_valid = 29687994.0 \n",
      "Model_2_4790 \t loss_train = 35571640.0 \t loss_valid = 30008086.0 \n",
      "Model_2_4800 \t loss_train = 34985996.0 \t loss_valid = 29446788.0 \n",
      "Model_2_4810 \t loss_train = 35054776.0 \t loss_valid = 29412738.0 \n",
      "Model_2_4820 \t loss_train = 34739976.0 \t loss_valid = 29178668.0 \n",
      "Model_2_4830 \t loss_train = 34892108.0 \t loss_valid = 29358918.0 \n",
      "Model_2_4840 \t loss_train = 34728544.0 \t loss_valid = 29188062.0 \n",
      "Model_2_4850 \t loss_train = 34597480.0 \t loss_valid = 29134652.0 \n",
      "Model_2_4860 \t loss_train = 34327584.0 \t loss_valid = 28799118.0 \n",
      "Model_2_4870 \t loss_train = 34546824.0 \t loss_valid = 29143082.0 \n",
      "Model_2_4880 \t loss_train = 34851744.0 \t loss_valid = 29246240.0 \n",
      "Model_2_4890 \t loss_train = 35266024.0 \t loss_valid = 29735882.0 \n",
      "Model_2_4900 \t loss_train = 35116132.0 \t loss_valid = 29492484.0 \n",
      "Model_2_4910 \t loss_train = 35218936.0 \t loss_valid = 29660410.0 \n",
      "Model_2_4920 \t loss_train = 34351096.0 \t loss_valid = 28931618.0 \n",
      "Model_2_4930 \t loss_train = 34481824.0 \t loss_valid = 28813602.0 \n",
      "Model_2_4940 \t loss_train = 35707000.0 \t loss_valid = 30147192.0 \n",
      "Model_2_4950 \t loss_train = 35055928.0 \t loss_valid = 29463224.0 \n",
      "Model_2_4960 \t loss_train = 34322400.0 \t loss_valid = 28662442.0 \n",
      "Model_2_4970 \t loss_train = 34484972.0 \t loss_valid = 28841580.0 \n",
      "Model_2_4980 \t loss_train = 35023392.0 \t loss_valid = 29283182.0 \n",
      "Model_2_4990 \t loss_train = 35675116.0 \t loss_valid = 30212254.0 \n",
      "Model_2_5000 \t loss_train = 34744964.0 \t loss_valid = 28968442.0 \n",
      "Model_2_5010 \t loss_train = 34278168.0 \t loss_valid = 28793508.0 \n",
      "Model_2_5020 \t loss_train = 34833728.0 \t loss_valid = 28976988.0 \n",
      "Model_2_5030 \t loss_train = 34535740.0 \t loss_valid = 29096474.0 \n",
      "Model_2_5040 \t loss_train = 34856228.0 \t loss_valid = 29261046.0 \n",
      "Model_2_5050 \t loss_train = 35055924.0 \t loss_valid = 29335774.0 \n",
      "Model_2_5060 \t loss_train = 35186688.0 \t loss_valid = 29606742.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_2_5070 \t loss_train = 35522168.0 \t loss_valid = 29932000.0 \n",
      "Model_2_5080 \t loss_train = 34897408.0 \t loss_valid = 29087726.0 \n",
      "Model_2_5090 \t loss_train = 34269252.0 \t loss_valid = 28930872.0 \n",
      "Model_2_5100 \t loss_train = 34492820.0 \t loss_valid = 28784608.0 \n",
      "Model_2_5110 \t loss_train = 34679944.0 \t loss_valid = 29104046.0 \n",
      "Model_2_5120 \t loss_train = 35537144.0 \t loss_valid = 29711146.0 \n",
      "Model_2_5130 \t loss_train = 35128192.0 \t loss_valid = 29476280.0 \n",
      "Model_2_5140 \t loss_train = 34845544.0 \t loss_valid = 29244442.0 \n",
      "Model_2_5150 \t loss_train = 34704452.0 \t loss_valid = 28997420.0 \n",
      "Model_2_5160 \t loss_train = 35133640.0 \t loss_valid = 29513694.0 \n",
      "Model_2_5170 \t loss_train = 35974336.0 \t loss_valid = 30174300.0 \n",
      "Model_2_5180 \t loss_train = 35440272.0 \t loss_valid = 29692770.0 \n",
      "Model_2_5190 \t loss_train = 35114420.0 \t loss_valid = 29473902.0 \n",
      "Model_2_5200 \t loss_train = 35195808.0 \t loss_valid = 29459504.0 \n",
      "Model_2_5210 \t loss_train = 35315428.0 \t loss_valid = 29588126.0 \n",
      "Model_2_5220 \t loss_train = 35714300.0 \t loss_valid = 29990118.0 \n",
      "Model_2_5230 \t loss_train = 35435116.0 \t loss_valid = 29709012.0 \n",
      "Model_2_5240 \t loss_train = 35726564.0 \t loss_valid = 30044374.0 \n",
      "Model_2_5250 \t loss_train = 35229816.0 \t loss_valid = 29481858.0 \n",
      "Model_2_5260 \t loss_train = 34809532.0 \t loss_valid = 29237286.0 \n",
      "Model_2_5270 \t loss_train = 34957488.0 \t loss_valid = 29296612.0 \n",
      "Model_2_5280 \t loss_train = 35802816.0 \t loss_valid = 30246900.0 \n",
      "Model_2_5290 \t loss_train = 35366012.0 \t loss_valid = 29844424.0 \n",
      "Model_2_5300 \t loss_train = 34776700.0 \t loss_valid = 29066720.0 \n",
      "Model_2_5310 \t loss_train = 35951628.0 \t loss_valid = 30169926.0 \n",
      "Model_2_5320 \t loss_train = 35882324.0 \t loss_valid = 30142944.0 \n",
      "Model_2_5330 \t loss_train = 35423624.0 \t loss_valid = 29649976.0 \n",
      "Model_2_5340 \t loss_train = 34915056.0 \t loss_valid = 29165496.0 \n",
      "Model_2_5350 \t loss_train = 35752048.0 \t loss_valid = 30018298.0 \n",
      "Model_2_5360 \t loss_train = 35424716.0 \t loss_valid = 29594184.0 \n",
      "Model_2_5370 \t loss_train = 35594968.0 \t loss_valid = 29882624.0 \n",
      "Model_2_5380 \t loss_train = 34738096.0 \t loss_valid = 29059710.0 \n",
      "Model_2_5390 \t loss_train = 35445544.0 \t loss_valid = 29712014.0 \n",
      "Model_2_5400 \t loss_train = 35488220.0 \t loss_valid = 29889540.0 \n",
      "Model_2_5410 \t loss_train = 35665856.0 \t loss_valid = 29708762.0 \n",
      "Model_2_5420 \t loss_train = 34406348.0 \t loss_valid = 28986346.0 \n",
      "Model_2_5430 \t loss_train = 35383660.0 \t loss_valid = 29441682.0 \n",
      "Model_2_5440 \t loss_train = 35711460.0 \t loss_valid = 30108878.0 \n",
      "Model_2_5450 \t loss_train = 36006592.0 \t loss_valid = 30243208.0 \n",
      "Model_2_5460 \t loss_train = 35689540.0 \t loss_valid = 30016124.0 \n",
      "Model_2_5470 \t loss_train = 36998924.0 \t loss_valid = 31170790.0 \n",
      "Model_2_5480 \t loss_train = 35619268.0 \t loss_valid = 29973728.0 \n",
      "Model_2_5490 \t loss_train = 34947024.0 \t loss_valid = 29126532.0 \n",
      "Model_2_5500 \t loss_train = 35219168.0 \t loss_valid = 29517534.0 \n",
      "Model_2_5510 \t loss_train = 35703672.0 \t loss_valid = 29932594.0 \n",
      "Model_2_5520 \t loss_train = 35654864.0 \t loss_valid = 29750484.0 \n",
      "Model_2_5530 \t loss_train = 35351424.0 \t loss_valid = 29572364.0 \n",
      "Model_2_5540 \t loss_train = 36157700.0 \t loss_valid = 30375886.0 \n",
      "Model_2_5550 \t loss_train = 35499636.0 \t loss_valid = 29725216.0 \n",
      "Model_2_5560 \t loss_train = 35528016.0 \t loss_valid = 29853238.0 \n",
      "Model_2_5570 \t loss_train = 36186360.0 \t loss_valid = 30393954.0 \n",
      "Model_2_5580 \t loss_train = 35647740.0 \t loss_valid = 29876926.0 \n",
      "Model_2_5590 \t loss_train = 35001412.0 \t loss_valid = 29233186.0 \n",
      "Model_2_5600 \t loss_train = 35516408.0 \t loss_valid = 29704616.0 \n",
      "Model_2_5610 \t loss_train = 35528304.0 \t loss_valid = 29760424.0 \n",
      "Model_2_5620 \t loss_train = 35769260.0 \t loss_valid = 29771634.0 \n",
      "Model_2_5630 \t loss_train = 35315572.0 \t loss_valid = 29532416.0 \n",
      "Model_2_5640 \t loss_train = 35876236.0 \t loss_valid = 30174580.0 \n",
      "Model_2_5650 \t loss_train = 35790956.0 \t loss_valid = 29833242.0 \n",
      "Model_2_5660 \t loss_train = 35114196.0 \t loss_valid = 29354366.0 \n",
      "Model_2_5670 \t loss_train = 34535652.0 \t loss_valid = 28810966.0 \n",
      "Model_2_5680 \t loss_train = 36016136.0 \t loss_valid = 30165716.0 \n",
      "Model_2_5690 \t loss_train = 36082596.0 \t loss_valid = 30319672.0 \n",
      "Model_2_5700 \t loss_train = 35406112.0 \t loss_valid = 29740562.0 \n",
      "Model_2_5710 \t loss_train = 35743380.0 \t loss_valid = 29888938.0 \n",
      "Model_2_5720 \t loss_train = 35753252.0 \t loss_valid = 29983406.0 \n",
      "Model_2_5730 \t loss_train = 35146252.0 \t loss_valid = 29264378.0 \n",
      "Model_2_5740 \t loss_train = 35240920.0 \t loss_valid = 29239748.0 \n",
      "Model_2_5750 \t loss_train = 34374876.0 \t loss_valid = 28685906.0 \n",
      "Model_2_5760 \t loss_train = 36004324.0 \t loss_valid = 30118224.0 \n",
      "Model_2_5770 \t loss_train = 36141316.0 \t loss_valid = 30326404.0 \n",
      "Model_2_5780 \t loss_train = 35979568.0 \t loss_valid = 30101814.0 \n",
      "Model_2_5790 \t loss_train = 35409844.0 \t loss_valid = 29650338.0 \n",
      "Model_2_5800 \t loss_train = 35947304.0 \t loss_valid = 30006426.0 \n",
      "Model_2_5810 \t loss_train = 35285772.0 \t loss_valid = 29744488.0 \n",
      "Model_2_5820 \t loss_train = 36157084.0 \t loss_valid = 30165460.0 \n",
      "Model_2_5830 \t loss_train = 36422592.0 \t loss_valid = 30480270.0 \n",
      "Model_2_5840 \t loss_train = 35954208.0 \t loss_valid = 29952802.0 \n",
      "Model_2_5850 \t loss_train = 35603864.0 \t loss_valid = 29680952.0 \n",
      "Model_2_5860 \t loss_train = 35817400.0 \t loss_valid = 30139022.0 \n",
      "Model_2_5870 \t loss_train = 35670644.0 \t loss_valid = 29625416.0 \n",
      "Model_2_5880 \t loss_train = 36835316.0 \t loss_valid = 31020222.0 \n",
      "Model_2_5890 \t loss_train = 35980508.0 \t loss_valid = 30167068.0 \n",
      "Model_2_5900 \t loss_train = 35719448.0 \t loss_valid = 29849138.0 \n",
      "Model_2_5910 \t loss_train = 35252252.0 \t loss_valid = 29371118.0 \n",
      "Model_2_5920 \t loss_train = 36118388.0 \t loss_valid = 30178424.0 \n",
      "Model_2_5930 \t loss_train = 36281440.0 \t loss_valid = 30327088.0 \n",
      "Model_2_5940 \t loss_train = 35958292.0 \t loss_valid = 30014650.0 \n",
      "Model_2_5950 \t loss_train = 36423656.0 \t loss_valid = 30502374.0 \n",
      "Model_2_5960 \t loss_train = 36034348.0 \t loss_valid = 30168374.0 \n",
      "Model_2_5970 \t loss_train = 35921692.0 \t loss_valid = 30069124.0 \n",
      "Model_2_5980 \t loss_train = 36473680.0 \t loss_valid = 30437364.0 \n",
      "Model_2_5990 \t loss_train = 36698588.0 \t loss_valid = 30686840.0 \n",
      "Model_2_6000 \t loss_train = 35459620.0 \t loss_valid = 29573430.0 \n",
      "Model_2_6010 \t loss_train = 34955964.0 \t loss_valid = 29256040.0 \n",
      "Model_2_6020 \t loss_train = 36484456.0 \t loss_valid = 30465172.0 \n",
      "Model_2_6030 \t loss_train = 35750224.0 \t loss_valid = 29987640.0 \n",
      "Model_2_6040 \t loss_train = 35821436.0 \t loss_valid = 30053114.0 \n",
      "Model_2_6050 \t loss_train = 35967440.0 \t loss_valid = 29883828.0 \n",
      "Model_2_6060 \t loss_train = 36209868.0 \t loss_valid = 30381328.0 \n",
      "Model_2_6070 \t loss_train = 36357964.0 \t loss_valid = 30492618.0 \n",
      "Model_2_6080 \t loss_train = 35666944.0 \t loss_valid = 29824022.0 \n",
      "Model_2_6090 \t loss_train = 36669872.0 \t loss_valid = 30699564.0 \n",
      "Model_2_6100 \t loss_train = 35581492.0 \t loss_valid = 29682862.0 \n",
      "Model_2_6110 \t loss_train = 35314784.0 \t loss_valid = 29467772.0 \n",
      "Model_2_6120 \t loss_train = 35683792.0 \t loss_valid = 29831730.0 \n",
      "Model_2_6130 \t loss_train = 36750116.0 \t loss_valid = 30703148.0 \n",
      "Model_2_6140 \t loss_train = 35768400.0 \t loss_valid = 29784156.0 \n",
      "Model_2_6150 \t loss_train = 35107104.0 \t loss_valid = 29326468.0 \n",
      "Model_2_6160 \t loss_train = 36088528.0 \t loss_valid = 30207602.0 \n",
      "Model_2_6170 \t loss_train = 37057772.0 \t loss_valid = 31218180.0 \n",
      "Model_2_6180 \t loss_train = 36484696.0 \t loss_valid = 30632088.0 \n",
      "Model_2_6190 \t loss_train = 36359648.0 \t loss_valid = 30405954.0 \n",
      "Model_2_6200 \t loss_train = 36115392.0 \t loss_valid = 30285866.0 \n",
      "Model_2_6210 \t loss_train = 36138004.0 \t loss_valid = 30170984.0 \n",
      "Model_2_6220 \t loss_train = 35772620.0 \t loss_valid = 29845542.0 \n",
      "Model_2_6230 \t loss_train = 36149084.0 \t loss_valid = 30192378.0 \n",
      "Model_2_6240 \t loss_train = 36136784.0 \t loss_valid = 30304154.0 \n",
      "Model_2_6250 \t loss_train = 36290320.0 \t loss_valid = 30451920.0 \n",
      "Model_2_6260 \t loss_train = 36170972.0 \t loss_valid = 30261178.0 \n",
      "Model_2_6270 \t loss_train = 36141540.0 \t loss_valid = 30233446.0 \n",
      "Model_2_6280 \t loss_train = 36101180.0 \t loss_valid = 30218132.0 \n",
      "Model_2_6290 \t loss_train = 35771484.0 \t loss_valid = 29883708.0 \n",
      "Model_2_6300 \t loss_train = 36452312.0 \t loss_valid = 30423002.0 \n",
      "Model_2_6310 \t loss_train = 36107240.0 \t loss_valid = 30186344.0 \n",
      "Model_2_6320 \t loss_train = 35548300.0 \t loss_valid = 29646030.0 \n",
      "Model_2_6330 \t loss_train = 36617432.0 \t loss_valid = 30576950.0 \n",
      "Model_2_6340 \t loss_train = 36497460.0 \t loss_valid = 30586814.0 \n",
      "Model_2_6350 \t loss_train = 36335024.0 \t loss_valid = 30224042.0 \n",
      "Model_2_6360 \t loss_train = 35635284.0 \t loss_valid = 29695848.0 \n",
      "Model_2_6370 \t loss_train = 36115072.0 \t loss_valid = 30076300.0 \n",
      "Model_2_6380 \t loss_train = 36366560.0 \t loss_valid = 30353430.0 \n",
      "Model_2_6390 \t loss_train = 36484216.0 \t loss_valid = 30335506.0 \n",
      "Model_2_6400 \t loss_train = 35866344.0 \t loss_valid = 29974076.0 \n",
      "Model_2_6410 \t loss_train = 36299464.0 \t loss_valid = 30462574.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_2_6420 \t loss_train = 36986176.0 \t loss_valid = 30968844.0 \n",
      "Model_2_6430 \t loss_train = 36555812.0 \t loss_valid = 30523070.0 \n",
      "Model_2_6440 \t loss_train = 36746344.0 \t loss_valid = 30712594.0 \n",
      "Model_2_6450 \t loss_train = 36065644.0 \t loss_valid = 30096978.0 \n",
      "Model_2_6460 \t loss_train = 36627208.0 \t loss_valid = 30687372.0 \n",
      "Model_2_6470 \t loss_train = 36276212.0 \t loss_valid = 30401132.0 \n",
      "Model_2_6480 \t loss_train = 36526616.0 \t loss_valid = 30462476.0 \n",
      "Model_2_6490 \t loss_train = 36804008.0 \t loss_valid = 30782388.0 \n",
      "Model_2_6500 \t loss_train = 36947680.0 \t loss_valid = 30801408.0 \n",
      "Model_2_6510 \t loss_train = 36044648.0 \t loss_valid = 30131136.0 \n",
      "Model_2_6520 \t loss_train = 36605484.0 \t loss_valid = 30536834.0 \n",
      "Model_2_6530 \t loss_train = 36508168.0 \t loss_valid = 30528696.0 \n",
      "Model_2_6540 \t loss_train = 36584460.0 \t loss_valid = 30612398.0 \n",
      "Model_2_6550 \t loss_train = 36268788.0 \t loss_valid = 30299020.0 \n",
      "Model_2_6560 \t loss_train = 36911148.0 \t loss_valid = 30838224.0 \n",
      "Model_2_6570 \t loss_train = 36055604.0 \t loss_valid = 30063634.0 \n",
      "Model_2_6580 \t loss_train = 36375308.0 \t loss_valid = 30343038.0 \n",
      "Model_2_6590 \t loss_train = 36863744.0 \t loss_valid = 30770546.0 \n",
      "Model_2_6600 \t loss_train = 36875272.0 \t loss_valid = 30870932.0 \n",
      "Model_2_6610 \t loss_train = 36125660.0 \t loss_valid = 30186326.0 \n",
      "Model_2_6620 \t loss_train = 36675172.0 \t loss_valid = 30700848.0 \n",
      "Model_2_6630 \t loss_train = 36652744.0 \t loss_valid = 30704938.0 \n",
      "Model_2_6640 \t loss_train = 36145176.0 \t loss_valid = 30126348.0 \n",
      "Model_2_6650 \t loss_train = 37113308.0 \t loss_valid = 31143872.0 \n",
      "Model_2_6660 \t loss_train = 36773596.0 \t loss_valid = 30705314.0 \n",
      "Model_2_6670 \t loss_train = 36942520.0 \t loss_valid = 30777392.0 \n",
      "Model_2_6680 \t loss_train = 37000268.0 \t loss_valid = 30930654.0 \n",
      "Model_2_6690 \t loss_train = 36289496.0 \t loss_valid = 30349932.0 \n",
      "Model_2_6700 \t loss_train = 36804180.0 \t loss_valid = 30771452.0 \n",
      "Model_2_6710 \t loss_train = 36542752.0 \t loss_valid = 30396988.0 \n",
      "Model_2_6720 \t loss_train = 36795696.0 \t loss_valid = 30764344.0 \n",
      "Model_2_6730 \t loss_train = 36905680.0 \t loss_valid = 30789174.0 \n",
      "Model_2_6740 \t loss_train = 37130412.0 \t loss_valid = 30841028.0 \n",
      "Model_2_6750 \t loss_train = 36695472.0 \t loss_valid = 30622676.0 \n",
      "Model_2_6760 \t loss_train = 36737800.0 \t loss_valid = 30548942.0 \n",
      "Model_2_6770 \t loss_train = 36993516.0 \t loss_valid = 30907152.0 \n",
      "Model_2_6780 \t loss_train = 36425720.0 \t loss_valid = 30374848.0 \n",
      "Model_2_6790 \t loss_train = 36601484.0 \t loss_valid = 30689514.0 \n",
      "Model_2_6800 \t loss_train = 36796596.0 \t loss_valid = 30717270.0 \n",
      "Model_2_6810 \t loss_train = 36295148.0 \t loss_valid = 30234732.0 \n",
      "Model_2_6820 \t loss_train = 37409688.0 \t loss_valid = 31257496.0 \n",
      "Model_2_6830 \t loss_train = 37107296.0 \t loss_valid = 30979468.0 \n",
      "Model_2_6840 \t loss_train = 35936844.0 \t loss_valid = 29991658.0 \n",
      "Model_2_6850 \t loss_train = 36492940.0 \t loss_valid = 30346948.0 \n",
      "Model_2_6860 \t loss_train = 36629420.0 \t loss_valid = 30577146.0 \n",
      "Model_2_6870 \t loss_train = 36840004.0 \t loss_valid = 30670408.0 \n",
      "Model_2_6880 \t loss_train = 37200752.0 \t loss_valid = 31071018.0 \n",
      "Model_2_6890 \t loss_train = 36800468.0 \t loss_valid = 30759594.0 \n",
      "Model_2_6900 \t loss_train = 36862528.0 \t loss_valid = 30696982.0 \n",
      "Model_2_6910 \t loss_train = 37274228.0 \t loss_valid = 31034912.0 \n",
      "Model_2_6920 \t loss_train = 36851812.0 \t loss_valid = 30732604.0 \n",
      "Model_2_6930 \t loss_train = 36724920.0 \t loss_valid = 30583948.0 \n",
      "Model_2_6940 \t loss_train = 36802848.0 \t loss_valid = 30649920.0 \n",
      "Model_2_6950 \t loss_train = 37462156.0 \t loss_valid = 31326072.0 \n",
      "Model_2_6960 \t loss_train = 37011016.0 \t loss_valid = 30858638.0 \n",
      "Model_2_6970 \t loss_train = 36367776.0 \t loss_valid = 30153422.0 \n",
      "Model_2_6980 \t loss_train = 37160156.0 \t loss_valid = 30950868.0 \n",
      "Model_2_6990 \t loss_train = 37434512.0 \t loss_valid = 31385344.0 \n",
      "Model_2_7000 \t loss_train = 36965620.0 \t loss_valid = 30832984.0 \n",
      "Model_2_7010 \t loss_train = 37112708.0 \t loss_valid = 30796692.0 \n",
      "Model_2_7020 \t loss_train = 37257288.0 \t loss_valid = 31143098.0 \n",
      "Model_2_7030 \t loss_train = 36871956.0 \t loss_valid = 30796118.0 \n",
      "Model_2_7040 \t loss_train = 36870448.0 \t loss_valid = 30728708.0 \n",
      "Model_2_7050 \t loss_train = 37142924.0 \t loss_valid = 30996212.0 \n",
      "Model_2_7060 \t loss_train = 36198784.0 \t loss_valid = 30149192.0 \n",
      "Model_2_7070 \t loss_train = 37031304.0 \t loss_valid = 30876034.0 \n",
      "Model_2_7080 \t loss_train = 37384532.0 \t loss_valid = 31148528.0 \n",
      "Model_2_7090 \t loss_train = 36891060.0 \t loss_valid = 30757812.0 \n",
      "Model_2_7100 \t loss_train = 37012568.0 \t loss_valid = 30518968.0 \n",
      "Model_2_7110 \t loss_train = 36948124.0 \t loss_valid = 30717918.0 \n",
      "Model_2_7120 \t loss_train = 37082388.0 \t loss_valid = 30766156.0 \n",
      "Model_2_7130 \t loss_train = 36752524.0 \t loss_valid = 30635072.0 \n",
      "Model_2_7140 \t loss_train = 36943980.0 \t loss_valid = 30738368.0 \n",
      "Model_2_7150 \t loss_train = 36858184.0 \t loss_valid = 30676122.0 \n",
      "Model_2_7160 \t loss_train = 37288492.0 \t loss_valid = 31049188.0 \n",
      "Model_2_7170 \t loss_train = 36867928.0 \t loss_valid = 30639882.0 \n",
      "Model_2_7180 \t loss_train = 38183440.0 \t loss_valid = 31888258.0 \n",
      "Model_2_7190 \t loss_train = 36443052.0 \t loss_valid = 30336006.0 \n",
      "Model_2_7200 \t loss_train = 37254492.0 \t loss_valid = 31030720.0 \n",
      "Model_2_7210 \t loss_train = 37023484.0 \t loss_valid = 30911406.0 \n",
      "Model_2_7220 \t loss_train = 37528392.0 \t loss_valid = 31122758.0 \n",
      "Model_2_7230 \t loss_train = 37619700.0 \t loss_valid = 31431354.0 \n",
      "Model_2_7240 \t loss_train = 37136496.0 \t loss_valid = 30781408.0 \n",
      "Model_2_7250 \t loss_train = 37192276.0 \t loss_valid = 31112880.0 \n",
      "Model_2_7260 \t loss_train = 37948724.0 \t loss_valid = 31724794.0 \n",
      "Model_2_7270 \t loss_train = 37694436.0 \t loss_valid = 31418026.0 \n",
      "Model_2_7280 \t loss_train = 36909144.0 \t loss_valid = 30588586.0 \n",
      "Model_2_7290 \t loss_train = 37255108.0 \t loss_valid = 31193708.0 \n",
      "Model_2_7300 \t loss_train = 37644584.0 \t loss_valid = 31438640.0 \n",
      "Model_2_7310 \t loss_train = 37441624.0 \t loss_valid = 31219070.0 \n",
      "Model_2_7320 \t loss_train = 37286876.0 \t loss_valid = 30864308.0 \n",
      "Model_2_7330 \t loss_train = 37266340.0 \t loss_valid = 31050222.0 \n",
      "Model_2_7340 \t loss_train = 37474224.0 \t loss_valid = 31186530.0 \n",
      "Model_2_7350 \t loss_train = 37558980.0 \t loss_valid = 31294062.0 \n",
      "Model_2_7360 \t loss_train = 36844904.0 \t loss_valid = 30655570.0 \n",
      "Model_2_7370 \t loss_train = 37173660.0 \t loss_valid = 31030006.0 \n",
      "Model_2_7380 \t loss_train = 37528760.0 \t loss_valid = 31375250.0 \n",
      "Model_2_7390 \t loss_train = 36736436.0 \t loss_valid = 30723618.0 \n",
      "Model_2_7400 \t loss_train = 37424608.0 \t loss_valid = 31134256.0 \n",
      "Model_2_7410 \t loss_train = 36622260.0 \t loss_valid = 30482246.0 \n",
      "Model_2_7420 \t loss_train = 37765048.0 \t loss_valid = 31391472.0 \n",
      "Model_2_7430 \t loss_train = 36552784.0 \t loss_valid = 30369372.0 \n",
      "Model_2_7440 \t loss_train = 37727284.0 \t loss_valid = 31324586.0 \n",
      "Model_2_7450 \t loss_train = 37318888.0 \t loss_valid = 31161288.0 \n",
      "Model_2_7460 \t loss_train = 36960432.0 \t loss_valid = 30609098.0 \n",
      "Model_2_7470 \t loss_train = 36890032.0 \t loss_valid = 30599534.0 \n",
      "Model_2_7480 \t loss_train = 36960020.0 \t loss_valid = 30665630.0 \n",
      "Model_2_7490 \t loss_train = 37870728.0 \t loss_valid = 31611780.0 \n",
      "Model_2_7500 \t loss_train = 36652440.0 \t loss_valid = 30476768.0 \n",
      "Model_2_7510 \t loss_train = 36658080.0 \t loss_valid = 30540952.0 \n",
      "Model_2_7520 \t loss_train = 37247948.0 \t loss_valid = 30967094.0 \n",
      "Model_2_7530 \t loss_train = 36876680.0 \t loss_valid = 30843446.0 \n",
      "Model_2_7540 \t loss_train = 37512268.0 \t loss_valid = 31249380.0 \n",
      "Model_2_7550 \t loss_train = 36708312.0 \t loss_valid = 30462806.0 \n",
      "Model_2_7560 \t loss_train = 37879716.0 \t loss_valid = 31666112.0 \n",
      "Model_2_7570 \t loss_train = 37707676.0 \t loss_valid = 31389576.0 \n",
      "Model_2_7580 \t loss_train = 37575200.0 \t loss_valid = 31543574.0 \n",
      "Model_2_7590 \t loss_train = 36837876.0 \t loss_valid = 30746984.0 \n",
      "Model_2_7600 \t loss_train = 36600712.0 \t loss_valid = 30511888.0 \n",
      "Model_2_7610 \t loss_train = 37610924.0 \t loss_valid = 31297786.0 \n",
      "Model_2_7620 \t loss_train = 37276932.0 \t loss_valid = 31122752.0 \n",
      "Model_2_7630 \t loss_train = 37705732.0 \t loss_valid = 31473510.0 \n",
      "Model_2_7640 \t loss_train = 37528228.0 \t loss_valid = 31247170.0 \n",
      "Model_2_7650 \t loss_train = 37010408.0 \t loss_valid = 30814644.0 \n",
      "Model_2_7660 \t loss_train = 37380816.0 \t loss_valid = 31060202.0 \n",
      "Model_2_7670 \t loss_train = 37344988.0 \t loss_valid = 31153778.0 \n",
      "Model_2_7680 \t loss_train = 37304204.0 \t loss_valid = 30957060.0 \n",
      "Model_2_7690 \t loss_train = 36848304.0 \t loss_valid = 30755152.0 \n",
      "Model_2_7700 \t loss_train = 37924568.0 \t loss_valid = 31566386.0 \n",
      "Model_2_7710 \t loss_train = 37549028.0 \t loss_valid = 31270802.0 \n",
      "Model_2_7720 \t loss_train = 36987108.0 \t loss_valid = 30622438.0 \n",
      "Model_2_7730 \t loss_train = 37851784.0 \t loss_valid = 31592978.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_2_7740 \t loss_train = 37923888.0 \t loss_valid = 31658692.0 \n",
      "Model_2_7750 \t loss_train = 37162104.0 \t loss_valid = 30843360.0 \n",
      "Model_2_7760 \t loss_train = 37007736.0 \t loss_valid = 30880682.0 \n",
      "Model_2_7770 \t loss_train = 37462668.0 \t loss_valid = 31005902.0 \n",
      "Model_2_7780 \t loss_train = 37433792.0 \t loss_valid = 31125390.0 \n",
      "Model_2_7790 \t loss_train = 37873156.0 \t loss_valid = 31581228.0 \n",
      "Model_2_7800 \t loss_train = 37117076.0 \t loss_valid = 30772922.0 \n",
      "Model_2_7810 \t loss_train = 36763176.0 \t loss_valid = 30608162.0 \n",
      "Model_2_7820 \t loss_train = 37802092.0 \t loss_valid = 31389572.0 \n",
      "Model_2_7830 \t loss_train = 37203620.0 \t loss_valid = 30883272.0 \n",
      "Model_2_7840 \t loss_train = 37992312.0 \t loss_valid = 31578210.0 \n",
      "Model_2_7850 \t loss_train = 37204772.0 \t loss_valid = 31093744.0 \n",
      "Model_2_7860 \t loss_train = 37475012.0 \t loss_valid = 31052254.0 \n",
      "Model_2_7870 \t loss_train = 38079504.0 \t loss_valid = 31778450.0 \n",
      "Model_2_7880 \t loss_train = 37437672.0 \t loss_valid = 31046194.0 \n",
      "Model_2_7890 \t loss_train = 37172768.0 \t loss_valid = 30846884.0 \n",
      "Model_2_7900 \t loss_train = 38119732.0 \t loss_valid = 31714164.0 \n",
      "Model_2_7910 \t loss_train = 37318896.0 \t loss_valid = 30986416.0 \n",
      "Model_2_7920 \t loss_train = 37388612.0 \t loss_valid = 31176274.0 \n",
      "Model_2_7930 \t loss_train = 37986392.0 \t loss_valid = 31539718.0 \n",
      "Model_2_7940 \t loss_train = 37586684.0 \t loss_valid = 31200054.0 \n",
      "Model_2_7950 \t loss_train = 37833124.0 \t loss_valid = 31415454.0 \n",
      "Model_2_7960 \t loss_train = 37790984.0 \t loss_valid = 31436364.0 \n",
      "Model_2_7970 \t loss_train = 37293712.0 \t loss_valid = 30951036.0 \n",
      "Model_2_7980 \t loss_train = 37604680.0 \t loss_valid = 31323364.0 \n",
      "Model_2_7990 \t loss_train = 37518008.0 \t loss_valid = 31244284.0 \n",
      "Model_2_8000 \t loss_train = 38123596.0 \t loss_valid = 31871324.0 \n",
      "Model_2_8010 \t loss_train = 37257936.0 \t loss_valid = 30935096.0 \n",
      "Model_2_8020 \t loss_train = 38272184.0 \t loss_valid = 31901412.0 \n",
      "Model_2_8030 \t loss_train = 37482936.0 \t loss_valid = 31225340.0 \n",
      "Model_2_8040 \t loss_train = 37735812.0 \t loss_valid = 31492134.0 \n",
      "Model_2_8050 \t loss_train = 37927536.0 \t loss_valid = 31489776.0 \n",
      "Model_2_8060 \t loss_train = 37037408.0 \t loss_valid = 30628740.0 \n",
      "Model_2_8070 \t loss_train = 38127440.0 \t loss_valid = 31777564.0 \n",
      "Model_2_8080 \t loss_train = 38426932.0 \t loss_valid = 31999944.0 \n",
      "Model_2_8090 \t loss_train = 37658312.0 \t loss_valid = 31362250.0 \n",
      "Model_2_8100 \t loss_train = 37479996.0 \t loss_valid = 31133642.0 \n",
      "Model_2_8110 \t loss_train = 38042160.0 \t loss_valid = 31884396.0 \n",
      "Model_2_8120 \t loss_train = 38000788.0 \t loss_valid = 31638556.0 \n",
      "Model_2_8130 \t loss_train = 37825976.0 \t loss_valid = 31459068.0 \n",
      "Model_2_8140 \t loss_train = 37867432.0 \t loss_valid = 31410748.0 \n",
      "Model_2_8150 \t loss_train = 37081204.0 \t loss_valid = 30889276.0 \n",
      "Model_2_8160 \t loss_train = 37597944.0 \t loss_valid = 31159884.0 \n",
      "Model_2_8170 \t loss_train = 38038128.0 \t loss_valid = 31649704.0 \n",
      "Model_2_8180 \t loss_train = 37353280.0 \t loss_valid = 31089354.0 \n",
      "Model_2_8190 \t loss_train = 38125780.0 \t loss_valid = 31569560.0 \n",
      "Model_2_8200 \t loss_train = 37471388.0 \t loss_valid = 31174018.0 \n",
      "Model_2_8210 \t loss_train = 37392772.0 \t loss_valid = 31015652.0 \n",
      "Model_2_8220 \t loss_train = 37594588.0 \t loss_valid = 31304204.0 \n",
      "Model_2_8230 \t loss_train = 38184172.0 \t loss_valid = 31805624.0 \n",
      "Model_2_8240 \t loss_train = 37877360.0 \t loss_valid = 31413314.0 \n",
      "Model_2_8250 \t loss_train = 37036596.0 \t loss_valid = 30689268.0 \n",
      "Model_2_8260 \t loss_train = 37808880.0 \t loss_valid = 31342596.0 \n",
      "Model_2_8270 \t loss_train = 37795160.0 \t loss_valid = 31646650.0 \n",
      "Model_2_8280 \t loss_train = 37368008.0 \t loss_valid = 31157314.0 \n",
      "Model_2_8290 \t loss_train = 37842876.0 \t loss_valid = 31486742.0 \n",
      "Model_2_8300 \t loss_train = 37839416.0 \t loss_valid = 31624458.0 \n",
      "Model_2_8310 \t loss_train = 37257252.0 \t loss_valid = 31117640.0 \n",
      "Model_2_8320 \t loss_train = 37593576.0 \t loss_valid = 31270036.0 \n",
      "Model_2_8330 \t loss_train = 37864520.0 \t loss_valid = 31445778.0 \n",
      "Model_2_8340 \t loss_train = 37014792.0 \t loss_valid = 30649596.0 \n",
      "Model_2_8350 \t loss_train = 37878256.0 \t loss_valid = 31542850.0 \n",
      "Model_2_8360 \t loss_train = 37184488.0 \t loss_valid = 31107786.0 \n",
      "Model_2_8370 \t loss_train = 36912788.0 \t loss_valid = 30822284.0 \n",
      "Model_2_8380 \t loss_train = 37019192.0 \t loss_valid = 30833366.0 \n",
      "Model_2_8390 \t loss_train = 37172140.0 \t loss_valid = 31087714.0 \n",
      "Model_2_8400 \t loss_train = 37601324.0 \t loss_valid = 31398062.0 \n",
      "Model_2_8410 \t loss_train = 37131740.0 \t loss_valid = 30944622.0 \n",
      "Model_2_8420 \t loss_train = 37116700.0 \t loss_valid = 31091440.0 \n",
      "Model_2_8430 \t loss_train = 38064852.0 \t loss_valid = 31639028.0 \n",
      "Model_2_8440 \t loss_train = 36920428.0 \t loss_valid = 30759560.0 \n",
      "Model_2_8450 \t loss_train = 37300432.0 \t loss_valid = 31131218.0 \n",
      "Model_2_8460 \t loss_train = 37281700.0 \t loss_valid = 30933308.0 \n",
      "Model_2_8470 \t loss_train = 37907776.0 \t loss_valid = 31712800.0 \n",
      "Model_2_8480 \t loss_train = 38136440.0 \t loss_valid = 31793720.0 \n",
      "Model_2_8490 \t loss_train = 37074492.0 \t loss_valid = 30966020.0 \n",
      "Model_2_8500 \t loss_train = 37542232.0 \t loss_valid = 31341160.0 \n",
      "Model_2_8510 \t loss_train = 37766680.0 \t loss_valid = 31351906.0 \n",
      "Model_2_8520 \t loss_train = 37477704.0 \t loss_valid = 31240524.0 \n",
      "Model_2_8530 \t loss_train = 37913188.0 \t loss_valid = 31562676.0 \n",
      "Model_2_8540 \t loss_train = 37929820.0 \t loss_valid = 31536906.0 \n",
      "Model_2_8550 \t loss_train = 37693820.0 \t loss_valid = 31471894.0 \n",
      "Model_2_8560 \t loss_train = 37154056.0 \t loss_valid = 30926708.0 \n",
      "Model_2_8570 \t loss_train = 37517448.0 \t loss_valid = 31303968.0 \n",
      "Model_2_8580 \t loss_train = 37118904.0 \t loss_valid = 30913960.0 \n",
      "Model_2_8590 \t loss_train = 37673204.0 \t loss_valid = 31456502.0 \n",
      "Model_2_8600 \t loss_train = 37618592.0 \t loss_valid = 31450002.0 \n",
      "Model_2_8610 \t loss_train = 37533152.0 \t loss_valid = 31247098.0 \n",
      "Model_2_8620 \t loss_train = 37670784.0 \t loss_valid = 31664554.0 \n",
      "Model_2_8630 \t loss_train = 36838096.0 \t loss_valid = 30623586.0 \n",
      "Model_2_8640 \t loss_train = 38068884.0 \t loss_valid = 31712708.0 \n",
      "Model_2_8650 \t loss_train = 37167728.0 \t loss_valid = 30921766.0 \n",
      "Model_2_8660 \t loss_train = 37854976.0 \t loss_valid = 31495648.0 \n",
      "Model_2_8670 \t loss_train = 37063024.0 \t loss_valid = 30903334.0 \n",
      "Model_2_8680 \t loss_train = 37216836.0 \t loss_valid = 30927784.0 \n",
      "Model_2_8690 \t loss_train = 37541096.0 \t loss_valid = 31374354.0 \n",
      "Model_2_8700 \t loss_train = 37407788.0 \t loss_valid = 31005576.0 \n",
      "Model_2_8710 \t loss_train = 37120052.0 \t loss_valid = 30871928.0 \n",
      "Model_2_8720 \t loss_train = 38638872.0 \t loss_valid = 32294772.0 \n",
      "Model_2_8730 \t loss_train = 37309216.0 \t loss_valid = 31081244.0 \n",
      "Model_2_8740 \t loss_train = 37361312.0 \t loss_valid = 31105454.0 \n",
      "Model_2_8750 \t loss_train = 37120144.0 \t loss_valid = 30950334.0 \n",
      "Model_2_8760 \t loss_train = 37794252.0 \t loss_valid = 31416490.0 \n",
      "Model_2_8770 \t loss_train = 37214964.0 \t loss_valid = 30965304.0 \n",
      "Model_2_8780 \t loss_train = 37926376.0 \t loss_valid = 31817380.0 \n",
      "Model_2_8790 \t loss_train = 37678832.0 \t loss_valid = 31369430.0 \n",
      "Model_2_8800 \t loss_train = 38415028.0 \t loss_valid = 31944324.0 \n",
      "Model_2_8810 \t loss_train = 37698868.0 \t loss_valid = 31471034.0 \n",
      "Model_2_8820 \t loss_train = 38297128.0 \t loss_valid = 31872072.0 \n",
      "Model_2_8830 \t loss_train = 37641300.0 \t loss_valid = 31456484.0 \n",
      "Model_2_8840 \t loss_train = 37815488.0 \t loss_valid = 31517766.0 \n",
      "Model_2_8850 \t loss_train = 38165660.0 \t loss_valid = 31931524.0 \n",
      "Model_2_8860 \t loss_train = 37596284.0 \t loss_valid = 31361362.0 \n",
      "Model_2_8870 \t loss_train = 38543924.0 \t loss_valid = 31986840.0 \n",
      "Model_2_8880 \t loss_train = 37867080.0 \t loss_valid = 31596954.0 \n",
      "Model_2_8890 \t loss_train = 37947260.0 \t loss_valid = 31552456.0 \n",
      "Model_2_8900 \t loss_train = 36420908.0 \t loss_valid = 30066834.0 \n",
      "Model_2_8910 \t loss_train = 38659388.0 \t loss_valid = 32177992.0 \n",
      "Model_2_8920 \t loss_train = 37540868.0 \t loss_valid = 31187310.0 \n",
      "Model_2_8930 \t loss_train = 37905396.0 \t loss_valid = 31493222.0 \n",
      "Model_2_8940 \t loss_train = 37554888.0 \t loss_valid = 31136926.0 \n",
      "Model_2_8950 \t loss_train = 37254720.0 \t loss_valid = 30938826.0 \n",
      "Model_2_8960 \t loss_train = 37489132.0 \t loss_valid = 31126110.0 \n",
      "Model_2_8970 \t loss_train = 37984380.0 \t loss_valid = 31624742.0 \n",
      "Model_2_8980 \t loss_train = 37135260.0 \t loss_valid = 30953434.0 \n",
      "Model_2_8990 \t loss_train = 37977444.0 \t loss_valid = 31453504.0 \n",
      "Model_2_9000 \t loss_train = 37622200.0 \t loss_valid = 31338770.0 \n",
      "Model_2_9010 \t loss_train = 38531196.0 \t loss_valid = 32048096.0 \n",
      "Model_2_9020 \t loss_train = 37206240.0 \t loss_valid = 30927638.0 \n",
      "Model_2_9030 \t loss_train = 38014036.0 \t loss_valid = 31565880.0 \n",
      "Model_2_9040 \t loss_train = 38002520.0 \t loss_valid = 31393984.0 \n",
      "Model_2_9050 \t loss_train = 37596988.0 \t loss_valid = 31178104.0 \n",
      "Model_2_9060 \t loss_train = 37675144.0 \t loss_valid = 31404506.0 \n",
      "Model_2_9070 \t loss_train = 37649100.0 \t loss_valid = 31350654.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_2_9080 \t loss_train = 37416412.0 \t loss_valid = 31062398.0 \n",
      "Model_2_9090 \t loss_train = 37786720.0 \t loss_valid = 31247132.0 \n",
      "Model_2_9100 \t loss_train = 37913592.0 \t loss_valid = 31624590.0 \n",
      "Model_2_9110 \t loss_train = 37755904.0 \t loss_valid = 31373868.0 \n",
      "Model_2_9120 \t loss_train = 37696236.0 \t loss_valid = 31374462.0 \n",
      "Model_2_9130 \t loss_train = 38175308.0 \t loss_valid = 31683988.0 \n",
      "Model_2_9140 \t loss_train = 37903524.0 \t loss_valid = 31447160.0 \n",
      "Model_2_9150 \t loss_train = 38040648.0 \t loss_valid = 31477466.0 \n",
      "Model_2_9160 \t loss_train = 37394292.0 \t loss_valid = 30989830.0 \n",
      "Model_2_9170 \t loss_train = 38187004.0 \t loss_valid = 31891272.0 \n",
      "Model_2_9180 \t loss_train = 37311572.0 \t loss_valid = 30962352.0 \n",
      "Model_2_9190 \t loss_train = 37224384.0 \t loss_valid = 31009340.0 \n",
      "Model_2_9200 \t loss_train = 37645828.0 \t loss_valid = 31264288.0 \n",
      "Model_2_9210 \t loss_train = 38105372.0 \t loss_valid = 31582340.0 \n",
      "Model_2_9220 \t loss_train = 37860556.0 \t loss_valid = 31365448.0 \n",
      "Model_2_9230 \t loss_train = 37991044.0 \t loss_valid = 31600422.0 \n",
      "Model_2_9240 \t loss_train = 37607700.0 \t loss_valid = 31229054.0 \n",
      "Model_2_9250 \t loss_train = 37900864.0 \t loss_valid = 31545912.0 \n",
      "Model_2_9260 \t loss_train = 37620040.0 \t loss_valid = 31295204.0 \n",
      "Model_2_9270 \t loss_train = 37600628.0 \t loss_valid = 31132502.0 \n",
      "Model_2_9280 \t loss_train = 38263220.0 \t loss_valid = 31826918.0 \n",
      "Model_2_9290 \t loss_train = 37739616.0 \t loss_valid = 31268822.0 \n",
      "Model_2_9300 \t loss_train = 38022220.0 \t loss_valid = 31638502.0 \n",
      "Model_2_9310 \t loss_train = 38255212.0 \t loss_valid = 31740074.0 \n",
      "Model_2_9320 \t loss_train = 36669344.0 \t loss_valid = 30462104.0 \n",
      "Model_2_9330 \t loss_train = 38334296.0 \t loss_valid = 31831014.0 \n",
      "Model_2_9340 \t loss_train = 38342228.0 \t loss_valid = 31874364.0 \n",
      "Model_2_9350 \t loss_train = 37827500.0 \t loss_valid = 31196744.0 \n",
      "Model_2_9360 \t loss_train = 38394144.0 \t loss_valid = 31982380.0 \n",
      "Model_2_9370 \t loss_train = 37806508.0 \t loss_valid = 31336524.0 \n",
      "Model_2_9380 \t loss_train = 37886696.0 \t loss_valid = 31477056.0 \n",
      "Model_2_9390 \t loss_train = 37333280.0 \t loss_valid = 30995674.0 \n",
      "Model_2_9400 \t loss_train = 37867324.0 \t loss_valid = 31362500.0 \n",
      "Model_2_9410 \t loss_train = 38209464.0 \t loss_valid = 31741926.0 \n",
      "Model_2_9420 \t loss_train = 37797868.0 \t loss_valid = 31353528.0 \n",
      "Model_2_9430 \t loss_train = 38210256.0 \t loss_valid = 31743244.0 \n",
      "Model_2_9440 \t loss_train = 37817912.0 \t loss_valid = 31530800.0 \n",
      "Model_2_9450 \t loss_train = 38176736.0 \t loss_valid = 31657326.0 \n",
      "Model_2_9460 \t loss_train = 37851624.0 \t loss_valid = 31480888.0 \n",
      "Model_2_9470 \t loss_train = 38063652.0 \t loss_valid = 31801174.0 \n",
      "Model_2_9480 \t loss_train = 38037804.0 \t loss_valid = 31491672.0 \n",
      "Model_2_9490 \t loss_train = 38019736.0 \t loss_valid = 31488464.0 \n",
      "Model_2_9500 \t loss_train = 37631136.0 \t loss_valid = 31213992.0 \n",
      "Model_2_9510 \t loss_train = 38571916.0 \t loss_valid = 31962308.0 \n",
      "Model_2_9520 \t loss_train = 37456188.0 \t loss_valid = 31095202.0 \n",
      "Model_2_9530 \t loss_train = 37917812.0 \t loss_valid = 31442014.0 \n",
      "Model_2_9540 \t loss_train = 38102620.0 \t loss_valid = 31759120.0 \n",
      "Model_2_9550 \t loss_train = 38505712.0 \t loss_valid = 31993230.0 \n",
      "Model_2_9560 \t loss_train = 37905556.0 \t loss_valid = 31582498.0 \n",
      "Model_2_9570 \t loss_train = 37893672.0 \t loss_valid = 31479056.0 \n",
      "Model_2_9580 \t loss_train = 38503604.0 \t loss_valid = 32021500.0 \n",
      "Model_2_9590 \t loss_train = 37660328.0 \t loss_valid = 31092688.0 \n",
      "Model_2_9600 \t loss_train = 37805208.0 \t loss_valid = 31204484.0 \n",
      "Model_2_9610 \t loss_train = 38631080.0 \t loss_valid = 32058912.0 \n",
      "Model_2_9620 \t loss_train = 37897328.0 \t loss_valid = 31447796.0 \n",
      "Model_2_9630 \t loss_train = 37791272.0 \t loss_valid = 31294240.0 \n",
      "Model_2_9640 \t loss_train = 38540928.0 \t loss_valid = 32120124.0 \n",
      "Model_2_9650 \t loss_train = 37530896.0 \t loss_valid = 30957090.0 \n",
      "Model_2_9660 \t loss_train = 37558324.0 \t loss_valid = 31075414.0 \n",
      "Model_2_9670 \t loss_train = 37923532.0 \t loss_valid = 31414758.0 \n",
      "Model_2_9680 \t loss_train = 37853508.0 \t loss_valid = 31335446.0 \n",
      "Model_2_9690 \t loss_train = 38431668.0 \t loss_valid = 31946392.0 \n",
      "Model_2_9700 \t loss_train = 37786796.0 \t loss_valid = 31195854.0 \n",
      "Model_2_9710 \t loss_train = 38557844.0 \t loss_valid = 32122244.0 \n",
      "Model_2_9720 \t loss_train = 38065500.0 \t loss_valid = 31520168.0 \n",
      "Model_2_9730 \t loss_train = 38300876.0 \t loss_valid = 31805640.0 \n",
      "Model_2_9740 \t loss_train = 37939164.0 \t loss_valid = 31542674.0 \n",
      "Model_2_9750 \t loss_train = 38405356.0 \t loss_valid = 31969298.0 \n",
      "Model_2_9760 \t loss_train = 38050296.0 \t loss_valid = 31506706.0 \n",
      "Model_2_9770 \t loss_train = 38353184.0 \t loss_valid = 31905548.0 \n",
      "Model_2_9780 \t loss_train = 38389280.0 \t loss_valid = 31787520.0 \n",
      "Model_2_9790 \t loss_train = 38617684.0 \t loss_valid = 32247774.0 \n",
      "Model_2_9800 \t loss_train = 37959284.0 \t loss_valid = 31436036.0 \n",
      "Model_2_9810 \t loss_train = 37979528.0 \t loss_valid = 31506340.0 \n",
      "Model_2_9820 \t loss_train = 38320792.0 \t loss_valid = 31880956.0 \n",
      "Model_2_9830 \t loss_train = 38491512.0 \t loss_valid = 32014620.0 \n",
      "Model_2_9840 \t loss_train = 38091896.0 \t loss_valid = 31568380.0 \n",
      "Model_2_9850 \t loss_train = 38647008.0 \t loss_valid = 32070758.0 \n",
      "Model_2_9860 \t loss_train = 38435276.0 \t loss_valid = 31843720.0 \n",
      "Model_2_9870 \t loss_train = 38266300.0 \t loss_valid = 31683126.0 \n",
      "Model_2_9880 \t loss_train = 38435164.0 \t loss_valid = 31908614.0 \n",
      "Model_2_9890 \t loss_train = 38001140.0 \t loss_valid = 31523132.0 \n",
      "Model_2_9900 \t loss_train = 38155884.0 \t loss_valid = 31591028.0 \n",
      "Model_2_9910 \t loss_train = 38906284.0 \t loss_valid = 32334696.0 \n",
      "Model_2_9920 \t loss_train = 38112052.0 \t loss_valid = 31560182.0 \n",
      "Model_2_9930 \t loss_train = 38362812.0 \t loss_valid = 31731346.0 \n",
      "Model_2_9940 \t loss_train = 38779696.0 \t loss_valid = 32070308.0 \n",
      "Model_2_9950 \t loss_train = 38646856.0 \t loss_valid = 31996552.0 \n",
      "Model_2_9960 \t loss_train = 37923180.0 \t loss_valid = 31280826.0 \n",
      "Model_2_9970 \t loss_train = 38929680.0 \t loss_valid = 32311050.0 \n",
      "Model_2_9980 \t loss_train = 38104168.0 \t loss_valid = 31424676.0 \n",
      "Model_2_9990 \t loss_train = 38144504.0 \t loss_valid = 31520958.0 \n",
      "Model_2_10000 \t loss_train = 38493204.0 \t loss_valid = 31971454.0 \n",
      "Model_2_10010 \t loss_train = 38555636.0 \t loss_valid = 31974612.0 \n",
      "Model_2_10020 \t loss_train = 38835208.0 \t loss_valid = 32156910.0 \n",
      "Model_2_10030 \t loss_train = 38452228.0 \t loss_valid = 31770672.0 \n",
      "Model_2_10040 \t loss_train = 38342196.0 \t loss_valid = 31913968.0 \n",
      "Model_2_10050 \t loss_train = 37898544.0 \t loss_valid = 31342032.0 \n",
      "Model_2_10060 \t loss_train = 39063232.0 \t loss_valid = 32510154.0 \n",
      "Model_2_10070 \t loss_train = 38200120.0 \t loss_valid = 31629602.0 \n",
      "Model_2_10080 \t loss_train = 39084836.0 \t loss_valid = 32351080.0 \n",
      "Model_2_10090 \t loss_train = 37574816.0 \t loss_valid = 31001926.0 \n",
      "Model_2_10100 \t loss_train = 39383008.0 \t loss_valid = 32550870.0 \n",
      "Model_2_10110 \t loss_train = 38306416.0 \t loss_valid = 31754566.0 \n",
      "Model_2_10120 \t loss_train = 39282220.0 \t loss_valid = 32588984.0 \n",
      "Model_2_10130 \t loss_train = 37776988.0 \t loss_valid = 31072930.0 \n",
      "Model_2_10140 \t loss_train = 38554820.0 \t loss_valid = 31953028.0 \n",
      "Model_2_10150 \t loss_train = 39458688.0 \t loss_valid = 32833178.0 \n",
      "Model_2_10160 \t loss_train = 38207104.0 \t loss_valid = 31488148.0 \n",
      "Model_2_10170 \t loss_train = 39129568.0 \t loss_valid = 32439398.0 \n",
      "Model_2_10180 \t loss_train = 38195076.0 \t loss_valid = 31605048.0 \n",
      "Model_2_10190 \t loss_train = 38711140.0 \t loss_valid = 32137528.0 \n",
      "Model_2_10200 \t loss_train = 39070156.0 \t loss_valid = 32381532.0 \n",
      "Model_2_10210 \t loss_train = 38327360.0 \t loss_valid = 31836788.0 \n",
      "Model_2_10220 \t loss_train = 37965096.0 \t loss_valid = 31385506.0 \n",
      "Model_2_10230 \t loss_train = 37322288.0 \t loss_valid = 30799818.0 \n",
      "Model_2_10240 \t loss_train = 39056572.0 \t loss_valid = 32339596.0 \n",
      "Model_2_10250 \t loss_train = 38690504.0 \t loss_valid = 32027472.0 \n",
      "Model_2_10260 \t loss_train = 38566752.0 \t loss_valid = 31762894.0 \n",
      "Model_2_10270 \t loss_train = 38176744.0 \t loss_valid = 31608238.0 \n",
      "Model_2_10280 \t loss_train = 38816044.0 \t loss_valid = 32108782.0 \n",
      "Model_2_10290 \t loss_train = 38410336.0 \t loss_valid = 31663152.0 \n",
      "Model_2_10300 \t loss_train = 38823240.0 \t loss_valid = 32288294.0 \n",
      "Model_2_10310 \t loss_train = 38408632.0 \t loss_valid = 31750368.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_2_10320 \t loss_train = 38518540.0 \t loss_valid = 31927618.0 \n",
      "Model_2_10330 \t loss_train = 38268376.0 \t loss_valid = 31653376.0 \n",
      "Model_2_10340 \t loss_train = 37901756.0 \t loss_valid = 31300210.0 \n",
      "Model_2_10350 \t loss_train = 37645592.0 \t loss_valid = 31239270.0 \n",
      "Model_2_10360 \t loss_train = 38779352.0 \t loss_valid = 32057148.0 \n",
      "Model_2_10370 \t loss_train = 38055108.0 \t loss_valid = 31451102.0 \n",
      "Model_2_10380 \t loss_train = 38760708.0 \t loss_valid = 31998098.0 \n",
      "Model_2_10390 \t loss_train = 38140416.0 \t loss_valid = 31548774.0 \n",
      "Model_2_10400 \t loss_train = 38750964.0 \t loss_valid = 32241208.0 \n",
      "Model_2_10410 \t loss_train = 38829364.0 \t loss_valid = 32255860.0 \n",
      "Model_2_10420 \t loss_train = 38340908.0 \t loss_valid = 31928652.0 \n",
      "Model_2_10430 \t loss_train = 38715808.0 \t loss_valid = 32069146.0 \n",
      "Model_2_10440 \t loss_train = 38943364.0 \t loss_valid = 32424934.0 \n",
      "Model_2_10450 \t loss_train = 38526660.0 \t loss_valid = 31949204.0 \n",
      "Model_2_10460 \t loss_train = 38794408.0 \t loss_valid = 32170464.0 \n",
      "Model_2_10470 \t loss_train = 38407968.0 \t loss_valid = 31758408.0 \n",
      "Model_2_10480 \t loss_train = 38520276.0 \t loss_valid = 31975550.0 \n",
      "Model_2_10490 \t loss_train = 38748656.0 \t loss_valid = 31979830.0 \n",
      "Model_2_10500 \t loss_train = 38558012.0 \t loss_valid = 31965630.0 \n",
      "Model_2_10510 \t loss_train = 38198924.0 \t loss_valid = 31621490.0 \n",
      "Model_2_10520 \t loss_train = 38472124.0 \t loss_valid = 32002406.0 \n",
      "Model_2_10530 \t loss_train = 38024816.0 \t loss_valid = 31440214.0 \n",
      "Model_2_10540 \t loss_train = 39036732.0 \t loss_valid = 32319472.0 \n",
      "Model_2_10550 \t loss_train = 38357660.0 \t loss_valid = 31688164.0 \n",
      "Model_2_10560 \t loss_train = 38019796.0 \t loss_valid = 31416730.0 \n",
      "Model_2_10570 \t loss_train = 38519420.0 \t loss_valid = 31828936.0 \n",
      "Model_2_10580 \t loss_train = 38956280.0 \t loss_valid = 32190166.0 \n",
      "Model_2_10590 \t loss_train = 38340384.0 \t loss_valid = 31795362.0 \n",
      "Model_2_10600 \t loss_train = 38211372.0 \t loss_valid = 31647860.0 \n",
      "Model_2_10610 \t loss_train = 38928744.0 \t loss_valid = 32156050.0 \n",
      "Model_2_10620 \t loss_train = 39116496.0 \t loss_valid = 32578316.0 \n",
      "Model_2_10630 \t loss_train = 38583164.0 \t loss_valid = 31918444.0 \n",
      "Model_2_10640 \t loss_train = 38937136.0 \t loss_valid = 32292232.0 \n",
      "Model_2_10650 \t loss_train = 38732516.0 \t loss_valid = 32037762.0 \n",
      "Model_2_10660 \t loss_train = 38377424.0 \t loss_valid = 31866346.0 \n",
      "Model_2_10670 \t loss_train = 38694048.0 \t loss_valid = 32021688.0 \n",
      "Model_2_10680 \t loss_train = 39211784.0 \t loss_valid = 32600866.0 \n",
      "Model_2_10690 \t loss_train = 38443612.0 \t loss_valid = 31712000.0 \n",
      "Model_2_10700 \t loss_train = 39178832.0 \t loss_valid = 32546042.0 \n",
      "Model_2_10710 \t loss_train = 38660220.0 \t loss_valid = 31986486.0 \n",
      "Model_2_10720 \t loss_train = 38480424.0 \t loss_valid = 31840740.0 \n",
      "Model_2_10730 \t loss_train = 39102128.0 \t loss_valid = 32483192.0 \n",
      "Model_2_10740 \t loss_train = 39137964.0 \t loss_valid = 32617212.0 \n",
      "Model_2_10750 \t loss_train = 38464724.0 \t loss_valid = 31714130.0 \n",
      "Model_2_10760 \t loss_train = 38298768.0 \t loss_valid = 31488092.0 \n",
      "Model_2_10770 \t loss_train = 39074568.0 \t loss_valid = 32408016.0 \n",
      "Model_2_10780 \t loss_train = 37785152.0 \t loss_valid = 31303582.0 \n",
      "Model_2_10790 \t loss_train = 38590744.0 \t loss_valid = 31954716.0 \n",
      "Model_2_10800 \t loss_train = 38287760.0 \t loss_valid = 31786710.0 \n",
      "Model_2_10810 \t loss_train = 37906612.0 \t loss_valid = 31326524.0 \n",
      "Model_2_10820 \t loss_train = 39259424.0 \t loss_valid = 32678666.0 \n",
      "Model_2_10830 \t loss_train = 38054216.0 \t loss_valid = 31601734.0 \n",
      "Model_2_10840 \t loss_train = 38321024.0 \t loss_valid = 31815872.0 \n",
      "Model_2_10850 \t loss_train = 38164768.0 \t loss_valid = 31708940.0 \n",
      "Model_2_10860 \t loss_train = 38382260.0 \t loss_valid = 31928162.0 \n",
      "Model_2_10870 \t loss_train = 38036852.0 \t loss_valid = 31529400.0 \n",
      "Model_2_10880 \t loss_train = 38575300.0 \t loss_valid = 32030692.0 \n",
      "Model_2_10890 \t loss_train = 38562740.0 \t loss_valid = 31996012.0 \n",
      "Model_2_10900 \t loss_train = 38553436.0 \t loss_valid = 31956872.0 \n",
      "Model_2_10910 \t loss_train = 38320476.0 \t loss_valid = 31832980.0 \n",
      "Model_2_10920 \t loss_train = 38087384.0 \t loss_valid = 31575656.0 \n",
      "Model_2_10930 \t loss_train = 38491516.0 \t loss_valid = 31918456.0 \n",
      "Model_2_10940 \t loss_train = 38795228.0 \t loss_valid = 32010730.0 \n",
      "Model_2_10950 \t loss_train = 38509504.0 \t loss_valid = 31857582.0 \n",
      "Model_2_10960 \t loss_train = 38306496.0 \t loss_valid = 31638562.0 \n",
      "Model_2_10970 \t loss_train = 38014140.0 \t loss_valid = 31465792.0 \n",
      "Model_2_10980 \t loss_train = 37967676.0 \t loss_valid = 31462116.0 \n",
      "Model_2_10990 \t loss_train = 38349312.0 \t loss_valid = 31909432.0 \n",
      "Model_2_11000 \t loss_train = 38030840.0 \t loss_valid = 31503808.0 \n",
      "Model_2_11010 \t loss_train = 37501380.0 \t loss_valid = 31037746.0 \n",
      "Model_2_11020 \t loss_train = 38848872.0 \t loss_valid = 32259720.0 \n",
      "Model_2_11030 \t loss_train = 38643232.0 \t loss_valid = 32126464.0 \n",
      "Model_2_11040 \t loss_train = 38340576.0 \t loss_valid = 31712064.0 \n",
      "Model_2_11050 \t loss_train = 38514768.0 \t loss_valid = 32091926.0 \n",
      "Model_2_11060 \t loss_train = 37719396.0 \t loss_valid = 31190066.0 \n",
      "Model_2_11070 \t loss_train = 38019436.0 \t loss_valid = 31465756.0 \n",
      "Model_2_11080 \t loss_train = 38367576.0 \t loss_valid = 31736602.0 \n",
      "Model_2_11090 \t loss_train = 38156268.0 \t loss_valid = 31519282.0 \n",
      "Model_2_11100 \t loss_train = 38704572.0 \t loss_valid = 32126348.0 \n",
      "Model_2_11110 \t loss_train = 38315384.0 \t loss_valid = 31686464.0 \n",
      "Model_2_11120 \t loss_train = 39088804.0 \t loss_valid = 32378984.0 \n",
      "Model_2_11130 \t loss_train = 38331900.0 \t loss_valid = 31625424.0 \n",
      "Model_2_11140 \t loss_train = 38050544.0 \t loss_valid = 31424006.0 \n",
      "Model_2_11150 \t loss_train = 39101488.0 \t loss_valid = 32476300.0 \n",
      "Model_2_11160 \t loss_train = 37626576.0 \t loss_valid = 31189222.0 \n",
      "Model_2_11170 \t loss_train = 38507840.0 \t loss_valid = 32007428.0 \n",
      "Model_2_11180 \t loss_train = 38492216.0 \t loss_valid = 31928722.0 \n",
      "Model_2_11190 \t loss_train = 37839508.0 \t loss_valid = 31348462.0 \n",
      "Model_2_11200 \t loss_train = 38250120.0 \t loss_valid = 31819536.0 \n",
      "Model_2_11210 \t loss_train = 38465120.0 \t loss_valid = 31858736.0 \n",
      "Model_2_11220 \t loss_train = 37993384.0 \t loss_valid = 31600842.0 \n",
      "Model_2_11230 \t loss_train = 38275376.0 \t loss_valid = 31633238.0 \n",
      "Model_2_11240 \t loss_train = 37912492.0 \t loss_valid = 31337718.0 \n",
      "Model_2_11250 \t loss_train = 38252608.0 \t loss_valid = 31765716.0 \n",
      "Model_2_11260 \t loss_train = 38747320.0 \t loss_valid = 32087232.0 \n",
      "Model_2_11270 \t loss_train = 37990516.0 \t loss_valid = 31378932.0 \n",
      "Model_2_11280 \t loss_train = 38941260.0 \t loss_valid = 32225716.0 \n",
      "Model_2_11290 \t loss_train = 38118780.0 \t loss_valid = 31524314.0 \n",
      "Model_2_11300 \t loss_train = 38603504.0 \t loss_valid = 32032742.0 \n",
      "Model_2_11310 \t loss_train = 38717804.0 \t loss_valid = 32084634.0 \n",
      "Model_2_11320 \t loss_train = 38535124.0 \t loss_valid = 32084392.0 \n",
      "Model_2_11330 \t loss_train = 38698840.0 \t loss_valid = 32020890.0 \n",
      "Model_2_11340 \t loss_train = 38824532.0 \t loss_valid = 32255946.0 \n",
      "Model_2_11350 \t loss_train = 38309740.0 \t loss_valid = 31684608.0 \n",
      "Model_2_11360 \t loss_train = 38693412.0 \t loss_valid = 31975222.0 \n",
      "Model_2_11370 \t loss_train = 38648236.0 \t loss_valid = 32073570.0 \n",
      "Model_2_11380 \t loss_train = 38306604.0 \t loss_valid = 31723710.0 \n",
      "Early stopping!\n",
      "Model_3_0 \t loss_train = 118716840.0 \t loss_valid = 103434944.0 \n",
      "Model_3_10 \t loss_train = 115943200.0 \t loss_valid = 99800256.0 \n",
      "Model_3_20 \t loss_train = 111184096.0 \t loss_valid = 93655600.0 \n",
      "Model_3_30 \t loss_train = 101174008.0 \t loss_valid = 81367416.0 \n",
      "Model_3_40 \t loss_train = 82612792.0 \t loss_valid = 62153368.0 \n",
      "Model_3_50 \t loss_train = 70616768.0 \t loss_valid = 66928476.0 \n",
      "Model_3_60 \t loss_train = 69870464.0 \t loss_valid = 62414524.0 \n",
      "Model_3_70 \t loss_train = 70048904.0 \t loss_valid = 58146476.0 \n",
      "Model_3_80 \t loss_train = 68845264.0 \t loss_valid = 58014124.0 \n",
      "Model_3_90 \t loss_train = 67549392.0 \t loss_valid = 59208400.0 \n",
      "Model_3_100 \t loss_train = 67199288.0 \t loss_valid = 56617864.0 \n",
      "Model_3_110 \t loss_train = 65914644.0 \t loss_valid = 56732380.0 \n",
      "Model_3_120 \t loss_train = 64935860.0 \t loss_valid = 55709448.0 \n",
      "Model_3_130 \t loss_train = 64551300.0 \t loss_valid = 52970308.0 \n",
      "Model_3_140 \t loss_train = 62847228.0 \t loss_valid = 52721684.0 \n",
      "Model_3_150 \t loss_train = 61540368.0 \t loss_valid = 51256688.0 \n",
      "Model_3_160 \t loss_train = 60249792.0 \t loss_valid = 49436688.0 \n",
      "Model_3_170 \t loss_train = 58413564.0 \t loss_valid = 48965740.0 \n",
      "Model_3_180 \t loss_train = 57048168.0 \t loss_valid = 46991908.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_3_190 \t loss_train = 56193360.0 \t loss_valid = 45483476.0 \n",
      "Model_3_200 \t loss_train = 55650032.0 \t loss_valid = 44711316.0 \n",
      "Model_3_210 \t loss_train = 54478392.0 \t loss_valid = 46252852.0 \n",
      "Model_3_220 \t loss_train = 54076080.0 \t loss_valid = 44625352.0 \n",
      "Model_3_230 \t loss_train = 53824348.0 \t loss_valid = 43746904.0 \n",
      "Model_3_240 \t loss_train = 53136092.0 \t loss_valid = 43857784.0 \n",
      "Model_3_250 \t loss_train = 52291964.0 \t loss_valid = 44618856.0 \n",
      "Model_3_260 \t loss_train = 52335504.0 \t loss_valid = 42439196.0 \n",
      "Model_3_270 \t loss_train = 50899504.0 \t loss_valid = 42680580.0 \n",
      "Model_3_280 \t loss_train = 50021324.0 \t loss_valid = 42268596.0 \n",
      "Model_3_290 \t loss_train = 49241252.0 \t loss_valid = 41336468.0 \n",
      "Model_3_300 \t loss_train = 48786000.0 \t loss_valid = 40344992.0 \n",
      "Model_3_310 \t loss_train = 46766008.0 \t loss_valid = 40030668.0 \n",
      "Model_3_320 \t loss_train = 45197892.0 \t loss_valid = 39704284.0 \n",
      "Model_3_330 \t loss_train = 43509020.0 \t loss_valid = 38073896.0 \n",
      "Model_3_340 \t loss_train = 41519276.0 \t loss_valid = 37446416.0 \n",
      "Model_3_350 \t loss_train = 39307908.0 \t loss_valid = 35938704.0 \n",
      "Model_3_360 \t loss_train = 37456680.0 \t loss_valid = 32754292.0 \n",
      "Model_3_370 \t loss_train = 34640092.0 \t loss_valid = 30960886.0 \n",
      "Model_3_380 \t loss_train = 32052268.0 \t loss_valid = 30597082.0 \n",
      "Model_3_390 \t loss_train = 30426104.0 \t loss_valid = 28478230.0 \n",
      "Model_3_400 \t loss_train = 29470242.0 \t loss_valid = 27632622.0 \n",
      "Model_3_410 \t loss_train = 29066574.0 \t loss_valid = 26908562.0 \n",
      "Model_3_420 \t loss_train = 28740538.0 \t loss_valid = 26775812.0 \n",
      "Model_3_430 \t loss_train = 28616548.0 \t loss_valid = 26923580.0 \n",
      "Model_3_440 \t loss_train = 28914624.0 \t loss_valid = 26324154.0 \n",
      "Model_3_450 \t loss_train = 28884370.0 \t loss_valid = 26255304.0 \n",
      "Model_3_460 \t loss_train = 28539660.0 \t loss_valid = 27542796.0 \n",
      "Model_3_470 \t loss_train = 29613586.0 \t loss_valid = 26289314.0 \n",
      "Model_3_480 \t loss_train = 28472592.0 \t loss_valid = 26510204.0 \n",
      "Model_3_490 \t loss_train = 28519534.0 \t loss_valid = 26150236.0 \n",
      "Model_3_500 \t loss_train = 28492450.0 \t loss_valid = 26154834.0 \n",
      "Model_3_510 \t loss_train = 28376004.0 \t loss_valid = 26104068.0 \n",
      "Model_3_520 \t loss_train = 28857592.0 \t loss_valid = 25931152.0 \n",
      "Model_3_530 \t loss_train = 28508570.0 \t loss_valid = 26015670.0 \n",
      "Model_3_540 \t loss_train = 28383438.0 \t loss_valid = 25896062.0 \n",
      "Model_3_550 \t loss_train = 28417570.0 \t loss_valid = 25882474.0 \n",
      "Model_3_560 \t loss_train = 28346914.0 \t loss_valid = 26142434.0 \n",
      "Model_3_570 \t loss_train = 29243360.0 \t loss_valid = 25928708.0 \n",
      "Model_3_580 \t loss_train = 28472064.0 \t loss_valid = 26541088.0 \n",
      "Model_3_590 \t loss_train = 28769494.0 \t loss_valid = 25694460.0 \n",
      "Model_3_600 \t loss_train = 28368628.0 \t loss_valid = 25795578.0 \n",
      "Model_3_610 \t loss_train = 28398074.0 \t loss_valid = 25743464.0 \n",
      "Model_3_620 \t loss_train = 28387074.0 \t loss_valid = 25714888.0 \n",
      "Model_3_630 \t loss_train = 28596188.0 \t loss_valid = 25640668.0 \n",
      "Model_3_640 \t loss_train = 28244740.0 \t loss_valid = 26436144.0 \n",
      "Model_3_650 \t loss_train = 29328086.0 \t loss_valid = 25802852.0 \n",
      "Model_3_660 \t loss_train = 28420494.0 \t loss_valid = 25680516.0 \n",
      "Model_3_670 \t loss_train = 28241328.0 \t loss_valid = 26251238.0 \n",
      "Model_3_680 \t loss_train = 28802520.0 \t loss_valid = 25588664.0 \n",
      "Model_3_690 \t loss_train = 28231002.0 \t loss_valid = 26126416.0 \n",
      "Model_3_700 \t loss_train = 28369954.0 \t loss_valid = 25576684.0 \n",
      "Model_3_710 \t loss_train = 28241324.0 \t loss_valid = 25897612.0 \n",
      "Model_3_720 \t loss_train = 28693338.0 \t loss_valid = 25539696.0 \n",
      "Model_3_730 \t loss_train = 28377344.0 \t loss_valid = 25588874.0 \n",
      "Model_3_740 \t loss_train = 28768728.0 \t loss_valid = 25526488.0 \n",
      "Model_3_750 \t loss_train = 28275630.0 \t loss_valid = 25958002.0 \n",
      "Model_3_760 \t loss_train = 28787940.0 \t loss_valid = 25526652.0 \n",
      "Model_3_770 \t loss_train = 28192944.0 \t loss_valid = 26098342.0 \n",
      "Model_3_780 \t loss_train = 28321794.0 \t loss_valid = 25690294.0 \n",
      "Model_3_790 \t loss_train = 28649038.0 \t loss_valid = 25543064.0 \n",
      "Model_3_800 \t loss_train = 28294360.0 \t loss_valid = 25685836.0 \n",
      "Model_3_810 \t loss_train = 28496520.0 \t loss_valid = 25554366.0 \n",
      "Model_3_820 \t loss_train = 28235036.0 \t loss_valid = 25978590.0 \n",
      "Model_3_830 \t loss_train = 28983176.0 \t loss_valid = 25590532.0 \n",
      "Model_3_840 \t loss_train = 28316722.0 \t loss_valid = 25790374.0 \n",
      "Model_3_850 \t loss_train = 28369680.0 \t loss_valid = 25646740.0 \n",
      "Model_3_860 \t loss_train = 28840276.0 \t loss_valid = 25509860.0 \n",
      "Model_3_870 \t loss_train = 28169854.0 \t loss_valid = 25884700.0 \n",
      "Model_3_880 \t loss_train = 28303818.0 \t loss_valid = 25572624.0 \n",
      "Model_3_890 \t loss_train = 28431704.0 \t loss_valid = 25557998.0 \n",
      "Model_3_900 \t loss_train = 28661254.0 \t loss_valid = 25489768.0 \n",
      "Model_3_910 \t loss_train = 28250058.0 \t loss_valid = 25730766.0 \n",
      "Model_3_920 \t loss_train = 28769264.0 \t loss_valid = 25456488.0 \n",
      "Model_3_930 \t loss_train = 28244876.0 \t loss_valid = 25760496.0 \n",
      "Model_3_940 \t loss_train = 28241820.0 \t loss_valid = 25705124.0 \n",
      "Model_3_950 \t loss_train = 28265604.0 \t loss_valid = 25660002.0 \n",
      "Model_3_960 \t loss_train = 29505570.0 \t loss_valid = 25834054.0 \n",
      "Model_3_970 \t loss_train = 28201194.0 \t loss_valid = 26178982.0 \n",
      "Model_3_980 \t loss_train = 28306170.0 \t loss_valid = 25744294.0 \n",
      "Model_3_990 \t loss_train = 28633714.0 \t loss_valid = 25489736.0 \n",
      "Model_3_1000 \t loss_train = 28413596.0 \t loss_valid = 25592342.0 \n",
      "Model_3_1010 \t loss_train = 28508376.0 \t loss_valid = 25448768.0 \n",
      "Model_3_1020 \t loss_train = 28600564.0 \t loss_valid = 25426584.0 \n",
      "Model_3_1030 \t loss_train = 29003934.0 \t loss_valid = 25571416.0 \n",
      "Model_3_1040 \t loss_train = 28266984.0 \t loss_valid = 25764822.0 \n",
      "Model_3_1050 \t loss_train = 28945454.0 \t loss_valid = 25507916.0 \n",
      "Model_3_1060 \t loss_train = 28540214.0 \t loss_valid = 25430320.0 \n",
      "Model_3_1070 \t loss_train = 28564746.0 \t loss_valid = 25432896.0 \n",
      "Model_3_1080 \t loss_train = 28702560.0 \t loss_valid = 25457910.0 \n",
      "Model_3_1090 \t loss_train = 28770956.0 \t loss_valid = 25408784.0 \n",
      "Model_3_1100 \t loss_train = 28280136.0 \t loss_valid = 25611608.0 \n",
      "Model_3_1110 \t loss_train = 28966212.0 \t loss_valid = 25513790.0 \n",
      "Model_3_1120 \t loss_train = 28666092.0 \t loss_valid = 25448022.0 \n",
      "Model_3_1130 \t loss_train = 28292724.0 \t loss_valid = 25616816.0 \n",
      "Model_3_1140 \t loss_train = 29262672.0 \t loss_valid = 25624972.0 \n",
      "Model_3_1150 \t loss_train = 28709772.0 \t loss_valid = 25425864.0 \n",
      "Model_3_1160 \t loss_train = 28624032.0 \t loss_valid = 25407898.0 \n",
      "Model_3_1170 \t loss_train = 28657856.0 \t loss_valid = 25459206.0 \n",
      "Model_3_1180 \t loss_train = 29296146.0 \t loss_valid = 25624710.0 \n",
      "Model_3_1190 \t loss_train = 28296638.0 \t loss_valid = 25685688.0 \n",
      "Model_3_1200 \t loss_train = 28851386.0 \t loss_valid = 25429584.0 \n",
      "Model_3_1210 \t loss_train = 28823554.0 \t loss_valid = 25460966.0 \n",
      "Model_3_1220 \t loss_train = 29580680.0 \t loss_valid = 25705352.0 \n",
      "Model_3_1230 \t loss_train = 28966522.0 \t loss_valid = 25482044.0 \n",
      "Model_3_1240 \t loss_train = 28658798.0 \t loss_valid = 25405120.0 \n",
      "Model_3_1250 \t loss_train = 29290808.0 \t loss_valid = 25574276.0 \n",
      "Model_3_1260 \t loss_train = 28728124.0 \t loss_valid = 25403316.0 \n",
      "Model_3_1270 \t loss_train = 29138538.0 \t loss_valid = 25531510.0 \n",
      "Model_3_1280 \t loss_train = 29752720.0 \t loss_valid = 25784838.0 \n",
      "Model_3_1290 \t loss_train = 28637370.0 \t loss_valid = 25447800.0 \n",
      "Model_3_1300 \t loss_train = 29485968.0 \t loss_valid = 25620884.0 \n",
      "Model_3_1310 \t loss_train = 28688692.0 \t loss_valid = 25389018.0 \n",
      "Model_3_1320 \t loss_train = 29134722.0 \t loss_valid = 25494758.0 \n",
      "Model_3_1330 \t loss_train = 29627134.0 \t loss_valid = 25714006.0 \n",
      "Model_3_1340 \t loss_train = 28815604.0 \t loss_valid = 25454450.0 \n",
      "Model_3_1350 \t loss_train = 29322934.0 \t loss_valid = 25590426.0 \n",
      "Model_3_1360 \t loss_train = 29218666.0 \t loss_valid = 25517442.0 \n",
      "Model_3_1370 \t loss_train = 29309874.0 \t loss_valid = 25577174.0 \n",
      "Model_3_1380 \t loss_train = 28903380.0 \t loss_valid = 25411206.0 \n",
      "Model_3_1390 \t loss_train = 30400304.0 \t loss_valid = 26305074.0 \n",
      "Model_3_1400 \t loss_train = 28761428.0 \t loss_valid = 25633298.0 \n",
      "Model_3_1410 \t loss_train = 29929934.0 \t loss_valid = 25980306.0 \n",
      "Model_3_1420 \t loss_train = 29066318.0 \t loss_valid = 25448166.0 \n",
      "Model_3_1430 \t loss_train = 28993398.0 \t loss_valid = 25458266.0 \n",
      "Model_3_1440 \t loss_train = 30716614.0 \t loss_valid = 26461800.0 \n",
      "Model_3_1450 \t loss_train = 29237756.0 \t loss_valid = 25487172.0 \n",
      "Model_3_1460 \t loss_train = 29925766.0 \t loss_valid = 25922946.0 \n",
      "Model_3_1470 \t loss_train = 29375934.0 \t loss_valid = 25535868.0 \n",
      "Model_3_1480 \t loss_train = 29920746.0 \t loss_valid = 25857366.0 \n",
      "Model_3_1490 \t loss_train = 29281828.0 \t loss_valid = 25519370.0 \n",
      "Model_3_1500 \t loss_train = 29992452.0 \t loss_valid = 25904726.0 \n",
      "Model_3_1510 \t loss_train = 29895502.0 \t loss_valid = 25827098.0 \n",
      "Model_3_1520 \t loss_train = 29362800.0 \t loss_valid = 25537954.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_3_1530 \t loss_train = 29861652.0 \t loss_valid = 25802694.0 \n",
      "Model_3_1540 \t loss_train = 30421150.0 \t loss_valid = 26144924.0 \n",
      "Model_3_1550 \t loss_train = 29720570.0 \t loss_valid = 25634962.0 \n",
      "Model_3_1560 \t loss_train = 29778892.0 \t loss_valid = 25730672.0 \n",
      "Model_3_1570 \t loss_train = 29924300.0 \t loss_valid = 25779362.0 \n",
      "Model_3_1580 \t loss_train = 30075104.0 \t loss_valid = 25883976.0 \n",
      "Model_3_1590 \t loss_train = 30711512.0 \t loss_valid = 26274100.0 \n",
      "Model_3_1600 \t loss_train = 29632230.0 \t loss_valid = 25630886.0 \n",
      "Model_3_1610 \t loss_train = 30021366.0 \t loss_valid = 25825104.0 \n",
      "Model_3_1620 \t loss_train = 30515364.0 \t loss_valid = 26159914.0 \n",
      "Model_3_1630 \t loss_train = 30481926.0 \t loss_valid = 26021432.0 \n",
      "Model_3_1640 \t loss_train = 29873522.0 \t loss_valid = 25833048.0 \n",
      "Model_3_1650 \t loss_train = 30998538.0 \t loss_valid = 26334528.0 \n",
      "Model_3_1660 \t loss_train = 30185440.0 \t loss_valid = 25947956.0 \n",
      "Model_3_1670 \t loss_train = 31375820.0 \t loss_valid = 26812172.0 \n",
      "Model_3_1680 \t loss_train = 30287718.0 \t loss_valid = 25909862.0 \n",
      "Model_3_1690 \t loss_train = 30673364.0 \t loss_valid = 26223702.0 \n",
      "Model_3_1700 \t loss_train = 29988600.0 \t loss_valid = 25762284.0 \n",
      "Model_3_1710 \t loss_train = 31106408.0 \t loss_valid = 26467226.0 \n",
      "Model_3_1720 \t loss_train = 30710300.0 \t loss_valid = 26331962.0 \n",
      "Model_3_1730 \t loss_train = 31193478.0 \t loss_valid = 26545904.0 \n",
      "Model_3_1740 \t loss_train = 30170088.0 \t loss_valid = 25871072.0 \n",
      "Model_3_1750 \t loss_train = 31519982.0 \t loss_valid = 26810342.0 \n",
      "Model_3_1760 \t loss_train = 30900768.0 \t loss_valid = 26278394.0 \n",
      "Model_3_1770 \t loss_train = 30760952.0 \t loss_valid = 26233970.0 \n",
      "Model_3_1780 \t loss_train = 30839732.0 \t loss_valid = 26304878.0 \n",
      "Model_3_1790 \t loss_train = 31168732.0 \t loss_valid = 26555566.0 \n",
      "Model_3_1800 \t loss_train = 30990798.0 \t loss_valid = 26307464.0 \n",
      "Model_3_1810 \t loss_train = 30892850.0 \t loss_valid = 26355640.0 \n",
      "Model_3_1820 \t loss_train = 31361404.0 \t loss_valid = 26621592.0 \n",
      "Model_3_1830 \t loss_train = 30453180.0 \t loss_valid = 25996064.0 \n",
      "Model_3_1840 \t loss_train = 32187432.0 \t loss_valid = 27382720.0 \n",
      "Model_3_1850 \t loss_train = 30789654.0 \t loss_valid = 26200966.0 \n",
      "Model_3_1860 \t loss_train = 30976210.0 \t loss_valid = 26343454.0 \n",
      "Model_3_1870 \t loss_train = 32109752.0 \t loss_valid = 27199808.0 \n",
      "Model_3_1880 \t loss_train = 31070530.0 \t loss_valid = 26407924.0 \n",
      "Model_3_1890 \t loss_train = 31683376.0 \t loss_valid = 26800024.0 \n",
      "Model_3_1900 \t loss_train = 31324424.0 \t loss_valid = 26630698.0 \n",
      "Model_3_1910 \t loss_train = 31196142.0 \t loss_valid = 26547212.0 \n",
      "Model_3_1920 \t loss_train = 32575620.0 \t loss_valid = 27652988.0 \n",
      "Model_3_1930 \t loss_train = 31329452.0 \t loss_valid = 26559582.0 \n",
      "Model_3_1940 \t loss_train = 30963876.0 \t loss_valid = 26275028.0 \n",
      "Model_3_1950 \t loss_train = 32109792.0 \t loss_valid = 27214364.0 \n",
      "Model_3_1960 \t loss_train = 32068014.0 \t loss_valid = 27122764.0 \n",
      "Model_3_1970 \t loss_train = 30819228.0 \t loss_valid = 26203762.0 \n",
      "Model_3_1980 \t loss_train = 32501148.0 \t loss_valid = 27509220.0 \n",
      "Model_3_1990 \t loss_train = 31254132.0 \t loss_valid = 26449162.0 \n",
      "Model_3_2000 \t loss_train = 32264008.0 \t loss_valid = 27125368.0 \n",
      "Model_3_2010 \t loss_train = 31296020.0 \t loss_valid = 26558746.0 \n",
      "Model_3_2020 \t loss_train = 32122932.0 \t loss_valid = 27165210.0 \n",
      "Model_3_2030 \t loss_train = 31231676.0 \t loss_valid = 26487302.0 \n",
      "Model_3_2040 \t loss_train = 31947712.0 \t loss_valid = 27077948.0 \n",
      "Model_3_2050 \t loss_train = 31675150.0 \t loss_valid = 26739090.0 \n",
      "Model_3_2060 \t loss_train = 31919630.0 \t loss_valid = 26960792.0 \n",
      "Model_3_2070 \t loss_train = 31236890.0 \t loss_valid = 26420046.0 \n",
      "Model_3_2080 \t loss_train = 33167376.0 \t loss_valid = 28199136.0 \n",
      "Model_3_2090 \t loss_train = 32026788.0 \t loss_valid = 26961598.0 \n",
      "Model_3_2100 \t loss_train = 32134894.0 \t loss_valid = 27138420.0 \n",
      "Model_3_2110 \t loss_train = 32154092.0 \t loss_valid = 27219270.0 \n",
      "Model_3_2120 \t loss_train = 31926470.0 \t loss_valid = 26974562.0 \n",
      "Model_3_2130 \t loss_train = 31260582.0 \t loss_valid = 26491600.0 \n",
      "Model_3_2140 \t loss_train = 31621768.0 \t loss_valid = 26828538.0 \n",
      "Model_3_2150 \t loss_train = 32238732.0 \t loss_valid = 27160626.0 \n",
      "Model_3_2160 \t loss_train = 32063364.0 \t loss_valid = 27010948.0 \n",
      "Model_3_2170 \t loss_train = 31760928.0 \t loss_valid = 26932318.0 \n",
      "Model_3_2180 \t loss_train = 32844340.0 \t loss_valid = 27820664.0 \n",
      "Model_3_2190 \t loss_train = 31704476.0 \t loss_valid = 26848474.0 \n",
      "Model_3_2200 \t loss_train = 31998660.0 \t loss_valid = 26968782.0 \n",
      "Model_3_2210 \t loss_train = 32717408.0 \t loss_valid = 27734484.0 \n",
      "Model_3_2220 \t loss_train = 31471576.0 \t loss_valid = 26636708.0 \n",
      "Model_3_2230 \t loss_train = 31541550.0 \t loss_valid = 26725938.0 \n",
      "Model_3_2240 \t loss_train = 32846142.0 \t loss_valid = 27887110.0 \n",
      "Model_3_2250 \t loss_train = 31880214.0 \t loss_valid = 26812976.0 \n",
      "Model_3_2260 \t loss_train = 32267738.0 \t loss_valid = 27369106.0 \n",
      "Model_3_2270 \t loss_train = 31817868.0 \t loss_valid = 26820270.0 \n",
      "Model_3_2280 \t loss_train = 32395168.0 \t loss_valid = 27403794.0 \n",
      "Model_3_2290 \t loss_train = 32125388.0 \t loss_valid = 27054046.0 \n",
      "Model_3_2300 \t loss_train = 31785634.0 \t loss_valid = 26927920.0 \n",
      "Model_3_2310 \t loss_train = 32584394.0 \t loss_valid = 27474754.0 \n",
      "Model_3_2320 \t loss_train = 31377076.0 \t loss_valid = 26537206.0 \n",
      "Model_3_2330 \t loss_train = 31578460.0 \t loss_valid = 26767610.0 \n",
      "Model_3_2340 \t loss_train = 32451484.0 \t loss_valid = 27345746.0 \n",
      "Model_3_2350 \t loss_train = 32249756.0 \t loss_valid = 27289012.0 \n",
      "Model_3_2360 \t loss_train = 32273786.0 \t loss_valid = 27127874.0 \n",
      "Model_3_2370 \t loss_train = 32246244.0 \t loss_valid = 27356992.0 \n",
      "Model_3_2380 \t loss_train = 32303236.0 \t loss_valid = 27249588.0 \n",
      "Model_3_2390 \t loss_train = 31573568.0 \t loss_valid = 26698664.0 \n",
      "Model_3_2400 \t loss_train = 32796620.0 \t loss_valid = 27724964.0 \n",
      "Model_3_2410 \t loss_train = 32352698.0 \t loss_valid = 27319634.0 \n",
      "Model_3_2420 \t loss_train = 32514450.0 \t loss_valid = 27396522.0 \n",
      "Model_3_2430 \t loss_train = 31664040.0 \t loss_valid = 26838250.0 \n",
      "Model_3_2440 \t loss_train = 32263652.0 \t loss_valid = 27189908.0 \n",
      "Model_3_2450 \t loss_train = 32520346.0 \t loss_valid = 27479126.0 \n",
      "Model_3_2460 \t loss_train = 31882584.0 \t loss_valid = 26825248.0 \n",
      "Model_3_2470 \t loss_train = 33101344.0 \t loss_valid = 28156096.0 \n",
      "Model_3_2480 \t loss_train = 31947406.0 \t loss_valid = 26918596.0 \n",
      "Model_3_2490 \t loss_train = 32693468.0 \t loss_valid = 27531188.0 \n",
      "Model_3_2500 \t loss_train = 31414044.0 \t loss_valid = 26606634.0 \n",
      "Model_3_2510 \t loss_train = 32561630.0 \t loss_valid = 27619106.0 \n",
      "Model_3_2520 \t loss_train = 32312812.0 \t loss_valid = 27214668.0 \n",
      "Model_3_2530 \t loss_train = 32745316.0 \t loss_valid = 27703022.0 \n",
      "Model_3_2540 \t loss_train = 31868354.0 \t loss_valid = 26888202.0 \n",
      "Model_3_2550 \t loss_train = 32419620.0 \t loss_valid = 27383510.0 \n",
      "Model_3_2560 \t loss_train = 31921340.0 \t loss_valid = 26857940.0 \n",
      "Model_3_2570 \t loss_train = 31991974.0 \t loss_valid = 27049308.0 \n",
      "Model_3_2580 \t loss_train = 32581346.0 \t loss_valid = 27496044.0 \n",
      "Model_3_2590 \t loss_train = 32634554.0 \t loss_valid = 27481378.0 \n",
      "Model_3_2600 \t loss_train = 32354400.0 \t loss_valid = 27235000.0 \n",
      "Model_3_2610 \t loss_train = 32133552.0 \t loss_valid = 27130068.0 \n",
      "Model_3_2620 \t loss_train = 32617242.0 \t loss_valid = 27509154.0 \n",
      "Model_3_2630 \t loss_train = 32340508.0 \t loss_valid = 27295220.0 \n",
      "Model_3_2640 \t loss_train = 31864124.0 \t loss_valid = 27029192.0 \n",
      "Model_3_2650 \t loss_train = 32798566.0 \t loss_valid = 27671608.0 \n",
      "Model_3_2660 \t loss_train = 32109840.0 \t loss_valid = 27162188.0 \n",
      "Model_3_2670 \t loss_train = 32286158.0 \t loss_valid = 27219294.0 \n",
      "Model_3_2680 \t loss_train = 32293974.0 \t loss_valid = 27288828.0 \n",
      "Model_3_2690 \t loss_train = 33208308.0 \t loss_valid = 27973114.0 \n",
      "Model_3_2700 \t loss_train = 32144368.0 \t loss_valid = 27155484.0 \n",
      "Model_3_2710 \t loss_train = 32716490.0 \t loss_valid = 27588396.0 \n",
      "Model_3_2720 \t loss_train = 32863138.0 \t loss_valid = 27880878.0 \n",
      "Model_3_2730 \t loss_train = 32587426.0 \t loss_valid = 27518082.0 \n",
      "Model_3_2740 \t loss_train = 32595876.0 \t loss_valid = 27645626.0 \n",
      "Model_3_2750 \t loss_train = 32907584.0 \t loss_valid = 27777634.0 \n",
      "Model_3_2760 \t loss_train = 32311426.0 \t loss_valid = 27257360.0 \n",
      "Model_3_2770 \t loss_train = 33201982.0 \t loss_valid = 28190720.0 \n",
      "Model_3_2780 \t loss_train = 32431696.0 \t loss_valid = 27296266.0 \n",
      "Model_3_2790 \t loss_train = 33340302.0 \t loss_valid = 28181384.0 \n",
      "Model_3_2800 \t loss_train = 32492654.0 \t loss_valid = 27353072.0 \n",
      "Model_3_2810 \t loss_train = 32266982.0 \t loss_valid = 27262872.0 \n",
      "Model_3_2820 \t loss_train = 32885984.0 \t loss_valid = 27884292.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_3_2830 \t loss_train = 32461674.0 \t loss_valid = 27325616.0 \n",
      "Model_3_2840 \t loss_train = 31848856.0 \t loss_valid = 26910912.0 \n",
      "Model_3_2850 \t loss_train = 34140384.0 \t loss_valid = 28888816.0 \n",
      "Model_3_2860 \t loss_train = 32011098.0 \t loss_valid = 27087888.0 \n",
      "Model_3_2870 \t loss_train = 33600524.0 \t loss_valid = 28378010.0 \n",
      "Model_3_2880 \t loss_train = 33119000.0 \t loss_valid = 27877176.0 \n",
      "Model_3_2890 \t loss_train = 32842136.0 \t loss_valid = 27637802.0 \n",
      "Model_3_2900 \t loss_train = 33020824.0 \t loss_valid = 27937646.0 \n",
      "Model_3_2910 \t loss_train = 32623384.0 \t loss_valid = 27444986.0 \n",
      "Model_3_2920 \t loss_train = 33052222.0 \t loss_valid = 27928782.0 \n",
      "Model_3_2930 \t loss_train = 32881250.0 \t loss_valid = 27704972.0 \n",
      "Model_3_2940 \t loss_train = 32369100.0 \t loss_valid = 27233498.0 \n",
      "Model_3_2950 \t loss_train = 32979970.0 \t loss_valid = 27841138.0 \n",
      "Model_3_2960 \t loss_train = 32651822.0 \t loss_valid = 27475888.0 \n",
      "Model_3_2970 \t loss_train = 32889146.0 \t loss_valid = 27695616.0 \n",
      "Model_3_2980 \t loss_train = 33338110.0 \t loss_valid = 28156780.0 \n",
      "Model_3_2990 \t loss_train = 31604816.0 \t loss_valid = 26632960.0 \n",
      "Model_3_3000 \t loss_train = 33846408.0 \t loss_valid = 28665332.0 \n",
      "Model_3_3010 \t loss_train = 32397544.0 \t loss_valid = 27423620.0 \n",
      "Model_3_3020 \t loss_train = 32693516.0 \t loss_valid = 27704048.0 \n",
      "Model_3_3030 \t loss_train = 32374326.0 \t loss_valid = 27236128.0 \n",
      "Model_3_3040 \t loss_train = 32748372.0 \t loss_valid = 27622672.0 \n",
      "Model_3_3050 \t loss_train = 33455174.0 \t loss_valid = 28151296.0 \n",
      "Model_3_3060 \t loss_train = 31796182.0 \t loss_valid = 26864808.0 \n",
      "Model_3_3070 \t loss_train = 33166812.0 \t loss_valid = 27962140.0 \n",
      "Model_3_3080 \t loss_train = 33273776.0 \t loss_valid = 28111272.0 \n",
      "Model_3_3090 \t loss_train = 32748784.0 \t loss_valid = 27552628.0 \n",
      "Model_3_3100 \t loss_train = 32868518.0 \t loss_valid = 27682990.0 \n",
      "Model_3_3110 \t loss_train = 33190450.0 \t loss_valid = 28057454.0 \n",
      "Model_3_3120 \t loss_train = 32951282.0 \t loss_valid = 27750268.0 \n",
      "Model_3_3130 \t loss_train = 33066030.0 \t loss_valid = 27881276.0 \n",
      "Model_3_3140 \t loss_train = 32919808.0 \t loss_valid = 27811884.0 \n",
      "Model_3_3150 \t loss_train = 33347956.0 \t loss_valid = 28032844.0 \n",
      "Model_3_3160 \t loss_train = 32676524.0 \t loss_valid = 27533028.0 \n",
      "Model_3_3170 \t loss_train = 32733802.0 \t loss_valid = 27626334.0 \n",
      "Model_3_3180 \t loss_train = 32818644.0 \t loss_valid = 27600884.0 \n",
      "Model_3_3190 \t loss_train = 32804936.0 \t loss_valid = 27753004.0 \n",
      "Model_3_3200 \t loss_train = 33210924.0 \t loss_valid = 27923014.0 \n",
      "Model_3_3210 \t loss_train = 32908414.0 \t loss_valid = 27833808.0 \n",
      "Model_3_3220 \t loss_train = 32942726.0 \t loss_valid = 27748314.0 \n",
      "Model_3_3230 \t loss_train = 32486754.0 \t loss_valid = 27304872.0 \n",
      "Model_3_3240 \t loss_train = 33392164.0 \t loss_valid = 28273882.0 \n",
      "Model_3_3250 \t loss_train = 32696484.0 \t loss_valid = 27543458.0 \n",
      "Model_3_3260 \t loss_train = 32970796.0 \t loss_valid = 27903008.0 \n",
      "Model_3_3270 \t loss_train = 32786654.0 \t loss_valid = 27588944.0 \n",
      "Model_3_3280 \t loss_train = 33218476.0 \t loss_valid = 28117304.0 \n",
      "Model_3_3290 \t loss_train = 32720904.0 \t loss_valid = 27452258.0 \n",
      "Model_3_3300 \t loss_train = 34883844.0 \t loss_valid = 29611978.0 \n",
      "Model_3_3310 \t loss_train = 32333450.0 \t loss_valid = 27318642.0 \n",
      "Model_3_3320 \t loss_train = 33671976.0 \t loss_valid = 28447762.0 \n",
      "Model_3_3330 \t loss_train = 31828058.0 \t loss_valid = 26864146.0 \n",
      "Model_3_3340 \t loss_train = 33483284.0 \t loss_valid = 28284138.0 \n",
      "Model_3_3350 \t loss_train = 32511272.0 \t loss_valid = 27325738.0 \n",
      "Model_3_3360 \t loss_train = 32787652.0 \t loss_valid = 27784090.0 \n",
      "Model_3_3370 \t loss_train = 32671008.0 \t loss_valid = 27518964.0 \n",
      "Model_3_3380 \t loss_train = 33313244.0 \t loss_valid = 28239376.0 \n",
      "Model_3_3390 \t loss_train = 33143500.0 \t loss_valid = 27751112.0 \n",
      "Model_3_3400 \t loss_train = 32959470.0 \t loss_valid = 27926652.0 \n",
      "Model_3_3410 \t loss_train = 32820252.0 \t loss_valid = 27674156.0 \n",
      "Model_3_3420 \t loss_train = 33758592.0 \t loss_valid = 28581120.0 \n",
      "Model_3_3430 \t loss_train = 32465652.0 \t loss_valid = 27290484.0 \n",
      "Model_3_3440 \t loss_train = 33514606.0 \t loss_valid = 28361516.0 \n",
      "Model_3_3450 \t loss_train = 32897774.0 \t loss_valid = 27810870.0 \n",
      "Model_3_3460 \t loss_train = 32893872.0 \t loss_valid = 27791676.0 \n",
      "Model_3_3470 \t loss_train = 33632208.0 \t loss_valid = 28301338.0 \n",
      "Model_3_3480 \t loss_train = 33260526.0 \t loss_valid = 28089446.0 \n",
      "Model_3_3490 \t loss_train = 32966474.0 \t loss_valid = 27857848.0 \n",
      "Model_3_3500 \t loss_train = 33639584.0 \t loss_valid = 28246924.0 \n",
      "Model_3_3510 \t loss_train = 32773338.0 \t loss_valid = 27687314.0 \n",
      "Model_3_3520 \t loss_train = 33167076.0 \t loss_valid = 27918782.0 \n",
      "Model_3_3530 \t loss_train = 32517268.0 \t loss_valid = 27488060.0 \n",
      "Model_3_3540 \t loss_train = 34212040.0 \t loss_valid = 28868340.0 \n",
      "Model_3_3550 \t loss_train = 32338864.0 \t loss_valid = 27304332.0 \n",
      "Model_3_3560 \t loss_train = 33316308.0 \t loss_valid = 27951906.0 \n",
      "Model_3_3570 \t loss_train = 33166650.0 \t loss_valid = 28071790.0 \n",
      "Model_3_3580 \t loss_train = 33043600.0 \t loss_valid = 27847778.0 \n",
      "Model_3_3590 \t loss_train = 33843980.0 \t loss_valid = 28584972.0 \n",
      "Model_3_3600 \t loss_train = 33055304.0 \t loss_valid = 27963420.0 \n",
      "Model_3_3610 \t loss_train = 33459048.0 \t loss_valid = 28149096.0 \n",
      "Model_3_3620 \t loss_train = 32885390.0 \t loss_valid = 27809728.0 \n",
      "Model_3_3630 \t loss_train = 33304756.0 \t loss_valid = 28017784.0 \n",
      "Model_3_3640 \t loss_train = 32937288.0 \t loss_valid = 27838422.0 \n",
      "Model_3_3650 \t loss_train = 33347848.0 \t loss_valid = 28122614.0 \n",
      "Model_3_3660 \t loss_train = 33585716.0 \t loss_valid = 28300288.0 \n",
      "Model_3_3670 \t loss_train = 33412136.0 \t loss_valid = 28247406.0 \n",
      "Model_3_3680 \t loss_train = 32478076.0 \t loss_valid = 27365370.0 \n",
      "Model_3_3690 \t loss_train = 34157232.0 \t loss_valid = 28988470.0 \n",
      "Model_3_3700 \t loss_train = 33062448.0 \t loss_valid = 27714774.0 \n",
      "Model_3_3710 \t loss_train = 33032852.0 \t loss_valid = 27779110.0 \n",
      "Model_3_3720 \t loss_train = 33511974.0 \t loss_valid = 28317752.0 \n",
      "Model_3_3730 \t loss_train = 33608832.0 \t loss_valid = 28230902.0 \n",
      "Model_3_3740 \t loss_train = 32779896.0 \t loss_valid = 27609208.0 \n",
      "Model_3_3750 \t loss_train = 32556426.0 \t loss_valid = 27536738.0 \n",
      "Model_3_3760 \t loss_train = 33672172.0 \t loss_valid = 28413700.0 \n",
      "Model_3_3770 \t loss_train = 32619220.0 \t loss_valid = 27489352.0 \n",
      "Model_3_3780 \t loss_train = 33225660.0 \t loss_valid = 27937552.0 \n",
      "Model_3_3790 \t loss_train = 33026874.0 \t loss_valid = 27928174.0 \n",
      "Model_3_3800 \t loss_train = 33495264.0 \t loss_valid = 28230286.0 \n",
      "Model_3_3810 \t loss_train = 33284620.0 \t loss_valid = 28037448.0 \n",
      "Model_3_3820 \t loss_train = 33147694.0 \t loss_valid = 28006050.0 \n",
      "Model_3_3830 \t loss_train = 32730258.0 \t loss_valid = 27542620.0 \n",
      "Model_3_3840 \t loss_train = 34732592.0 \t loss_valid = 29455332.0 \n",
      "Model_3_3850 \t loss_train = 32660658.0 \t loss_valid = 27474012.0 \n",
      "Model_3_3860 \t loss_train = 33001926.0 \t loss_valid = 27830490.0 \n",
      "Model_3_3870 \t loss_train = 33091788.0 \t loss_valid = 27927520.0 \n",
      "Model_3_3880 \t loss_train = 33609388.0 \t loss_valid = 28397596.0 \n",
      "Model_3_3890 \t loss_train = 32987656.0 \t loss_valid = 27890132.0 \n",
      "Model_3_3900 \t loss_train = 33262222.0 \t loss_valid = 27971312.0 \n",
      "Model_3_3910 \t loss_train = 33043324.0 \t loss_valid = 27900134.0 \n",
      "Model_3_3920 \t loss_train = 32984526.0 \t loss_valid = 27857300.0 \n",
      "Model_3_3930 \t loss_train = 33261840.0 \t loss_valid = 28102548.0 \n",
      "Model_3_3940 \t loss_train = 33056412.0 \t loss_valid = 27809198.0 \n",
      "Model_3_3950 \t loss_train = 32924764.0 \t loss_valid = 27748788.0 \n",
      "Model_3_3960 \t loss_train = 33962484.0 \t loss_valid = 28751062.0 \n",
      "Model_3_3970 \t loss_train = 33180088.0 \t loss_valid = 28039310.0 \n",
      "Model_3_3980 \t loss_train = 32895354.0 \t loss_valid = 27745292.0 \n",
      "Model_3_3990 \t loss_train = 34177528.0 \t loss_valid = 29007530.0 \n",
      "Model_3_4000 \t loss_train = 31929090.0 \t loss_valid = 26846830.0 \n",
      "Model_3_4010 \t loss_train = 34128752.0 \t loss_valid = 28830524.0 \n",
      "Model_3_4020 \t loss_train = 33437864.0 \t loss_valid = 28141164.0 \n",
      "Model_3_4030 \t loss_train = 32901556.0 \t loss_valid = 27734550.0 \n",
      "Model_3_4040 \t loss_train = 34122452.0 \t loss_valid = 28691484.0 \n",
      "Model_3_4050 \t loss_train = 32807292.0 \t loss_valid = 27679800.0 \n",
      "Model_3_4060 \t loss_train = 32768748.0 \t loss_valid = 27648094.0 \n",
      "Model_3_4070 \t loss_train = 33975172.0 \t loss_valid = 28751454.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_3_4080 \t loss_train = 33765924.0 \t loss_valid = 28396920.0 \n",
      "Model_3_4090 \t loss_train = 32729090.0 \t loss_valid = 27549210.0 \n",
      "Model_3_4100 \t loss_train = 33873112.0 \t loss_valid = 28622640.0 \n",
      "Model_3_4110 \t loss_train = 33556060.0 \t loss_valid = 28188078.0 \n",
      "Model_3_4120 \t loss_train = 33999776.0 \t loss_valid = 28777428.0 \n",
      "Model_3_4130 \t loss_train = 32686952.0 \t loss_valid = 27544082.0 \n",
      "Model_3_4140 \t loss_train = 33500882.0 \t loss_valid = 28323956.0 \n",
      "Model_3_4150 \t loss_train = 33416476.0 \t loss_valid = 28170970.0 \n",
      "Model_3_4160 \t loss_train = 33265270.0 \t loss_valid = 28004766.0 \n",
      "Model_3_4170 \t loss_train = 33411834.0 \t loss_valid = 28362892.0 \n",
      "Model_3_4180 \t loss_train = 33521070.0 \t loss_valid = 28275256.0 \n",
      "Model_3_4190 \t loss_train = 32389230.0 \t loss_valid = 27347934.0 \n",
      "Model_3_4200 \t loss_train = 34199416.0 \t loss_valid = 28940218.0 \n",
      "Model_3_4210 \t loss_train = 32471034.0 \t loss_valid = 27319548.0 \n",
      "Model_3_4220 \t loss_train = 33454392.0 \t loss_valid = 28296708.0 \n",
      "Model_3_4230 \t loss_train = 33916600.0 \t loss_valid = 28631862.0 \n",
      "Model_3_4240 \t loss_train = 32507118.0 \t loss_valid = 27486866.0 \n",
      "Model_3_4250 \t loss_train = 33909624.0 \t loss_valid = 28501242.0 \n",
      "Model_3_4260 \t loss_train = 33312718.0 \t loss_valid = 28126732.0 \n",
      "Model_3_4270 \t loss_train = 33003600.0 \t loss_valid = 27822052.0 \n",
      "Model_3_4280 \t loss_train = 33495590.0 \t loss_valid = 28262516.0 \n",
      "Model_3_4290 \t loss_train = 33192850.0 \t loss_valid = 28005192.0 \n",
      "Model_3_4300 \t loss_train = 33822640.0 \t loss_valid = 28527208.0 \n",
      "Model_3_4310 \t loss_train = 33339882.0 \t loss_valid = 28067034.0 \n",
      "Model_3_4320 \t loss_train = 33358526.0 \t loss_valid = 28082608.0 \n",
      "Model_3_4330 \t loss_train = 33233374.0 \t loss_valid = 27999614.0 \n",
      "Model_3_4340 \t loss_train = 33603972.0 \t loss_valid = 28314908.0 \n",
      "Model_3_4350 \t loss_train = 33507850.0 \t loss_valid = 28179414.0 \n",
      "Model_3_4360 \t loss_train = 32755650.0 \t loss_valid = 27656426.0 \n",
      "Model_3_4370 \t loss_train = 34409108.0 \t loss_valid = 29084650.0 \n",
      "Model_3_4380 \t loss_train = 33208278.0 \t loss_valid = 28017474.0 \n",
      "Model_3_4390 \t loss_train = 33932580.0 \t loss_valid = 28609090.0 \n",
      "Model_3_4400 \t loss_train = 33758808.0 \t loss_valid = 28673156.0 \n",
      "Model_3_4410 \t loss_train = 33187848.0 \t loss_valid = 27985320.0 \n",
      "Model_3_4420 \t loss_train = 33122956.0 \t loss_valid = 27963004.0 \n",
      "Model_3_4430 \t loss_train = 33341964.0 \t loss_valid = 27997070.0 \n",
      "Model_3_4440 \t loss_train = 33240276.0 \t loss_valid = 28092910.0 \n",
      "Model_3_4450 \t loss_train = 33308856.0 \t loss_valid = 28106922.0 \n",
      "Model_3_4460 \t loss_train = 33776476.0 \t loss_valid = 28534960.0 \n",
      "Model_3_4470 \t loss_train = 32641826.0 \t loss_valid = 27587126.0 \n",
      "Model_3_4480 \t loss_train = 33606668.0 \t loss_valid = 28276152.0 \n",
      "Model_3_4490 \t loss_train = 33186416.0 \t loss_valid = 28002858.0 \n",
      "Model_3_4500 \t loss_train = 33854204.0 \t loss_valid = 28702426.0 \n",
      "Model_3_4510 \t loss_train = 32577808.0 \t loss_valid = 27269424.0 \n",
      "Model_3_4520 \t loss_train = 34264096.0 \t loss_valid = 29010540.0 \n",
      "Model_3_4530 \t loss_train = 32889488.0 \t loss_valid = 27655642.0 \n",
      "Model_3_4540 \t loss_train = 33525900.0 \t loss_valid = 28299182.0 \n",
      "Model_3_4550 \t loss_train = 34072468.0 \t loss_valid = 28698740.0 \n",
      "Model_3_4560 \t loss_train = 33555680.0 \t loss_valid = 28255068.0 \n",
      "Model_3_4570 \t loss_train = 33645404.0 \t loss_valid = 28282754.0 \n",
      "Model_3_4580 \t loss_train = 33673712.0 \t loss_valid = 28402710.0 \n",
      "Model_3_4590 \t loss_train = 33638476.0 \t loss_valid = 28383860.0 \n",
      "Model_3_4600 \t loss_train = 33746068.0 \t loss_valid = 28448540.0 \n",
      "Model_3_4610 \t loss_train = 33231010.0 \t loss_valid = 27959022.0 \n",
      "Model_3_4620 \t loss_train = 33603524.0 \t loss_valid = 28348966.0 \n",
      "Model_3_4630 \t loss_train = 32904792.0 \t loss_valid = 27686956.0 \n",
      "Model_3_4640 \t loss_train = 33551798.0 \t loss_valid = 28283876.0 \n",
      "Model_3_4650 \t loss_train = 32951878.0 \t loss_valid = 27742600.0 \n",
      "Model_3_4660 \t loss_train = 33636160.0 \t loss_valid = 28353390.0 \n",
      "Model_3_4670 \t loss_train = 33638476.0 \t loss_valid = 28298098.0 \n",
      "Model_3_4680 \t loss_train = 33533018.0 \t loss_valid = 28150766.0 \n",
      "Model_3_4690 \t loss_train = 32871938.0 \t loss_valid = 27669378.0 \n",
      "Model_3_4700 \t loss_train = 34157000.0 \t loss_valid = 28783818.0 \n",
      "Model_3_4710 \t loss_train = 32412302.0 \t loss_valid = 27294062.0 \n",
      "Model_3_4720 \t loss_train = 33064426.0 \t loss_valid = 27902998.0 \n",
      "Model_3_4730 \t loss_train = 33385760.0 \t loss_valid = 28075396.0 \n",
      "Model_3_4740 \t loss_train = 33246718.0 \t loss_valid = 27956208.0 \n",
      "Model_3_4750 \t loss_train = 33848336.0 \t loss_valid = 28551978.0 \n",
      "Model_3_4760 \t loss_train = 33598320.0 \t loss_valid = 28381670.0 \n",
      "Model_3_4770 \t loss_train = 33930184.0 \t loss_valid = 28495890.0 \n",
      "Model_3_4780 \t loss_train = 33211768.0 \t loss_valid = 27970876.0 \n",
      "Model_3_4790 \t loss_train = 33296794.0 \t loss_valid = 28089540.0 \n",
      "Model_3_4800 \t loss_train = 33519398.0 \t loss_valid = 28220862.0 \n",
      "Model_3_4810 \t loss_train = 33360068.0 \t loss_valid = 28122062.0 \n",
      "Model_3_4820 \t loss_train = 34017344.0 \t loss_valid = 28655600.0 \n",
      "Model_3_4830 \t loss_train = 32869244.0 \t loss_valid = 27638260.0 \n",
      "Model_3_4840 \t loss_train = 33799380.0 \t loss_valid = 28445702.0 \n",
      "Model_3_4850 \t loss_train = 33569056.0 \t loss_valid = 28184874.0 \n",
      "Model_3_4860 \t loss_train = 32940572.0 \t loss_valid = 27700470.0 \n",
      "Model_3_4870 \t loss_train = 33428596.0 \t loss_valid = 28236292.0 \n",
      "Model_3_4880 \t loss_train = 33925292.0 \t loss_valid = 28504790.0 \n",
      "Model_3_4890 \t loss_train = 33329050.0 \t loss_valid = 28021944.0 \n",
      "Model_3_4900 \t loss_train = 33478338.0 \t loss_valid = 28176618.0 \n",
      "Model_3_4910 \t loss_train = 33974556.0 \t loss_valid = 28552436.0 \n",
      "Model_3_4920 \t loss_train = 33466566.0 \t loss_valid = 28176602.0 \n",
      "Model_3_4930 \t loss_train = 33869268.0 \t loss_valid = 28451470.0 \n",
      "Model_3_4940 \t loss_train = 33415218.0 \t loss_valid = 28117412.0 \n",
      "Model_3_4950 \t loss_train = 33405028.0 \t loss_valid = 28048890.0 \n",
      "Model_3_4960 \t loss_train = 33489106.0 \t loss_valid = 28081958.0 \n",
      "Model_3_4970 \t loss_train = 32901002.0 \t loss_valid = 27700274.0 \n",
      "Model_3_4980 \t loss_train = 34686956.0 \t loss_valid = 29279876.0 \n",
      "Model_3_4990 \t loss_train = 33155458.0 \t loss_valid = 27871024.0 \n",
      "Model_3_5000 \t loss_train = 33557336.0 \t loss_valid = 28245140.0 \n",
      "Model_3_5010 \t loss_train = 34662996.0 \t loss_valid = 29032372.0 \n",
      "Model_3_5020 \t loss_train = 33085544.0 \t loss_valid = 27915214.0 \n",
      "Model_3_5030 \t loss_train = 34035428.0 \t loss_valid = 28644538.0 \n",
      "Model_3_5040 \t loss_train = 33320392.0 \t loss_valid = 28003328.0 \n",
      "Model_3_5050 \t loss_train = 33542730.0 \t loss_valid = 28267318.0 \n",
      "Model_3_5060 \t loss_train = 33777960.0 \t loss_valid = 28433826.0 \n",
      "Model_3_5070 \t loss_train = 33679204.0 \t loss_valid = 28342992.0 \n",
      "Model_3_5080 \t loss_train = 32841926.0 \t loss_valid = 27544560.0 \n",
      "Model_3_5090 \t loss_train = 33676568.0 \t loss_valid = 28413580.0 \n",
      "Model_3_5100 \t loss_train = 33475974.0 \t loss_valid = 28200220.0 \n",
      "Model_3_5110 \t loss_train = 33238294.0 \t loss_valid = 27881468.0 \n",
      "Model_3_5120 \t loss_train = 34204796.0 \t loss_valid = 28752162.0 \n",
      "Model_3_5130 \t loss_train = 33140106.0 \t loss_valid = 27888794.0 \n",
      "Model_3_5140 \t loss_train = 33705892.0 \t loss_valid = 28309334.0 \n",
      "Model_3_5150 \t loss_train = 33144436.0 \t loss_valid = 27917828.0 \n",
      "Model_3_5160 \t loss_train = 34320620.0 \t loss_valid = 28793420.0 \n",
      "Model_3_5170 \t loss_train = 33436044.0 \t loss_valid = 28158730.0 \n",
      "Model_3_5180 \t loss_train = 34000876.0 \t loss_valid = 28540884.0 \n",
      "Model_3_5190 \t loss_train = 34124660.0 \t loss_valid = 28676340.0 \n",
      "Model_3_5200 \t loss_train = 33649664.0 \t loss_valid = 28338956.0 \n",
      "Model_3_5210 \t loss_train = 33929428.0 \t loss_valid = 28519022.0 \n",
      "Model_3_5220 \t loss_train = 33542970.0 \t loss_valid = 28182510.0 \n",
      "Model_3_5230 \t loss_train = 34412236.0 \t loss_valid = 28976372.0 \n",
      "Model_3_5240 \t loss_train = 33191836.0 \t loss_valid = 27903390.0 \n",
      "Model_3_5250 \t loss_train = 33715852.0 \t loss_valid = 28294558.0 \n",
      "Model_3_5260 \t loss_train = 33137722.0 \t loss_valid = 27999778.0 \n",
      "Model_3_5270 \t loss_train = 34539412.0 \t loss_valid = 29092576.0 \n",
      "Model_3_5280 \t loss_train = 32979588.0 \t loss_valid = 27715378.0 \n",
      "Model_3_5290 \t loss_train = 34458912.0 \t loss_valid = 28983394.0 \n",
      "Model_3_5300 \t loss_train = 33614596.0 \t loss_valid = 28059178.0 \n",
      "Model_3_5310 \t loss_train = 34089172.0 \t loss_valid = 28713402.0 \n",
      "Model_3_5320 \t loss_train = 33911104.0 \t loss_valid = 28298038.0 \n",
      "Model_3_5330 \t loss_train = 34262144.0 \t loss_valid = 29065368.0 \n",
      "Model_3_5340 \t loss_train = 33720220.0 \t loss_valid = 28203924.0 \n",
      "Model_3_5350 \t loss_train = 34391708.0 \t loss_valid = 29045864.0 \n",
      "Model_3_5360 \t loss_train = 33085302.0 \t loss_valid = 27785020.0 \n",
      "Model_3_5370 \t loss_train = 34031888.0 \t loss_valid = 28492156.0 \n",
      "Model_3_5380 \t loss_train = 33933668.0 \t loss_valid = 28678984.0 \n",
      "Model_3_5390 \t loss_train = 34278020.0 \t loss_valid = 28697038.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_3_5400 \t loss_train = 33087932.0 \t loss_valid = 27788196.0 \n",
      "Model_3_5410 \t loss_train = 33500464.0 \t loss_valid = 28151120.0 \n",
      "Model_3_5420 \t loss_train = 33326324.0 \t loss_valid = 27992358.0 \n",
      "Model_3_5430 \t loss_train = 33656344.0 \t loss_valid = 28274842.0 \n",
      "Model_3_5440 \t loss_train = 33893472.0 \t loss_valid = 28516762.0 \n",
      "Model_3_5450 \t loss_train = 33375478.0 \t loss_valid = 27956704.0 \n",
      "Model_3_5460 \t loss_train = 33936176.0 \t loss_valid = 28511908.0 \n",
      "Model_3_5470 \t loss_train = 33854716.0 \t loss_valid = 28490672.0 \n",
      "Model_3_5480 \t loss_train = 34207108.0 \t loss_valid = 28684778.0 \n",
      "Model_3_5490 \t loss_train = 34069680.0 \t loss_valid = 28666782.0 \n",
      "Model_3_5500 \t loss_train = 33520568.0 \t loss_valid = 28116942.0 \n",
      "Model_3_5510 \t loss_train = 34170532.0 \t loss_valid = 28767890.0 \n",
      "Model_3_5520 \t loss_train = 34280084.0 \t loss_valid = 28809114.0 \n",
      "Model_3_5530 \t loss_train = 33349156.0 \t loss_valid = 27998626.0 \n",
      "Model_3_5540 \t loss_train = 34544968.0 \t loss_valid = 29216034.0 \n",
      "Model_3_5550 \t loss_train = 33945164.0 \t loss_valid = 28438730.0 \n",
      "Model_3_5560 \t loss_train = 33578200.0 \t loss_valid = 28153910.0 \n",
      "Model_3_5570 \t loss_train = 33992676.0 \t loss_valid = 28487990.0 \n",
      "Model_3_5580 \t loss_train = 33991464.0 \t loss_valid = 28611182.0 \n",
      "Model_3_5590 \t loss_train = 34134448.0 \t loss_valid = 28623914.0 \n",
      "Model_3_5600 \t loss_train = 33775532.0 \t loss_valid = 28357840.0 \n",
      "Model_3_5610 \t loss_train = 34078000.0 \t loss_valid = 28554590.0 \n",
      "Model_3_5620 \t loss_train = 34609040.0 \t loss_valid = 29180944.0 \n",
      "Model_3_5630 \t loss_train = 34015512.0 \t loss_valid = 28436638.0 \n",
      "Model_3_5640 \t loss_train = 33781196.0 \t loss_valid = 28304352.0 \n",
      "Model_3_5650 \t loss_train = 34365684.0 \t loss_valid = 28767342.0 \n",
      "Model_3_5660 \t loss_train = 33714408.0 \t loss_valid = 28286790.0 \n",
      "Model_3_5670 \t loss_train = 34035600.0 \t loss_valid = 28605898.0 \n",
      "Model_3_5680 \t loss_train = 34078652.0 \t loss_valid = 28564078.0 \n",
      "Model_3_5690 \t loss_train = 33964972.0 \t loss_valid = 28373094.0 \n",
      "Model_3_5700 \t loss_train = 33727968.0 \t loss_valid = 28250804.0 \n",
      "Model_3_5710 \t loss_train = 34025456.0 \t loss_valid = 28490726.0 \n",
      "Model_3_5720 \t loss_train = 34458040.0 \t loss_valid = 28917552.0 \n",
      "Model_3_5730 \t loss_train = 33834468.0 \t loss_valid = 28360504.0 \n",
      "Model_3_5740 \t loss_train = 34762456.0 \t loss_valid = 29202432.0 \n",
      "Model_3_5750 \t loss_train = 33296368.0 \t loss_valid = 27776986.0 \n",
      "Model_3_5760 \t loss_train = 34999632.0 \t loss_valid = 29293770.0 \n",
      "Model_3_5770 \t loss_train = 34369404.0 \t loss_valid = 28786706.0 \n",
      "Model_3_5780 \t loss_train = 34588848.0 \t loss_valid = 29069286.0 \n",
      "Model_3_5790 \t loss_train = 33700744.0 \t loss_valid = 28197392.0 \n",
      "Model_3_5800 \t loss_train = 34470552.0 \t loss_valid = 29039116.0 \n",
      "Model_3_5810 \t loss_train = 33616884.0 \t loss_valid = 28134230.0 \n",
      "Model_3_5820 \t loss_train = 34656940.0 \t loss_valid = 29126508.0 \n",
      "Model_3_5830 \t loss_train = 34014972.0 \t loss_valid = 28397934.0 \n",
      "Model_3_5840 \t loss_train = 34856996.0 \t loss_valid = 29288360.0 \n",
      "Model_3_5850 \t loss_train = 33889392.0 \t loss_valid = 28289154.0 \n",
      "Model_3_5860 \t loss_train = 34255376.0 \t loss_valid = 28822714.0 \n",
      "Model_3_5870 \t loss_train = 34526888.0 \t loss_valid = 28958720.0 \n",
      "Model_3_5880 \t loss_train = 34302936.0 \t loss_valid = 28803944.0 \n",
      "Model_3_5890 \t loss_train = 34150176.0 \t loss_valid = 28479664.0 \n",
      "Model_3_5900 \t loss_train = 34241344.0 \t loss_valid = 28568924.0 \n",
      "Model_3_5910 \t loss_train = 34626688.0 \t loss_valid = 29131160.0 \n",
      "Model_3_5920 \t loss_train = 34062940.0 \t loss_valid = 28505868.0 \n",
      "Model_3_5930 \t loss_train = 34285588.0 \t loss_valid = 28835850.0 \n",
      "Model_3_5940 \t loss_train = 34021508.0 \t loss_valid = 28420040.0 \n",
      "Model_3_5950 \t loss_train = 34174520.0 \t loss_valid = 28624178.0 \n",
      "Model_3_5960 \t loss_train = 33493668.0 \t loss_valid = 28076750.0 \n",
      "Model_3_5970 \t loss_train = 34577760.0 \t loss_valid = 28846716.0 \n",
      "Model_3_5980 \t loss_train = 34232284.0 \t loss_valid = 28745102.0 \n",
      "Model_3_5990 \t loss_train = 33867908.0 \t loss_valid = 28222060.0 \n",
      "Model_3_6000 \t loss_train = 35154068.0 \t loss_valid = 29564044.0 \n",
      "Model_3_6010 \t loss_train = 33990092.0 \t loss_valid = 28330770.0 \n",
      "Model_3_6020 \t loss_train = 34453264.0 \t loss_valid = 28981668.0 \n",
      "Model_3_6030 \t loss_train = 34751308.0 \t loss_valid = 28962886.0 \n",
      "Model_3_6040 \t loss_train = 34150004.0 \t loss_valid = 28585182.0 \n",
      "Model_3_6050 \t loss_train = 34886976.0 \t loss_valid = 29348334.0 \n",
      "Model_3_6060 \t loss_train = 34169072.0 \t loss_valid = 28591628.0 \n",
      "Model_3_6070 \t loss_train = 34157264.0 \t loss_valid = 28480800.0 \n",
      "Model_3_6080 \t loss_train = 34522952.0 \t loss_valid = 29039878.0 \n",
      "Model_3_6090 \t loss_train = 34482568.0 \t loss_valid = 28799206.0 \n",
      "Model_3_6100 \t loss_train = 34983892.0 \t loss_valid = 29376628.0 \n",
      "Model_3_6110 \t loss_train = 34139596.0 \t loss_valid = 28544102.0 \n",
      "Model_3_6120 \t loss_train = 34225672.0 \t loss_valid = 28620038.0 \n",
      "Model_3_6130 \t loss_train = 34104016.0 \t loss_valid = 28495082.0 \n",
      "Model_3_6140 \t loss_train = 35165312.0 \t loss_valid = 29421966.0 \n",
      "Model_3_6150 \t loss_train = 33978824.0 \t loss_valid = 28399746.0 \n",
      "Model_3_6160 \t loss_train = 34346648.0 \t loss_valid = 28705280.0 \n",
      "Model_3_6170 \t loss_train = 34573264.0 \t loss_valid = 28953780.0 \n",
      "Model_3_6180 \t loss_train = 35062604.0 \t loss_valid = 29328094.0 \n",
      "Model_3_6190 \t loss_train = 34456348.0 \t loss_valid = 28896452.0 \n",
      "Model_3_6200 \t loss_train = 34776572.0 \t loss_valid = 29119444.0 \n",
      "Model_3_6210 \t loss_train = 34876336.0 \t loss_valid = 29220620.0 \n",
      "Model_3_6220 \t loss_train = 34711808.0 \t loss_valid = 29079776.0 \n",
      "Model_3_6230 \t loss_train = 34331900.0 \t loss_valid = 28579066.0 \n",
      "Model_3_6240 \t loss_train = 34603888.0 \t loss_valid = 29049520.0 \n",
      "Model_3_6250 \t loss_train = 34311516.0 \t loss_valid = 28687658.0 \n",
      "Model_3_6260 \t loss_train = 34474444.0 \t loss_valid = 28967052.0 \n",
      "Model_3_6270 \t loss_train = 34877680.0 \t loss_valid = 29122128.0 \n",
      "Model_3_6280 \t loss_train = 34250188.0 \t loss_valid = 28730026.0 \n",
      "Model_3_6290 \t loss_train = 34746668.0 \t loss_valid = 29093894.0 \n",
      "Model_3_6300 \t loss_train = 35754952.0 \t loss_valid = 30036976.0 \n",
      "Model_3_6310 \t loss_train = 34270508.0 \t loss_valid = 28664794.0 \n",
      "Model_3_6320 \t loss_train = 34754164.0 \t loss_valid = 29044152.0 \n",
      "Model_3_6330 \t loss_train = 35190064.0 \t loss_valid = 29495518.0 \n",
      "Model_3_6340 \t loss_train = 34482612.0 \t loss_valid = 28684902.0 \n",
      "Model_3_6350 \t loss_train = 35524172.0 \t loss_valid = 29713560.0 \n",
      "Model_3_6360 \t loss_train = 34689200.0 \t loss_valid = 28928262.0 \n",
      "Model_3_6370 \t loss_train = 35063808.0 \t loss_valid = 29383674.0 \n",
      "Model_3_6380 \t loss_train = 34728808.0 \t loss_valid = 29033248.0 \n",
      "Model_3_6390 \t loss_train = 34429268.0 \t loss_valid = 28770216.0 \n",
      "Model_3_6400 \t loss_train = 35076872.0 \t loss_valid = 29349714.0 \n",
      "Model_3_6410 \t loss_train = 34207328.0 \t loss_valid = 28480856.0 \n",
      "Model_3_6420 \t loss_train = 34313412.0 \t loss_valid = 28611710.0 \n",
      "Model_3_6430 \t loss_train = 34893104.0 \t loss_valid = 29189296.0 \n",
      "Model_3_6440 \t loss_train = 34578136.0 \t loss_valid = 28845704.0 \n",
      "Model_3_6450 \t loss_train = 35187012.0 \t loss_valid = 29357324.0 \n",
      "Model_3_6460 \t loss_train = 34544344.0 \t loss_valid = 28758266.0 \n",
      "Model_3_6470 \t loss_train = 35645120.0 \t loss_valid = 29935010.0 \n",
      "Model_3_6480 \t loss_train = 34806280.0 \t loss_valid = 29019250.0 \n",
      "Model_3_6490 \t loss_train = 34931728.0 \t loss_valid = 29155502.0 \n",
      "Model_3_6500 \t loss_train = 35012732.0 \t loss_valid = 29247498.0 \n",
      "Model_3_6510 \t loss_train = 34678124.0 \t loss_valid = 28748702.0 \n",
      "Model_3_6520 \t loss_train = 34778060.0 \t loss_valid = 29065396.0 \n",
      "Model_3_6530 \t loss_train = 34403564.0 \t loss_valid = 28648874.0 \n",
      "Model_3_6540 \t loss_train = 35405384.0 \t loss_valid = 29656858.0 \n",
      "Model_3_6550 \t loss_train = 34596108.0 \t loss_valid = 28844902.0 \n",
      "Model_3_6560 \t loss_train = 34876864.0 \t loss_valid = 29068790.0 \n",
      "Model_3_6570 \t loss_train = 35805776.0 \t loss_valid = 29990390.0 \n",
      "Model_3_6580 \t loss_train = 34598180.0 \t loss_valid = 28852784.0 \n",
      "Model_3_6590 \t loss_train = 34630880.0 \t loss_valid = 28830862.0 \n",
      "Model_3_6600 \t loss_train = 35044856.0 \t loss_valid = 29245746.0 \n",
      "Model_3_6610 \t loss_train = 35163916.0 \t loss_valid = 29290256.0 \n",
      "Model_3_6620 \t loss_train = 35264520.0 \t loss_valid = 29561138.0 \n",
      "Model_3_6630 \t loss_train = 35079956.0 \t loss_valid = 29320572.0 \n",
      "Model_3_6640 \t loss_train = 34876212.0 \t loss_valid = 29066546.0 \n",
      "Model_3_6650 \t loss_train = 35473916.0 \t loss_valid = 29820570.0 \n",
      "Model_3_6660 \t loss_train = 34664620.0 \t loss_valid = 28884610.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_3_6670 \t loss_train = 34813024.0 \t loss_valid = 29176194.0 \n",
      "Model_3_6680 \t loss_train = 34788108.0 \t loss_valid = 29077620.0 \n",
      "Model_3_6690 \t loss_train = 35130716.0 \t loss_valid = 29352000.0 \n",
      "Model_3_6700 \t loss_train = 34506708.0 \t loss_valid = 28843282.0 \n",
      "Model_3_6710 \t loss_train = 36063140.0 \t loss_valid = 30072114.0 \n",
      "Model_3_6720 \t loss_train = 34888048.0 \t loss_valid = 29103834.0 \n",
      "Model_3_6730 \t loss_train = 35065852.0 \t loss_valid = 29314902.0 \n",
      "Model_3_6740 \t loss_train = 35463924.0 \t loss_valid = 29690694.0 \n",
      "Model_3_6750 \t loss_train = 34617716.0 \t loss_valid = 28961520.0 \n",
      "Model_3_6760 \t loss_train = 36050948.0 \t loss_valid = 29975384.0 \n",
      "Model_3_6770 \t loss_train = 35024356.0 \t loss_valid = 29278452.0 \n",
      "Model_3_6780 \t loss_train = 35248848.0 \t loss_valid = 29426226.0 \n",
      "Model_3_6790 \t loss_train = 34715484.0 \t loss_valid = 29115430.0 \n",
      "Model_3_6800 \t loss_train = 35356972.0 \t loss_valid = 29362312.0 \n",
      "Model_3_6810 \t loss_train = 35614824.0 \t loss_valid = 29735396.0 \n",
      "Model_3_6820 \t loss_train = 35222124.0 \t loss_valid = 29437330.0 \n",
      "Model_3_6830 \t loss_train = 35068764.0 \t loss_valid = 29287142.0 \n",
      "Model_3_6840 \t loss_train = 34938560.0 \t loss_valid = 29180368.0 \n",
      "Model_3_6850 \t loss_train = 34176788.0 \t loss_valid = 28351308.0 \n",
      "Model_3_6860 \t loss_train = 36052792.0 \t loss_valid = 30153362.0 \n",
      "Model_3_6870 \t loss_train = 34740048.0 \t loss_valid = 29036322.0 \n",
      "Model_3_6880 \t loss_train = 35202240.0 \t loss_valid = 29302584.0 \n",
      "Model_3_6890 \t loss_train = 35628660.0 \t loss_valid = 29699882.0 \n",
      "Model_3_6900 \t loss_train = 34849976.0 \t loss_valid = 29051380.0 \n",
      "Model_3_6910 \t loss_train = 35157288.0 \t loss_valid = 29311664.0 \n",
      "Model_3_6920 \t loss_train = 35199340.0 \t loss_valid = 29376544.0 \n",
      "Model_3_6930 \t loss_train = 34964024.0 \t loss_valid = 29189186.0 \n",
      "Model_3_6940 \t loss_train = 35216224.0 \t loss_valid = 29454004.0 \n",
      "Model_3_6950 \t loss_train = 35915808.0 \t loss_valid = 29853686.0 \n",
      "Model_3_6960 \t loss_train = 34838196.0 \t loss_valid = 29051192.0 \n",
      "Model_3_6970 \t loss_train = 35225280.0 \t loss_valid = 29274368.0 \n",
      "Model_3_6980 \t loss_train = 34967264.0 \t loss_valid = 29123290.0 \n",
      "Model_3_6990 \t loss_train = 35214992.0 \t loss_valid = 29217374.0 \n",
      "Model_3_7000 \t loss_train = 35331992.0 \t loss_valid = 29513260.0 \n",
      "Model_3_7010 \t loss_train = 34692732.0 \t loss_valid = 28905804.0 \n",
      "Model_3_7020 \t loss_train = 35737692.0 \t loss_valid = 29700602.0 \n",
      "Model_3_7030 \t loss_train = 35635740.0 \t loss_valid = 29691480.0 \n",
      "Model_3_7040 \t loss_train = 35284856.0 \t loss_valid = 29405266.0 \n",
      "Model_3_7050 \t loss_train = 35455168.0 \t loss_valid = 29658434.0 \n",
      "Model_3_7060 \t loss_train = 35334760.0 \t loss_valid = 29375776.0 \n",
      "Model_3_7070 \t loss_train = 34891592.0 \t loss_valid = 28867160.0 \n",
      "Model_3_7080 \t loss_train = 35497444.0 \t loss_valid = 29756556.0 \n",
      "Model_3_7090 \t loss_train = 35672912.0 \t loss_valid = 29619500.0 \n",
      "Model_3_7100 \t loss_train = 36400964.0 \t loss_valid = 30475824.0 \n",
      "Model_3_7110 \t loss_train = 35384712.0 \t loss_valid = 29401116.0 \n",
      "Model_3_7120 \t loss_train = 35192624.0 \t loss_valid = 29291960.0 \n",
      "Model_3_7130 \t loss_train = 35926780.0 \t loss_valid = 29972568.0 \n",
      "Model_3_7140 \t loss_train = 35872292.0 \t loss_valid = 29913568.0 \n",
      "Model_3_7150 \t loss_train = 36071348.0 \t loss_valid = 29994568.0 \n",
      "Model_3_7160 \t loss_train = 36160160.0 \t loss_valid = 30157628.0 \n",
      "Model_3_7170 \t loss_train = 35304228.0 \t loss_valid = 29353794.0 \n",
      "Model_3_7180 \t loss_train = 36202128.0 \t loss_valid = 30182454.0 \n",
      "Model_3_7190 \t loss_train = 35836448.0 \t loss_valid = 29883456.0 \n",
      "Model_3_7200 \t loss_train = 35736904.0 \t loss_valid = 29710222.0 \n",
      "Model_3_7210 \t loss_train = 35131624.0 \t loss_valid = 29169636.0 \n",
      "Model_3_7220 \t loss_train = 36089700.0 \t loss_valid = 29991532.0 \n",
      "Model_3_7230 \t loss_train = 36087588.0 \t loss_valid = 30027668.0 \n",
      "Model_3_7240 \t loss_train = 35890092.0 \t loss_valid = 29871300.0 \n",
      "Model_3_7250 \t loss_train = 36199716.0 \t loss_valid = 30214968.0 \n",
      "Model_3_7260 \t loss_train = 35834704.0 \t loss_valid = 29851682.0 \n",
      "Model_3_7270 \t loss_train = 34803728.0 \t loss_valid = 28995306.0 \n",
      "Model_3_7280 \t loss_train = 35292320.0 \t loss_valid = 29331450.0 \n",
      "Model_3_7290 \t loss_train = 35056792.0 \t loss_valid = 29152114.0 \n",
      "Model_3_7300 \t loss_train = 35778752.0 \t loss_valid = 29786228.0 \n",
      "Model_3_7310 \t loss_train = 35735960.0 \t loss_valid = 29730664.0 \n",
      "Model_3_7320 \t loss_train = 35874760.0 \t loss_valid = 29906666.0 \n",
      "Model_3_7330 \t loss_train = 35929352.0 \t loss_valid = 29879290.0 \n",
      "Model_3_7340 \t loss_train = 35674264.0 \t loss_valid = 29633466.0 \n",
      "Model_3_7350 \t loss_train = 36016636.0 \t loss_valid = 29932630.0 \n",
      "Model_3_7360 \t loss_train = 35706808.0 \t loss_valid = 29813560.0 \n",
      "Model_3_7370 \t loss_train = 36215728.0 \t loss_valid = 30094128.0 \n",
      "Model_3_7380 \t loss_train = 35230264.0 \t loss_valid = 29279582.0 \n",
      "Model_3_7390 \t loss_train = 35824100.0 \t loss_valid = 29719476.0 \n",
      "Model_3_7400 \t loss_train = 35884908.0 \t loss_valid = 29942272.0 \n",
      "Model_3_7410 \t loss_train = 36358676.0 \t loss_valid = 30272274.0 \n",
      "Model_3_7420 \t loss_train = 36292268.0 \t loss_valid = 30161358.0 \n",
      "Model_3_7430 \t loss_train = 36326316.0 \t loss_valid = 30184394.0 \n",
      "Model_3_7440 \t loss_train = 35999072.0 \t loss_valid = 30079864.0 \n",
      "Model_3_7450 \t loss_train = 36006340.0 \t loss_valid = 29902744.0 \n",
      "Model_3_7460 \t loss_train = 36444848.0 \t loss_valid = 30501398.0 \n",
      "Model_3_7470 \t loss_train = 36122168.0 \t loss_valid = 30134690.0 \n",
      "Model_3_7480 \t loss_train = 35569916.0 \t loss_valid = 29556890.0 \n",
      "Model_3_7490 \t loss_train = 35979044.0 \t loss_valid = 29956620.0 \n",
      "Model_3_7500 \t loss_train = 36453260.0 \t loss_valid = 30432440.0 \n",
      "Model_3_7510 \t loss_train = 35868412.0 \t loss_valid = 29795180.0 \n",
      "Model_3_7520 \t loss_train = 36086464.0 \t loss_valid = 29971582.0 \n",
      "Model_3_7530 \t loss_train = 36637336.0 \t loss_valid = 30521958.0 \n",
      "Model_3_7540 \t loss_train = 36229708.0 \t loss_valid = 30120406.0 \n",
      "Model_3_7550 \t loss_train = 36398584.0 \t loss_valid = 30301798.0 \n",
      "Model_3_7560 \t loss_train = 36240108.0 \t loss_valid = 29992328.0 \n",
      "Model_3_7570 \t loss_train = 36306668.0 \t loss_valid = 30204682.0 \n",
      "Model_3_7580 \t loss_train = 36524244.0 \t loss_valid = 30389062.0 \n",
      "Model_3_7590 \t loss_train = 36265132.0 \t loss_valid = 30127910.0 \n",
      "Model_3_7600 \t loss_train = 36705064.0 \t loss_valid = 30472932.0 \n",
      "Model_3_7610 \t loss_train = 35695420.0 \t loss_valid = 29809648.0 \n",
      "Model_3_7620 \t loss_train = 36240356.0 \t loss_valid = 30152230.0 \n",
      "Model_3_7630 \t loss_train = 36683332.0 \t loss_valid = 30603886.0 \n",
      "Model_3_7640 \t loss_train = 35705712.0 \t loss_valid = 29668092.0 \n",
      "Model_3_7650 \t loss_train = 36123460.0 \t loss_valid = 30019504.0 \n",
      "Model_3_7660 \t loss_train = 36377636.0 \t loss_valid = 30152422.0 \n",
      "Model_3_7670 \t loss_train = 36596472.0 \t loss_valid = 30451940.0 \n",
      "Model_3_7680 \t loss_train = 36270652.0 \t loss_valid = 30233088.0 \n",
      "Model_3_7690 \t loss_train = 36502052.0 \t loss_valid = 30316074.0 \n",
      "Model_3_7700 \t loss_train = 36256900.0 \t loss_valid = 30095496.0 \n",
      "Model_3_7710 \t loss_train = 36297052.0 \t loss_valid = 30133154.0 \n",
      "Model_3_7720 \t loss_train = 36468360.0 \t loss_valid = 30366694.0 \n",
      "Model_3_7730 \t loss_train = 36407216.0 \t loss_valid = 30190830.0 \n",
      "Model_3_7740 \t loss_train = 36689328.0 \t loss_valid = 30503648.0 \n",
      "Model_3_7750 \t loss_train = 36542120.0 \t loss_valid = 30422082.0 \n",
      "Model_3_7760 \t loss_train = 36655200.0 \t loss_valid = 30557504.0 \n",
      "Model_3_7770 \t loss_train = 36641684.0 \t loss_valid = 30501094.0 \n",
      "Model_3_7780 \t loss_train = 36399780.0 \t loss_valid = 30391384.0 \n",
      "Model_3_7790 \t loss_train = 36812640.0 \t loss_valid = 30533256.0 \n",
      "Model_3_7800 \t loss_train = 35987356.0 \t loss_valid = 29873186.0 \n",
      "Model_3_7810 \t loss_train = 37141932.0 \t loss_valid = 30916020.0 \n",
      "Model_3_7820 \t loss_train = 36246212.0 \t loss_valid = 30100426.0 \n",
      "Model_3_7830 \t loss_train = 36447056.0 \t loss_valid = 30238202.0 \n",
      "Model_3_7840 \t loss_train = 35484292.0 \t loss_valid = 29229148.0 \n",
      "Model_3_7850 \t loss_train = 36613584.0 \t loss_valid = 30538130.0 \n",
      "Model_3_7860 \t loss_train = 36501116.0 \t loss_valid = 30219320.0 \n",
      "Model_3_7870 \t loss_train = 36348280.0 \t loss_valid = 30207476.0 \n",
      "Model_3_7880 \t loss_train = 36294456.0 \t loss_valid = 30082052.0 \n",
      "Model_3_7890 \t loss_train = 36916768.0 \t loss_valid = 30422082.0 \n",
      "Model_3_7900 \t loss_train = 36530108.0 \t loss_valid = 30387646.0 \n",
      "Model_3_7910 \t loss_train = 36821592.0 \t loss_valid = 30627628.0 \n",
      "Model_3_7920 \t loss_train = 37091236.0 \t loss_valid = 30882974.0 \n",
      "Model_3_7930 \t loss_train = 36516840.0 \t loss_valid = 30182930.0 \n",
      "Model_3_7940 \t loss_train = 36970708.0 \t loss_valid = 30677372.0 \n",
      "Model_3_7950 \t loss_train = 36376304.0 \t loss_valid = 30085620.0 \n",
      "Model_3_7960 \t loss_train = 36470548.0 \t loss_valid = 30271950.0 \n",
      "Model_3_7970 \t loss_train = 35935276.0 \t loss_valid = 29648690.0 \n",
      "Model_3_7980 \t loss_train = 36444204.0 \t loss_valid = 30357668.0 \n",
      "Model_3_7990 \t loss_train = 36579932.0 \t loss_valid = 30284706.0 \n",
      "Model_3_8000 \t loss_train = 36374104.0 \t loss_valid = 30060872.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_3_8010 \t loss_train = 37173076.0 \t loss_valid = 30904828.0 \n",
      "Model_3_8020 \t loss_train = 36825900.0 \t loss_valid = 30546296.0 \n",
      "Model_3_8030 \t loss_train = 36781020.0 \t loss_valid = 30536416.0 \n",
      "Model_3_8040 \t loss_train = 36725752.0 \t loss_valid = 30333466.0 \n",
      "Model_3_8050 \t loss_train = 37362912.0 \t loss_valid = 31193114.0 \n",
      "Model_3_8060 \t loss_train = 36954768.0 \t loss_valid = 30669742.0 \n",
      "Model_3_8070 \t loss_train = 37202364.0 \t loss_valid = 30907948.0 \n",
      "Model_3_8080 \t loss_train = 36429268.0 \t loss_valid = 30262196.0 \n",
      "Model_3_8090 \t loss_train = 37508852.0 \t loss_valid = 31135276.0 \n",
      "Model_3_8100 \t loss_train = 36747992.0 \t loss_valid = 30443668.0 \n",
      "Model_3_8110 \t loss_train = 37337576.0 \t loss_valid = 30963936.0 \n",
      "Model_3_8120 \t loss_train = 36776056.0 \t loss_valid = 30630732.0 \n",
      "Model_3_8130 \t loss_train = 36859192.0 \t loss_valid = 30604162.0 \n",
      "Model_3_8140 \t loss_train = 36356824.0 \t loss_valid = 30066650.0 \n",
      "Model_3_8150 \t loss_train = 36575488.0 \t loss_valid = 30294876.0 \n",
      "Model_3_8160 \t loss_train = 37135864.0 \t loss_valid = 30937072.0 \n",
      "Model_3_8170 \t loss_train = 37014700.0 \t loss_valid = 30631904.0 \n",
      "Model_3_8180 \t loss_train = 36709724.0 \t loss_valid = 30537450.0 \n",
      "Model_3_8190 \t loss_train = 37287312.0 \t loss_valid = 30944502.0 \n",
      "Model_3_8200 \t loss_train = 36742660.0 \t loss_valid = 30445428.0 \n",
      "Model_3_8210 \t loss_train = 37432136.0 \t loss_valid = 31080458.0 \n",
      "Model_3_8220 \t loss_train = 36997088.0 \t loss_valid = 30656876.0 \n",
      "Model_3_8230 \t loss_train = 36734980.0 \t loss_valid = 30565872.0 \n",
      "Model_3_8240 \t loss_train = 36916960.0 \t loss_valid = 30456702.0 \n",
      "Model_3_8250 \t loss_train = 37284800.0 \t loss_valid = 30961572.0 \n",
      "Model_3_8260 \t loss_train = 36927408.0 \t loss_valid = 30608694.0 \n",
      "Model_3_8270 \t loss_train = 37378888.0 \t loss_valid = 31087966.0 \n",
      "Model_3_8280 \t loss_train = 36863288.0 \t loss_valid = 30480998.0 \n",
      "Model_3_8290 \t loss_train = 37256616.0 \t loss_valid = 30978670.0 \n",
      "Model_3_8300 \t loss_train = 37240856.0 \t loss_valid = 30995994.0 \n",
      "Model_3_8310 \t loss_train = 37241084.0 \t loss_valid = 30856476.0 \n",
      "Model_3_8320 \t loss_train = 37075488.0 \t loss_valid = 30680370.0 \n",
      "Model_3_8330 \t loss_train = 37451280.0 \t loss_valid = 31145836.0 \n",
      "Model_3_8340 \t loss_train = 37155684.0 \t loss_valid = 30770556.0 \n",
      "Model_3_8350 \t loss_train = 37109620.0 \t loss_valid = 30746804.0 \n",
      "Model_3_8360 \t loss_train = 37104784.0 \t loss_valid = 30723660.0 \n",
      "Model_3_8370 \t loss_train = 37236416.0 \t loss_valid = 30859770.0 \n",
      "Model_3_8380 \t loss_train = 37291396.0 \t loss_valid = 31081836.0 \n",
      "Model_3_8390 \t loss_train = 37837644.0 \t loss_valid = 31355448.0 \n",
      "Model_3_8400 \t loss_train = 36809256.0 \t loss_valid = 30582930.0 \n",
      "Model_3_8410 \t loss_train = 38373900.0 \t loss_valid = 31863662.0 \n",
      "Model_3_8420 \t loss_train = 37105048.0 \t loss_valid = 30757556.0 \n",
      "Model_3_8430 \t loss_train = 37363028.0 \t loss_valid = 31040066.0 \n",
      "Model_3_8440 \t loss_train = 37582472.0 \t loss_valid = 31203618.0 \n",
      "Model_3_8450 \t loss_train = 37487280.0 \t loss_valid = 31104850.0 \n",
      "Model_3_8460 \t loss_train = 37134416.0 \t loss_valid = 30805912.0 \n",
      "Model_3_8470 \t loss_train = 37672128.0 \t loss_valid = 31335406.0 \n",
      "Model_3_8480 \t loss_train = 37523704.0 \t loss_valid = 31089974.0 \n",
      "Model_3_8490 \t loss_train = 37376388.0 \t loss_valid = 31033970.0 \n",
      "Model_3_8500 \t loss_train = 36895936.0 \t loss_valid = 30596374.0 \n",
      "Model_3_8510 \t loss_train = 37386584.0 \t loss_valid = 30883574.0 \n",
      "Model_3_8520 \t loss_train = 36828140.0 \t loss_valid = 30483708.0 \n",
      "Model_3_8530 \t loss_train = 37381020.0 \t loss_valid = 30841104.0 \n",
      "Model_3_8540 \t loss_train = 37611480.0 \t loss_valid = 31315494.0 \n",
      "Model_3_8550 \t loss_train = 37145608.0 \t loss_valid = 30765428.0 \n",
      "Model_3_8560 \t loss_train = 37705300.0 \t loss_valid = 31359564.0 \n",
      "Model_3_8570 \t loss_train = 37129036.0 \t loss_valid = 30843500.0 \n",
      "Model_3_8580 \t loss_train = 37084976.0 \t loss_valid = 30661278.0 \n",
      "Model_3_8590 \t loss_train = 36818280.0 \t loss_valid = 30327084.0 \n",
      "Model_3_8600 \t loss_train = 37263260.0 \t loss_valid = 30732916.0 \n",
      "Model_3_8610 \t loss_train = 37701176.0 \t loss_valid = 31255678.0 \n",
      "Model_3_8620 \t loss_train = 37389288.0 \t loss_valid = 30814506.0 \n",
      "Model_3_8630 \t loss_train = 38170936.0 \t loss_valid = 31715752.0 \n",
      "Model_3_8640 \t loss_train = 36942508.0 \t loss_valid = 30589630.0 \n",
      "Model_3_8650 \t loss_train = 37887796.0 \t loss_valid = 31609856.0 \n",
      "Model_3_8660 \t loss_train = 37544040.0 \t loss_valid = 30978882.0 \n",
      "Model_3_8670 \t loss_train = 37739240.0 \t loss_valid = 31399496.0 \n",
      "Model_3_8680 \t loss_train = 37627992.0 \t loss_valid = 31186286.0 \n",
      "Model_3_8690 \t loss_train = 37434580.0 \t loss_valid = 31010746.0 \n",
      "Model_3_8700 \t loss_train = 37825412.0 \t loss_valid = 31390708.0 \n",
      "Model_3_8710 \t loss_train = 37352236.0 \t loss_valid = 30964002.0 \n",
      "Model_3_8720 \t loss_train = 37743804.0 \t loss_valid = 31365676.0 \n",
      "Model_3_8730 \t loss_train = 37740612.0 \t loss_valid = 31425524.0 \n",
      "Model_3_8740 \t loss_train = 37531160.0 \t loss_valid = 31115428.0 \n",
      "Model_3_8750 \t loss_train = 37250844.0 \t loss_valid = 30966440.0 \n",
      "Model_3_8760 \t loss_train = 37914596.0 \t loss_valid = 31482228.0 \n",
      "Model_3_8770 \t loss_train = 37212100.0 \t loss_valid = 30805750.0 \n",
      "Model_3_8780 \t loss_train = 37712444.0 \t loss_valid = 31359178.0 \n",
      "Model_3_8790 \t loss_train = 38128912.0 \t loss_valid = 31728770.0 \n",
      "Model_3_8800 \t loss_train = 37341964.0 \t loss_valid = 30948516.0 \n",
      "Model_3_8810 \t loss_train = 37916500.0 \t loss_valid = 31420428.0 \n",
      "Model_3_8820 \t loss_train = 37475512.0 \t loss_valid = 31007484.0 \n",
      "Model_3_8830 \t loss_train = 36960524.0 \t loss_valid = 30492410.0 \n",
      "Model_3_8840 \t loss_train = 37337540.0 \t loss_valid = 30995340.0 \n",
      "Model_3_8850 \t loss_train = 37037224.0 \t loss_valid = 30477720.0 \n",
      "Model_3_8860 \t loss_train = 37190232.0 \t loss_valid = 30764594.0 \n",
      "Model_3_8870 \t loss_train = 37939808.0 \t loss_valid = 31390938.0 \n",
      "Model_3_8880 \t loss_train = 37066500.0 \t loss_valid = 30761282.0 \n",
      "Model_3_8890 \t loss_train = 38140844.0 \t loss_valid = 31662946.0 \n",
      "Model_3_8900 \t loss_train = 37582640.0 \t loss_valid = 31206488.0 \n",
      "Model_3_8910 \t loss_train = 37938424.0 \t loss_valid = 31378256.0 \n",
      "Model_3_8920 \t loss_train = 37675380.0 \t loss_valid = 31231504.0 \n",
      "Model_3_8930 \t loss_train = 37389464.0 \t loss_valid = 30994344.0 \n",
      "Model_3_8940 \t loss_train = 38578424.0 \t loss_valid = 32105346.0 \n",
      "Model_3_8950 \t loss_train = 37643384.0 \t loss_valid = 31112640.0 \n",
      "Model_3_8960 \t loss_train = 37705376.0 \t loss_valid = 31214950.0 \n",
      "Model_3_8970 \t loss_train = 38439388.0 \t loss_valid = 32085056.0 \n",
      "Model_3_8980 \t loss_train = 37487276.0 \t loss_valid = 30991654.0 \n",
      "Model_3_8990 \t loss_train = 37541296.0 \t loss_valid = 31087410.0 \n",
      "Model_3_9000 \t loss_train = 37431764.0 \t loss_valid = 31030212.0 \n",
      "Model_3_9010 \t loss_train = 37554512.0 \t loss_valid = 31156354.0 \n",
      "Model_3_9020 \t loss_train = 38018968.0 \t loss_valid = 31615194.0 \n",
      "Model_3_9030 \t loss_train = 37655956.0 \t loss_valid = 31313472.0 \n",
      "Model_3_9040 \t loss_train = 38122104.0 \t loss_valid = 31570316.0 \n",
      "Model_3_9050 \t loss_train = 37456096.0 \t loss_valid = 31079262.0 \n",
      "Model_3_9060 \t loss_train = 38056796.0 \t loss_valid = 31557540.0 \n",
      "Model_3_9070 \t loss_train = 37600108.0 \t loss_valid = 31172974.0 \n",
      "Model_3_9080 \t loss_train = 38151012.0 \t loss_valid = 31709070.0 \n",
      "Model_3_9090 \t loss_train = 37141396.0 \t loss_valid = 30717316.0 \n",
      "Model_3_9100 \t loss_train = 37977872.0 \t loss_valid = 31550922.0 \n",
      "Model_3_9110 \t loss_train = 37613032.0 \t loss_valid = 31265824.0 \n",
      "Model_3_9120 \t loss_train = 37752044.0 \t loss_valid = 31250268.0 \n",
      "Model_3_9130 \t loss_train = 37879208.0 \t loss_valid = 31505240.0 \n",
      "Model_3_9140 \t loss_train = 37644324.0 \t loss_valid = 31137290.0 \n",
      "Model_3_9150 \t loss_train = 37974184.0 \t loss_valid = 31560286.0 \n",
      "Model_3_9160 \t loss_train = 38264000.0 \t loss_valid = 31693442.0 \n",
      "Model_3_9170 \t loss_train = 38221116.0 \t loss_valid = 31772546.0 \n",
      "Model_3_9180 \t loss_train = 37370676.0 \t loss_valid = 30870000.0 \n",
      "Model_3_9190 \t loss_train = 37144840.0 \t loss_valid = 30754076.0 \n",
      "Model_3_9200 \t loss_train = 38066176.0 \t loss_valid = 31574178.0 \n",
      "Model_3_9210 \t loss_train = 37703928.0 \t loss_valid = 31235076.0 \n",
      "Model_3_9220 \t loss_train = 37843480.0 \t loss_valid = 31538514.0 \n",
      "Model_3_9230 \t loss_train = 37387416.0 \t loss_valid = 30910676.0 \n",
      "Model_3_9240 \t loss_train = 38387640.0 \t loss_valid = 31973478.0 \n",
      "Model_3_9250 \t loss_train = 37586224.0 \t loss_valid = 31034918.0 \n",
      "Model_3_9260 \t loss_train = 38031884.0 \t loss_valid = 31552572.0 \n",
      "Model_3_9270 \t loss_train = 37829272.0 \t loss_valid = 31409720.0 \n",
      "Model_3_9280 \t loss_train = 37901432.0 \t loss_valid = 31368546.0 \n",
      "Model_3_9290 \t loss_train = 38262196.0 \t loss_valid = 31781470.0 \n",
      "Model_3_9300 \t loss_train = 37098724.0 \t loss_valid = 30778434.0 \n",
      "Model_3_9310 \t loss_train = 38299900.0 \t loss_valid = 31739720.0 \n",
      "Model_3_9320 \t loss_train = 37093916.0 \t loss_valid = 30736884.0 \n",
      "Model_3_9330 \t loss_train = 38767384.0 \t loss_valid = 32229752.0 \n",
      "Model_3_9340 \t loss_train = 37666828.0 \t loss_valid = 31105268.0 \n",
      "Model_3_9350 \t loss_train = 37289740.0 \t loss_valid = 30790532.0 \n",
      "Model_3_9360 \t loss_train = 38132032.0 \t loss_valid = 31612056.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_3_9370 \t loss_train = 38282840.0 \t loss_valid = 31812362.0 \n",
      "Model_3_9380 \t loss_train = 38194880.0 \t loss_valid = 31719076.0 \n",
      "Model_3_9390 \t loss_train = 37704588.0 \t loss_valid = 31262340.0 \n",
      "Model_3_9400 \t loss_train = 38401720.0 \t loss_valid = 31863014.0 \n",
      "Model_3_9410 \t loss_train = 38285616.0 \t loss_valid = 31795320.0 \n",
      "Model_3_9420 \t loss_train = 37790620.0 \t loss_valid = 31284062.0 \n",
      "Model_3_9430 \t loss_train = 38143900.0 \t loss_valid = 31635032.0 \n",
      "Model_3_9440 \t loss_train = 37546292.0 \t loss_valid = 31104026.0 \n",
      "Model_3_9450 \t loss_train = 37881876.0 \t loss_valid = 31378450.0 \n",
      "Model_3_9460 \t loss_train = 37635348.0 \t loss_valid = 31247606.0 \n",
      "Model_3_9470 \t loss_train = 37576204.0 \t loss_valid = 31191350.0 \n",
      "Model_3_9480 \t loss_train = 38527196.0 \t loss_valid = 32042098.0 \n",
      "Model_3_9490 \t loss_train = 38007260.0 \t loss_valid = 31511616.0 \n",
      "Model_3_9500 \t loss_train = 38472776.0 \t loss_valid = 31951386.0 \n",
      "Model_3_9510 \t loss_train = 37755180.0 \t loss_valid = 31285260.0 \n",
      "Model_3_9520 \t loss_train = 38485376.0 \t loss_valid = 32006602.0 \n",
      "Model_3_9530 \t loss_train = 37768704.0 \t loss_valid = 31322206.0 \n",
      "Model_3_9540 \t loss_train = 38527792.0 \t loss_valid = 32012412.0 \n",
      "Model_3_9550 \t loss_train = 37530516.0 \t loss_valid = 31109274.0 \n",
      "Model_3_9560 \t loss_train = 37706540.0 \t loss_valid = 31223340.0 \n",
      "Model_3_9570 \t loss_train = 38115992.0 \t loss_valid = 31643878.0 \n",
      "Model_3_9580 \t loss_train = 38281932.0 \t loss_valid = 31776234.0 \n",
      "Model_3_9590 \t loss_train = 37817580.0 \t loss_valid = 31221084.0 \n",
      "Model_3_9600 \t loss_train = 38285684.0 \t loss_valid = 31741904.0 \n",
      "Model_3_9610 \t loss_train = 37582764.0 \t loss_valid = 31226334.0 \n",
      "Model_3_9620 \t loss_train = 38654416.0 \t loss_valid = 32068472.0 \n",
      "Model_3_9630 \t loss_train = 37897592.0 \t loss_valid = 31419244.0 \n",
      "Model_3_9640 \t loss_train = 37303536.0 \t loss_valid = 30907976.0 \n",
      "Model_3_9650 \t loss_train = 38081360.0 \t loss_valid = 31373470.0 \n",
      "Model_3_9660 \t loss_train = 37516524.0 \t loss_valid = 31227690.0 \n",
      "Model_3_9670 \t loss_train = 37959892.0 \t loss_valid = 31319378.0 \n",
      "Model_3_9680 \t loss_train = 37609604.0 \t loss_valid = 31199080.0 \n",
      "Model_3_9690 \t loss_train = 37862564.0 \t loss_valid = 31403418.0 \n",
      "Model_3_9700 \t loss_train = 38269664.0 \t loss_valid = 31749252.0 \n",
      "Model_3_9710 \t loss_train = 37977804.0 \t loss_valid = 31426522.0 \n",
      "Model_3_9720 \t loss_train = 38389040.0 \t loss_valid = 31873530.0 \n",
      "Model_3_9730 \t loss_train = 38305496.0 \t loss_valid = 31809924.0 \n",
      "Model_3_9740 \t loss_train = 38198624.0 \t loss_valid = 31664516.0 \n",
      "Model_3_9750 \t loss_train = 37767088.0 \t loss_valid = 31350294.0 \n",
      "Model_3_9760 \t loss_train = 38734044.0 \t loss_valid = 32183088.0 \n",
      "Model_3_9770 \t loss_train = 37720676.0 \t loss_valid = 31261488.0 \n",
      "Model_3_9780 \t loss_train = 38179524.0 \t loss_valid = 31710294.0 \n",
      "Model_3_9790 \t loss_train = 37875616.0 \t loss_valid = 31409632.0 \n",
      "Model_3_9800 \t loss_train = 38084316.0 \t loss_valid = 31581974.0 \n",
      "Model_3_9810 \t loss_train = 38145200.0 \t loss_valid = 31717146.0 \n",
      "Model_3_9820 \t loss_train = 37812852.0 \t loss_valid = 31275292.0 \n",
      "Model_3_9830 \t loss_train = 37867136.0 \t loss_valid = 31481038.0 \n",
      "Model_3_9840 \t loss_train = 38336340.0 \t loss_valid = 31854690.0 \n",
      "Model_3_9850 \t loss_train = 38318076.0 \t loss_valid = 31798768.0 \n",
      "Model_3_9860 \t loss_train = 37793076.0 \t loss_valid = 31344498.0 \n",
      "Model_3_9870 \t loss_train = 38605940.0 \t loss_valid = 32067182.0 \n",
      "Model_3_9880 \t loss_train = 37438252.0 \t loss_valid = 31034368.0 \n",
      "Model_3_9890 \t loss_train = 38248312.0 \t loss_valid = 31714086.0 \n",
      "Model_3_9900 \t loss_train = 38417212.0 \t loss_valid = 31974314.0 \n",
      "Model_3_9910 \t loss_train = 38141876.0 \t loss_valid = 31557316.0 \n",
      "Model_3_9920 \t loss_train = 38283672.0 \t loss_valid = 31823316.0 \n",
      "Model_3_9930 \t loss_train = 38246496.0 \t loss_valid = 31675246.0 \n",
      "Model_3_9940 \t loss_train = 37852100.0 \t loss_valid = 31417720.0 \n",
      "Model_3_9950 \t loss_train = 38719568.0 \t loss_valid = 32104616.0 \n",
      "Model_3_9960 \t loss_train = 38118840.0 \t loss_valid = 31730442.0 \n",
      "Model_3_9970 \t loss_train = 38401536.0 \t loss_valid = 31828088.0 \n",
      "Model_3_9980 \t loss_train = 37873860.0 \t loss_valid = 31452684.0 \n",
      "Model_3_9990 \t loss_train = 38204652.0 \t loss_valid = 31646948.0 \n",
      "Model_3_10000 \t loss_train = 37984692.0 \t loss_valid = 31472772.0 \n",
      "Model_3_10010 \t loss_train = 37989828.0 \t loss_valid = 31468412.0 \n",
      "Model_3_10020 \t loss_train = 38312184.0 \t loss_valid = 31855018.0 \n",
      "Model_3_10030 \t loss_train = 38176616.0 \t loss_valid = 31688220.0 \n",
      "Model_3_10040 \t loss_train = 38103192.0 \t loss_valid = 31535252.0 \n",
      "Model_3_10050 \t loss_train = 38045960.0 \t loss_valid = 31601548.0 \n",
      "Model_3_10060 \t loss_train = 38504544.0 \t loss_valid = 31892792.0 \n",
      "Model_3_10070 \t loss_train = 38210240.0 \t loss_valid = 31703618.0 \n",
      "Model_3_10080 \t loss_train = 38339540.0 \t loss_valid = 31799720.0 \n",
      "Model_3_10090 \t loss_train = 38533764.0 \t loss_valid = 32106416.0 \n",
      "Model_3_10100 \t loss_train = 37817596.0 \t loss_valid = 31248786.0 \n",
      "Model_3_10110 \t loss_train = 38034060.0 \t loss_valid = 31600802.0 \n",
      "Model_3_10120 \t loss_train = 37961632.0 \t loss_valid = 31388496.0 \n",
      "Model_3_10130 \t loss_train = 38186216.0 \t loss_valid = 31703536.0 \n",
      "Model_3_10140 \t loss_train = 38049608.0 \t loss_valid = 31474096.0 \n",
      "Model_3_10150 \t loss_train = 38081952.0 \t loss_valid = 31664840.0 \n",
      "Model_3_10160 \t loss_train = 38006152.0 \t loss_valid = 31512678.0 \n",
      "Model_3_10170 \t loss_train = 38164332.0 \t loss_valid = 31661444.0 \n",
      "Model_3_10180 \t loss_train = 38581828.0 \t loss_valid = 32039860.0 \n",
      "Model_3_10190 \t loss_train = 37875344.0 \t loss_valid = 31417502.0 \n",
      "Model_3_10200 \t loss_train = 38088612.0 \t loss_valid = 31457596.0 \n",
      "Model_3_10210 \t loss_train = 37958180.0 \t loss_valid = 31435668.0 \n",
      "Model_3_10220 \t loss_train = 38220212.0 \t loss_valid = 31651088.0 \n",
      "Model_3_10230 \t loss_train = 38434612.0 \t loss_valid = 31858488.0 \n",
      "Model_3_10240 \t loss_train = 38407064.0 \t loss_valid = 31894192.0 \n",
      "Model_3_10250 \t loss_train = 37951576.0 \t loss_valid = 31448582.0 \n",
      "Model_3_10260 \t loss_train = 38859640.0 \t loss_valid = 32279714.0 \n",
      "Model_3_10270 \t loss_train = 37477160.0 \t loss_valid = 30992896.0 \n",
      "Model_3_10280 \t loss_train = 38943132.0 \t loss_valid = 32426846.0 \n",
      "Model_3_10290 \t loss_train = 37963200.0 \t loss_valid = 31423570.0 \n",
      "Model_3_10300 \t loss_train = 38074240.0 \t loss_valid = 31586800.0 \n",
      "Model_3_10310 \t loss_train = 38307416.0 \t loss_valid = 31792966.0 \n",
      "Model_3_10320 \t loss_train = 37622688.0 \t loss_valid = 31159278.0 \n",
      "Model_3_10330 \t loss_train = 38660684.0 \t loss_valid = 32085592.0 \n",
      "Model_3_10340 \t loss_train = 37556692.0 \t loss_valid = 31037458.0 \n",
      "Model_3_10350 \t loss_train = 38421684.0 \t loss_valid = 31964542.0 \n",
      "Model_3_10360 \t loss_train = 38336368.0 \t loss_valid = 31794264.0 \n",
      "Model_3_10370 \t loss_train = 38388952.0 \t loss_valid = 31863902.0 \n",
      "Model_3_10380 \t loss_train = 38150156.0 \t loss_valid = 31685410.0 \n",
      "Model_3_10390 \t loss_train = 38421564.0 \t loss_valid = 31836020.0 \n",
      "Model_3_10400 \t loss_train = 38194992.0 \t loss_valid = 31635656.0 \n",
      "Model_3_10410 \t loss_train = 37902156.0 \t loss_valid = 31453582.0 \n",
      "Model_3_10420 \t loss_train = 38370232.0 \t loss_valid = 31658582.0 \n",
      "Model_3_10430 \t loss_train = 38007384.0 \t loss_valid = 31454840.0 \n",
      "Model_3_10440 \t loss_train = 38353176.0 \t loss_valid = 31756424.0 \n",
      "Model_3_10450 \t loss_train = 38067264.0 \t loss_valid = 31529332.0 \n",
      "Model_3_10460 \t loss_train = 38094888.0 \t loss_valid = 31605592.0 \n",
      "Model_3_10470 \t loss_train = 38425264.0 \t loss_valid = 31871190.0 \n",
      "Model_3_10480 \t loss_train = 38123952.0 \t loss_valid = 31632464.0 \n",
      "Model_3_10490 \t loss_train = 38760232.0 \t loss_valid = 32146912.0 \n",
      "Model_3_10500 \t loss_train = 37750096.0 \t loss_valid = 31349204.0 \n",
      "Model_3_10510 \t loss_train = 38723908.0 \t loss_valid = 32078924.0 \n",
      "Model_3_10520 \t loss_train = 38044728.0 \t loss_valid = 31605204.0 \n",
      "Model_3_10530 \t loss_train = 38211360.0 \t loss_valid = 31684356.0 \n",
      "Model_3_10540 \t loss_train = 37959128.0 \t loss_valid = 31443968.0 \n",
      "Model_3_10550 \t loss_train = 38878432.0 \t loss_valid = 32338014.0 \n",
      "Model_3_10560 \t loss_train = 38636868.0 \t loss_valid = 32002946.0 \n",
      "Model_3_10570 \t loss_train = 37750312.0 \t loss_valid = 31297352.0 \n",
      "Model_3_10580 \t loss_train = 38768908.0 \t loss_valid = 32235170.0 \n",
      "Model_3_10590 \t loss_train = 38092296.0 \t loss_valid = 31572388.0 \n",
      "Model_3_10600 \t loss_train = 38277460.0 \t loss_valid = 31732704.0 \n",
      "Model_3_10610 \t loss_train = 38118788.0 \t loss_valid = 31601004.0 \n",
      "Model_3_10620 \t loss_train = 38557648.0 \t loss_valid = 32031226.0 \n",
      "Model_3_10630 \t loss_train = 37809368.0 \t loss_valid = 31270992.0 \n",
      "Model_3_10640 \t loss_train = 38382548.0 \t loss_valid = 31940836.0 \n",
      "Model_3_10650 \t loss_train = 38021192.0 \t loss_valid = 31508502.0 \n",
      "Model_3_10660 \t loss_train = 38200572.0 \t loss_valid = 31712692.0 \n",
      "Model_3_10670 \t loss_train = 38334596.0 \t loss_valid = 31796938.0 \n",
      "Model_3_10680 \t loss_train = 38498772.0 \t loss_valid = 32076604.0 \n",
      "Model_3_10690 \t loss_train = 38037924.0 \t loss_valid = 31453776.0 \n",
      "Model_3_10700 \t loss_train = 38355028.0 \t loss_valid = 31839412.0 \n",
      "Model_3_10710 \t loss_train = 38221156.0 \t loss_valid = 31682058.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_3_10720 \t loss_train = 38463424.0 \t loss_valid = 31931322.0 \n",
      "Model_3_10730 \t loss_train = 38543836.0 \t loss_valid = 31992866.0 \n",
      "Model_3_10740 \t loss_train = 37901404.0 \t loss_valid = 31388970.0 \n",
      "Model_3_10750 \t loss_train = 39046084.0 \t loss_valid = 32500948.0 \n",
      "Model_3_10760 \t loss_train = 37644156.0 \t loss_valid = 31153386.0 \n",
      "Model_3_10770 \t loss_train = 38283436.0 \t loss_valid = 31798164.0 \n",
      "Model_3_10780 \t loss_train = 38228228.0 \t loss_valid = 31678678.0 \n",
      "Model_3_10790 \t loss_train = 38165140.0 \t loss_valid = 31572498.0 \n",
      "Model_3_10800 \t loss_train = 38263476.0 \t loss_valid = 31778074.0 \n",
      "Model_3_10810 \t loss_train = 38044284.0 \t loss_valid = 31488636.0 \n",
      "Model_3_10820 \t loss_train = 38107816.0 \t loss_valid = 31609888.0 \n",
      "Model_3_10830 \t loss_train = 38356420.0 \t loss_valid = 31729976.0 \n",
      "Model_3_10840 \t loss_train = 38268324.0 \t loss_valid = 31809840.0 \n",
      "Model_3_10850 \t loss_train = 38096672.0 \t loss_valid = 31514410.0 \n",
      "Model_3_10860 \t loss_train = 38357580.0 \t loss_valid = 31899034.0 \n",
      "Model_3_10870 \t loss_train = 38162960.0 \t loss_valid = 31690108.0 \n",
      "Model_3_10880 \t loss_train = 38074328.0 \t loss_valid = 31577686.0 \n",
      "Model_3_10890 \t loss_train = 38002016.0 \t loss_valid = 31518922.0 \n",
      "Model_3_10900 \t loss_train = 37730228.0 \t loss_valid = 31274426.0 \n",
      "Model_3_10910 \t loss_train = 38556356.0 \t loss_valid = 31932694.0 \n",
      "Model_3_10920 \t loss_train = 37909864.0 \t loss_valid = 31495490.0 \n",
      "Model_3_10930 \t loss_train = 38165528.0 \t loss_valid = 31533536.0 \n",
      "Model_3_10940 \t loss_train = 37977320.0 \t loss_valid = 31571156.0 \n",
      "Model_3_10950 \t loss_train = 38362560.0 \t loss_valid = 31766180.0 \n",
      "Model_3_10960 \t loss_train = 38181392.0 \t loss_valid = 31625618.0 \n",
      "Model_3_10970 \t loss_train = 38589196.0 \t loss_valid = 32091844.0 \n",
      "Model_3_10980 \t loss_train = 38033032.0 \t loss_valid = 31511586.0 \n",
      "Model_3_10990 \t loss_train = 38625272.0 \t loss_valid = 32073800.0 \n",
      "Model_3_11000 \t loss_train = 37712552.0 \t loss_valid = 31216878.0 \n",
      "Model_3_11010 \t loss_train = 38594860.0 \t loss_valid = 32003786.0 \n",
      "Model_3_11020 \t loss_train = 38108596.0 \t loss_valid = 31648168.0 \n",
      "Model_3_11030 \t loss_train = 38675116.0 \t loss_valid = 32109872.0 \n",
      "Model_3_11040 \t loss_train = 37696136.0 \t loss_valid = 31235098.0 \n",
      "Model_3_11050 \t loss_train = 39010076.0 \t loss_valid = 32442378.0 \n",
      "Model_3_11060 \t loss_train = 37978032.0 \t loss_valid = 31504612.0 \n",
      "Model_3_11070 \t loss_train = 38614348.0 \t loss_valid = 32050548.0 \n",
      "Model_3_11080 \t loss_train = 38152972.0 \t loss_valid = 31649508.0 \n",
      "Model_3_11090 \t loss_train = 38068952.0 \t loss_valid = 31568672.0 \n",
      "Model_3_11100 \t loss_train = 39104692.0 \t loss_valid = 32542688.0 \n",
      "Model_3_11110 \t loss_train = 37588656.0 \t loss_valid = 31098438.0 \n",
      "Model_3_11120 \t loss_train = 38293256.0 \t loss_valid = 31833556.0 \n",
      "Model_3_11130 \t loss_train = 38011480.0 \t loss_valid = 31499252.0 \n",
      "Model_3_11140 \t loss_train = 38567460.0 \t loss_valid = 32068380.0 \n",
      "Model_3_11150 \t loss_train = 37965816.0 \t loss_valid = 31303022.0 \n",
      "Model_3_11160 \t loss_train = 37881016.0 \t loss_valid = 31286376.0 \n",
      "Model_3_11170 \t loss_train = 37743464.0 \t loss_valid = 31109860.0 \n",
      "Model_3_11180 \t loss_train = 38087292.0 \t loss_valid = 31493708.0 \n",
      "Model_3_11190 \t loss_train = 38510824.0 \t loss_valid = 31883042.0 \n",
      "Model_3_11200 \t loss_train = 38079612.0 \t loss_valid = 31524364.0 \n",
      "Model_3_11210 \t loss_train = 38509800.0 \t loss_valid = 31818802.0 \n",
      "Model_3_11220 \t loss_train = 37892236.0 \t loss_valid = 31407844.0 \n",
      "Model_3_11230 \t loss_train = 38317032.0 \t loss_valid = 31636408.0 \n",
      "Model_3_11240 \t loss_train = 37659028.0 \t loss_valid = 31062082.0 \n",
      "Model_3_11250 \t loss_train = 38078756.0 \t loss_valid = 31578364.0 \n",
      "Model_3_11260 \t loss_train = 38118640.0 \t loss_valid = 31414262.0 \n",
      "Model_3_11270 \t loss_train = 37747492.0 \t loss_valid = 31204320.0 \n",
      "Model_3_11280 \t loss_train = 38705604.0 \t loss_valid = 32080314.0 \n",
      "Model_3_11290 \t loss_train = 38063672.0 \t loss_valid = 31561310.0 \n",
      "Model_3_11300 \t loss_train = 38967384.0 \t loss_valid = 32402572.0 \n",
      "Model_3_11310 \t loss_train = 37951980.0 \t loss_valid = 31363236.0 \n",
      "Model_3_11320 \t loss_train = 38443260.0 \t loss_valid = 31967898.0 \n",
      "Early stopping!\n",
      "Model_4_0 \t loss_train = 119133304.0 \t loss_valid = 104019320.0 \n",
      "Model_4_10 \t loss_train = 116992264.0 \t loss_valid = 101323272.0 \n",
      "Model_4_20 \t loss_train = 112800520.0 \t loss_valid = 95824848.0 \n",
      "Model_4_30 \t loss_train = 104095232.0 \t loss_valid = 84827400.0 \n",
      "Model_4_40 \t loss_train = 88233624.0 \t loss_valid = 66962736.0 \n",
      "Model_4_50 \t loss_train = 71700408.0 \t loss_valid = 59980232.0 \n",
      "Model_4_60 \t loss_train = 70661656.0 \t loss_valid = 71616576.0 \n",
      "Model_4_70 \t loss_train = 69662096.0 \t loss_valid = 58246680.0 \n",
      "Model_4_80 \t loss_train = 68460528.0 \t loss_valid = 57219276.0 \n",
      "Model_4_90 \t loss_train = 66649076.0 \t loss_valid = 57701312.0 \n",
      "Model_4_100 \t loss_train = 65285320.0 \t loss_valid = 56376536.0 \n",
      "Model_4_110 \t loss_train = 64215636.0 \t loss_valid = 53972044.0 \n",
      "Model_4_120 \t loss_train = 62449304.0 \t loss_valid = 52900184.0 \n",
      "Model_4_130 \t loss_train = 61057020.0 \t loss_valid = 50629032.0 \n",
      "Model_4_140 \t loss_train = 59269916.0 \t loss_valid = 49054036.0 \n",
      "Model_4_150 \t loss_train = 58160508.0 \t loss_valid = 46675700.0 \n",
      "Model_4_160 \t loss_train = 56223588.0 \t loss_valid = 45726576.0 \n",
      "Model_4_170 \t loss_train = 55667264.0 \t loss_valid = 43734636.0 \n",
      "Model_4_180 \t loss_train = 54835300.0 \t loss_valid = 42814520.0 \n",
      "Model_4_190 \t loss_train = 53887528.0 \t loss_valid = 42485948.0 \n",
      "Model_4_200 \t loss_train = 53701856.0 \t loss_valid = 41922200.0 \n",
      "Model_4_210 \t loss_train = 53452320.0 \t loss_valid = 41531008.0 \n",
      "Model_4_220 \t loss_train = 52544192.0 \t loss_valid = 41744708.0 \n",
      "Model_4_230 \t loss_train = 52914752.0 \t loss_valid = 41220184.0 \n",
      "Model_4_240 \t loss_train = 52650516.0 \t loss_valid = 41018976.0 \n",
      "Model_4_250 \t loss_train = 51596228.0 \t loss_valid = 41858800.0 \n",
      "Model_4_260 \t loss_train = 52492532.0 \t loss_valid = 40730624.0 \n",
      "Model_4_270 \t loss_train = 51218052.0 \t loss_valid = 40767948.0 \n",
      "Model_4_280 \t loss_train = 50882876.0 \t loss_valid = 40483492.0 \n",
      "Model_4_290 \t loss_train = 51388904.0 \t loss_valid = 40019004.0 \n",
      "Model_4_300 \t loss_train = 50264396.0 \t loss_valid = 40210908.0 \n",
      "Model_4_310 \t loss_train = 50300116.0 \t loss_valid = 39907992.0 \n",
      "Model_4_320 \t loss_train = 49365396.0 \t loss_valid = 39827688.0 \n",
      "Model_4_330 \t loss_train = 49275380.0 \t loss_valid = 39198416.0 \n",
      "Model_4_340 \t loss_train = 48980692.0 \t loss_valid = 38616392.0 \n",
      "Model_4_350 \t loss_train = 48408180.0 \t loss_valid = 38238220.0 \n",
      "Model_4_360 \t loss_train = 46906536.0 \t loss_valid = 38796932.0 \n",
      "Model_4_370 \t loss_train = 47391016.0 \t loss_valid = 37636792.0 \n",
      "Model_4_380 \t loss_train = 45402648.0 \t loss_valid = 37627760.0 \n",
      "Model_4_390 \t loss_train = 45103256.0 \t loss_valid = 36566760.0 \n",
      "Model_4_400 \t loss_train = 43662148.0 \t loss_valid = 36337020.0 \n",
      "Model_4_410 \t loss_train = 42431316.0 \t loss_valid = 35947240.0 \n",
      "Model_4_420 \t loss_train = 41257940.0 \t loss_valid = 34731828.0 \n",
      "Model_4_430 \t loss_train = 40451088.0 \t loss_valid = 33807544.0 \n",
      "Model_4_440 \t loss_train = 38519244.0 \t loss_valid = 32920696.0 \n",
      "Model_4_450 \t loss_train = 36587116.0 \t loss_valid = 32194842.0 \n",
      "Model_4_460 \t loss_train = 34768132.0 \t loss_valid = 31131708.0 \n",
      "Model_4_470 \t loss_train = 33072968.0 \t loss_valid = 30517668.0 \n",
      "Model_4_480 \t loss_train = 31723794.0 \t loss_valid = 29804708.0 \n",
      "Model_4_490 \t loss_train = 32073632.0 \t loss_valid = 28956274.0 \n",
      "Model_4_500 \t loss_train = 30381430.0 \t loss_valid = 27973110.0 \n",
      "Model_4_510 \t loss_train = 29638890.0 \t loss_valid = 27699166.0 \n",
      "Model_4_520 \t loss_train = 29494230.0 \t loss_valid = 27081574.0 \n",
      "Model_4_530 \t loss_train = 29600838.0 \t loss_valid = 26798636.0 \n",
      "Model_4_540 \t loss_train = 29471360.0 \t loss_valid = 26502942.0 \n",
      "Model_4_550 \t loss_train = 29563958.0 \t loss_valid = 26565762.0 \n",
      "Model_4_560 \t loss_train = 28754406.0 \t loss_valid = 26674732.0 \n",
      "Model_4_570 \t loss_train = 29999908.0 \t loss_valid = 26758264.0 \n",
      "Model_4_580 \t loss_train = 28636442.0 \t loss_valid = 26847732.0 \n",
      "Model_4_590 \t loss_train = 29335892.0 \t loss_valid = 26164720.0 \n",
      "Model_4_600 \t loss_train = 29255414.0 \t loss_valid = 26137272.0 \n",
      "Model_4_610 \t loss_train = 28779014.0 \t loss_valid = 25980050.0 \n",
      "Model_4_620 \t loss_train = 28775484.0 \t loss_valid = 25927050.0 \n",
      "Model_4_630 \t loss_train = 29058874.0 \t loss_valid = 25857864.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_4_640 \t loss_train = 28752672.0 \t loss_valid = 25939618.0 \n",
      "Model_4_650 \t loss_train = 29344548.0 \t loss_valid = 26094714.0 \n",
      "Model_4_660 \t loss_train = 28426678.0 \t loss_valid = 26278226.0 \n",
      "Model_4_670 \t loss_train = 29736128.0 \t loss_valid = 26382520.0 \n",
      "Model_4_680 \t loss_train = 28435876.0 \t loss_valid = 25752950.0 \n",
      "Model_4_690 \t loss_train = 29227390.0 \t loss_valid = 25863948.0 \n",
      "Model_4_700 \t loss_train = 28805146.0 \t loss_valid = 25714748.0 \n",
      "Model_4_710 \t loss_train = 28514290.0 \t loss_valid = 25832704.0 \n",
      "Model_4_720 \t loss_train = 29167906.0 \t loss_valid = 25865302.0 \n",
      "Model_4_730 \t loss_train = 28543622.0 \t loss_valid = 25640256.0 \n",
      "Model_4_740 \t loss_train = 29779574.0 \t loss_valid = 26313134.0 \n",
      "Model_4_750 \t loss_train = 28840446.0 \t loss_valid = 25615756.0 \n",
      "Model_4_760 \t loss_train = 28586640.0 \t loss_valid = 25555920.0 \n",
      "Model_4_770 \t loss_train = 29064380.0 \t loss_valid = 25707766.0 \n",
      "Model_4_780 \t loss_train = 28719574.0 \t loss_valid = 25552156.0 \n",
      "Model_4_790 \t loss_train = 29445286.0 \t loss_valid = 26031220.0 \n",
      "Model_4_800 \t loss_train = 28564918.0 \t loss_valid = 25563196.0 \n",
      "Model_4_810 \t loss_train = 28574564.0 \t loss_valid = 25476464.0 \n",
      "Model_4_820 \t loss_train = 28424142.0 \t loss_valid = 25645404.0 \n",
      "Model_4_830 \t loss_train = 29123108.0 \t loss_valid = 25687416.0 \n",
      "Model_4_840 \t loss_train = 28304044.0 \t loss_valid = 25917640.0 \n",
      "Model_4_850 \t loss_train = 28895816.0 \t loss_valid = 25558020.0 \n",
      "Model_4_860 \t loss_train = 28534158.0 \t loss_valid = 25500270.0 \n",
      "Model_4_870 \t loss_train = 28557092.0 \t loss_valid = 25435914.0 \n",
      "Model_4_880 \t loss_train = 28780124.0 \t loss_valid = 25470816.0 \n",
      "Model_4_890 \t loss_train = 29237702.0 \t loss_valid = 25772540.0 \n",
      "Model_4_900 \t loss_train = 28561912.0 \t loss_valid = 25456882.0 \n",
      "Model_4_910 \t loss_train = 30040282.0 \t loss_valid = 26402084.0 \n",
      "Model_4_920 \t loss_train = 28749944.0 \t loss_valid = 25488214.0 \n",
      "Model_4_930 \t loss_train = 28470474.0 \t loss_valid = 25488140.0 \n",
      "Model_4_940 \t loss_train = 28639010.0 \t loss_valid = 25460868.0 \n",
      "Model_4_950 \t loss_train = 28751046.0 \t loss_valid = 25480974.0 \n",
      "Model_4_960 \t loss_train = 28751388.0 \t loss_valid = 25496534.0 \n",
      "Model_4_970 \t loss_train = 29210432.0 \t loss_valid = 25658658.0 \n",
      "Model_4_980 \t loss_train = 28577728.0 \t loss_valid = 25417798.0 \n",
      "Model_4_990 \t loss_train = 29316202.0 \t loss_valid = 25688390.0 \n",
      "Model_4_1000 \t loss_train = 29041686.0 \t loss_valid = 25629744.0 \n",
      "Model_4_1010 \t loss_train = 28650398.0 \t loss_valid = 25442682.0 \n",
      "Model_4_1020 \t loss_train = 28987504.0 \t loss_valid = 25548354.0 \n",
      "Model_4_1030 \t loss_train = 29267722.0 \t loss_valid = 25654470.0 \n",
      "Model_4_1040 \t loss_train = 28669012.0 \t loss_valid = 25420364.0 \n",
      "Model_4_1050 \t loss_train = 29341528.0 \t loss_valid = 25697874.0 \n",
      "Model_4_1060 \t loss_train = 29738420.0 \t loss_valid = 25965918.0 \n",
      "Model_4_1070 \t loss_train = 29012464.0 \t loss_valid = 25543810.0 \n",
      "Model_4_1080 \t loss_train = 29078974.0 \t loss_valid = 25561822.0 \n",
      "Model_4_1090 \t loss_train = 29384528.0 \t loss_valid = 25762488.0 \n",
      "Model_4_1100 \t loss_train = 29188360.0 \t loss_valid = 25593188.0 \n",
      "Model_4_1110 \t loss_train = 28937656.0 \t loss_valid = 25461164.0 \n",
      "Model_4_1120 \t loss_train = 29676204.0 \t loss_valid = 25875602.0 \n",
      "Model_4_1130 \t loss_train = 29139098.0 \t loss_valid = 25590158.0 \n",
      "Model_4_1140 \t loss_train = 29267686.0 \t loss_valid = 25564728.0 \n",
      "Model_4_1150 \t loss_train = 29840222.0 \t loss_valid = 26103040.0 \n",
      "Model_4_1160 \t loss_train = 29269592.0 \t loss_valid = 25574220.0 \n",
      "Model_4_1170 \t loss_train = 30263990.0 \t loss_valid = 26401408.0 \n",
      "Model_4_1180 \t loss_train = 28922026.0 \t loss_valid = 25472298.0 \n",
      "Model_4_1190 \t loss_train = 29920492.0 \t loss_valid = 26095420.0 \n",
      "Model_4_1200 \t loss_train = 29195598.0 \t loss_valid = 25569954.0 \n",
      "Model_4_1210 \t loss_train = 29502014.0 \t loss_valid = 25708140.0 \n",
      "Model_4_1220 \t loss_train = 28963810.0 \t loss_valid = 25458058.0 \n",
      "Model_4_1230 \t loss_train = 29265890.0 \t loss_valid = 25562734.0 \n",
      "Model_4_1240 \t loss_train = 29277906.0 \t loss_valid = 25554662.0 \n",
      "Model_4_1250 \t loss_train = 30245424.0 \t loss_valid = 26324560.0 \n",
      "Model_4_1260 \t loss_train = 29445766.0 \t loss_valid = 25610530.0 \n",
      "Model_4_1270 \t loss_train = 30014006.0 \t loss_valid = 26016612.0 \n",
      "Model_4_1280 \t loss_train = 29313186.0 \t loss_valid = 25589360.0 \n",
      "Model_4_1290 \t loss_train = 29391898.0 \t loss_valid = 25606944.0 \n",
      "Model_4_1300 \t loss_train = 30083576.0 \t loss_valid = 26098944.0 \n",
      "Model_4_1310 \t loss_train = 29365966.0 \t loss_valid = 25610514.0 \n",
      "Model_4_1320 \t loss_train = 30400030.0 \t loss_valid = 26438156.0 \n",
      "Model_4_1330 \t loss_train = 29299610.0 \t loss_valid = 25565218.0 \n",
      "Model_4_1340 \t loss_train = 29749192.0 \t loss_valid = 25884414.0 \n",
      "Model_4_1350 \t loss_train = 29827732.0 \t loss_valid = 25865542.0 \n",
      "Model_4_1360 \t loss_train = 30326846.0 \t loss_valid = 26385394.0 \n",
      "Model_4_1370 \t loss_train = 29477942.0 \t loss_valid = 25666514.0 \n",
      "Model_4_1380 \t loss_train = 29727980.0 \t loss_valid = 25848918.0 \n",
      "Model_4_1390 \t loss_train = 29579294.0 \t loss_valid = 25683510.0 \n",
      "Model_4_1400 \t loss_train = 29701290.0 \t loss_valid = 25788386.0 \n",
      "Model_4_1410 \t loss_train = 29939134.0 \t loss_valid = 25933806.0 \n",
      "Model_4_1420 \t loss_train = 30025782.0 \t loss_valid = 26053058.0 \n",
      "Model_4_1430 \t loss_train = 29487140.0 \t loss_valid = 25600388.0 \n",
      "Model_4_1440 \t loss_train = 29709812.0 \t loss_valid = 25769242.0 \n",
      "Model_4_1450 \t loss_train = 29564492.0 \t loss_valid = 25633288.0 \n",
      "Model_4_1460 \t loss_train = 29545752.0 \t loss_valid = 25681534.0 \n",
      "Model_4_1470 \t loss_train = 31202442.0 \t loss_valid = 26892344.0 \n",
      "Model_4_1480 \t loss_train = 29964966.0 \t loss_valid = 26028216.0 \n",
      "Model_4_1490 \t loss_train = 30266158.0 \t loss_valid = 26073704.0 \n",
      "Model_4_1500 \t loss_train = 30157666.0 \t loss_valid = 26206338.0 \n",
      "Model_4_1510 \t loss_train = 29722484.0 \t loss_valid = 25707080.0 \n",
      "Model_4_1520 \t loss_train = 29647232.0 \t loss_valid = 25768348.0 \n",
      "Model_4_1530 \t loss_train = 30200058.0 \t loss_valid = 26062438.0 \n",
      "Model_4_1540 \t loss_train = 31086498.0 \t loss_valid = 26980052.0 \n",
      "Model_4_1550 \t loss_train = 30090274.0 \t loss_valid = 25962424.0 \n",
      "Model_4_1560 \t loss_train = 30219842.0 \t loss_valid = 26138178.0 \n",
      "Model_4_1570 \t loss_train = 30181126.0 \t loss_valid = 26047132.0 \n",
      "Model_4_1580 \t loss_train = 30555458.0 \t loss_valid = 26424384.0 \n",
      "Model_4_1590 \t loss_train = 29962598.0 \t loss_valid = 25922504.0 \n",
      "Model_4_1600 \t loss_train = 30351286.0 \t loss_valid = 26272240.0 \n",
      "Model_4_1610 \t loss_train = 30355970.0 \t loss_valid = 26158452.0 \n",
      "Model_4_1620 \t loss_train = 30381800.0 \t loss_valid = 26278034.0 \n",
      "Model_4_1630 \t loss_train = 31389320.0 \t loss_valid = 27132220.0 \n",
      "Model_4_1640 \t loss_train = 29836534.0 \t loss_valid = 25774762.0 \n",
      "Model_4_1650 \t loss_train = 31111424.0 \t loss_valid = 26985722.0 \n",
      "Model_4_1660 \t loss_train = 30730292.0 \t loss_valid = 26569318.0 \n",
      "Model_4_1670 \t loss_train = 30411498.0 \t loss_valid = 26245780.0 \n",
      "Model_4_1680 \t loss_train = 30428816.0 \t loss_valid = 26155208.0 \n",
      "Model_4_1690 \t loss_train = 30052118.0 \t loss_valid = 25993608.0 \n",
      "Model_4_1700 \t loss_train = 30771996.0 \t loss_valid = 26464222.0 \n",
      "Model_4_1710 \t loss_train = 31077454.0 \t loss_valid = 26827404.0 \n",
      "Model_4_1720 \t loss_train = 30885488.0 \t loss_valid = 26604102.0 \n",
      "Model_4_1730 \t loss_train = 30346086.0 \t loss_valid = 26116348.0 \n",
      "Model_4_1740 \t loss_train = 31285122.0 \t loss_valid = 26967084.0 \n",
      "Model_4_1750 \t loss_train = 30047214.0 \t loss_valid = 25884590.0 \n",
      "Model_4_1760 \t loss_train = 30430510.0 \t loss_valid = 26189474.0 \n",
      "Model_4_1770 \t loss_train = 30643258.0 \t loss_valid = 26366686.0 \n",
      "Model_4_1780 \t loss_train = 31071818.0 \t loss_valid = 26921852.0 \n",
      "Model_4_1790 \t loss_train = 30051744.0 \t loss_valid = 25857842.0 \n",
      "Model_4_1800 \t loss_train = 31030120.0 \t loss_valid = 26694034.0 \n",
      "Model_4_1810 \t loss_train = 30259304.0 \t loss_valid = 26037860.0 \n",
      "Model_4_1820 \t loss_train = 31045302.0 \t loss_valid = 26730680.0 \n",
      "Model_4_1830 \t loss_train = 30601460.0 \t loss_valid = 26403570.0 \n",
      "Model_4_1840 \t loss_train = 30876672.0 \t loss_valid = 26543382.0 \n",
      "Model_4_1850 \t loss_train = 30316454.0 \t loss_valid = 26068988.0 \n",
      "Model_4_1860 \t loss_train = 31096362.0 \t loss_valid = 26761188.0 \n",
      "Model_4_1870 \t loss_train = 31393342.0 \t loss_valid = 26992870.0 \n",
      "Model_4_1880 \t loss_train = 30896232.0 \t loss_valid = 26647166.0 \n",
      "Model_4_1890 \t loss_train = 31392978.0 \t loss_valid = 26954724.0 \n",
      "Model_4_1900 \t loss_train = 30402538.0 \t loss_valid = 26183066.0 \n",
      "Model_4_1910 \t loss_train = 31577788.0 \t loss_valid = 27178666.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_4_1920 \t loss_train = 30626672.0 \t loss_valid = 26312492.0 \n",
      "Model_4_1930 \t loss_train = 30742240.0 \t loss_valid = 26475432.0 \n",
      "Model_4_1940 \t loss_train = 31902304.0 \t loss_valid = 27428378.0 \n",
      "Model_4_1950 \t loss_train = 31108636.0 \t loss_valid = 26567474.0 \n",
      "Model_4_1960 \t loss_train = 29889968.0 \t loss_valid = 25792788.0 \n",
      "Model_4_1970 \t loss_train = 30941512.0 \t loss_valid = 26572398.0 \n",
      "Model_4_1980 \t loss_train = 30967248.0 \t loss_valid = 26580964.0 \n",
      "Model_4_1990 \t loss_train = 30992534.0 \t loss_valid = 26647890.0 \n",
      "Model_4_2000 \t loss_train = 31149450.0 \t loss_valid = 26726748.0 \n",
      "Model_4_2010 \t loss_train = 31333744.0 \t loss_valid = 26735780.0 \n",
      "Model_4_2020 \t loss_train = 31613058.0 \t loss_valid = 27382016.0 \n",
      "Model_4_2030 \t loss_train = 31366318.0 \t loss_valid = 26846578.0 \n",
      "Model_4_2040 \t loss_train = 31111718.0 \t loss_valid = 26704192.0 \n",
      "Model_4_2050 \t loss_train = 31375754.0 \t loss_valid = 26966256.0 \n",
      "Model_4_2060 \t loss_train = 30775876.0 \t loss_valid = 26347568.0 \n",
      "Model_4_2070 \t loss_train = 30829014.0 \t loss_valid = 26523190.0 \n",
      "Model_4_2080 \t loss_train = 31333698.0 \t loss_valid = 26757372.0 \n",
      "Model_4_2090 \t loss_train = 31274496.0 \t loss_valid = 27048060.0 \n",
      "Model_4_2100 \t loss_train = 31188480.0 \t loss_valid = 26623754.0 \n",
      "Model_4_2110 \t loss_train = 31680698.0 \t loss_valid = 27231576.0 \n",
      "Model_4_2120 \t loss_train = 31533914.0 \t loss_valid = 26960598.0 \n",
      "Model_4_2130 \t loss_train = 31062266.0 \t loss_valid = 26597530.0 \n",
      "Model_4_2140 \t loss_train = 31422400.0 \t loss_valid = 26904986.0 \n",
      "Model_4_2150 \t loss_train = 31305758.0 \t loss_valid = 26910900.0 \n",
      "Model_4_2160 \t loss_train = 31633896.0 \t loss_valid = 27113408.0 \n",
      "Model_4_2170 \t loss_train = 31473340.0 \t loss_valid = 27007472.0 \n",
      "Model_4_2180 \t loss_train = 31158890.0 \t loss_valid = 26701934.0 \n",
      "Model_4_2190 \t loss_train = 31566860.0 \t loss_valid = 27050546.0 \n",
      "Model_4_2200 \t loss_train = 31354436.0 \t loss_valid = 26923840.0 \n",
      "Model_4_2210 \t loss_train = 31158546.0 \t loss_valid = 26533614.0 \n",
      "Model_4_2220 \t loss_train = 30959896.0 \t loss_valid = 26538442.0 \n",
      "Model_4_2230 \t loss_train = 31449218.0 \t loss_valid = 26783996.0 \n",
      "Model_4_2240 \t loss_train = 31597330.0 \t loss_valid = 27026622.0 \n",
      "Model_4_2250 \t loss_train = 31059176.0 \t loss_valid = 26441476.0 \n",
      "Model_4_2260 \t loss_train = 31312756.0 \t loss_valid = 26928402.0 \n",
      "Model_4_2270 \t loss_train = 31275552.0 \t loss_valid = 26637018.0 \n",
      "Model_4_2280 \t loss_train = 31427936.0 \t loss_valid = 26860876.0 \n",
      "Model_4_2290 \t loss_train = 31227690.0 \t loss_valid = 26787580.0 \n",
      "Model_4_2300 \t loss_train = 31676918.0 \t loss_valid = 27095186.0 \n",
      "Model_4_2310 \t loss_train = 32484196.0 \t loss_valid = 27984320.0 \n",
      "Model_4_2320 \t loss_train = 30934232.0 \t loss_valid = 26554134.0 \n",
      "Model_4_2330 \t loss_train = 31842376.0 \t loss_valid = 27120166.0 \n",
      "Model_4_2340 \t loss_train = 32320944.0 \t loss_valid = 27715784.0 \n",
      "Model_4_2350 \t loss_train = 31417178.0 \t loss_valid = 26879102.0 \n",
      "Model_4_2360 \t loss_train = 31576306.0 \t loss_valid = 26973456.0 \n",
      "Model_4_2370 \t loss_train = 31909826.0 \t loss_valid = 27436038.0 \n",
      "Model_4_2380 \t loss_train = 31439646.0 \t loss_valid = 26840468.0 \n",
      "Model_4_2390 \t loss_train = 31988994.0 \t loss_valid = 27437872.0 \n",
      "Model_4_2400 \t loss_train = 31360996.0 \t loss_valid = 26733180.0 \n",
      "Model_4_2410 \t loss_train = 31075436.0 \t loss_valid = 26664562.0 \n",
      "Model_4_2420 \t loss_train = 32048416.0 \t loss_valid = 27403280.0 \n",
      "Model_4_2430 \t loss_train = 31833202.0 \t loss_valid = 27288892.0 \n",
      "Model_4_2440 \t loss_train = 31638082.0 \t loss_valid = 26878370.0 \n",
      "Model_4_2450 \t loss_train = 32031218.0 \t loss_valid = 27430280.0 \n",
      "Model_4_2460 \t loss_train = 31603778.0 \t loss_valid = 26866192.0 \n",
      "Model_4_2470 \t loss_train = 31881968.0 \t loss_valid = 27369222.0 \n",
      "Model_4_2480 \t loss_train = 31699544.0 \t loss_valid = 27032560.0 \n",
      "Model_4_2490 \t loss_train = 32131034.0 \t loss_valid = 27437220.0 \n",
      "Model_4_2500 \t loss_train = 31597984.0 \t loss_valid = 27024760.0 \n",
      "Model_4_2510 \t loss_train = 32215700.0 \t loss_valid = 27473118.0 \n",
      "Model_4_2520 \t loss_train = 32389172.0 \t loss_valid = 27928436.0 \n",
      "Model_4_2530 \t loss_train = 31669792.0 \t loss_valid = 27000984.0 \n",
      "Model_4_2540 \t loss_train = 31775954.0 \t loss_valid = 27236988.0 \n",
      "Model_4_2550 \t loss_train = 32055794.0 \t loss_valid = 27370092.0 \n",
      "Model_4_2560 \t loss_train = 32263386.0 \t loss_valid = 27527276.0 \n",
      "Model_4_2570 \t loss_train = 31975840.0 \t loss_valid = 27328250.0 \n",
      "Model_4_2580 \t loss_train = 31267972.0 \t loss_valid = 26713628.0 \n",
      "Model_4_2590 \t loss_train = 31892940.0 \t loss_valid = 27243514.0 \n",
      "Model_4_2600 \t loss_train = 31706720.0 \t loss_valid = 27061498.0 \n",
      "Model_4_2610 \t loss_train = 31806380.0 \t loss_valid = 27102692.0 \n",
      "Model_4_2620 \t loss_train = 31429328.0 \t loss_valid = 26844558.0 \n",
      "Model_4_2630 \t loss_train = 31571418.0 \t loss_valid = 26851212.0 \n",
      "Model_4_2640 \t loss_train = 31592850.0 \t loss_valid = 26935504.0 \n",
      "Model_4_2650 \t loss_train = 32037126.0 \t loss_valid = 27226946.0 \n",
      "Model_4_2660 \t loss_train = 31763126.0 \t loss_valid = 27042598.0 \n",
      "Model_4_2670 \t loss_train = 31710838.0 \t loss_valid = 26938652.0 \n",
      "Model_4_2680 \t loss_train = 32168410.0 \t loss_valid = 27320106.0 \n",
      "Model_4_2690 \t loss_train = 32119436.0 \t loss_valid = 27533410.0 \n",
      "Model_4_2700 \t loss_train = 32388958.0 \t loss_valid = 27595502.0 \n",
      "Model_4_2710 \t loss_train = 32257762.0 \t loss_valid = 27504500.0 \n",
      "Model_4_2720 \t loss_train = 31951152.0 \t loss_valid = 27245270.0 \n",
      "Model_4_2730 \t loss_train = 31826080.0 \t loss_valid = 27125848.0 \n",
      "Model_4_2740 \t loss_train = 32329750.0 \t loss_valid = 27574130.0 \n",
      "Model_4_2750 \t loss_train = 32742256.0 \t loss_valid = 28060352.0 \n",
      "Model_4_2760 \t loss_train = 31996656.0 \t loss_valid = 27106734.0 \n",
      "Model_4_2770 \t loss_train = 31985084.0 \t loss_valid = 27280944.0 \n",
      "Model_4_2780 \t loss_train = 32623712.0 \t loss_valid = 27890330.0 \n",
      "Model_4_2790 \t loss_train = 32119256.0 \t loss_valid = 27390708.0 \n",
      "Model_4_2800 \t loss_train = 31588854.0 \t loss_valid = 26889816.0 \n",
      "Model_4_2810 \t loss_train = 32264356.0 \t loss_valid = 27497144.0 \n",
      "Model_4_2820 \t loss_train = 32477110.0 \t loss_valid = 27630896.0 \n",
      "Model_4_2830 \t loss_train = 31936024.0 \t loss_valid = 27093912.0 \n",
      "Model_4_2840 \t loss_train = 32302512.0 \t loss_valid = 27375666.0 \n",
      "Model_4_2850 \t loss_train = 32247198.0 \t loss_valid = 27519646.0 \n",
      "Model_4_2860 \t loss_train = 32014772.0 \t loss_valid = 27061266.0 \n",
      "Model_4_2870 \t loss_train = 32076802.0 \t loss_valid = 27328530.0 \n",
      "Model_4_2880 \t loss_train = 32208270.0 \t loss_valid = 27382816.0 \n",
      "Model_4_2890 \t loss_train = 32267148.0 \t loss_valid = 27368786.0 \n",
      "Model_4_2900 \t loss_train = 31883600.0 \t loss_valid = 27100242.0 \n",
      "Model_4_2910 \t loss_train = 32325660.0 \t loss_valid = 27371650.0 \n",
      "Model_4_2920 \t loss_train = 32301180.0 \t loss_valid = 27632308.0 \n",
      "Model_4_2930 \t loss_train = 32775618.0 \t loss_valid = 27837292.0 \n",
      "Model_4_2940 \t loss_train = 32521098.0 \t loss_valid = 27775236.0 \n",
      "Model_4_2950 \t loss_train = 31662726.0 \t loss_valid = 26774582.0 \n",
      "Model_4_2960 \t loss_train = 33011962.0 \t loss_valid = 28333534.0 \n",
      "Model_4_2970 \t loss_train = 32430818.0 \t loss_valid = 27502174.0 \n",
      "Model_4_2980 \t loss_train = 31724286.0 \t loss_valid = 27064544.0 \n",
      "Model_4_2990 \t loss_train = 32487942.0 \t loss_valid = 27540454.0 \n",
      "Model_4_3000 \t loss_train = 33064878.0 \t loss_valid = 28385786.0 \n",
      "Model_4_3010 \t loss_train = 31946812.0 \t loss_valid = 27053710.0 \n",
      "Model_4_3020 \t loss_train = 32161992.0 \t loss_valid = 27330308.0 \n",
      "Model_4_3030 \t loss_train = 32844212.0 \t loss_valid = 28049038.0 \n",
      "Model_4_3040 \t loss_train = 32385388.0 \t loss_valid = 27446790.0 \n",
      "Model_4_3050 \t loss_train = 32130440.0 \t loss_valid = 27267084.0 \n",
      "Model_4_3060 \t loss_train = 31918976.0 \t loss_valid = 27067238.0 \n",
      "Model_4_3070 \t loss_train = 32411282.0 \t loss_valid = 27522712.0 \n",
      "Model_4_3080 \t loss_train = 32470402.0 \t loss_valid = 27553314.0 \n",
      "Model_4_3090 \t loss_train = 32653338.0 \t loss_valid = 27805858.0 \n",
      "Model_4_3100 \t loss_train = 32179888.0 \t loss_valid = 27304328.0 \n",
      "Model_4_3110 \t loss_train = 32592918.0 \t loss_valid = 27659606.0 \n",
      "Model_4_3120 \t loss_train = 32232946.0 \t loss_valid = 27340888.0 \n",
      "Model_4_3130 \t loss_train = 33179904.0 \t loss_valid = 28217160.0 \n",
      "Model_4_3140 \t loss_train = 32500898.0 \t loss_valid = 27637492.0 \n",
      "Model_4_3150 \t loss_train = 32212820.0 \t loss_valid = 27275946.0 \n",
      "Model_4_3160 \t loss_train = 32744556.0 \t loss_valid = 27897502.0 \n",
      "Model_4_3170 \t loss_train = 32247212.0 \t loss_valid = 27373170.0 \n",
      "Model_4_3180 \t loss_train = 33043500.0 \t loss_valid = 28088610.0 \n",
      "Model_4_3190 \t loss_train = 32165534.0 \t loss_valid = 27225094.0 \n",
      "Model_4_3200 \t loss_train = 32735086.0 \t loss_valid = 27650620.0 \n",
      "Model_4_3210 \t loss_train = 32107474.0 \t loss_valid = 27373880.0 \n",
      "Model_4_3220 \t loss_train = 32378604.0 \t loss_valid = 27480436.0 \n",
      "Model_4_3230 \t loss_train = 33011856.0 \t loss_valid = 28092928.0 \n",
      "Model_4_3240 \t loss_train = 32867086.0 \t loss_valid = 27841410.0 \n",
      "Model_4_3250 \t loss_train = 33164886.0 \t loss_valid = 28187960.0 \n",
      "Model_4_3260 \t loss_train = 32854790.0 \t loss_valid = 27873334.0 \n",
      "Model_4_3270 \t loss_train = 32268054.0 \t loss_valid = 27374672.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_4_3280 \t loss_train = 33763336.0 \t loss_valid = 28741610.0 \n",
      "Model_4_3290 \t loss_train = 32699674.0 \t loss_valid = 27835860.0 \n",
      "Model_4_3300 \t loss_train = 31962892.0 \t loss_valid = 27056014.0 \n",
      "Model_4_3310 \t loss_train = 33133108.0 \t loss_valid = 28087274.0 \n",
      "Model_4_3320 \t loss_train = 32617216.0 \t loss_valid = 27758528.0 \n",
      "Model_4_3330 \t loss_train = 32903188.0 \t loss_valid = 27924906.0 \n",
      "Model_4_3340 \t loss_train = 32258022.0 \t loss_valid = 27402832.0 \n",
      "Model_4_3350 \t loss_train = 32930514.0 \t loss_valid = 27987564.0 \n",
      "Model_4_3360 \t loss_train = 32369512.0 \t loss_valid = 27455492.0 \n",
      "Model_4_3370 \t loss_train = 32813386.0 \t loss_valid = 27852026.0 \n",
      "Model_4_3380 \t loss_train = 33005486.0 \t loss_valid = 27973670.0 \n",
      "Model_4_3390 \t loss_train = 32322782.0 \t loss_valid = 27482712.0 \n",
      "Model_4_3400 \t loss_train = 33284568.0 \t loss_valid = 28349364.0 \n",
      "Model_4_3410 \t loss_train = 32101052.0 \t loss_valid = 27282182.0 \n",
      "Model_4_3420 \t loss_train = 32867758.0 \t loss_valid = 27737190.0 \n",
      "Model_4_3430 \t loss_train = 33276896.0 \t loss_valid = 28438958.0 \n",
      "Model_4_3440 \t loss_train = 32503086.0 \t loss_valid = 27514482.0 \n",
      "Model_4_3450 \t loss_train = 32761780.0 \t loss_valid = 27921464.0 \n",
      "Model_4_3460 \t loss_train = 32424804.0 \t loss_valid = 27451430.0 \n",
      "Model_4_3470 \t loss_train = 32806476.0 \t loss_valid = 27778932.0 \n",
      "Model_4_3480 \t loss_train = 33009654.0 \t loss_valid = 28022720.0 \n",
      "Model_4_3490 \t loss_train = 32744530.0 \t loss_valid = 27778888.0 \n",
      "Model_4_3500 \t loss_train = 32255462.0 \t loss_valid = 27382992.0 \n",
      "Model_4_3510 \t loss_train = 32704510.0 \t loss_valid = 27833666.0 \n",
      "Model_4_3520 \t loss_train = 33017672.0 \t loss_valid = 27992702.0 \n",
      "Model_4_3530 \t loss_train = 32867164.0 \t loss_valid = 27890422.0 \n",
      "Model_4_3540 \t loss_train = 32750328.0 \t loss_valid = 27760560.0 \n",
      "Model_4_3550 \t loss_train = 32687414.0 \t loss_valid = 27688274.0 \n",
      "Model_4_3560 \t loss_train = 32304876.0 \t loss_valid = 27281174.0 \n",
      "Model_4_3570 \t loss_train = 32214408.0 \t loss_valid = 27413100.0 \n",
      "Model_4_3580 \t loss_train = 32960030.0 \t loss_valid = 27904126.0 \n",
      "Model_4_3590 \t loss_train = 31954900.0 \t loss_valid = 27136076.0 \n",
      "Model_4_3600 \t loss_train = 32587990.0 \t loss_valid = 27740176.0 \n",
      "Model_4_3610 \t loss_train = 32075782.0 \t loss_valid = 27177678.0 \n",
      "Model_4_3620 \t loss_train = 33049570.0 \t loss_valid = 27992092.0 \n",
      "Model_4_3630 \t loss_train = 32513796.0 \t loss_valid = 27670104.0 \n",
      "Model_4_3640 \t loss_train = 32856922.0 \t loss_valid = 27894294.0 \n",
      "Model_4_3650 \t loss_train = 32176060.0 \t loss_valid = 27311578.0 \n",
      "Model_4_3660 \t loss_train = 32863174.0 \t loss_valid = 27951920.0 \n",
      "Model_4_3670 \t loss_train = 33253268.0 \t loss_valid = 28236080.0 \n",
      "Model_4_3680 \t loss_train = 32254196.0 \t loss_valid = 27288342.0 \n",
      "Model_4_3690 \t loss_train = 32746666.0 \t loss_valid = 27750668.0 \n",
      "Model_4_3700 \t loss_train = 32676160.0 \t loss_valid = 27849418.0 \n",
      "Model_4_3710 \t loss_train = 32595652.0 \t loss_valid = 27578160.0 \n",
      "Model_4_3720 \t loss_train = 32476002.0 \t loss_valid = 27548650.0 \n",
      "Model_4_3730 \t loss_train = 33240866.0 \t loss_valid = 28285978.0 \n",
      "Model_4_3740 \t loss_train = 32350560.0 \t loss_valid = 27388464.0 \n",
      "Model_4_3750 \t loss_train = 33107016.0 \t loss_valid = 28197998.0 \n",
      "Model_4_3760 \t loss_train = 32355380.0 \t loss_valid = 27419136.0 \n",
      "Model_4_3770 \t loss_train = 32965600.0 \t loss_valid = 27934056.0 \n",
      "Model_4_3780 \t loss_train = 32559046.0 \t loss_valid = 27707970.0 \n",
      "Model_4_3790 \t loss_train = 32708480.0 \t loss_valid = 27568204.0 \n",
      "Model_4_3800 \t loss_train = 32915096.0 \t loss_valid = 27969954.0 \n",
      "Model_4_3810 \t loss_train = 32915598.0 \t loss_valid = 28034092.0 \n",
      "Model_4_3820 \t loss_train = 32199430.0 \t loss_valid = 27383472.0 \n",
      "Model_4_3830 \t loss_train = 33006330.0 \t loss_valid = 27998868.0 \n",
      "Model_4_3840 \t loss_train = 32703680.0 \t loss_valid = 27692670.0 \n",
      "Model_4_3850 \t loss_train = 33048450.0 \t loss_valid = 28200166.0 \n",
      "Model_4_3860 \t loss_train = 32748278.0 \t loss_valid = 27701526.0 \n",
      "Model_4_3870 \t loss_train = 32872562.0 \t loss_valid = 27933626.0 \n",
      "Model_4_3880 \t loss_train = 32783022.0 \t loss_valid = 27850718.0 \n",
      "Model_4_3890 \t loss_train = 32777812.0 \t loss_valid = 27723166.0 \n",
      "Model_4_3900 \t loss_train = 33232860.0 \t loss_valid = 28254506.0 \n",
      "Model_4_3910 \t loss_train = 32633300.0 \t loss_valid = 27672070.0 \n",
      "Model_4_3920 \t loss_train = 32722316.0 \t loss_valid = 27884060.0 \n",
      "Model_4_3930 \t loss_train = 32797872.0 \t loss_valid = 27863850.0 \n",
      "Model_4_3940 \t loss_train = 32821638.0 \t loss_valid = 27808320.0 \n",
      "Model_4_3950 \t loss_train = 33187236.0 \t loss_valid = 28131858.0 \n",
      "Model_4_3960 \t loss_train = 33069736.0 \t loss_valid = 28081534.0 \n",
      "Model_4_3970 \t loss_train = 33383890.0 \t loss_valid = 28496688.0 \n",
      "Model_4_3980 \t loss_train = 32828492.0 \t loss_valid = 27708524.0 \n",
      "Model_4_3990 \t loss_train = 32784882.0 \t loss_valid = 27859936.0 \n",
      "Model_4_4000 \t loss_train = 33118994.0 \t loss_valid = 27976056.0 \n",
      "Model_4_4010 \t loss_train = 32722404.0 \t loss_valid = 27842556.0 \n",
      "Model_4_4020 \t loss_train = 32832544.0 \t loss_valid = 27829460.0 \n",
      "Model_4_4030 \t loss_train = 32820852.0 \t loss_valid = 27874516.0 \n",
      "Model_4_4040 \t loss_train = 33749824.0 \t loss_valid = 28800914.0 \n",
      "Model_4_4050 \t loss_train = 32676850.0 \t loss_valid = 27632236.0 \n",
      "Model_4_4060 \t loss_train = 32461992.0 \t loss_valid = 27640146.0 \n",
      "Model_4_4070 \t loss_train = 33571416.0 \t loss_valid = 28466428.0 \n",
      "Model_4_4080 \t loss_train = 33029432.0 \t loss_valid = 28213652.0 \n",
      "Model_4_4090 \t loss_train = 33066896.0 \t loss_valid = 27931462.0 \n",
      "Model_4_4100 \t loss_train = 33299494.0 \t loss_valid = 28325604.0 \n",
      "Model_4_4110 \t loss_train = 33111896.0 \t loss_valid = 28052268.0 \n",
      "Model_4_4120 \t loss_train = 32567204.0 \t loss_valid = 27532010.0 \n",
      "Model_4_4130 \t loss_train = 32060722.0 \t loss_valid = 27078412.0 \n",
      "Model_4_4140 \t loss_train = 33358108.0 \t loss_valid = 28352530.0 \n",
      "Model_4_4150 \t loss_train = 32508040.0 \t loss_valid = 27563482.0 \n",
      "Model_4_4160 \t loss_train = 33122886.0 \t loss_valid = 28165582.0 \n",
      "Model_4_4170 \t loss_train = 32922512.0 \t loss_valid = 27915576.0 \n",
      "Model_4_4180 \t loss_train = 32793766.0 \t loss_valid = 27845000.0 \n",
      "Model_4_4190 \t loss_train = 32820038.0 \t loss_valid = 27892600.0 \n",
      "Model_4_4200 \t loss_train = 33403886.0 \t loss_valid = 28405320.0 \n",
      "Model_4_4210 \t loss_train = 32467408.0 \t loss_valid = 27531960.0 \n",
      "Model_4_4220 \t loss_train = 33082058.0 \t loss_valid = 28047318.0 \n",
      "Model_4_4230 \t loss_train = 33385258.0 \t loss_valid = 28396408.0 \n",
      "Model_4_4240 \t loss_train = 32477434.0 \t loss_valid = 27530528.0 \n",
      "Model_4_4250 \t loss_train = 32778090.0 \t loss_valid = 27765564.0 \n",
      "Model_4_4260 \t loss_train = 33641308.0 \t loss_valid = 28585942.0 \n",
      "Model_4_4270 \t loss_train = 32953902.0 \t loss_valid = 27899064.0 \n",
      "Model_4_4280 \t loss_train = 32014606.0 \t loss_valid = 27134296.0 \n",
      "Model_4_4290 \t loss_train = 33931992.0 \t loss_valid = 28770292.0 \n",
      "Model_4_4300 \t loss_train = 33240782.0 \t loss_valid = 28145804.0 \n",
      "Model_4_4310 \t loss_train = 32635758.0 \t loss_valid = 27546280.0 \n",
      "Model_4_4320 \t loss_train = 32976006.0 \t loss_valid = 28023148.0 \n",
      "Model_4_4330 \t loss_train = 32976084.0 \t loss_valid = 27839206.0 \n",
      "Model_4_4340 \t loss_train = 32700766.0 \t loss_valid = 27771364.0 \n",
      "Model_4_4350 \t loss_train = 32505830.0 \t loss_valid = 27574556.0 \n",
      "Model_4_4360 \t loss_train = 33287668.0 \t loss_valid = 28288502.0 \n",
      "Model_4_4370 \t loss_train = 32607188.0 \t loss_valid = 27583570.0 \n",
      "Model_4_4380 \t loss_train = 33229744.0 \t loss_valid = 28283202.0 \n",
      "Model_4_4390 \t loss_train = 33983136.0 \t loss_valid = 28870954.0 \n",
      "Model_4_4400 \t loss_train = 32599104.0 \t loss_valid = 27537496.0 \n",
      "Model_4_4410 \t loss_train = 32811684.0 \t loss_valid = 27866342.0 \n",
      "Model_4_4420 \t loss_train = 33173632.0 \t loss_valid = 28163994.0 \n",
      "Model_4_4430 \t loss_train = 32746930.0 \t loss_valid = 27756238.0 \n",
      "Model_4_4440 \t loss_train = 33332640.0 \t loss_valid = 28252404.0 \n",
      "Model_4_4450 \t loss_train = 32720130.0 \t loss_valid = 27762774.0 \n",
      "Model_4_4460 \t loss_train = 33080428.0 \t loss_valid = 28045488.0 \n",
      "Model_4_4470 \t loss_train = 33057364.0 \t loss_valid = 27963840.0 \n",
      "Model_4_4480 \t loss_train = 33126560.0 \t loss_valid = 28017066.0 \n",
      "Model_4_4490 \t loss_train = 33195116.0 \t loss_valid = 28168802.0 \n",
      "Model_4_4500 \t loss_train = 32781416.0 \t loss_valid = 27723564.0 \n",
      "Model_4_4510 \t loss_train = 33183228.0 \t loss_valid = 28196832.0 \n",
      "Model_4_4520 \t loss_train = 32774014.0 \t loss_valid = 27675750.0 \n",
      "Model_4_4530 \t loss_train = 32708512.0 \t loss_valid = 27848234.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_4_4540 \t loss_train = 32617058.0 \t loss_valid = 27602704.0 \n",
      "Model_4_4550 \t loss_train = 33098958.0 \t loss_valid = 28058342.0 \n",
      "Model_4_4560 \t loss_train = 32405522.0 \t loss_valid = 27499662.0 \n",
      "Model_4_4570 \t loss_train = 32909108.0 \t loss_valid = 27865234.0 \n",
      "Model_4_4580 \t loss_train = 32321780.0 \t loss_valid = 27353606.0 \n",
      "Model_4_4590 \t loss_train = 32855198.0 \t loss_valid = 27874968.0 \n",
      "Model_4_4600 \t loss_train = 33397088.0 \t loss_valid = 28374322.0 \n",
      "Model_4_4610 \t loss_train = 32853686.0 \t loss_valid = 27898440.0 \n",
      "Model_4_4620 \t loss_train = 32778552.0 \t loss_valid = 27749752.0 \n",
      "Model_4_4630 \t loss_train = 32631380.0 \t loss_valid = 27612758.0 \n",
      "Model_4_4640 \t loss_train = 33392618.0 \t loss_valid = 28331826.0 \n",
      "Model_4_4650 \t loss_train = 32780124.0 \t loss_valid = 27711924.0 \n",
      "Model_4_4660 \t loss_train = 32483256.0 \t loss_valid = 27609790.0 \n",
      "Model_4_4670 \t loss_train = 32972896.0 \t loss_valid = 27916746.0 \n",
      "Model_4_4680 \t loss_train = 32810238.0 \t loss_valid = 27876428.0 \n",
      "Model_4_4690 \t loss_train = 32923228.0 \t loss_valid = 27969906.0 \n",
      "Model_4_4700 \t loss_train = 32734760.0 \t loss_valid = 27639164.0 \n",
      "Model_4_4710 \t loss_train = 32879026.0 \t loss_valid = 27899568.0 \n",
      "Model_4_4720 \t loss_train = 32568074.0 \t loss_valid = 27601516.0 \n",
      "Model_4_4730 \t loss_train = 33306308.0 \t loss_valid = 28274978.0 \n",
      "Model_4_4740 \t loss_train = 32144208.0 \t loss_valid = 27197462.0 \n",
      "Model_4_4750 \t loss_train = 33312216.0 \t loss_valid = 28260542.0 \n",
      "Model_4_4760 \t loss_train = 33181600.0 \t loss_valid = 28220802.0 \n",
      "Model_4_4770 \t loss_train = 33094226.0 \t loss_valid = 28063988.0 \n",
      "Model_4_4780 \t loss_train = 32804338.0 \t loss_valid = 27743182.0 \n",
      "Model_4_4790 \t loss_train = 32547924.0 \t loss_valid = 27474248.0 \n",
      "Model_4_4800 \t loss_train = 33315240.0 \t loss_valid = 28217334.0 \n",
      "Model_4_4810 \t loss_train = 32494576.0 \t loss_valid = 27572746.0 \n",
      "Model_4_4820 \t loss_train = 32667508.0 \t loss_valid = 27684696.0 \n",
      "Model_4_4830 \t loss_train = 32394812.0 \t loss_valid = 27485232.0 \n",
      "Model_4_4840 \t loss_train = 32594328.0 \t loss_valid = 27659786.0 \n",
      "Model_4_4850 \t loss_train = 32520144.0 \t loss_valid = 27507592.0 \n",
      "Model_4_4860 \t loss_train = 33101718.0 \t loss_valid = 28020812.0 \n",
      "Model_4_4870 \t loss_train = 32986996.0 \t loss_valid = 27924606.0 \n",
      "Model_4_4880 \t loss_train = 32398492.0 \t loss_valid = 27465468.0 \n",
      "Model_4_4890 \t loss_train = 33076550.0 \t loss_valid = 28103282.0 \n",
      "Model_4_4900 \t loss_train = 32467226.0 \t loss_valid = 27407536.0 \n",
      "Model_4_4910 \t loss_train = 33139398.0 \t loss_valid = 28137750.0 \n",
      "Model_4_4920 \t loss_train = 32688248.0 \t loss_valid = 27644984.0 \n",
      "Model_4_4930 \t loss_train = 32815418.0 \t loss_valid = 27740546.0 \n",
      "Model_4_4940 \t loss_train = 33053702.0 \t loss_valid = 27944666.0 \n",
      "Model_4_4950 \t loss_train = 33675268.0 \t loss_valid = 28493400.0 \n",
      "Model_4_4960 \t loss_train = 32431314.0 \t loss_valid = 27608664.0 \n",
      "Model_4_4970 \t loss_train = 33038330.0 \t loss_valid = 27950054.0 \n",
      "Model_4_4980 \t loss_train = 32384482.0 \t loss_valid = 27465580.0 \n",
      "Model_4_4990 \t loss_train = 32703890.0 \t loss_valid = 27696976.0 \n",
      "Model_4_5000 \t loss_train = 33103244.0 \t loss_valid = 28008252.0 \n",
      "Model_4_5010 \t loss_train = 32670962.0 \t loss_valid = 27710392.0 \n",
      "Model_4_5020 \t loss_train = 33198860.0 \t loss_valid = 28127936.0 \n",
      "Model_4_5030 \t loss_train = 32648002.0 \t loss_valid = 27680082.0 \n",
      "Model_4_5040 \t loss_train = 33038092.0 \t loss_valid = 27942564.0 \n",
      "Model_4_5050 \t loss_train = 32614758.0 \t loss_valid = 27656492.0 \n",
      "Model_4_5060 \t loss_train = 33008850.0 \t loss_valid = 27955694.0 \n",
      "Model_4_5070 \t loss_train = 33006088.0 \t loss_valid = 27903446.0 \n",
      "Model_4_5080 \t loss_train = 33384300.0 \t loss_valid = 28423630.0 \n",
      "Model_4_5090 \t loss_train = 32315646.0 \t loss_valid = 27342206.0 \n",
      "Model_4_5100 \t loss_train = 32581234.0 \t loss_valid = 27613314.0 \n",
      "Model_4_5110 \t loss_train = 33593380.0 \t loss_valid = 28474918.0 \n",
      "Model_4_5120 \t loss_train = 32000664.0 \t loss_valid = 27061652.0 \n",
      "Model_4_5130 \t loss_train = 32990244.0 \t loss_valid = 27936222.0 \n",
      "Model_4_5140 \t loss_train = 33277516.0 \t loss_valid = 28223962.0 \n",
      "Model_4_5150 \t loss_train = 32982546.0 \t loss_valid = 27948462.0 \n",
      "Model_4_5160 \t loss_train = 32945742.0 \t loss_valid = 27868018.0 \n",
      "Model_4_5170 \t loss_train = 32871830.0 \t loss_valid = 27860300.0 \n",
      "Model_4_5180 \t loss_train = 33199000.0 \t loss_valid = 28092012.0 \n",
      "Model_4_5190 \t loss_train = 32830944.0 \t loss_valid = 27924974.0 \n",
      "Model_4_5200 \t loss_train = 32594434.0 \t loss_valid = 27607684.0 \n",
      "Model_4_5210 \t loss_train = 33136264.0 \t loss_valid = 28121628.0 \n",
      "Model_4_5220 \t loss_train = 33208590.0 \t loss_valid = 28047436.0 \n",
      "Model_4_5230 \t loss_train = 33317812.0 \t loss_valid = 28237502.0 \n",
      "Model_4_5240 \t loss_train = 33112912.0 \t loss_valid = 27956938.0 \n",
      "Model_4_5250 \t loss_train = 32545374.0 \t loss_valid = 27631868.0 \n",
      "Model_4_5260 \t loss_train = 33660220.0 \t loss_valid = 28544840.0 \n",
      "Model_4_5270 \t loss_train = 32751154.0 \t loss_valid = 27681134.0 \n",
      "Model_4_5280 \t loss_train = 33309772.0 \t loss_valid = 28208128.0 \n",
      "Model_4_5290 \t loss_train = 33062676.0 \t loss_valid = 27994292.0 \n",
      "Model_4_5300 \t loss_train = 32706448.0 \t loss_valid = 27725062.0 \n",
      "Model_4_5310 \t loss_train = 33205028.0 \t loss_valid = 28093364.0 \n",
      "Model_4_5320 \t loss_train = 32454684.0 \t loss_valid = 27520500.0 \n",
      "Model_4_5330 \t loss_train = 33117686.0 \t loss_valid = 28090740.0 \n",
      "Model_4_5340 \t loss_train = 33653532.0 \t loss_valid = 28378974.0 \n",
      "Model_4_5350 \t loss_train = 32678618.0 \t loss_valid = 27789150.0 \n",
      "Model_4_5360 \t loss_train = 33562860.0 \t loss_valid = 28374588.0 \n",
      "Model_4_5370 \t loss_train = 32744332.0 \t loss_valid = 27699860.0 \n",
      "Model_4_5380 \t loss_train = 33520200.0 \t loss_valid = 28496274.0 \n",
      "Model_4_5390 \t loss_train = 33092706.0 \t loss_valid = 28017038.0 \n",
      "Model_4_5400 \t loss_train = 33340126.0 \t loss_valid = 28208388.0 \n",
      "Model_4_5410 \t loss_train = 33269240.0 \t loss_valid = 28160566.0 \n",
      "Model_4_5420 \t loss_train = 32608322.0 \t loss_valid = 27661796.0 \n",
      "Model_4_5430 \t loss_train = 33003028.0 \t loss_valid = 28014014.0 \n",
      "Model_4_5440 \t loss_train = 33415430.0 \t loss_valid = 28279972.0 \n",
      "Model_4_5450 \t loss_train = 32502558.0 \t loss_valid = 27541222.0 \n",
      "Model_4_5460 \t loss_train = 33929784.0 \t loss_valid = 28764820.0 \n",
      "Model_4_5470 \t loss_train = 32718298.0 \t loss_valid = 27737272.0 \n",
      "Model_4_5480 \t loss_train = 33290502.0 \t loss_valid = 28067082.0 \n",
      "Model_4_5490 \t loss_train = 32960092.0 \t loss_valid = 27921734.0 \n",
      "Model_4_5500 \t loss_train = 32899920.0 \t loss_valid = 27790870.0 \n",
      "Model_4_5510 \t loss_train = 33043848.0 \t loss_valid = 27919250.0 \n",
      "Model_4_5520 \t loss_train = 33271472.0 \t loss_valid = 28111890.0 \n",
      "Model_4_5530 \t loss_train = 33100066.0 \t loss_valid = 28099114.0 \n",
      "Model_4_5540 \t loss_train = 33485908.0 \t loss_valid = 28234272.0 \n",
      "Model_4_5550 \t loss_train = 33081244.0 \t loss_valid = 27984590.0 \n",
      "Model_4_5560 \t loss_train = 32832716.0 \t loss_valid = 27794256.0 \n",
      "Model_4_5570 \t loss_train = 33317276.0 \t loss_valid = 28269888.0 \n",
      "Model_4_5580 \t loss_train = 32660438.0 \t loss_valid = 27613548.0 \n",
      "Model_4_5590 \t loss_train = 34010784.0 \t loss_valid = 28811170.0 \n",
      "Model_4_5600 \t loss_train = 32599064.0 \t loss_valid = 27559532.0 \n",
      "Model_4_5610 \t loss_train = 33105674.0 \t loss_valid = 27927640.0 \n",
      "Model_4_5620 \t loss_train = 33285228.0 \t loss_valid = 28180322.0 \n",
      "Model_4_5630 \t loss_train = 32509004.0 \t loss_valid = 27486814.0 \n",
      "Model_4_5640 \t loss_train = 33478826.0 \t loss_valid = 28322190.0 \n",
      "Model_4_5650 \t loss_train = 33354946.0 \t loss_valid = 28151688.0 \n",
      "Model_4_5660 \t loss_train = 33380440.0 \t loss_valid = 28265482.0 \n",
      "Model_4_5670 \t loss_train = 33532028.0 \t loss_valid = 28388336.0 \n",
      "Model_4_5680 \t loss_train = 33459708.0 \t loss_valid = 28362240.0 \n",
      "Model_4_5690 \t loss_train = 33316468.0 \t loss_valid = 28135698.0 \n",
      "Model_4_5700 \t loss_train = 33767972.0 \t loss_valid = 28590934.0 \n",
      "Model_4_5710 \t loss_train = 33444808.0 \t loss_valid = 28334798.0 \n",
      "Model_4_5720 \t loss_train = 33177446.0 \t loss_valid = 28025888.0 \n",
      "Model_4_5730 \t loss_train = 33270060.0 \t loss_valid = 28081878.0 \n",
      "Model_4_5740 \t loss_train = 33928480.0 \t loss_valid = 28688696.0 \n",
      "Model_4_5750 \t loss_train = 32820874.0 \t loss_valid = 27733568.0 \n",
      "Model_4_5760 \t loss_train = 32883150.0 \t loss_valid = 27728810.0 \n",
      "Model_4_5770 \t loss_train = 33726120.0 \t loss_valid = 28513802.0 \n",
      "Model_4_5780 \t loss_train = 32659538.0 \t loss_valid = 27561244.0 \n",
      "Model_4_5790 \t loss_train = 33670068.0 \t loss_valid = 28450892.0 \n",
      "Model_4_5800 \t loss_train = 33204738.0 \t loss_valid = 27986638.0 \n",
      "Model_4_5810 \t loss_train = 33164860.0 \t loss_valid = 28105934.0 \n",
      "Model_4_5820 \t loss_train = 33272176.0 \t loss_valid = 28059974.0 \n",
      "Model_4_5830 \t loss_train = 32835164.0 \t loss_valid = 27654674.0 \n",
      "Model_4_5840 \t loss_train = 33434056.0 \t loss_valid = 28235846.0 \n",
      "Model_4_5850 \t loss_train = 33202594.0 \t loss_valid = 28025544.0 \n",
      "Model_4_5860 \t loss_train = 33110454.0 \t loss_valid = 27998376.0 \n",
      "Model_4_5870 \t loss_train = 33815420.0 \t loss_valid = 28538832.0 \n",
      "Model_4_5880 \t loss_train = 33266976.0 \t loss_valid = 28159526.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_4_5890 \t loss_train = 33297224.0 \t loss_valid = 28037524.0 \n",
      "Model_4_5900 \t loss_train = 33578720.0 \t loss_valid = 28378542.0 \n",
      "Model_4_5910 \t loss_train = 32729604.0 \t loss_valid = 27682384.0 \n",
      "Model_4_5920 \t loss_train = 33855412.0 \t loss_valid = 28612994.0 \n",
      "Model_4_5930 \t loss_train = 32684104.0 \t loss_valid = 27585302.0 \n",
      "Model_4_5940 \t loss_train = 33580596.0 \t loss_valid = 28311578.0 \n",
      "Model_4_5950 \t loss_train = 32503354.0 \t loss_valid = 27469596.0 \n",
      "Model_4_5960 \t loss_train = 33078432.0 \t loss_valid = 27938962.0 \n",
      "Model_4_5970 \t loss_train = 33896904.0 \t loss_valid = 28546420.0 \n",
      "Model_4_5980 \t loss_train = 33044098.0 \t loss_valid = 27976894.0 \n",
      "Model_4_5990 \t loss_train = 33686148.0 \t loss_valid = 28451528.0 \n",
      "Model_4_6000 \t loss_train = 33405354.0 \t loss_valid = 28189654.0 \n",
      "Model_4_6010 \t loss_train = 33324526.0 \t loss_valid = 28149928.0 \n",
      "Model_4_6020 \t loss_train = 32836738.0 \t loss_valid = 27681720.0 \n",
      "Model_4_6030 \t loss_train = 33212230.0 \t loss_valid = 28103014.0 \n",
      "Model_4_6040 \t loss_train = 33583584.0 \t loss_valid = 28346040.0 \n",
      "Model_4_6050 \t loss_train = 33586148.0 \t loss_valid = 28379636.0 \n",
      "Model_4_6060 \t loss_train = 33297866.0 \t loss_valid = 28032354.0 \n",
      "Model_4_6070 \t loss_train = 33728600.0 \t loss_valid = 28465740.0 \n",
      "Model_4_6080 \t loss_train = 33457180.0 \t loss_valid = 28219644.0 \n",
      "Model_4_6090 \t loss_train = 33154476.0 \t loss_valid = 27990288.0 \n",
      "Model_4_6100 \t loss_train = 33720552.0 \t loss_valid = 28487292.0 \n",
      "Model_4_6110 \t loss_train = 33209240.0 \t loss_valid = 27982418.0 \n",
      "Model_4_6120 \t loss_train = 33353038.0 \t loss_valid = 28104274.0 \n",
      "Model_4_6130 \t loss_train = 33357474.0 \t loss_valid = 28202894.0 \n",
      "Model_4_6140 \t loss_train = 33827952.0 \t loss_valid = 28493312.0 \n",
      "Model_4_6150 \t loss_train = 33229894.0 \t loss_valid = 28039680.0 \n",
      "Model_4_6160 \t loss_train = 33614684.0 \t loss_valid = 28336406.0 \n",
      "Model_4_6170 \t loss_train = 33249372.0 \t loss_valid = 27996480.0 \n",
      "Model_4_6180 \t loss_train = 33554212.0 \t loss_valid = 28366532.0 \n",
      "Model_4_6190 \t loss_train = 33455462.0 \t loss_valid = 28271426.0 \n",
      "Model_4_6200 \t loss_train = 33514246.0 \t loss_valid = 28243168.0 \n",
      "Model_4_6210 \t loss_train = 33043802.0 \t loss_valid = 27893794.0 \n",
      "Model_4_6220 \t loss_train = 33631108.0 \t loss_valid = 28443434.0 \n",
      "Model_4_6230 \t loss_train = 33514344.0 \t loss_valid = 28177652.0 \n",
      "Model_4_6240 \t loss_train = 33254674.0 \t loss_valid = 28027784.0 \n",
      "Model_4_6250 \t loss_train = 34464144.0 \t loss_valid = 29084350.0 \n",
      "Model_4_6260 \t loss_train = 33475196.0 \t loss_valid = 28351498.0 \n",
      "Model_4_6270 \t loss_train = 33189026.0 \t loss_valid = 27933520.0 \n",
      "Model_4_6280 \t loss_train = 33835540.0 \t loss_valid = 28578090.0 \n",
      "Model_4_6290 \t loss_train = 33467322.0 \t loss_valid = 28239742.0 \n",
      "Model_4_6300 \t loss_train = 34106892.0 \t loss_valid = 28722796.0 \n",
      "Model_4_6310 \t loss_train = 33112256.0 \t loss_valid = 27884006.0 \n",
      "Model_4_6320 \t loss_train = 33383262.0 \t loss_valid = 28107472.0 \n",
      "Model_4_6330 \t loss_train = 34286684.0 \t loss_valid = 28862746.0 \n",
      "Model_4_6340 \t loss_train = 33368954.0 \t loss_valid = 27999766.0 \n",
      "Model_4_6350 \t loss_train = 33595428.0 \t loss_valid = 28258212.0 \n",
      "Model_4_6360 \t loss_train = 34062984.0 \t loss_valid = 28628862.0 \n",
      "Model_4_6370 \t loss_train = 33445394.0 \t loss_valid = 28147504.0 \n",
      "Model_4_6380 \t loss_train = 33993820.0 \t loss_valid = 28576214.0 \n",
      "Model_4_6390 \t loss_train = 33929752.0 \t loss_valid = 28583968.0 \n",
      "Model_4_6400 \t loss_train = 33813716.0 \t loss_valid = 28498896.0 \n",
      "Model_4_6410 \t loss_train = 33844072.0 \t loss_valid = 28461624.0 \n",
      "Model_4_6420 \t loss_train = 34389512.0 \t loss_valid = 28935918.0 \n",
      "Model_4_6430 \t loss_train = 33775580.0 \t loss_valid = 28370672.0 \n",
      "Model_4_6440 \t loss_train = 33752084.0 \t loss_valid = 28331536.0 \n",
      "Model_4_6450 \t loss_train = 34120620.0 \t loss_valid = 28739056.0 \n",
      "Model_4_6460 \t loss_train = 33855736.0 \t loss_valid = 28409672.0 \n",
      "Model_4_6470 \t loss_train = 33888032.0 \t loss_valid = 28605788.0 \n",
      "Model_4_6480 \t loss_train = 33390934.0 \t loss_valid = 28126610.0 \n",
      "Model_4_6490 \t loss_train = 34036624.0 \t loss_valid = 28678340.0 \n",
      "Model_4_6500 \t loss_train = 33710032.0 \t loss_valid = 28344716.0 \n",
      "Model_4_6510 \t loss_train = 34054156.0 \t loss_valid = 28629342.0 \n",
      "Model_4_6520 \t loss_train = 34077144.0 \t loss_valid = 28613394.0 \n",
      "Model_4_6530 \t loss_train = 33792360.0 \t loss_valid = 28516706.0 \n",
      "Model_4_6540 \t loss_train = 33910504.0 \t loss_valid = 28422350.0 \n",
      "Model_4_6550 \t loss_train = 34313160.0 \t loss_valid = 28871550.0 \n",
      "Model_4_6560 \t loss_train = 33374522.0 \t loss_valid = 28021596.0 \n",
      "Model_4_6570 \t loss_train = 34256608.0 \t loss_valid = 28859974.0 \n",
      "Model_4_6580 \t loss_train = 33456076.0 \t loss_valid = 28166194.0 \n",
      "Model_4_6590 \t loss_train = 33689392.0 \t loss_valid = 28263414.0 \n",
      "Model_4_6600 \t loss_train = 34150648.0 \t loss_valid = 28696424.0 \n",
      "Model_4_6610 \t loss_train = 33135736.0 \t loss_valid = 27914016.0 \n",
      "Model_4_6620 \t loss_train = 34473428.0 \t loss_valid = 28928152.0 \n",
      "Model_4_6630 \t loss_train = 34280576.0 \t loss_valid = 28884938.0 \n",
      "Model_4_6640 \t loss_train = 33351808.0 \t loss_valid = 28029194.0 \n",
      "Model_4_6650 \t loss_train = 34252672.0 \t loss_valid = 28874576.0 \n",
      "Model_4_6660 \t loss_train = 33210704.0 \t loss_valid = 27887916.0 \n",
      "Model_4_6670 \t loss_train = 34010472.0 \t loss_valid = 28527038.0 \n",
      "Model_4_6680 \t loss_train = 33826420.0 \t loss_valid = 28434878.0 \n",
      "Model_4_6690 \t loss_train = 33748600.0 \t loss_valid = 28396010.0 \n",
      "Model_4_6700 \t loss_train = 33814968.0 \t loss_valid = 28454618.0 \n",
      "Model_4_6710 \t loss_train = 33738328.0 \t loss_valid = 28366646.0 \n",
      "Model_4_6720 \t loss_train = 34123052.0 \t loss_valid = 28691106.0 \n",
      "Model_4_6730 \t loss_train = 34138424.0 \t loss_valid = 28684844.0 \n",
      "Model_4_6740 \t loss_train = 34047052.0 \t loss_valid = 28725482.0 \n",
      "Model_4_6750 \t loss_train = 34311596.0 \t loss_valid = 28835426.0 \n",
      "Model_4_6760 \t loss_train = 34076204.0 \t loss_valid = 28571064.0 \n",
      "Model_4_6770 \t loss_train = 33740200.0 \t loss_valid = 28314112.0 \n",
      "Model_4_6780 \t loss_train = 34079276.0 \t loss_valid = 28653006.0 \n",
      "Model_4_6790 \t loss_train = 34109316.0 \t loss_valid = 28652850.0 \n",
      "Model_4_6800 \t loss_train = 33974524.0 \t loss_valid = 28545492.0 \n",
      "Model_4_6810 \t loss_train = 33987544.0 \t loss_valid = 28576676.0 \n",
      "Model_4_6820 \t loss_train = 34349644.0 \t loss_valid = 28864360.0 \n",
      "Model_4_6830 \t loss_train = 34135976.0 \t loss_valid = 28692344.0 \n",
      "Model_4_6840 \t loss_train = 34165288.0 \t loss_valid = 28662570.0 \n",
      "Model_4_6850 \t loss_train = 33945552.0 \t loss_valid = 28474216.0 \n",
      "Model_4_6860 \t loss_train = 34125776.0 \t loss_valid = 28611444.0 \n",
      "Model_4_6870 \t loss_train = 34244608.0 \t loss_valid = 28793740.0 \n",
      "Model_4_6880 \t loss_train = 33865092.0 \t loss_valid = 28380508.0 \n",
      "Model_4_6890 \t loss_train = 34316564.0 \t loss_valid = 28916048.0 \n",
      "Model_4_6900 \t loss_train = 33716520.0 \t loss_valid = 28313590.0 \n",
      "Model_4_6910 \t loss_train = 34446364.0 \t loss_valid = 28888760.0 \n",
      "Model_4_6920 \t loss_train = 33863008.0 \t loss_valid = 28455152.0 \n",
      "Model_4_6930 \t loss_train = 34028384.0 \t loss_valid = 28560400.0 \n",
      "Model_4_6940 \t loss_train = 34030096.0 \t loss_valid = 28567210.0 \n",
      "Model_4_6950 \t loss_train = 34481884.0 \t loss_valid = 28961296.0 \n",
      "Model_4_6960 \t loss_train = 33704836.0 \t loss_valid = 28257622.0 \n",
      "Model_4_6970 \t loss_train = 34470584.0 \t loss_valid = 28971418.0 \n",
      "Model_4_6980 \t loss_train = 33977404.0 \t loss_valid = 28467516.0 \n",
      "Model_4_6990 \t loss_train = 34034028.0 \t loss_valid = 28611050.0 \n",
      "Model_4_7000 \t loss_train = 34347944.0 \t loss_valid = 28774208.0 \n",
      "Model_4_7010 \t loss_train = 34186708.0 \t loss_valid = 28627326.0 \n",
      "Model_4_7020 \t loss_train = 34241124.0 \t loss_valid = 28771726.0 \n",
      "Model_4_7030 \t loss_train = 34323888.0 \t loss_valid = 28840584.0 \n",
      "Model_4_7040 \t loss_train = 33842524.0 \t loss_valid = 28442162.0 \n",
      "Model_4_7050 \t loss_train = 33914552.0 \t loss_valid = 28500998.0 \n",
      "Model_4_7060 \t loss_train = 34496064.0 \t loss_valid = 29002044.0 \n",
      "Model_4_7070 \t loss_train = 34499212.0 \t loss_valid = 28942254.0 \n",
      "Model_4_7080 \t loss_train = 34499024.0 \t loss_valid = 28997824.0 \n",
      "Model_4_7090 \t loss_train = 34165932.0 \t loss_valid = 28674484.0 \n",
      "Model_4_7100 \t loss_train = 34048816.0 \t loss_valid = 28487790.0 \n",
      "Model_4_7110 \t loss_train = 34537144.0 \t loss_valid = 29025736.0 \n",
      "Model_4_7120 \t loss_train = 34033264.0 \t loss_valid = 28540704.0 \n",
      "Model_4_7130 \t loss_train = 34686476.0 \t loss_valid = 29018146.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_4_7140 \t loss_train = 34263728.0 \t loss_valid = 28720960.0 \n",
      "Model_4_7150 \t loss_train = 34210912.0 \t loss_valid = 28738490.0 \n",
      "Model_4_7160 \t loss_train = 34759132.0 \t loss_valid = 29150894.0 \n",
      "Model_4_7170 \t loss_train = 33868624.0 \t loss_valid = 28379496.0 \n",
      "Model_4_7180 \t loss_train = 34260936.0 \t loss_valid = 28795824.0 \n",
      "Model_4_7190 \t loss_train = 34689732.0 \t loss_valid = 29060488.0 \n",
      "Model_4_7200 \t loss_train = 34350808.0 \t loss_valid = 28847152.0 \n",
      "Model_4_7210 \t loss_train = 34442768.0 \t loss_valid = 28871626.0 \n",
      "Model_4_7220 \t loss_train = 34185460.0 \t loss_valid = 28712956.0 \n",
      "Model_4_7230 \t loss_train = 34487916.0 \t loss_valid = 28912214.0 \n",
      "Model_4_7240 \t loss_train = 34716572.0 \t loss_valid = 29107520.0 \n",
      "Model_4_7250 \t loss_train = 34354236.0 \t loss_valid = 28815022.0 \n",
      "Model_4_7260 \t loss_train = 34594180.0 \t loss_valid = 28998314.0 \n",
      "Model_4_7270 \t loss_train = 34511092.0 \t loss_valid = 28972898.0 \n",
      "Model_4_7280 \t loss_train = 34017040.0 \t loss_valid = 28447982.0 \n",
      "Model_4_7290 \t loss_train = 34571868.0 \t loss_valid = 28998656.0 \n",
      "Model_4_7300 \t loss_train = 33621368.0 \t loss_valid = 28237280.0 \n",
      "Model_4_7310 \t loss_train = 35233296.0 \t loss_valid = 29526856.0 \n",
      "Model_4_7320 \t loss_train = 34060368.0 \t loss_valid = 28512898.0 \n",
      "Model_4_7330 \t loss_train = 34741644.0 \t loss_valid = 29131998.0 \n",
      "Model_4_7340 \t loss_train = 34360260.0 \t loss_valid = 28772860.0 \n",
      "Model_4_7350 \t loss_train = 34476320.0 \t loss_valid = 28887668.0 \n",
      "Model_4_7360 \t loss_train = 34357552.0 \t loss_valid = 28871048.0 \n",
      "Model_4_7370 \t loss_train = 34272036.0 \t loss_valid = 28780986.0 \n",
      "Model_4_7380 \t loss_train = 34239864.0 \t loss_valid = 28631840.0 \n",
      "Model_4_7390 \t loss_train = 34616832.0 \t loss_valid = 28981580.0 \n",
      "Model_4_7400 \t loss_train = 34129408.0 \t loss_valid = 28628010.0 \n",
      "Model_4_7410 \t loss_train = 34505756.0 \t loss_valid = 28923960.0 \n",
      "Model_4_7420 \t loss_train = 34557796.0 \t loss_valid = 28955216.0 \n",
      "Model_4_7430 \t loss_train = 34559976.0 \t loss_valid = 28879846.0 \n",
      "Model_4_7440 \t loss_train = 34682856.0 \t loss_valid = 29084846.0 \n",
      "Model_4_7450 \t loss_train = 34490456.0 \t loss_valid = 28843592.0 \n",
      "Model_4_7460 \t loss_train = 34776252.0 \t loss_valid = 29070264.0 \n",
      "Model_4_7470 \t loss_train = 35078476.0 \t loss_valid = 29399868.0 \n",
      "Model_4_7480 \t loss_train = 34307864.0 \t loss_valid = 28715140.0 \n",
      "Model_4_7490 \t loss_train = 35015644.0 \t loss_valid = 29370304.0 \n",
      "Model_4_7500 \t loss_train = 34292304.0 \t loss_valid = 28840628.0 \n",
      "Model_4_7510 \t loss_train = 34602232.0 \t loss_valid = 29009532.0 \n",
      "Model_4_7520 \t loss_train = 34609200.0 \t loss_valid = 28962782.0 \n",
      "Model_4_7530 \t loss_train = 34263860.0 \t loss_valid = 28673122.0 \n",
      "Model_4_7540 \t loss_train = 34721388.0 \t loss_valid = 29122032.0 \n",
      "Model_4_7550 \t loss_train = 34269364.0 \t loss_valid = 28723680.0 \n",
      "Model_4_7560 \t loss_train = 34897400.0 \t loss_valid = 29191886.0 \n",
      "Model_4_7570 \t loss_train = 34157152.0 \t loss_valid = 28619574.0 \n",
      "Model_4_7580 \t loss_train = 34561264.0 \t loss_valid = 29026000.0 \n",
      "Model_4_7590 \t loss_train = 34538568.0 \t loss_valid = 28967676.0 \n",
      "Model_4_7600 \t loss_train = 34329500.0 \t loss_valid = 28766062.0 \n",
      "Model_4_7610 \t loss_train = 34810796.0 \t loss_valid = 29101192.0 \n",
      "Model_4_7620 \t loss_train = 34404416.0 \t loss_valid = 28793460.0 \n",
      "Model_4_7630 \t loss_train = 34519324.0 \t loss_valid = 28934034.0 \n",
      "Model_4_7640 \t loss_train = 34532856.0 \t loss_valid = 28810294.0 \n",
      "Model_4_7650 \t loss_train = 34605480.0 \t loss_valid = 28961502.0 \n",
      "Model_4_7660 \t loss_train = 34894288.0 \t loss_valid = 29119150.0 \n",
      "Model_4_7670 \t loss_train = 34738628.0 \t loss_valid = 29145208.0 \n",
      "Model_4_7680 \t loss_train = 34404648.0 \t loss_valid = 28721758.0 \n",
      "Model_4_7690 \t loss_train = 34636216.0 \t loss_valid = 29036118.0 \n",
      "Model_4_7700 \t loss_train = 34954492.0 \t loss_valid = 29227362.0 \n",
      "Model_4_7710 \t loss_train = 34084220.0 \t loss_valid = 28571764.0 \n",
      "Model_4_7720 \t loss_train = 35026164.0 \t loss_valid = 29354572.0 \n",
      "Model_4_7730 \t loss_train = 34653696.0 \t loss_valid = 29023264.0 \n",
      "Model_4_7740 \t loss_train = 34931808.0 \t loss_valid = 29219934.0 \n",
      "Model_4_7750 \t loss_train = 35068396.0 \t loss_valid = 29329124.0 \n",
      "Model_4_7760 \t loss_train = 34535440.0 \t loss_valid = 28937994.0 \n",
      "Model_4_7770 \t loss_train = 34084804.0 \t loss_valid = 28528602.0 \n",
      "Model_4_7780 \t loss_train = 35013436.0 \t loss_valid = 29327996.0 \n",
      "Model_4_7790 \t loss_train = 34653384.0 \t loss_valid = 28989370.0 \n",
      "Model_4_7800 \t loss_train = 34609192.0 \t loss_valid = 28939660.0 \n",
      "Model_4_7810 \t loss_train = 34365488.0 \t loss_valid = 28771038.0 \n",
      "Model_4_7820 \t loss_train = 35157608.0 \t loss_valid = 29422494.0 \n",
      "Model_4_7830 \t loss_train = 34572204.0 \t loss_valid = 28914328.0 \n",
      "Model_4_7840 \t loss_train = 34652436.0 \t loss_valid = 28951072.0 \n",
      "Model_4_7850 \t loss_train = 34925868.0 \t loss_valid = 29316412.0 \n",
      "Model_4_7860 \t loss_train = 34983980.0 \t loss_valid = 29336504.0 \n",
      "Model_4_7870 \t loss_train = 34651248.0 \t loss_valid = 28970266.0 \n",
      "Model_4_7880 \t loss_train = 34992308.0 \t loss_valid = 29271220.0 \n",
      "Model_4_7890 \t loss_train = 35002816.0 \t loss_valid = 29229132.0 \n",
      "Model_4_7900 \t loss_train = 34943292.0 \t loss_valid = 29146950.0 \n",
      "Model_4_7910 \t loss_train = 34625400.0 \t loss_valid = 28995764.0 \n",
      "Model_4_7920 \t loss_train = 34954232.0 \t loss_valid = 29231590.0 \n",
      "Model_4_7930 \t loss_train = 34748688.0 \t loss_valid = 29087466.0 \n",
      "Model_4_7940 \t loss_train = 34797404.0 \t loss_valid = 29152250.0 \n",
      "Model_4_7950 \t loss_train = 35121516.0 \t loss_valid = 29321292.0 \n",
      "Model_4_7960 \t loss_train = 35177816.0 \t loss_valid = 29399280.0 \n",
      "Model_4_7970 \t loss_train = 34569844.0 \t loss_valid = 28930690.0 \n",
      "Model_4_7980 \t loss_train = 35225780.0 \t loss_valid = 29483602.0 \n",
      "Model_4_7990 \t loss_train = 34703952.0 \t loss_valid = 29032748.0 \n",
      "Model_4_8000 \t loss_train = 34735384.0 \t loss_valid = 29060688.0 \n",
      "Model_4_8010 \t loss_train = 34656728.0 \t loss_valid = 28953680.0 \n",
      "Model_4_8020 \t loss_train = 35297716.0 \t loss_valid = 29499006.0 \n",
      "Model_4_8030 \t loss_train = 34614640.0 \t loss_valid = 28876762.0 \n",
      "Model_4_8040 \t loss_train = 35055672.0 \t loss_valid = 29286678.0 \n",
      "Model_4_8050 \t loss_train = 35198024.0 \t loss_valid = 29465430.0 \n",
      "Model_4_8060 \t loss_train = 34542504.0 \t loss_valid = 28962348.0 \n",
      "Model_4_8070 \t loss_train = 34957876.0 \t loss_valid = 29150264.0 \n",
      "Model_4_8080 \t loss_train = 35130412.0 \t loss_valid = 29410744.0 \n",
      "Model_4_8090 \t loss_train = 35009424.0 \t loss_valid = 29170444.0 \n",
      "Model_4_8100 \t loss_train = 35088672.0 \t loss_valid = 29375086.0 \n",
      "Model_4_8110 \t loss_train = 35128384.0 \t loss_valid = 29272038.0 \n",
      "Model_4_8120 \t loss_train = 35148284.0 \t loss_valid = 29413812.0 \n",
      "Model_4_8130 \t loss_train = 34460868.0 \t loss_valid = 28807450.0 \n",
      "Model_4_8140 \t loss_train = 35296200.0 \t loss_valid = 29476874.0 \n",
      "Model_4_8150 \t loss_train = 34803640.0 \t loss_valid = 29188506.0 \n",
      "Model_4_8160 \t loss_train = 35093080.0 \t loss_valid = 29267074.0 \n",
      "Model_4_8170 \t loss_train = 35516464.0 \t loss_valid = 29696824.0 \n",
      "Model_4_8180 \t loss_train = 34742104.0 \t loss_valid = 29006522.0 \n",
      "Model_4_8190 \t loss_train = 35365228.0 \t loss_valid = 29598288.0 \n",
      "Model_4_8200 \t loss_train = 35483692.0 \t loss_valid = 29674528.0 \n",
      "Model_4_8210 \t loss_train = 34840460.0 \t loss_valid = 29093274.0 \n",
      "Model_4_8220 \t loss_train = 35116800.0 \t loss_valid = 29425942.0 \n",
      "Model_4_8230 \t loss_train = 35013200.0 \t loss_valid = 29228614.0 \n",
      "Model_4_8240 \t loss_train = 34695376.0 \t loss_valid = 28880434.0 \n",
      "Model_4_8250 \t loss_train = 35437508.0 \t loss_valid = 29633094.0 \n",
      "Model_4_8260 \t loss_train = 35041096.0 \t loss_valid = 29153994.0 \n",
      "Model_4_8270 \t loss_train = 35625196.0 \t loss_valid = 29815428.0 \n",
      "Model_4_8280 \t loss_train = 34840808.0 \t loss_valid = 29019244.0 \n",
      "Model_4_8290 \t loss_train = 35199280.0 \t loss_valid = 29421650.0 \n",
      "Model_4_8300 \t loss_train = 34728376.0 \t loss_valid = 28892160.0 \n",
      "Model_4_8310 \t loss_train = 35523364.0 \t loss_valid = 29619452.0 \n",
      "Model_4_8320 \t loss_train = 35000564.0 \t loss_valid = 29331522.0 \n",
      "Model_4_8330 \t loss_train = 35479816.0 \t loss_valid = 29567760.0 \n",
      "Model_4_8340 \t loss_train = 35260484.0 \t loss_valid = 29587904.0 \n",
      "Model_4_8350 \t loss_train = 35265580.0 \t loss_valid = 29381164.0 \n",
      "Model_4_8360 \t loss_train = 35353724.0 \t loss_valid = 29496882.0 \n",
      "Model_4_8370 \t loss_train = 35289960.0 \t loss_valid = 29461982.0 \n",
      "Model_4_8380 \t loss_train = 34882076.0 \t loss_valid = 29183438.0 \n",
      "Model_4_8390 \t loss_train = 35594972.0 \t loss_valid = 29763534.0 \n",
      "Model_4_8400 \t loss_train = 35450124.0 \t loss_valid = 29558734.0 \n",
      "Model_4_8410 \t loss_train = 35274164.0 \t loss_valid = 29481930.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_4_8420 \t loss_train = 35223844.0 \t loss_valid = 29350216.0 \n",
      "Model_4_8430 \t loss_train = 35419916.0 \t loss_valid = 29575010.0 \n",
      "Model_4_8440 \t loss_train = 35549700.0 \t loss_valid = 29673956.0 \n",
      "Model_4_8450 \t loss_train = 34813012.0 \t loss_valid = 29117576.0 \n",
      "Model_4_8460 \t loss_train = 35507404.0 \t loss_valid = 29708970.0 \n",
      "Model_4_8470 \t loss_train = 35245640.0 \t loss_valid = 29337632.0 \n",
      "Model_4_8480 \t loss_train = 35676404.0 \t loss_valid = 29866718.0 \n",
      "Model_4_8490 \t loss_train = 34746500.0 \t loss_valid = 28977022.0 \n",
      "Model_4_8500 \t loss_train = 35801928.0 \t loss_valid = 29972258.0 \n",
      "Model_4_8510 \t loss_train = 34932456.0 \t loss_valid = 29175422.0 \n",
      "Model_4_8520 \t loss_train = 34972800.0 \t loss_valid = 29216448.0 \n",
      "Model_4_8530 \t loss_train = 36194540.0 \t loss_valid = 30287860.0 \n",
      "Model_4_8540 \t loss_train = 34805252.0 \t loss_valid = 29026042.0 \n",
      "Model_4_8550 \t loss_train = 35301684.0 \t loss_valid = 29433508.0 \n",
      "Model_4_8560 \t loss_train = 35316164.0 \t loss_valid = 29457990.0 \n",
      "Model_4_8570 \t loss_train = 35417260.0 \t loss_valid = 29643426.0 \n",
      "Model_4_8580 \t loss_train = 35509120.0 \t loss_valid = 29559034.0 \n",
      "Model_4_8590 \t loss_train = 35663672.0 \t loss_valid = 29770142.0 \n",
      "Model_4_8600 \t loss_train = 35287712.0 \t loss_valid = 29369860.0 \n",
      "Model_4_8610 \t loss_train = 35707276.0 \t loss_valid = 29758468.0 \n",
      "Model_4_8620 \t loss_train = 35191728.0 \t loss_valid = 29425622.0 \n",
      "Model_4_8630 \t loss_train = 35620580.0 \t loss_valid = 29738306.0 \n",
      "Model_4_8640 \t loss_train = 35749040.0 \t loss_valid = 29775948.0 \n",
      "Model_4_8650 \t loss_train = 35358940.0 \t loss_valid = 29485760.0 \n",
      "Model_4_8660 \t loss_train = 35700040.0 \t loss_valid = 29803924.0 \n",
      "Model_4_8670 \t loss_train = 35402552.0 \t loss_valid = 29400532.0 \n",
      "Model_4_8680 \t loss_train = 35992084.0 \t loss_valid = 30077360.0 \n",
      "Model_4_8690 \t loss_train = 35881524.0 \t loss_valid = 29889716.0 \n",
      "Model_4_8700 \t loss_train = 35461228.0 \t loss_valid = 29626852.0 \n",
      "Model_4_8710 \t loss_train = 35642920.0 \t loss_valid = 29686000.0 \n",
      "Model_4_8720 \t loss_train = 35610320.0 \t loss_valid = 29650672.0 \n",
      "Model_4_8730 \t loss_train = 35765976.0 \t loss_valid = 29848994.0 \n",
      "Model_4_8740 \t loss_train = 35761772.0 \t loss_valid = 29810536.0 \n",
      "Model_4_8750 \t loss_train = 35659592.0 \t loss_valid = 29760298.0 \n",
      "Model_4_8760 \t loss_train = 35749000.0 \t loss_valid = 29666880.0 \n",
      "Model_4_8770 \t loss_train = 35681036.0 \t loss_valid = 29780634.0 \n",
      "Model_4_8780 \t loss_train = 35816440.0 \t loss_valid = 29975812.0 \n",
      "Model_4_8790 \t loss_train = 36115856.0 \t loss_valid = 30094212.0 \n",
      "Model_4_8800 \t loss_train = 35165096.0 \t loss_valid = 29342502.0 \n",
      "Model_4_8810 \t loss_train = 35988328.0 \t loss_valid = 29917632.0 \n",
      "Model_4_8820 \t loss_train = 36563912.0 \t loss_valid = 30509866.0 \n",
      "Model_4_8830 \t loss_train = 35528036.0 \t loss_valid = 29602658.0 \n",
      "Model_4_8840 \t loss_train = 36198992.0 \t loss_valid = 30271604.0 \n",
      "Model_4_8850 \t loss_train = 35653596.0 \t loss_valid = 29671964.0 \n",
      "Model_4_8860 \t loss_train = 35684700.0 \t loss_valid = 29800894.0 \n",
      "Model_4_8870 \t loss_train = 35899448.0 \t loss_valid = 29862366.0 \n",
      "Model_4_8880 \t loss_train = 35773700.0 \t loss_valid = 29863020.0 \n",
      "Model_4_8890 \t loss_train = 35804608.0 \t loss_valid = 29912270.0 \n",
      "Model_4_8900 \t loss_train = 35837164.0 \t loss_valid = 29838428.0 \n",
      "Model_4_8910 \t loss_train = 36183880.0 \t loss_valid = 30216230.0 \n",
      "Model_4_8920 \t loss_train = 35978808.0 \t loss_valid = 30049810.0 \n",
      "Model_4_8930 \t loss_train = 36277372.0 \t loss_valid = 30257930.0 \n",
      "Model_4_8940 \t loss_train = 36021732.0 \t loss_valid = 29952530.0 \n",
      "Model_4_8950 \t loss_train = 35753096.0 \t loss_valid = 29745632.0 \n",
      "Model_4_8960 \t loss_train = 36593808.0 \t loss_valid = 30612688.0 \n",
      "Model_4_8970 \t loss_train = 35636920.0 \t loss_valid = 29734292.0 \n",
      "Model_4_8980 \t loss_train = 35769184.0 \t loss_valid = 29797840.0 \n",
      "Model_4_8990 \t loss_train = 36128480.0 \t loss_valid = 30033440.0 \n",
      "Model_4_9000 \t loss_train = 36001472.0 \t loss_valid = 29970252.0 \n",
      "Model_4_9010 \t loss_train = 35895012.0 \t loss_valid = 29859490.0 \n",
      "Model_4_9020 \t loss_train = 36457044.0 \t loss_valid = 30419244.0 \n",
      "Model_4_9030 \t loss_train = 35640760.0 \t loss_valid = 29769756.0 \n",
      "Model_4_9040 \t loss_train = 36139920.0 \t loss_valid = 30069896.0 \n",
      "Model_4_9050 \t loss_train = 36110852.0 \t loss_valid = 29991142.0 \n",
      "Model_4_9060 \t loss_train = 35712148.0 \t loss_valid = 29701022.0 \n",
      "Model_4_9070 \t loss_train = 36210312.0 \t loss_valid = 30161300.0 \n",
      "Model_4_9080 \t loss_train = 35914604.0 \t loss_valid = 29919656.0 \n",
      "Model_4_9090 \t loss_train = 36218848.0 \t loss_valid = 30273612.0 \n",
      "Model_4_9100 \t loss_train = 36004276.0 \t loss_valid = 29920990.0 \n",
      "Model_4_9110 \t loss_train = 35976824.0 \t loss_valid = 29987758.0 \n",
      "Model_4_9120 \t loss_train = 36325000.0 \t loss_valid = 30290444.0 \n",
      "Model_4_9130 \t loss_train = 36518888.0 \t loss_valid = 30344460.0 \n",
      "Model_4_9140 \t loss_train = 36174004.0 \t loss_valid = 30099478.0 \n",
      "Model_4_9150 \t loss_train = 36343284.0 \t loss_valid = 30298444.0 \n",
      "Model_4_9160 \t loss_train = 35719696.0 \t loss_valid = 29762090.0 \n",
      "Model_4_9170 \t loss_train = 36246308.0 \t loss_valid = 30241072.0 \n",
      "Model_4_9180 \t loss_train = 36259504.0 \t loss_valid = 30205226.0 \n",
      "Model_4_9190 \t loss_train = 36201704.0 \t loss_valid = 30225664.0 \n",
      "Model_4_9200 \t loss_train = 36606088.0 \t loss_valid = 30484926.0 \n",
      "Model_4_9210 \t loss_train = 36619900.0 \t loss_valid = 30512508.0 \n",
      "Model_4_9220 \t loss_train = 35830384.0 \t loss_valid = 29784022.0 \n",
      "Model_4_9230 \t loss_train = 36131468.0 \t loss_valid = 30141304.0 \n",
      "Model_4_9240 \t loss_train = 36527364.0 \t loss_valid = 30426542.0 \n",
      "Model_4_9250 \t loss_train = 36266788.0 \t loss_valid = 30299674.0 \n",
      "Model_4_9260 \t loss_train = 36005968.0 \t loss_valid = 29943608.0 \n",
      "Model_4_9270 \t loss_train = 36015844.0 \t loss_valid = 30002748.0 \n",
      "Model_4_9280 \t loss_train = 37212848.0 \t loss_valid = 31125754.0 \n",
      "Model_4_9290 \t loss_train = 35749108.0 \t loss_valid = 29778578.0 \n",
      "Model_4_9300 \t loss_train = 36098684.0 \t loss_valid = 30013958.0 \n",
      "Model_4_9310 \t loss_train = 36260024.0 \t loss_valid = 30157944.0 \n",
      "Model_4_9320 \t loss_train = 36536624.0 \t loss_valid = 30484876.0 \n",
      "Model_4_9330 \t loss_train = 35732964.0 \t loss_valid = 29746820.0 \n",
      "Model_4_9340 \t loss_train = 36208692.0 \t loss_valid = 30246930.0 \n",
      "Model_4_9350 \t loss_train = 36443616.0 \t loss_valid = 30409548.0 \n",
      "Model_4_9360 \t loss_train = 36476008.0 \t loss_valid = 30418088.0 \n",
      "Model_4_9370 \t loss_train = 36305736.0 \t loss_valid = 30213072.0 \n",
      "Model_4_9380 \t loss_train = 36470256.0 \t loss_valid = 30422904.0 \n",
      "Model_4_9390 \t loss_train = 36726280.0 \t loss_valid = 30547396.0 \n",
      "Model_4_9400 \t loss_train = 36612456.0 \t loss_valid = 30477188.0 \n",
      "Model_4_9410 \t loss_train = 36610172.0 \t loss_valid = 30447590.0 \n",
      "Model_4_9420 \t loss_train = 36100548.0 \t loss_valid = 30055200.0 \n",
      "Model_4_9430 \t loss_train = 36889548.0 \t loss_valid = 30739956.0 \n",
      "Model_4_9440 \t loss_train = 36424136.0 \t loss_valid = 30298504.0 \n",
      "Model_4_9450 \t loss_train = 36736312.0 \t loss_valid = 30577314.0 \n",
      "Model_4_9460 \t loss_train = 36942992.0 \t loss_valid = 30668894.0 \n",
      "Model_4_9470 \t loss_train = 36335648.0 \t loss_valid = 30190504.0 \n",
      "Model_4_9480 \t loss_train = 36467048.0 \t loss_valid = 30209372.0 \n",
      "Model_4_9490 \t loss_train = 36653780.0 \t loss_valid = 30492682.0 \n",
      "Model_4_9500 \t loss_train = 37166944.0 \t loss_valid = 30818070.0 \n",
      "Model_4_9510 \t loss_train = 36439960.0 \t loss_valid = 30371230.0 \n",
      "Model_4_9520 \t loss_train = 36947356.0 \t loss_valid = 30695064.0 \n",
      "Model_4_9530 \t loss_train = 36864508.0 \t loss_valid = 30659676.0 \n",
      "Model_4_9540 \t loss_train = 36667652.0 \t loss_valid = 30435650.0 \n",
      "Model_4_9550 \t loss_train = 37053684.0 \t loss_valid = 30915546.0 \n",
      "Model_4_9560 \t loss_train = 36960332.0 \t loss_valid = 30691942.0 \n",
      "Model_4_9570 \t loss_train = 36855196.0 \t loss_valid = 30657208.0 \n",
      "Model_4_9580 \t loss_train = 36624060.0 \t loss_valid = 30398720.0 \n",
      "Model_4_9590 \t loss_train = 36915500.0 \t loss_valid = 30630780.0 \n",
      "Model_4_9600 \t loss_train = 36731536.0 \t loss_valid = 30465340.0 \n",
      "Model_4_9610 \t loss_train = 36960696.0 \t loss_valid = 30635934.0 \n",
      "Model_4_9620 \t loss_train = 36471172.0 \t loss_valid = 30422066.0 \n",
      "Model_4_9630 \t loss_train = 37076956.0 \t loss_valid = 30878360.0 \n",
      "Model_4_9640 \t loss_train = 37336520.0 \t loss_valid = 31119996.0 \n",
      "Model_4_9650 \t loss_train = 36722516.0 \t loss_valid = 30456756.0 \n",
      "Model_4_9660 \t loss_train = 36601920.0 \t loss_valid = 30395468.0 \n",
      "Model_4_9670 \t loss_train = 37060976.0 \t loss_valid = 30793918.0 \n",
      "Model_4_9680 \t loss_train = 37300968.0 \t loss_valid = 31057152.0 \n",
      "Model_4_9690 \t loss_train = 36679716.0 \t loss_valid = 30467808.0 \n",
      "Model_4_9700 \t loss_train = 36735216.0 \t loss_valid = 30505112.0 \n",
      "Model_4_9710 \t loss_train = 36589440.0 \t loss_valid = 30324884.0 \n",
      "Model_4_9720 \t loss_train = 36594744.0 \t loss_valid = 30408016.0 \n",
      "Model_4_9730 \t loss_train = 37102664.0 \t loss_valid = 30885688.0 \n",
      "Model_4_9740 \t loss_train = 37332636.0 \t loss_valid = 31082594.0 \n",
      "Model_4_9750 \t loss_train = 37277244.0 \t loss_valid = 30978180.0 \n",
      "Model_4_9760 \t loss_train = 37095932.0 \t loss_valid = 30858222.0 \n",
      "Model_4_9770 \t loss_train = 36780768.0 \t loss_valid = 30578066.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_4_9780 \t loss_train = 37139380.0 \t loss_valid = 30888928.0 \n",
      "Model_4_9790 \t loss_train = 37398952.0 \t loss_valid = 31120892.0 \n",
      "Model_4_9800 \t loss_train = 37157144.0 \t loss_valid = 30933978.0 \n",
      "Model_4_9810 \t loss_train = 37233412.0 \t loss_valid = 30973004.0 \n",
      "Model_4_9820 \t loss_train = 37042272.0 \t loss_valid = 30795100.0 \n",
      "Model_4_9830 \t loss_train = 37213720.0 \t loss_valid = 30776358.0 \n",
      "Model_4_9840 \t loss_train = 36977936.0 \t loss_valid = 30764010.0 \n",
      "Model_4_9850 \t loss_train = 36973732.0 \t loss_valid = 30749272.0 \n",
      "Model_4_9860 \t loss_train = 36836160.0 \t loss_valid = 30642922.0 \n",
      "Model_4_9870 \t loss_train = 36631472.0 \t loss_valid = 30398034.0 \n",
      "Model_4_9880 \t loss_train = 37087720.0 \t loss_valid = 30777824.0 \n",
      "Model_4_9890 \t loss_train = 37228168.0 \t loss_valid = 31036624.0 \n",
      "Model_4_9900 \t loss_train = 36766384.0 \t loss_valid = 30611144.0 \n",
      "Model_4_9910 \t loss_train = 37036756.0 \t loss_valid = 30730484.0 \n",
      "Model_4_9920 \t loss_train = 37231176.0 \t loss_valid = 30949480.0 \n",
      "Model_4_9930 \t loss_train = 36880664.0 \t loss_valid = 30625226.0 \n",
      "Model_4_9940 \t loss_train = 37196596.0 \t loss_valid = 30915954.0 \n",
      "Model_4_9950 \t loss_train = 36969128.0 \t loss_valid = 30742588.0 \n",
      "Model_4_9960 \t loss_train = 37207472.0 \t loss_valid = 30934828.0 \n",
      "Model_4_9970 \t loss_train = 36846404.0 \t loss_valid = 30548234.0 \n",
      "Model_4_9980 \t loss_train = 36542224.0 \t loss_valid = 30287986.0 \n",
      "Model_4_9990 \t loss_train = 37152376.0 \t loss_valid = 30869918.0 \n",
      "Model_4_10000 \t loss_train = 37400744.0 \t loss_valid = 31199130.0 \n",
      "Model_4_10010 \t loss_train = 37132912.0 \t loss_valid = 30776266.0 \n",
      "Model_4_10020 \t loss_train = 36685712.0 \t loss_valid = 30340308.0 \n",
      "Model_4_10030 \t loss_train = 36944208.0 \t loss_valid = 30732762.0 \n",
      "Model_4_10040 \t loss_train = 37665596.0 \t loss_valid = 31286058.0 \n",
      "Model_4_10050 \t loss_train = 37218212.0 \t loss_valid = 30960906.0 \n",
      "Model_4_10060 \t loss_train = 36937516.0 \t loss_valid = 30719630.0 \n",
      "Model_4_10070 \t loss_train = 36941936.0 \t loss_valid = 30574756.0 \n",
      "Model_4_10080 \t loss_train = 37674196.0 \t loss_valid = 31379178.0 \n",
      "Model_4_10090 \t loss_train = 37283356.0 \t loss_valid = 30937148.0 \n",
      "Model_4_10100 \t loss_train = 37292884.0 \t loss_valid = 30998120.0 \n",
      "Model_4_10110 \t loss_train = 37195544.0 \t loss_valid = 30853926.0 \n",
      "Model_4_10120 \t loss_train = 37630432.0 \t loss_valid = 31319580.0 \n",
      "Model_4_10130 \t loss_train = 37502040.0 \t loss_valid = 31118664.0 \n",
      "Model_4_10140 \t loss_train = 37275580.0 \t loss_valid = 31027346.0 \n",
      "Model_4_10150 \t loss_train = 37226568.0 \t loss_valid = 30933848.0 \n",
      "Model_4_10160 \t loss_train = 37522824.0 \t loss_valid = 31172958.0 \n",
      "Model_4_10170 \t loss_train = 37637284.0 \t loss_valid = 31336540.0 \n",
      "Model_4_10180 \t loss_train = 37459284.0 \t loss_valid = 31138718.0 \n",
      "Model_4_10190 \t loss_train = 37494588.0 \t loss_valid = 31154322.0 \n",
      "Model_4_10200 \t loss_train = 37316660.0 \t loss_valid = 31043186.0 \n",
      "Model_4_10210 \t loss_train = 37103076.0 \t loss_valid = 30762808.0 \n",
      "Model_4_10220 \t loss_train = 37041620.0 \t loss_valid = 30671502.0 \n",
      "Model_4_10230 \t loss_train = 37285408.0 \t loss_valid = 30912926.0 \n",
      "Model_4_10240 \t loss_train = 37510852.0 \t loss_valid = 31113444.0 \n",
      "Model_4_10250 \t loss_train = 37289216.0 \t loss_valid = 30997704.0 \n",
      "Model_4_10260 \t loss_train = 37690724.0 \t loss_valid = 31282448.0 \n",
      "Model_4_10270 \t loss_train = 37294312.0 \t loss_valid = 30880554.0 \n",
      "Model_4_10280 \t loss_train = 37481652.0 \t loss_valid = 31089850.0 \n",
      "Model_4_10290 \t loss_train = 37428088.0 \t loss_valid = 31102170.0 \n",
      "Model_4_10300 \t loss_train = 37643652.0 \t loss_valid = 31288730.0 \n",
      "Model_4_10310 \t loss_train = 37761728.0 \t loss_valid = 31446038.0 \n",
      "Model_4_10320 \t loss_train = 37798784.0 \t loss_valid = 31363856.0 \n",
      "Model_4_10330 \t loss_train = 37412376.0 \t loss_valid = 30949410.0 \n",
      "Model_4_10340 \t loss_train = 37170948.0 \t loss_valid = 30894286.0 \n",
      "Model_4_10350 \t loss_train = 38077516.0 \t loss_valid = 31683280.0 \n",
      "Model_4_10360 \t loss_train = 37352028.0 \t loss_valid = 30928602.0 \n",
      "Model_4_10370 \t loss_train = 37775016.0 \t loss_valid = 31400480.0 \n",
      "Model_4_10380 \t loss_train = 37343004.0 \t loss_valid = 31025072.0 \n",
      "Model_4_10390 \t loss_train = 37917868.0 \t loss_valid = 31513008.0 \n",
      "Model_4_10400 \t loss_train = 37763300.0 \t loss_valid = 31301746.0 \n",
      "Model_4_10410 \t loss_train = 37792752.0 \t loss_valid = 31436560.0 \n",
      "Model_4_10420 \t loss_train = 37300016.0 \t loss_valid = 30931706.0 \n",
      "Model_4_10430 \t loss_train = 37854620.0 \t loss_valid = 31480384.0 \n",
      "Model_4_10440 \t loss_train = 37641876.0 \t loss_valid = 31235552.0 \n",
      "Model_4_10450 \t loss_train = 37419412.0 \t loss_valid = 31088706.0 \n",
      "Model_4_10460 \t loss_train = 37359516.0 \t loss_valid = 31087986.0 \n",
      "Model_4_10470 \t loss_train = 37598172.0 \t loss_valid = 31123064.0 \n",
      "Model_4_10480 \t loss_train = 37544864.0 \t loss_valid = 31226358.0 \n",
      "Model_4_10490 \t loss_train = 37965644.0 \t loss_valid = 31565904.0 \n",
      "Model_4_10500 \t loss_train = 37325920.0 \t loss_valid = 30879498.0 \n",
      "Model_4_10510 \t loss_train = 37472104.0 \t loss_valid = 31199494.0 \n",
      "Model_4_10520 \t loss_train = 37673568.0 \t loss_valid = 31277640.0 \n",
      "Model_4_10530 \t loss_train = 37708368.0 \t loss_valid = 31295886.0 \n",
      "Model_4_10540 \t loss_train = 37298744.0 \t loss_valid = 30868470.0 \n",
      "Model_4_10550 \t loss_train = 37624940.0 \t loss_valid = 31226476.0 \n",
      "Model_4_10560 \t loss_train = 37569944.0 \t loss_valid = 31240316.0 \n",
      "Model_4_10570 \t loss_train = 37346000.0 \t loss_valid = 31074526.0 \n",
      "Model_4_10580 \t loss_train = 37882352.0 \t loss_valid = 31494094.0 \n",
      "Model_4_10590 \t loss_train = 37477032.0 \t loss_valid = 31120314.0 \n",
      "Model_4_10600 \t loss_train = 37916000.0 \t loss_valid = 31557082.0 \n",
      "Model_4_10610 \t loss_train = 37747460.0 \t loss_valid = 31306898.0 \n",
      "Model_4_10620 \t loss_train = 37524012.0 \t loss_valid = 31063668.0 \n",
      "Model_4_10630 \t loss_train = 37349552.0 \t loss_valid = 31046666.0 \n",
      "Model_4_10640 \t loss_train = 37673844.0 \t loss_valid = 31245078.0 \n",
      "Model_4_10650 \t loss_train = 37864432.0 \t loss_valid = 31451960.0 \n",
      "Model_4_10660 \t loss_train = 38287336.0 \t loss_valid = 31883268.0 \n",
      "Model_4_10670 \t loss_train = 37464608.0 \t loss_valid = 31096074.0 \n",
      "Model_4_10680 \t loss_train = 37514840.0 \t loss_valid = 31046306.0 \n",
      "Model_4_10690 \t loss_train = 37471612.0 \t loss_valid = 30996960.0 \n",
      "Model_4_10700 \t loss_train = 37913664.0 \t loss_valid = 31554358.0 \n",
      "Model_4_10710 \t loss_train = 37832708.0 \t loss_valid = 31357984.0 \n",
      "Model_4_10720 \t loss_train = 37588980.0 \t loss_valid = 31183616.0 \n",
      "Model_4_10730 \t loss_train = 37442216.0 \t loss_valid = 31037538.0 \n",
      "Model_4_10740 \t loss_train = 37743504.0 \t loss_valid = 31365742.0 \n",
      "Model_4_10750 \t loss_train = 37762804.0 \t loss_valid = 31335240.0 \n",
      "Model_4_10760 \t loss_train = 38146784.0 \t loss_valid = 31685970.0 \n",
      "Model_4_10770 \t loss_train = 38329020.0 \t loss_valid = 31802412.0 \n",
      "Model_4_10780 \t loss_train = 37553404.0 \t loss_valid = 31141224.0 \n",
      "Model_4_10790 \t loss_train = 38012452.0 \t loss_valid = 31543638.0 \n",
      "Model_4_10800 \t loss_train = 37960836.0 \t loss_valid = 31450448.0 \n",
      "Model_4_10810 \t loss_train = 37537968.0 \t loss_valid = 31065460.0 \n",
      "Model_4_10820 \t loss_train = 37812112.0 \t loss_valid = 31338174.0 \n",
      "Model_4_10830 \t loss_train = 38193412.0 \t loss_valid = 31682504.0 \n",
      "Model_4_10840 \t loss_train = 38139464.0 \t loss_valid = 31703558.0 \n",
      "Model_4_10850 \t loss_train = 38300868.0 \t loss_valid = 31883296.0 \n",
      "Model_4_10860 \t loss_train = 38083180.0 \t loss_valid = 31617170.0 \n",
      "Model_4_10870 \t loss_train = 37631216.0 \t loss_valid = 31284708.0 \n",
      "Model_4_10880 \t loss_train = 37869896.0 \t loss_valid = 31391188.0 \n",
      "Model_4_10890 \t loss_train = 37702564.0 \t loss_valid = 31203688.0 \n",
      "Model_4_10900 \t loss_train = 37698824.0 \t loss_valid = 31220212.0 \n",
      "Model_4_10910 \t loss_train = 37936444.0 \t loss_valid = 31466250.0 \n",
      "Model_4_10920 \t loss_train = 38263228.0 \t loss_valid = 31709936.0 \n",
      "Model_4_10930 \t loss_train = 38436728.0 \t loss_valid = 31963158.0 \n",
      "Model_4_10940 \t loss_train = 38494688.0 \t loss_valid = 32003912.0 \n",
      "Model_4_10950 \t loss_train = 37613984.0 \t loss_valid = 31147886.0 \n",
      "Model_4_10960 \t loss_train = 37926844.0 \t loss_valid = 31360432.0 \n",
      "Model_4_10970 \t loss_train = 37823508.0 \t loss_valid = 31431308.0 \n",
      "Model_4_10980 \t loss_train = 37845600.0 \t loss_valid = 31352156.0 \n",
      "Model_4_10990 \t loss_train = 38439620.0 \t loss_valid = 31920488.0 \n",
      "Early stopping!\n",
      "Model_5_0 \t loss_train = 119228984.0 \t loss_valid = 104259896.0 \n",
      "Model_5_10 \t loss_train = 116791056.0 \t loss_valid = 100939376.0 \n",
      "Model_5_20 \t loss_train = 110725688.0 \t loss_valid = 92734056.0 \n",
      "Model_5_30 \t loss_train = 97051112.0 \t loss_valid = 75522744.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_5_40 \t loss_train = 75272608.0 \t loss_valid = 56324044.0 \n",
      "Model_5_50 \t loss_train = 70115160.0 \t loss_valid = 72106136.0 \n",
      "Model_5_60 \t loss_train = 67685664.0 \t loss_valid = 58921124.0 \n",
      "Model_5_70 \t loss_train = 66231536.0 \t loss_valid = 55666044.0 \n",
      "Model_5_80 \t loss_train = 63690756.0 \t loss_valid = 56505060.0 \n",
      "Model_5_90 \t loss_train = 61980188.0 \t loss_valid = 52247380.0 \n",
      "Model_5_100 \t loss_train = 59681352.0 \t loss_valid = 52082500.0 \n",
      "Model_5_110 \t loss_train = 57909512.0 \t loss_valid = 47265680.0 \n",
      "Model_5_120 \t loss_train = 55632600.0 \t loss_valid = 45188104.0 \n",
      "Model_5_130 \t loss_train = 54224444.0 \t loss_valid = 42359980.0 \n",
      "Model_5_140 \t loss_train = 53052164.0 \t loss_valid = 41007300.0 \n",
      "Model_5_150 \t loss_train = 52609948.0 \t loss_valid = 39879160.0 \n",
      "Model_5_160 \t loss_train = 51877128.0 \t loss_valid = 39965324.0 \n",
      "Model_5_170 \t loss_train = 51569628.0 \t loss_valid = 39631752.0 \n",
      "Model_5_180 \t loss_train = 51470704.0 \t loss_valid = 39195668.0 \n",
      "Model_5_190 \t loss_train = 51053108.0 \t loss_valid = 39040756.0 \n",
      "Model_5_200 \t loss_train = 50446328.0 \t loss_valid = 39097924.0 \n",
      "Model_5_210 \t loss_train = 49999308.0 \t loss_valid = 38711664.0 \n",
      "Model_5_220 \t loss_train = 49506436.0 \t loss_valid = 38412464.0 \n",
      "Model_5_230 \t loss_train = 49235768.0 \t loss_valid = 37859340.0 \n",
      "Model_5_240 \t loss_train = 48924200.0 \t loss_valid = 37572072.0 \n",
      "Model_5_250 \t loss_train = 47954132.0 \t loss_valid = 37774628.0 \n",
      "Model_5_260 \t loss_train = 47404928.0 \t loss_valid = 36964676.0 \n",
      "Model_5_270 \t loss_train = 46828720.0 \t loss_valid = 36342552.0 \n",
      "Model_5_280 \t loss_train = 45693928.0 \t loss_valid = 36232756.0 \n",
      "Model_5_290 \t loss_train = 44945300.0 \t loss_valid = 35635640.0 \n",
      "Model_5_300 \t loss_train = 44046788.0 \t loss_valid = 35025100.0 \n",
      "Model_5_310 \t loss_train = 42660392.0 \t loss_valid = 34399280.0 \n",
      "Model_5_320 \t loss_train = 41364532.0 \t loss_valid = 33485742.0 \n",
      "Model_5_330 \t loss_train = 40076144.0 \t loss_valid = 32593986.0 \n",
      "Model_5_340 \t loss_train = 38151272.0 \t loss_valid = 32069998.0 \n",
      "Model_5_350 \t loss_train = 36244576.0 \t loss_valid = 31286540.0 \n",
      "Model_5_360 \t loss_train = 34613856.0 \t loss_valid = 29902330.0 \n",
      "Model_5_370 \t loss_train = 33037130.0 \t loss_valid = 29138868.0 \n",
      "Model_5_380 \t loss_train = 31502842.0 \t loss_valid = 29112956.0 \n",
      "Model_5_390 \t loss_train = 30439098.0 \t loss_valid = 27391886.0 \n",
      "Model_5_400 \t loss_train = 29819392.0 \t loss_valid = 26597758.0 \n",
      "Model_5_410 \t loss_train = 29770122.0 \t loss_valid = 26258616.0 \n",
      "Model_5_420 \t loss_train = 28580928.0 \t loss_valid = 26129174.0 \n",
      "Model_5_430 \t loss_train = 28429034.0 \t loss_valid = 26267326.0 \n",
      "Model_5_440 \t loss_train = 28361586.0 \t loss_valid = 25665492.0 \n",
      "Model_5_450 \t loss_train = 28558314.0 \t loss_valid = 25590858.0 \n",
      "Model_5_460 \t loss_train = 28306836.0 \t loss_valid = 25604766.0 \n",
      "Model_5_470 \t loss_train = 28259472.0 \t loss_valid = 26010372.0 \n",
      "Model_5_480 \t loss_train = 28160424.0 \t loss_valid = 25813048.0 \n",
      "Model_5_490 \t loss_train = 28369340.0 \t loss_valid = 25504808.0 \n",
      "Model_5_500 \t loss_train = 28335528.0 \t loss_valid = 25513716.0 \n",
      "Model_5_510 \t loss_train = 28130680.0 \t loss_valid = 25802414.0 \n",
      "Model_5_520 \t loss_train = 28513622.0 \t loss_valid = 25507252.0 \n",
      "Model_5_530 \t loss_train = 28145622.0 \t loss_valid = 25992778.0 \n",
      "Model_5_540 \t loss_train = 28196160.0 \t loss_valid = 25684428.0 \n",
      "Model_5_550 \t loss_train = 28232746.0 \t loss_valid = 25595936.0 \n",
      "Model_5_560 \t loss_train = 28119018.0 \t loss_valid = 25783312.0 \n",
      "Model_5_570 \t loss_train = 28514806.0 \t loss_valid = 25451938.0 \n",
      "Model_5_580 \t loss_train = 28311896.0 \t loss_valid = 25443596.0 \n",
      "Model_5_590 \t loss_train = 28437740.0 \t loss_valid = 25424984.0 \n",
      "Model_5_600 \t loss_train = 28098536.0 \t loss_valid = 25702318.0 \n",
      "Model_5_610 \t loss_train = 28117254.0 \t loss_valid = 25860838.0 \n",
      "Model_5_620 \t loss_train = 28242750.0 \t loss_valid = 25486596.0 \n",
      "Model_5_630 \t loss_train = 28136438.0 \t loss_valid = 25643080.0 \n",
      "Model_5_640 \t loss_train = 28134438.0 \t loss_valid = 25718656.0 \n",
      "Model_5_650 \t loss_train = 28136044.0 \t loss_valid = 25999782.0 \n",
      "Model_5_660 \t loss_train = 28144988.0 \t loss_valid = 25554890.0 \n",
      "Model_5_670 \t loss_train = 28195998.0 \t loss_valid = 25591668.0 \n",
      "Model_5_680 \t loss_train = 28168538.0 \t loss_valid = 25504814.0 \n",
      "Model_5_690 \t loss_train = 28173296.0 \t loss_valid = 25544114.0 \n",
      "Model_5_700 \t loss_train = 28214894.0 \t loss_valid = 25509812.0 \n",
      "Model_5_710 \t loss_train = 28064290.0 \t loss_valid = 25721100.0 \n",
      "Model_5_720 \t loss_train = 28206676.0 \t loss_valid = 25454554.0 \n",
      "Model_5_730 \t loss_train = 28329062.0 \t loss_valid = 25414562.0 \n",
      "Model_5_740 \t loss_train = 28178858.0 \t loss_valid = 25481488.0 \n",
      "Model_5_750 \t loss_train = 28281228.0 \t loss_valid = 25407326.0 \n",
      "Model_5_760 \t loss_train = 28118728.0 \t loss_valid = 25718722.0 \n",
      "Model_5_770 \t loss_train = 28100168.0 \t loss_valid = 25798858.0 \n",
      "Model_5_780 \t loss_train = 28171964.0 \t loss_valid = 25731018.0 \n",
      "Model_5_790 \t loss_train = 28406510.0 \t loss_valid = 25430638.0 \n",
      "Model_5_800 \t loss_train = 28375208.0 \t loss_valid = 25375590.0 \n",
      "Model_5_810 \t loss_train = 28218162.0 \t loss_valid = 25476114.0 \n",
      "Model_5_820 \t loss_train = 28126096.0 \t loss_valid = 25503696.0 \n",
      "Model_5_830 \t loss_train = 28084222.0 \t loss_valid = 25826428.0 \n",
      "Model_5_840 \t loss_train = 28089756.0 \t loss_valid = 25794572.0 \n",
      "Model_5_850 \t loss_train = 28344134.0 \t loss_valid = 25371784.0 \n",
      "Model_5_860 \t loss_train = 28515362.0 \t loss_valid = 25424062.0 \n",
      "Model_5_870 \t loss_train = 28332388.0 \t loss_valid = 25370666.0 \n",
      "Model_5_880 \t loss_train = 28127396.0 \t loss_valid = 25601204.0 \n",
      "Model_5_890 \t loss_train = 28054074.0 \t loss_valid = 25898442.0 \n",
      "Model_5_900 \t loss_train = 28292300.0 \t loss_valid = 25398994.0 \n",
      "Model_5_910 \t loss_train = 28119976.0 \t loss_valid = 25683618.0 \n",
      "Model_5_920 \t loss_train = 28158738.0 \t loss_valid = 25440562.0 \n",
      "Model_5_930 \t loss_train = 28068790.0 \t loss_valid = 25746360.0 \n",
      "Model_5_940 \t loss_train = 28086312.0 \t loss_valid = 25696176.0 \n",
      "Model_5_950 \t loss_train = 28273684.0 \t loss_valid = 25368576.0 \n",
      "Model_5_960 \t loss_train = 28454062.0 \t loss_valid = 25372578.0 \n",
      "Model_5_970 \t loss_train = 28116440.0 \t loss_valid = 26181102.0 \n",
      "Model_5_980 \t loss_train = 28090252.0 \t loss_valid = 25736790.0 \n",
      "Model_5_990 \t loss_train = 28079012.0 \t loss_valid = 25605510.0 \n",
      "Model_5_1000 \t loss_train = 28104236.0 \t loss_valid = 25544146.0 \n",
      "Model_5_1010 \t loss_train = 28287180.0 \t loss_valid = 25374796.0 \n",
      "Model_5_1020 \t loss_train = 28112976.0 \t loss_valid = 25517876.0 \n",
      "Model_5_1030 \t loss_train = 28218666.0 \t loss_valid = 25454416.0 \n",
      "Model_5_1040 \t loss_train = 28151728.0 \t loss_valid = 25473306.0 \n",
      "Model_5_1050 \t loss_train = 28138558.0 \t loss_valid = 25456812.0 \n",
      "Model_5_1060 \t loss_train = 28227260.0 \t loss_valid = 25388130.0 \n",
      "Model_5_1070 \t loss_train = 28473274.0 \t loss_valid = 25357080.0 \n",
      "Model_5_1080 \t loss_train = 28328102.0 \t loss_valid = 25355448.0 \n",
      "Model_5_1090 \t loss_train = 28352644.0 \t loss_valid = 25329298.0 \n",
      "Model_5_1100 \t loss_train = 28120794.0 \t loss_valid = 25491874.0 \n",
      "Model_5_1110 \t loss_train = 28066148.0 \t loss_valid = 25542140.0 \n",
      "Model_5_1120 \t loss_train = 28248668.0 \t loss_valid = 25358798.0 \n",
      "Model_5_1130 \t loss_train = 28276670.0 \t loss_valid = 25336482.0 \n",
      "Model_5_1140 \t loss_train = 28053100.0 \t loss_valid = 25641476.0 \n",
      "Model_5_1150 \t loss_train = 28086266.0 \t loss_valid = 25508684.0 \n",
      "Model_5_1160 \t loss_train = 28072384.0 \t loss_valid = 25714792.0 \n",
      "Model_5_1170 \t loss_train = 28314070.0 \t loss_valid = 25346516.0 \n",
      "Model_5_1180 \t loss_train = 28107400.0 \t loss_valid = 25447726.0 \n",
      "Model_5_1190 \t loss_train = 28104730.0 \t loss_valid = 25532890.0 \n",
      "Model_5_1200 \t loss_train = 28269700.0 \t loss_valid = 25380146.0 \n",
      "Model_5_1210 \t loss_train = 28182806.0 \t loss_valid = 25390162.0 \n",
      "Model_5_1220 \t loss_train = 28069810.0 \t loss_valid = 25590900.0 \n",
      "Model_5_1230 \t loss_train = 28043024.0 \t loss_valid = 25982240.0 \n",
      "Model_5_1240 \t loss_train = 28051208.0 \t loss_valid = 25635550.0 \n",
      "Model_5_1250 \t loss_train = 28056420.0 \t loss_valid = 25655878.0 \n",
      "Model_5_1260 \t loss_train = 28098322.0 \t loss_valid = 25478160.0 \n",
      "Model_5_1270 \t loss_train = 28395084.0 \t loss_valid = 25337602.0 \n",
      "Model_5_1280 \t loss_train = 28377960.0 \t loss_valid = 25325460.0 \n",
      "Model_5_1290 \t loss_train = 28070696.0 \t loss_valid = 25731804.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_5_1300 \t loss_train = 28053988.0 \t loss_valid = 25596650.0 \n",
      "Model_5_1310 \t loss_train = 28197402.0 \t loss_valid = 25360950.0 \n",
      "Model_5_1320 \t loss_train = 28113314.0 \t loss_valid = 25542234.0 \n",
      "Model_5_1330 \t loss_train = 28026754.0 \t loss_valid = 25638650.0 \n",
      "Model_5_1340 \t loss_train = 28191032.0 \t loss_valid = 25393598.0 \n",
      "Model_5_1350 \t loss_train = 28129884.0 \t loss_valid = 25450658.0 \n",
      "Model_5_1360 \t loss_train = 28056886.0 \t loss_valid = 25787720.0 \n",
      "Model_5_1370 \t loss_train = 28047026.0 \t loss_valid = 25615154.0 \n",
      "Model_5_1380 \t loss_train = 28129716.0 \t loss_valid = 25384406.0 \n",
      "Model_5_1390 \t loss_train = 28146870.0 \t loss_valid = 25431758.0 \n",
      "Model_5_1400 \t loss_train = 28139010.0 \t loss_valid = 25390348.0 \n",
      "Model_5_1410 \t loss_train = 28158372.0 \t loss_valid = 25368904.0 \n",
      "Model_5_1420 \t loss_train = 28222010.0 \t loss_valid = 25390984.0 \n",
      "Model_5_1430 \t loss_train = 28236610.0 \t loss_valid = 25320912.0 \n",
      "Model_5_1440 \t loss_train = 28271084.0 \t loss_valid = 25319854.0 \n",
      "Model_5_1450 \t loss_train = 28177228.0 \t loss_valid = 25356014.0 \n",
      "Model_5_1460 \t loss_train = 28302614.0 \t loss_valid = 25386638.0 \n",
      "Model_5_1470 \t loss_train = 28193388.0 \t loss_valid = 25357926.0 \n",
      "Model_5_1480 \t loss_train = 28136762.0 \t loss_valid = 25378774.0 \n",
      "Model_5_1490 \t loss_train = 28273658.0 \t loss_valid = 25316426.0 \n",
      "Model_5_1500 \t loss_train = 28296008.0 \t loss_valid = 25309082.0 \n",
      "Model_5_1510 \t loss_train = 28405428.0 \t loss_valid = 25309384.0 \n",
      "Model_5_1520 \t loss_train = 28382022.0 \t loss_valid = 25310000.0 \n",
      "Model_5_1530 \t loss_train = 28059222.0 \t loss_valid = 25481314.0 \n",
      "Model_5_1540 \t loss_train = 28051840.0 \t loss_valid = 25664352.0 \n",
      "Model_5_1550 \t loss_train = 28063722.0 \t loss_valid = 25658346.0 \n",
      "Model_5_1560 \t loss_train = 28055224.0 \t loss_valid = 26022002.0 \n",
      "Model_5_1570 \t loss_train = 28065156.0 \t loss_valid = 25830390.0 \n",
      "Model_5_1580 \t loss_train = 28055826.0 \t loss_valid = 25976406.0 \n",
      "Model_5_1590 \t loss_train = 28039034.0 \t loss_valid = 25615308.0 \n",
      "Model_5_1600 \t loss_train = 28026456.0 \t loss_valid = 25624390.0 \n",
      "Model_5_1610 \t loss_train = 28035728.0 \t loss_valid = 25659088.0 \n",
      "Model_5_1620 \t loss_train = 28039886.0 \t loss_valid = 25563392.0 \n",
      "Model_5_1630 \t loss_train = 28050340.0 \t loss_valid = 25624712.0 \n",
      "Model_5_1640 \t loss_train = 28070340.0 \t loss_valid = 25515242.0 \n",
      "Model_5_1650 \t loss_train = 28044208.0 \t loss_valid = 25595616.0 \n",
      "Model_5_1660 \t loss_train = 28105204.0 \t loss_valid = 25438430.0 \n",
      "Model_5_1670 \t loss_train = 28153550.0 \t loss_valid = 25358066.0 \n",
      "Model_5_1680 \t loss_train = 28106942.0 \t loss_valid = 25421896.0 \n",
      "Model_5_1690 \t loss_train = 28089122.0 \t loss_valid = 25444816.0 \n",
      "Model_5_1700 \t loss_train = 28114278.0 \t loss_valid = 25416846.0 \n",
      "Model_5_1710 \t loss_train = 28080572.0 \t loss_valid = 25450158.0 \n",
      "Model_5_1720 \t loss_train = 28046224.0 \t loss_valid = 25472290.0 \n",
      "Model_5_1730 \t loss_train = 28122448.0 \t loss_valid = 25406072.0 \n",
      "Model_5_1740 \t loss_train = 28123944.0 \t loss_valid = 25425924.0 \n",
      "Model_5_1750 \t loss_train = 28137576.0 \t loss_valid = 25339872.0 \n",
      "Model_5_1760 \t loss_train = 28131458.0 \t loss_valid = 25352692.0 \n",
      "Model_5_1770 \t loss_train = 28126350.0 \t loss_valid = 25353764.0 \n",
      "Model_5_1780 \t loss_train = 28196292.0 \t loss_valid = 25323048.0 \n",
      "Model_5_1790 \t loss_train = 28174734.0 \t loss_valid = 25329902.0 \n",
      "Model_5_1800 \t loss_train = 28126134.0 \t loss_valid = 25369066.0 \n",
      "Model_5_1810 \t loss_train = 28139908.0 \t loss_valid = 25363950.0 \n",
      "Model_5_1820 \t loss_train = 28031814.0 \t loss_valid = 25546146.0 \n",
      "Model_5_1830 \t loss_train = 28086044.0 \t loss_valid = 25508092.0 \n",
      "Model_5_1840 \t loss_train = 28055062.0 \t loss_valid = 25668748.0 \n",
      "Model_5_1850 \t loss_train = 28109450.0 \t loss_valid = 25363588.0 \n",
      "Model_5_1860 \t loss_train = 28290640.0 \t loss_valid = 25284840.0 \n",
      "Model_5_1870 \t loss_train = 28117910.0 \t loss_valid = 25360050.0 \n",
      "Model_5_1880 \t loss_train = 28077280.0 \t loss_valid = 25424920.0 \n",
      "Model_5_1890 \t loss_train = 28127172.0 \t loss_valid = 25349234.0 \n",
      "Model_5_1900 \t loss_train = 28210672.0 \t loss_valid = 25311040.0 \n",
      "Model_5_1910 \t loss_train = 28116898.0 \t loss_valid = 25367928.0 \n",
      "Model_5_1920 \t loss_train = 28071330.0 \t loss_valid = 25440932.0 \n",
      "Model_5_1930 \t loss_train = 28193902.0 \t loss_valid = 25321922.0 \n",
      "Model_5_1940 \t loss_train = 28218464.0 \t loss_valid = 25301406.0 \n",
      "Model_5_1950 \t loss_train = 28210582.0 \t loss_valid = 25309882.0 \n",
      "Model_5_1960 \t loss_train = 28280084.0 \t loss_valid = 25292096.0 \n",
      "Model_5_1970 \t loss_train = 28264572.0 \t loss_valid = 25286756.0 \n",
      "Model_5_1980 \t loss_train = 28183170.0 \t loss_valid = 25314736.0 \n",
      "Model_5_1990 \t loss_train = 28222108.0 \t loss_valid = 25297238.0 \n",
      "Model_5_2000 \t loss_train = 28051582.0 \t loss_valid = 25439536.0 \n",
      "Model_5_2010 \t loss_train = 28062328.0 \t loss_valid = 25520558.0 \n",
      "Model_5_2020 \t loss_train = 28015800.0 \t loss_valid = 25793546.0 \n",
      "Model_5_2030 \t loss_train = 28030444.0 \t loss_valid = 25995548.0 \n",
      "Model_5_2040 \t loss_train = 28069316.0 \t loss_valid = 25428942.0 \n",
      "Model_5_2050 \t loss_train = 28016496.0 \t loss_valid = 25610744.0 \n",
      "Model_5_2060 \t loss_train = 28096412.0 \t loss_valid = 25405970.0 \n",
      "Model_5_2070 \t loss_train = 28116060.0 \t loss_valid = 25355510.0 \n",
      "Model_5_2080 \t loss_train = 28086060.0 \t loss_valid = 25382252.0 \n",
      "Model_5_2090 \t loss_train = 28054390.0 \t loss_valid = 25531980.0 \n",
      "Model_5_2100 \t loss_train = 28140962.0 \t loss_valid = 25337838.0 \n",
      "Model_5_2110 \t loss_train = 28046304.0 \t loss_valid = 25476964.0 \n",
      "Model_5_2120 \t loss_train = 28119936.0 \t loss_valid = 25386096.0 \n",
      "Model_5_2130 \t loss_train = 28123474.0 \t loss_valid = 25345588.0 \n",
      "Model_5_2140 \t loss_train = 28112596.0 \t loss_valid = 25371206.0 \n",
      "Model_5_2150 \t loss_train = 28091098.0 \t loss_valid = 25421024.0 \n",
      "Model_5_2160 \t loss_train = 28061564.0 \t loss_valid = 25464052.0 \n",
      "Model_5_2170 \t loss_train = 28093400.0 \t loss_valid = 25375618.0 \n",
      "Model_5_2180 \t loss_train = 28178634.0 \t loss_valid = 25324246.0 \n",
      "Model_5_2190 \t loss_train = 28150718.0 \t loss_valid = 25344120.0 \n",
      "Model_5_2200 \t loss_train = 28062396.0 \t loss_valid = 25426896.0 \n",
      "Model_5_2210 \t loss_train = 28086196.0 \t loss_valid = 25387080.0 \n",
      "Model_5_2220 \t loss_train = 28065396.0 \t loss_valid = 25489010.0 \n",
      "Model_5_2230 \t loss_train = 28080358.0 \t loss_valid = 25411812.0 \n",
      "Model_5_2240 \t loss_train = 28226258.0 \t loss_valid = 25309304.0 \n",
      "Model_5_2250 \t loss_train = 28242264.0 \t loss_valid = 25306816.0 \n",
      "Model_5_2260 \t loss_train = 28147740.0 \t loss_valid = 25396432.0 \n",
      "Model_5_2270 \t loss_train = 28185954.0 \t loss_valid = 25320172.0 \n",
      "Model_5_2280 \t loss_train = 28143338.0 \t loss_valid = 25337298.0 \n",
      "Model_5_2290 \t loss_train = 28247100.0 \t loss_valid = 25305800.0 \n",
      "Model_5_2300 \t loss_train = 28181968.0 \t loss_valid = 25370990.0 \n",
      "Model_5_2310 \t loss_train = 28347084.0 \t loss_valid = 25297170.0 \n",
      "Model_5_2320 \t loss_train = 28216160.0 \t loss_valid = 25304588.0 \n",
      "Model_5_2330 \t loss_train = 28246142.0 \t loss_valid = 25298048.0 \n",
      "Model_5_2340 \t loss_train = 28088450.0 \t loss_valid = 25415212.0 \n",
      "Model_5_2350 \t loss_train = 28121106.0 \t loss_valid = 25361120.0 \n",
      "Model_5_2360 \t loss_train = 28393626.0 \t loss_valid = 25278972.0 \n",
      "Model_5_2370 \t loss_train = 28353970.0 \t loss_valid = 25299768.0 \n",
      "Model_5_2380 \t loss_train = 28437938.0 \t loss_valid = 25345906.0 \n",
      "Model_5_2390 \t loss_train = 28202484.0 \t loss_valid = 25323256.0 \n",
      "Model_5_2400 \t loss_train = 28237696.0 \t loss_valid = 25307458.0 \n",
      "Model_5_2410 \t loss_train = 28092838.0 \t loss_valid = 25399262.0 \n",
      "Model_5_2420 \t loss_train = 28053636.0 \t loss_valid = 25516728.0 \n",
      "Model_5_2430 \t loss_train = 28094356.0 \t loss_valid = 25444744.0 \n",
      "Model_5_2440 \t loss_train = 28094592.0 \t loss_valid = 25428588.0 \n",
      "Model_5_2450 \t loss_train = 28234134.0 \t loss_valid = 25304380.0 \n",
      "Model_5_2460 \t loss_train = 28259576.0 \t loss_valid = 25302332.0 \n",
      "Model_5_2470 \t loss_train = 28216918.0 \t loss_valid = 25296366.0 \n",
      "Model_5_2480 \t loss_train = 28107448.0 \t loss_valid = 25380572.0 \n",
      "Model_5_2490 \t loss_train = 28123966.0 \t loss_valid = 25374134.0 \n",
      "Model_5_2500 \t loss_train = 28116080.0 \t loss_valid = 25373740.0 \n",
      "Model_5_2510 \t loss_train = 28154806.0 \t loss_valid = 25333012.0 \n",
      "Model_5_2520 \t loss_train = 28057788.0 \t loss_valid = 25654556.0 \n",
      "Model_5_2530 \t loss_train = 28104858.0 \t loss_valid = 25445290.0 \n",
      "Model_5_2540 \t loss_train = 28206298.0 \t loss_valid = 25302670.0 \n",
      "Model_5_2550 \t loss_train = 28362538.0 \t loss_valid = 25282332.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_5_2560 \t loss_train = 28404720.0 \t loss_valid = 25291688.0 \n",
      "Model_5_2570 \t loss_train = 28184582.0 \t loss_valid = 25335632.0 \n",
      "Model_5_2580 \t loss_train = 28264428.0 \t loss_valid = 25305424.0 \n",
      "Model_5_2590 \t loss_train = 28212220.0 \t loss_valid = 25298676.0 \n",
      "Model_5_2600 \t loss_train = 28478110.0 \t loss_valid = 25318486.0 \n",
      "Model_5_2610 \t loss_train = 28377450.0 \t loss_valid = 25280746.0 \n",
      "Model_5_2620 \t loss_train = 28204122.0 \t loss_valid = 25306064.0 \n",
      "Model_5_2630 \t loss_train = 28131838.0 \t loss_valid = 25414902.0 \n",
      "Model_5_2640 \t loss_train = 28101052.0 \t loss_valid = 25434700.0 \n",
      "Model_5_2650 \t loss_train = 28098430.0 \t loss_valid = 25411998.0 \n",
      "Model_5_2660 \t loss_train = 28127740.0 \t loss_valid = 25370722.0 \n",
      "Model_5_2670 \t loss_train = 28506224.0 \t loss_valid = 25305644.0 \n",
      "Model_5_2680 \t loss_train = 28433916.0 \t loss_valid = 25281034.0 \n",
      "Model_5_2690 \t loss_train = 28340246.0 \t loss_valid = 25275974.0 \n",
      "Model_5_2700 \t loss_train = 28218344.0 \t loss_valid = 25314834.0 \n",
      "Model_5_2710 \t loss_train = 28223378.0 \t loss_valid = 25305972.0 \n",
      "Model_5_2720 \t loss_train = 28228570.0 \t loss_valid = 25326338.0 \n",
      "Model_5_2730 \t loss_train = 28160560.0 \t loss_valid = 25354440.0 \n",
      "Model_5_2740 \t loss_train = 28209764.0 \t loss_valid = 25303606.0 \n",
      "Model_5_2750 \t loss_train = 28162182.0 \t loss_valid = 25359132.0 \n",
      "Model_5_2760 \t loss_train = 28414542.0 \t loss_valid = 25293726.0 \n",
      "Model_5_2770 \t loss_train = 28288366.0 \t loss_valid = 25290700.0 \n",
      "Model_5_2780 \t loss_train = 28346832.0 \t loss_valid = 25277964.0 \n",
      "Model_5_2790 \t loss_train = 28266364.0 \t loss_valid = 25292796.0 \n",
      "Model_5_2800 \t loss_train = 28365226.0 \t loss_valid = 25280240.0 \n",
      "Model_5_2810 \t loss_train = 28359516.0 \t loss_valid = 25282796.0 \n",
      "Model_5_2820 \t loss_train = 28397422.0 \t loss_valid = 25299390.0 \n",
      "Model_5_2830 \t loss_train = 28304812.0 \t loss_valid = 25289580.0 \n",
      "Model_5_2840 \t loss_train = 28394204.0 \t loss_valid = 25274622.0 \n",
      "Model_5_2850 \t loss_train = 28413404.0 \t loss_valid = 25277338.0 \n",
      "Model_5_2860 \t loss_train = 28300254.0 \t loss_valid = 25282156.0 \n",
      "Model_5_2870 \t loss_train = 28510110.0 \t loss_valid = 25301472.0 \n",
      "Model_5_2880 \t loss_train = 28627826.0 \t loss_valid = 25326390.0 \n",
      "Model_5_2890 \t loss_train = 28420674.0 \t loss_valid = 25289042.0 \n",
      "Model_5_2900 \t loss_train = 28729620.0 \t loss_valid = 25335938.0 \n",
      "Model_5_2910 \t loss_train = 28350494.0 \t loss_valid = 25288406.0 \n",
      "Model_5_2920 \t loss_train = 28189520.0 \t loss_valid = 25316672.0 \n",
      "Model_5_2930 \t loss_train = 28232340.0 \t loss_valid = 25287902.0 \n",
      "Model_5_2940 \t loss_train = 28368262.0 \t loss_valid = 25270482.0 \n",
      "Model_5_2950 \t loss_train = 28160724.0 \t loss_valid = 25322380.0 \n",
      "Model_5_2960 \t loss_train = 28266496.0 \t loss_valid = 25282516.0 \n",
      "Model_5_2970 \t loss_train = 28534734.0 \t loss_valid = 25316542.0 \n",
      "Model_5_2980 \t loss_train = 28361614.0 \t loss_valid = 25271432.0 \n",
      "Model_5_2990 \t loss_train = 28486028.0 \t loss_valid = 25286330.0 \n",
      "Model_5_3000 \t loss_train = 28143720.0 \t loss_valid = 25360942.0 \n",
      "Model_5_3010 \t loss_train = 28123182.0 \t loss_valid = 25350406.0 \n",
      "Model_5_3020 \t loss_train = 28290440.0 \t loss_valid = 25273416.0 \n",
      "Model_5_3030 \t loss_train = 28232020.0 \t loss_valid = 25287184.0 \n",
      "Model_5_3040 \t loss_train = 28211606.0 \t loss_valid = 25341690.0 \n",
      "Model_5_3050 \t loss_train = 28211890.0 \t loss_valid = 25327532.0 \n",
      "Model_5_3060 \t loss_train = 28349956.0 \t loss_valid = 25287278.0 \n",
      "Model_5_3070 \t loss_train = 28385184.0 \t loss_valid = 25280010.0 \n",
      "Model_5_3080 \t loss_train = 28467014.0 \t loss_valid = 25289514.0 \n",
      "Model_5_3090 \t loss_train = 28407486.0 \t loss_valid = 25295006.0 \n",
      "Model_5_3100 \t loss_train = 28109188.0 \t loss_valid = 25414384.0 \n",
      "Model_5_3110 \t loss_train = 28246920.0 \t loss_valid = 25316898.0 \n",
      "Model_5_3120 \t loss_train = 28378056.0 \t loss_valid = 25275178.0 \n",
      "Model_5_3130 \t loss_train = 28400500.0 \t loss_valid = 25267048.0 \n",
      "Model_5_3140 \t loss_train = 28417940.0 \t loss_valid = 25270812.0 \n",
      "Model_5_3150 \t loss_train = 28419798.0 \t loss_valid = 25291112.0 \n",
      "Model_5_3160 \t loss_train = 28311296.0 \t loss_valid = 25294940.0 \n",
      "Model_5_3170 \t loss_train = 28463036.0 \t loss_valid = 25315510.0 \n",
      "Model_5_3180 \t loss_train = 28505758.0 \t loss_valid = 25297690.0 \n",
      "Model_5_3190 \t loss_train = 28256978.0 \t loss_valid = 25285730.0 \n",
      "Model_5_3200 \t loss_train = 28399454.0 \t loss_valid = 25277242.0 \n",
      "Model_5_3210 \t loss_train = 28352616.0 \t loss_valid = 25271464.0 \n",
      "Model_5_3220 \t loss_train = 28331336.0 \t loss_valid = 25268350.0 \n",
      "Model_5_3230 \t loss_train = 28312990.0 \t loss_valid = 25276014.0 \n",
      "Model_5_3240 \t loss_train = 28340672.0 \t loss_valid = 25271740.0 \n",
      "Model_5_3250 \t loss_train = 28124610.0 \t loss_valid = 25392778.0 \n",
      "Model_5_3260 \t loss_train = 28156112.0 \t loss_valid = 25367464.0 \n",
      "Model_5_3270 \t loss_train = 28141736.0 \t loss_valid = 25421796.0 \n",
      "Model_5_3280 \t loss_train = 28245486.0 \t loss_valid = 25297582.0 \n",
      "Model_5_3290 \t loss_train = 28443652.0 \t loss_valid = 25279994.0 \n",
      "Model_5_3300 \t loss_train = 28355834.0 \t loss_valid = 25283414.0 \n",
      "Model_5_3310 \t loss_train = 28447602.0 \t loss_valid = 25273588.0 \n",
      "Model_5_3320 \t loss_train = 28453842.0 \t loss_valid = 25274816.0 \n",
      "Model_5_3330 \t loss_train = 28484590.0 \t loss_valid = 25273358.0 \n",
      "Model_5_3340 \t loss_train = 28422924.0 \t loss_valid = 25274806.0 \n",
      "Model_5_3350 \t loss_train = 28569854.0 \t loss_valid = 25320120.0 \n",
      "Model_5_3360 \t loss_train = 28429426.0 \t loss_valid = 25267642.0 \n",
      "Model_5_3370 \t loss_train = 28119646.0 \t loss_valid = 25387828.0 \n",
      "Model_5_3380 \t loss_train = 28416402.0 \t loss_valid = 25276732.0 \n",
      "Model_5_3390 \t loss_train = 28473684.0 \t loss_valid = 25287816.0 \n",
      "Model_5_3400 \t loss_train = 28360100.0 \t loss_valid = 25277876.0 \n",
      "Model_5_3410 \t loss_train = 28361242.0 \t loss_valid = 25274438.0 \n",
      "Model_5_3420 \t loss_train = 28175762.0 \t loss_valid = 25352426.0 \n",
      "Model_5_3430 \t loss_train = 28341936.0 \t loss_valid = 25292990.0 \n",
      "Model_5_3440 \t loss_train = 28238590.0 \t loss_valid = 25282650.0 \n",
      "Model_5_3450 \t loss_train = 28530534.0 \t loss_valid = 25299010.0 \n",
      "Model_5_3460 \t loss_train = 28428848.0 \t loss_valid = 25283016.0 \n",
      "Model_5_3470 \t loss_train = 28641116.0 \t loss_valid = 25317022.0 \n",
      "Model_5_3480 \t loss_train = 28579234.0 \t loss_valid = 25292924.0 \n",
      "Model_5_3490 \t loss_train = 28241722.0 \t loss_valid = 25325012.0 \n",
      "Model_5_3500 \t loss_train = 28184528.0 \t loss_valid = 25307948.0 \n",
      "Model_5_3510 \t loss_train = 28763892.0 \t loss_valid = 25375532.0 \n",
      "Model_5_3520 \t loss_train = 28531946.0 \t loss_valid = 25292120.0 \n",
      "Model_5_3530 \t loss_train = 28465198.0 \t loss_valid = 25282422.0 \n",
      "Model_5_3540 \t loss_train = 28415508.0 \t loss_valid = 25280718.0 \n",
      "Model_5_3550 \t loss_train = 28568158.0 \t loss_valid = 25295996.0 \n",
      "Model_5_3560 \t loss_train = 28609090.0 \t loss_valid = 25350208.0 \n",
      "Model_5_3570 \t loss_train = 28512234.0 \t loss_valid = 25296334.0 \n",
      "Model_5_3580 \t loss_train = 28535108.0 \t loss_valid = 25276178.0 \n",
      "Model_5_3590 \t loss_train = 28277324.0 \t loss_valid = 25282992.0 \n",
      "Model_5_3600 \t loss_train = 28494146.0 \t loss_valid = 25279616.0 \n",
      "Model_5_3610 \t loss_train = 28725438.0 \t loss_valid = 25351390.0 \n",
      "Model_5_3620 \t loss_train = 28446176.0 \t loss_valid = 25284926.0 \n",
      "Model_5_3630 \t loss_train = 28485648.0 \t loss_valid = 25290994.0 \n",
      "Model_5_3640 \t loss_train = 28258494.0 \t loss_valid = 25293088.0 \n",
      "Model_5_3650 \t loss_train = 28659404.0 \t loss_valid = 25318354.0 \n",
      "Model_5_3660 \t loss_train = 28602344.0 \t loss_valid = 25313880.0 \n",
      "Model_5_3670 \t loss_train = 28495094.0 \t loss_valid = 25278256.0 \n",
      "Model_5_3680 \t loss_train = 28485882.0 \t loss_valid = 25273770.0 \n",
      "Model_5_3690 \t loss_train = 28482278.0 \t loss_valid = 25279122.0 \n",
      "Model_5_3700 \t loss_train = 28465992.0 \t loss_valid = 25279858.0 \n",
      "Model_5_3710 \t loss_train = 28700838.0 \t loss_valid = 25317048.0 \n",
      "Model_5_3720 \t loss_train = 28567650.0 \t loss_valid = 25294364.0 \n",
      "Model_5_3730 \t loss_train = 28410208.0 \t loss_valid = 25302832.0 \n",
      "Model_5_3740 \t loss_train = 28318424.0 \t loss_valid = 25293648.0 \n",
      "Model_5_3750 \t loss_train = 28397880.0 \t loss_valid = 25272490.0 \n",
      "Model_5_3760 \t loss_train = 28437550.0 \t loss_valid = 25274710.0 \n",
      "Model_5_3770 \t loss_train = 28634286.0 \t loss_valid = 25291568.0 \n",
      "Model_5_3780 \t loss_train = 28552332.0 \t loss_valid = 25291986.0 \n",
      "Model_5_3790 \t loss_train = 28608212.0 \t loss_valid = 25304178.0 \n",
      "Model_5_3800 \t loss_train = 28601470.0 \t loss_valid = 25297028.0 \n",
      "Model_5_3810 \t loss_train = 28422666.0 \t loss_valid = 25279242.0 \n",
      "Model_5_3820 \t loss_train = 28454788.0 \t loss_valid = 25280346.0 \n",
      "Model_5_3830 \t loss_train = 28826672.0 \t loss_valid = 25362286.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_5_3840 \t loss_train = 28816168.0 \t loss_valid = 25387088.0 \n",
      "Model_5_3850 \t loss_train = 28877952.0 \t loss_valid = 25394898.0 \n",
      "Model_5_3860 \t loss_train = 28791690.0 \t loss_valid = 25364780.0 \n",
      "Model_5_3870 \t loss_train = 28473314.0 \t loss_valid = 25298092.0 \n",
      "Model_5_3880 \t loss_train = 28378812.0 \t loss_valid = 25301192.0 \n",
      "Model_5_3890 \t loss_train = 28495832.0 \t loss_valid = 25281194.0 \n",
      "Model_5_3900 \t loss_train = 28585736.0 \t loss_valid = 25296324.0 \n",
      "Model_5_3910 \t loss_train = 28642452.0 \t loss_valid = 25314934.0 \n",
      "Model_5_3920 \t loss_train = 28694004.0 \t loss_valid = 25320528.0 \n",
      "Model_5_3930 \t loss_train = 28437818.0 \t loss_valid = 25275072.0 \n",
      "Model_5_3940 \t loss_train = 28519320.0 \t loss_valid = 25299628.0 \n",
      "Model_5_3950 \t loss_train = 28613128.0 \t loss_valid = 25295514.0 \n",
      "Model_5_3960 \t loss_train = 28645280.0 \t loss_valid = 25336012.0 \n",
      "Model_5_3970 \t loss_train = 28719728.0 \t loss_valid = 25338158.0 \n",
      "Model_5_3980 \t loss_train = 28552126.0 \t loss_valid = 25293906.0 \n",
      "Model_5_3990 \t loss_train = 28503314.0 \t loss_valid = 25287692.0 \n",
      "Model_5_4000 \t loss_train = 28743178.0 \t loss_valid = 25332560.0 \n",
      "Model_5_4010 \t loss_train = 28576448.0 \t loss_valid = 25314064.0 \n",
      "Model_5_4020 \t loss_train = 28805962.0 \t loss_valid = 25386854.0 \n",
      "Model_5_4030 \t loss_train = 28713102.0 \t loss_valid = 25348704.0 \n",
      "Model_5_4040 \t loss_train = 28668568.0 \t loss_valid = 25331282.0 \n",
      "Model_5_4050 \t loss_train = 28612670.0 \t loss_valid = 25298804.0 \n",
      "Model_5_4060 \t loss_train = 28726150.0 \t loss_valid = 25310180.0 \n",
      "Model_5_4070 \t loss_train = 29029654.0 \t loss_valid = 25456890.0 \n",
      "Model_5_4080 \t loss_train = 28818408.0 \t loss_valid = 25388480.0 \n",
      "Model_5_4090 \t loss_train = 29127206.0 \t loss_valid = 25535214.0 \n",
      "Model_5_4100 \t loss_train = 28609354.0 \t loss_valid = 25300116.0 \n",
      "Model_5_4110 \t loss_train = 28337786.0 \t loss_valid = 25295480.0 \n",
      "Model_5_4120 \t loss_train = 28393058.0 \t loss_valid = 25313388.0 \n",
      "Model_5_4130 \t loss_train = 28268736.0 \t loss_valid = 25306492.0 \n",
      "Model_5_4140 \t loss_train = 28525774.0 \t loss_valid = 25293922.0 \n",
      "Model_5_4150 \t loss_train = 28735348.0 \t loss_valid = 25366222.0 \n",
      "Model_5_4160 \t loss_train = 28712004.0 \t loss_valid = 25349866.0 \n",
      "Model_5_4170 \t loss_train = 28989182.0 \t loss_valid = 25392498.0 \n",
      "Model_5_4180 \t loss_train = 29033712.0 \t loss_valid = 25487876.0 \n",
      "Model_5_4190 \t loss_train = 28865384.0 \t loss_valid = 25401566.0 \n",
      "Model_5_4200 \t loss_train = 28852008.0 \t loss_valid = 25365650.0 \n",
      "Model_5_4210 \t loss_train = 28616010.0 \t loss_valid = 25308448.0 \n",
      "Model_5_4220 \t loss_train = 28856030.0 \t loss_valid = 25400436.0 \n",
      "Model_5_4230 \t loss_train = 28640826.0 \t loss_valid = 25321732.0 \n",
      "Model_5_4240 \t loss_train = 28557662.0 \t loss_valid = 25292648.0 \n",
      "Model_5_4250 \t loss_train = 28796584.0 \t loss_valid = 25361178.0 \n",
      "Model_5_4260 \t loss_train = 28957386.0 \t loss_valid = 25440272.0 \n",
      "Model_5_4270 \t loss_train = 28634438.0 \t loss_valid = 25321752.0 \n",
      "Model_5_4280 \t loss_train = 28544804.0 \t loss_valid = 25310226.0 \n",
      "Model_5_4290 \t loss_train = 28468974.0 \t loss_valid = 25283274.0 \n",
      "Model_5_4300 \t loss_train = 28934732.0 \t loss_valid = 25372638.0 \n",
      "Model_5_4310 \t loss_train = 29213422.0 \t loss_valid = 25571008.0 \n",
      "Model_5_4320 \t loss_train = 29117214.0 \t loss_valid = 25527940.0 \n",
      "Model_5_4330 \t loss_train = 28914118.0 \t loss_valid = 25431040.0 \n",
      "Model_5_4340 \t loss_train = 28761464.0 \t loss_valid = 25366898.0 \n",
      "Model_5_4350 \t loss_train = 29173598.0 \t loss_valid = 25513266.0 \n",
      "Model_5_4360 \t loss_train = 29003814.0 \t loss_valid = 25417592.0 \n",
      "Model_5_4370 \t loss_train = 28732864.0 \t loss_valid = 25354380.0 \n",
      "Model_5_4380 \t loss_train = 28768496.0 \t loss_valid = 25351484.0 \n",
      "Model_5_4390 \t loss_train = 28538804.0 \t loss_valid = 25291050.0 \n",
      "Model_5_4400 \t loss_train = 28529036.0 \t loss_valid = 25291084.0 \n",
      "Model_5_4410 \t loss_train = 28826780.0 \t loss_valid = 25375410.0 \n",
      "Model_5_4420 \t loss_train = 28979252.0 \t loss_valid = 25447668.0 \n",
      "Model_5_4430 \t loss_train = 28792192.0 \t loss_valid = 25381322.0 \n",
      "Model_5_4440 \t loss_train = 28777378.0 \t loss_valid = 25329870.0 \n",
      "Model_5_4450 \t loss_train = 28628810.0 \t loss_valid = 25304912.0 \n",
      "Model_5_4460 \t loss_train = 28628608.0 \t loss_valid = 25307142.0 \n",
      "Model_5_4470 \t loss_train = 28536370.0 \t loss_valid = 25299608.0 \n",
      "Model_5_4480 \t loss_train = 28630768.0 \t loss_valid = 25288610.0 \n",
      "Model_5_4490 \t loss_train = 28626486.0 \t loss_valid = 25293512.0 \n",
      "Model_5_4500 \t loss_train = 28688246.0 \t loss_valid = 25311728.0 \n",
      "Model_5_4510 \t loss_train = 28763924.0 \t loss_valid = 25374456.0 \n",
      "Model_5_4520 \t loss_train = 28815138.0 \t loss_valid = 25358602.0 \n",
      "Model_5_4530 \t loss_train = 28692596.0 \t loss_valid = 25305986.0 \n",
      "Model_5_4540 \t loss_train = 28670268.0 \t loss_valid = 25344862.0 \n",
      "Model_5_4550 \t loss_train = 29081294.0 \t loss_valid = 25498192.0 \n",
      "Model_5_4560 \t loss_train = 28996684.0 \t loss_valid = 25449042.0 \n",
      "Model_5_4570 \t loss_train = 28930234.0 \t loss_valid = 25412228.0 \n",
      "Model_5_4580 \t loss_train = 28842998.0 \t loss_valid = 25364144.0 \n",
      "Model_5_4590 \t loss_train = 28942710.0 \t loss_valid = 25423218.0 \n",
      "Model_5_4600 \t loss_train = 29184098.0 \t loss_valid = 25530960.0 \n",
      "Model_5_4610 \t loss_train = 29098504.0 \t loss_valid = 25524948.0 \n",
      "Model_5_4620 \t loss_train = 28688954.0 \t loss_valid = 25306264.0 \n",
      "Model_5_4630 \t loss_train = 28576408.0 \t loss_valid = 25283708.0 \n",
      "Model_5_4640 \t loss_train = 28674866.0 \t loss_valid = 25305648.0 \n",
      "Model_5_4650 \t loss_train = 28975866.0 \t loss_valid = 25443226.0 \n",
      "Model_5_4660 \t loss_train = 28936612.0 \t loss_valid = 25390770.0 \n",
      "Model_5_4670 \t loss_train = 28691530.0 \t loss_valid = 25339320.0 \n",
      "Model_5_4680 \t loss_train = 28990956.0 \t loss_valid = 25407478.0 \n",
      "Model_5_4690 \t loss_train = 29089956.0 \t loss_valid = 25480756.0 \n",
      "Model_5_4700 \t loss_train = 28669880.0 \t loss_valid = 25308918.0 \n",
      "Model_5_4710 \t loss_train = 28419212.0 \t loss_valid = 25282700.0 \n",
      "Model_5_4720 \t loss_train = 28558476.0 \t loss_valid = 25287578.0 \n",
      "Model_5_4730 \t loss_train = 28509468.0 \t loss_valid = 25290078.0 \n",
      "Model_5_4740 \t loss_train = 28741318.0 \t loss_valid = 25347130.0 \n",
      "Model_5_4750 \t loss_train = 29171392.0 \t loss_valid = 25539632.0 \n",
      "Model_5_4760 \t loss_train = 29138952.0 \t loss_valid = 25491966.0 \n",
      "Model_5_4770 \t loss_train = 29250762.0 \t loss_valid = 25539866.0 \n",
      "Model_5_4780 \t loss_train = 28814246.0 \t loss_valid = 25381870.0 \n",
      "Model_5_4790 \t loss_train = 28923524.0 \t loss_valid = 25378416.0 \n",
      "Model_5_4800 \t loss_train = 29311508.0 \t loss_valid = 25564208.0 \n",
      "Model_5_4810 \t loss_train = 28789376.0 \t loss_valid = 25366480.0 \n",
      "Model_5_4820 \t loss_train = 28767986.0 \t loss_valid = 25328548.0 \n",
      "Model_5_4830 \t loss_train = 28802518.0 \t loss_valid = 25354736.0 \n",
      "Model_5_4840 \t loss_train = 28905622.0 \t loss_valid = 25390330.0 \n",
      "Model_5_4850 \t loss_train = 28886044.0 \t loss_valid = 25405000.0 \n",
      "Model_5_4860 \t loss_train = 29215688.0 \t loss_valid = 25602514.0 \n",
      "Model_5_4870 \t loss_train = 29099282.0 \t loss_valid = 25466726.0 \n",
      "Model_5_4880 \t loss_train = 29214086.0 \t loss_valid = 25557500.0 \n",
      "Model_5_4890 \t loss_train = 28876220.0 \t loss_valid = 25353980.0 \n",
      "Model_5_4900 \t loss_train = 28559414.0 \t loss_valid = 25306452.0 \n",
      "Model_5_4910 \t loss_train = 28828686.0 \t loss_valid = 25338484.0 \n",
      "Model_5_4920 \t loss_train = 29282130.0 \t loss_valid = 25583190.0 \n",
      "Model_5_4930 \t loss_train = 29412022.0 \t loss_valid = 25684016.0 \n",
      "Model_5_4940 \t loss_train = 28819438.0 \t loss_valid = 25337572.0 \n",
      "Model_5_4950 \t loss_train = 28971722.0 \t loss_valid = 25392774.0 \n",
      "Model_5_4960 \t loss_train = 28716696.0 \t loss_valid = 25337458.0 \n",
      "Model_5_4970 \t loss_train = 28974748.0 \t loss_valid = 25402254.0 \n",
      "Model_5_4980 \t loss_train = 29146440.0 \t loss_valid = 25452284.0 \n",
      "Model_5_4990 \t loss_train = 28819532.0 \t loss_valid = 25385028.0 \n",
      "Model_5_5000 \t loss_train = 28708046.0 \t loss_valid = 25317764.0 \n",
      "Model_5_5010 \t loss_train = 28865332.0 \t loss_valid = 25354658.0 \n",
      "Model_5_5020 \t loss_train = 29073086.0 \t loss_valid = 25481492.0 \n",
      "Model_5_5030 \t loss_train = 29304948.0 \t loss_valid = 25534084.0 \n",
      "Model_5_5040 \t loss_train = 29495908.0 \t loss_valid = 25732464.0 \n",
      "Model_5_5050 \t loss_train = 29858250.0 \t loss_valid = 25911592.0 \n",
      "Model_5_5060 \t loss_train = 29152146.0 \t loss_valid = 25546666.0 \n",
      "Model_5_5070 \t loss_train = 28931148.0 \t loss_valid = 25407032.0 \n",
      "Model_5_5080 \t loss_train = 28921108.0 \t loss_valid = 25375794.0 \n",
      "Model_5_5090 \t loss_train = 28850440.0 \t loss_valid = 25354222.0 \n",
      "Model_5_5100 \t loss_train = 28717154.0 \t loss_valid = 25309630.0 \n",
      "Model_5_5110 \t loss_train = 28979234.0 \t loss_valid = 25392856.0 \n",
      "Model_5_5120 \t loss_train = 28937770.0 \t loss_valid = 25378042.0 \n",
      "Model_5_5130 \t loss_train = 28971184.0 \t loss_valid = 25378260.0 \n",
      "Model_5_5140 \t loss_train = 28810976.0 \t loss_valid = 25355526.0 \n",
      "Model_5_5150 \t loss_train = 29141522.0 \t loss_valid = 25480836.0 \n",
      "Model_5_5160 \t loss_train = 29047928.0 \t loss_valid = 25424612.0 \n",
      "Model_5_5170 \t loss_train = 29141070.0 \t loss_valid = 25495930.0 \n",
      "Model_5_5180 \t loss_train = 28942058.0 \t loss_valid = 25373290.0 \n",
      "Model_5_5190 \t loss_train = 29358866.0 \t loss_valid = 25572990.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_5_5200 \t loss_train = 28774672.0 \t loss_valid = 25320996.0 \n",
      "Model_5_5210 \t loss_train = 28852486.0 \t loss_valid = 25349506.0 \n",
      "Model_5_5220 \t loss_train = 28841600.0 \t loss_valid = 25355946.0 \n",
      "Model_5_5230 \t loss_train = 29309694.0 \t loss_valid = 25507528.0 \n",
      "Model_5_5240 \t loss_train = 29127262.0 \t loss_valid = 25488274.0 \n",
      "Model_5_5250 \t loss_train = 29436454.0 \t loss_valid = 25620122.0 \n",
      "Model_5_5260 \t loss_train = 29139266.0 \t loss_valid = 25477702.0 \n",
      "Model_5_5270 \t loss_train = 29039884.0 \t loss_valid = 25467488.0 \n",
      "Model_5_5280 \t loss_train = 28877736.0 \t loss_valid = 25364304.0 \n",
      "Model_5_5290 \t loss_train = 29068412.0 \t loss_valid = 25449228.0 \n",
      "Model_5_5300 \t loss_train = 29282732.0 \t loss_valid = 25546544.0 \n",
      "Model_5_5310 \t loss_train = 28955960.0 \t loss_valid = 25388374.0 \n",
      "Model_5_5320 \t loss_train = 29110912.0 \t loss_valid = 25457126.0 \n",
      "Model_5_5330 \t loss_train = 29293878.0 \t loss_valid = 25604178.0 \n",
      "Model_5_5340 \t loss_train = 29486422.0 \t loss_valid = 25628928.0 \n",
      "Model_5_5350 \t loss_train = 29171766.0 \t loss_valid = 25496648.0 \n",
      "Model_5_5360 \t loss_train = 29225378.0 \t loss_valid = 25524898.0 \n",
      "Model_5_5370 \t loss_train = 29115950.0 \t loss_valid = 25454194.0 \n",
      "Model_5_5380 \t loss_train = 28860030.0 \t loss_valid = 25339910.0 \n",
      "Model_5_5390 \t loss_train = 28936786.0 \t loss_valid = 25361586.0 \n",
      "Model_5_5400 \t loss_train = 29180124.0 \t loss_valid = 25490632.0 \n",
      "Model_5_5410 \t loss_train = 29232338.0 \t loss_valid = 25494818.0 \n",
      "Model_5_5420 \t loss_train = 28874874.0 \t loss_valid = 25352520.0 \n",
      "Model_5_5430 \t loss_train = 29145364.0 \t loss_valid = 25458144.0 \n",
      "Model_5_5440 \t loss_train = 29025200.0 \t loss_valid = 25397832.0 \n",
      "Model_5_5450 \t loss_train = 29241190.0 \t loss_valid = 25500834.0 \n",
      "Model_5_5460 \t loss_train = 29103080.0 \t loss_valid = 25473894.0 \n",
      "Model_5_5470 \t loss_train = 28901638.0 \t loss_valid = 25365794.0 \n",
      "Model_5_5480 \t loss_train = 29296554.0 \t loss_valid = 25518320.0 \n",
      "Model_5_5490 \t loss_train = 29103188.0 \t loss_valid = 25452620.0 \n",
      "Model_5_5500 \t loss_train = 29383886.0 \t loss_valid = 25522224.0 \n",
      "Model_5_5510 \t loss_train = 29851840.0 \t loss_valid = 25935132.0 \n",
      "Model_5_5520 \t loss_train = 29568748.0 \t loss_valid = 25697500.0 \n",
      "Model_5_5530 \t loss_train = 29524420.0 \t loss_valid = 25629482.0 \n",
      "Model_5_5540 \t loss_train = 29103676.0 \t loss_valid = 25456854.0 \n",
      "Model_5_5550 \t loss_train = 29128576.0 \t loss_valid = 25437630.0 \n",
      "Model_5_5560 \t loss_train = 29319516.0 \t loss_valid = 25540128.0 \n",
      "Model_5_5570 \t loss_train = 29202178.0 \t loss_valid = 25525808.0 \n",
      "Model_5_5580 \t loss_train = 29051258.0 \t loss_valid = 25395618.0 \n",
      "Model_5_5590 \t loss_train = 29140162.0 \t loss_valid = 25460454.0 \n",
      "Model_5_5600 \t loss_train = 28833386.0 \t loss_valid = 25329388.0 \n",
      "Model_5_5610 \t loss_train = 28830724.0 \t loss_valid = 25323084.0 \n",
      "Model_5_5620 \t loss_train = 28935392.0 \t loss_valid = 25357006.0 \n",
      "Model_5_5630 \t loss_train = 29331420.0 \t loss_valid = 25548468.0 \n",
      "Model_5_5640 \t loss_train = 29239250.0 \t loss_valid = 25500226.0 \n",
      "Model_5_5650 \t loss_train = 29050620.0 \t loss_valid = 25423598.0 \n",
      "Model_5_5660 \t loss_train = 29307812.0 \t loss_valid = 25555536.0 \n",
      "Model_5_5670 \t loss_train = 29242724.0 \t loss_valid = 25479612.0 \n",
      "Model_5_5680 \t loss_train = 29065492.0 \t loss_valid = 25437332.0 \n",
      "Model_5_5690 \t loss_train = 29436236.0 \t loss_valid = 25572496.0 \n",
      "Model_5_5700 \t loss_train = 29600058.0 \t loss_valid = 25720444.0 \n",
      "Model_5_5710 \t loss_train = 29609784.0 \t loss_valid = 25680296.0 \n",
      "Model_5_5720 \t loss_train = 29412182.0 \t loss_valid = 25628192.0 \n",
      "Model_5_5730 \t loss_train = 29362148.0 \t loss_valid = 25556930.0 \n",
      "Model_5_5740 \t loss_train = 29353478.0 \t loss_valid = 25533534.0 \n",
      "Model_5_5750 \t loss_train = 29090624.0 \t loss_valid = 25434584.0 \n",
      "Model_5_5760 \t loss_train = 29287028.0 \t loss_valid = 25516654.0 \n",
      "Model_5_5770 \t loss_train = 29315644.0 \t loss_valid = 25545190.0 \n",
      "Model_5_5780 \t loss_train = 29377742.0 \t loss_valid = 25554706.0 \n",
      "Model_5_5790 \t loss_train = 29244184.0 \t loss_valid = 25520858.0 \n",
      "Model_5_5800 \t loss_train = 29351500.0 \t loss_valid = 25538594.0 \n",
      "Model_5_5810 \t loss_train = 29471552.0 \t loss_valid = 25596614.0 \n",
      "Model_5_5820 \t loss_train = 29517002.0 \t loss_valid = 25660526.0 \n",
      "Model_5_5830 \t loss_train = 29595916.0 \t loss_valid = 25669818.0 \n",
      "Model_5_5840 \t loss_train = 29257656.0 \t loss_valid = 25498920.0 \n",
      "Model_5_5850 \t loss_train = 29448060.0 \t loss_valid = 25572974.0 \n",
      "Model_5_5860 \t loss_train = 29245696.0 \t loss_valid = 25513850.0 \n",
      "Model_5_5870 \t loss_train = 29779232.0 \t loss_valid = 25759006.0 \n",
      "Model_5_5880 \t loss_train = 29393654.0 \t loss_valid = 25598160.0 \n",
      "Model_5_5890 \t loss_train = 29414142.0 \t loss_valid = 25534820.0 \n",
      "Model_5_5900 \t loss_train = 29139324.0 \t loss_valid = 25433982.0 \n",
      "Model_5_5910 \t loss_train = 29180834.0 \t loss_valid = 25460868.0 \n",
      "Model_5_5920 \t loss_train = 29052944.0 \t loss_valid = 25392966.0 \n",
      "Model_5_5930 \t loss_train = 29092546.0 \t loss_valid = 25428704.0 \n",
      "Model_5_5940 \t loss_train = 29454848.0 \t loss_valid = 25655592.0 \n",
      "Model_5_5950 \t loss_train = 29394466.0 \t loss_valid = 25555794.0 \n",
      "Model_5_5960 \t loss_train = 29131688.0 \t loss_valid = 25410720.0 \n",
      "Model_5_5970 \t loss_train = 28722794.0 \t loss_valid = 25313068.0 \n",
      "Model_5_5980 \t loss_train = 28910998.0 \t loss_valid = 25368658.0 \n",
      "Model_5_5990 \t loss_train = 29164682.0 \t loss_valid = 25489696.0 \n",
      "Model_5_6000 \t loss_train = 29240478.0 \t loss_valid = 25465844.0 \n",
      "Model_5_6010 \t loss_train = 29542302.0 \t loss_valid = 25640182.0 \n",
      "Model_5_6020 \t loss_train = 29825502.0 \t loss_valid = 25857248.0 \n",
      "Model_5_6030 \t loss_train = 29786580.0 \t loss_valid = 25760700.0 \n",
      "Model_5_6040 \t loss_train = 29598426.0 \t loss_valid = 25667748.0 \n",
      "Model_5_6050 \t loss_train = 29182892.0 \t loss_valid = 25463410.0 \n",
      "Model_5_6060 \t loss_train = 29470458.0 \t loss_valid = 25584802.0 \n",
      "Model_5_6070 \t loss_train = 29478250.0 \t loss_valid = 25600698.0 \n",
      "Model_5_6080 \t loss_train = 29762976.0 \t loss_valid = 25726332.0 \n",
      "Model_5_6090 \t loss_train = 29141664.0 \t loss_valid = 25412946.0 \n",
      "Model_5_6100 \t loss_train = 29049748.0 \t loss_valid = 25379522.0 \n",
      "Model_5_6110 \t loss_train = 29402232.0 \t loss_valid = 25576496.0 \n",
      "Model_5_6120 \t loss_train = 29384642.0 \t loss_valid = 25576356.0 \n",
      "Model_5_6130 \t loss_train = 29296376.0 \t loss_valid = 25521774.0 \n",
      "Model_5_6140 \t loss_train = 29452396.0 \t loss_valid = 25558902.0 \n",
      "Model_5_6150 \t loss_train = 29635746.0 \t loss_valid = 25694024.0 \n",
      "Model_5_6160 \t loss_train = 29577100.0 \t loss_valid = 25654112.0 \n",
      "Model_5_6170 \t loss_train = 29363324.0 \t loss_valid = 25538190.0 \n",
      "Model_5_6180 \t loss_train = 29693256.0 \t loss_valid = 25708924.0 \n",
      "Model_5_6190 \t loss_train = 29815478.0 \t loss_valid = 25791840.0 \n",
      "Model_5_6200 \t loss_train = 29260502.0 \t loss_valid = 25495866.0 \n",
      "Model_5_6210 \t loss_train = 29439946.0 \t loss_valid = 25545030.0 \n",
      "Model_5_6220 \t loss_train = 29373388.0 \t loss_valid = 25568218.0 \n",
      "Model_5_6230 \t loss_train = 29286732.0 \t loss_valid = 25486318.0 \n",
      "Model_5_6240 \t loss_train = 29276768.0 \t loss_valid = 25481090.0 \n",
      "Model_5_6250 \t loss_train = 29308296.0 \t loss_valid = 25509080.0 \n",
      "Model_5_6260 \t loss_train = 29291740.0 \t loss_valid = 25508566.0 \n",
      "Model_5_6270 \t loss_train = 29547994.0 \t loss_valid = 25649390.0 \n",
      "Model_5_6280 \t loss_train = 29878934.0 \t loss_valid = 25837830.0 \n",
      "Model_5_6290 \t loss_train = 29546660.0 \t loss_valid = 25661390.0 \n",
      "Model_5_6300 \t loss_train = 29784710.0 \t loss_valid = 25798518.0 \n",
      "Model_5_6310 \t loss_train = 29212056.0 \t loss_valid = 25472598.0 \n",
      "Model_5_6320 \t loss_train = 29407128.0 \t loss_valid = 25540922.0 \n",
      "Model_5_6330 \t loss_train = 29519584.0 \t loss_valid = 25630288.0 \n",
      "Model_5_6340 \t loss_train = 29928822.0 \t loss_valid = 25847630.0 \n",
      "Model_5_6350 \t loss_train = 29717070.0 \t loss_valid = 25757158.0 \n",
      "Model_5_6360 \t loss_train = 29378736.0 \t loss_valid = 25528534.0 \n",
      "Model_5_6370 \t loss_train = 29549270.0 \t loss_valid = 25594154.0 \n",
      "Model_5_6380 \t loss_train = 29531452.0 \t loss_valid = 25641438.0 \n",
      "Model_5_6390 \t loss_train = 29658840.0 \t loss_valid = 25689862.0 \n",
      "Model_5_6400 \t loss_train = 29453280.0 \t loss_valid = 25571686.0 \n",
      "Model_5_6410 \t loss_train = 29662712.0 \t loss_valid = 25717390.0 \n",
      "Model_5_6420 \t loss_train = 29902022.0 \t loss_valid = 25914696.0 \n",
      "Model_5_6430 \t loss_train = 29538050.0 \t loss_valid = 25646928.0 \n",
      "Model_5_6440 \t loss_train = 29552124.0 \t loss_valid = 25630242.0 \n",
      "Model_5_6450 \t loss_train = 29180996.0 \t loss_valid = 25460122.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_5_6460 \t loss_train = 29695610.0 \t loss_valid = 25748072.0 \n",
      "Model_5_6470 \t loss_train = 29919660.0 \t loss_valid = 25843388.0 \n",
      "Model_5_6480 \t loss_train = 29630892.0 \t loss_valid = 25753506.0 \n",
      "Model_5_6490 \t loss_train = 29320892.0 \t loss_valid = 25522850.0 \n",
      "Model_5_6500 \t loss_train = 29288246.0 \t loss_valid = 25469282.0 \n",
      "Model_5_6510 \t loss_train = 29147428.0 \t loss_valid = 25423306.0 \n",
      "Model_5_6520 \t loss_train = 29628908.0 \t loss_valid = 25654588.0 \n",
      "Model_5_6530 \t loss_train = 29739268.0 \t loss_valid = 25736730.0 \n",
      "Model_5_6540 \t loss_train = 29599622.0 \t loss_valid = 25675372.0 \n",
      "Model_5_6550 \t loss_train = 29550542.0 \t loss_valid = 25612652.0 \n",
      "Model_5_6560 \t loss_train = 29168726.0 \t loss_valid = 25460236.0 \n",
      "Model_5_6570 \t loss_train = 29187904.0 \t loss_valid = 25458014.0 \n",
      "Model_5_6580 \t loss_train = 29428212.0 \t loss_valid = 25544120.0 \n",
      "Model_5_6590 \t loss_train = 29477618.0 \t loss_valid = 25629108.0 \n",
      "Model_5_6600 \t loss_train = 29789618.0 \t loss_valid = 25790144.0 \n",
      "Model_5_6610 \t loss_train = 29768998.0 \t loss_valid = 25808592.0 \n",
      "Model_5_6620 \t loss_train = 29479752.0 \t loss_valid = 25595964.0 \n",
      "Model_5_6630 \t loss_train = 29392244.0 \t loss_valid = 25542296.0 \n",
      "Model_5_6640 \t loss_train = 29242086.0 \t loss_valid = 25502874.0 \n",
      "Model_5_6650 \t loss_train = 29223408.0 \t loss_valid = 25470262.0 \n",
      "Model_5_6660 \t loss_train = 29136588.0 \t loss_valid = 25436030.0 \n",
      "Model_5_6670 \t loss_train = 29482170.0 \t loss_valid = 25601378.0 \n",
      "Model_5_6680 \t loss_train = 29602788.0 \t loss_valid = 25665208.0 \n",
      "Model_5_6690 \t loss_train = 29794856.0 \t loss_valid = 25800994.0 \n",
      "Model_5_6700 \t loss_train = 29921214.0 \t loss_valid = 25823134.0 \n",
      "Model_5_6710 \t loss_train = 30069938.0 \t loss_valid = 25940010.0 \n",
      "Model_5_6720 \t loss_train = 29780412.0 \t loss_valid = 25743792.0 \n",
      "Model_5_6730 \t loss_train = 29398708.0 \t loss_valid = 25556014.0 \n",
      "Model_5_6740 \t loss_train = 29531684.0 \t loss_valid = 25590192.0 \n",
      "Model_5_6750 \t loss_train = 29531196.0 \t loss_valid = 25572994.0 \n",
      "Model_5_6760 \t loss_train = 29745090.0 \t loss_valid = 25718532.0 \n",
      "Model_5_6770 \t loss_train = 29716612.0 \t loss_valid = 25697654.0 \n",
      "Model_5_6780 \t loss_train = 29621846.0 \t loss_valid = 25633520.0 \n",
      "Model_5_6790 \t loss_train = 29799272.0 \t loss_valid = 25754718.0 \n",
      "Model_5_6800 \t loss_train = 29696786.0 \t loss_valid = 25661526.0 \n",
      "Model_5_6810 \t loss_train = 29545726.0 \t loss_valid = 25605930.0 \n",
      "Model_5_6820 \t loss_train = 29644662.0 \t loss_valid = 25701632.0 \n",
      "Model_5_6830 \t loss_train = 29764492.0 \t loss_valid = 25694446.0 \n",
      "Model_5_6840 \t loss_train = 29598788.0 \t loss_valid = 25694702.0 \n",
      "Model_5_6850 \t loss_train = 29598948.0 \t loss_valid = 25635574.0 \n",
      "Model_5_6860 \t loss_train = 30013502.0 \t loss_valid = 25913032.0 \n",
      "Model_5_6870 \t loss_train = 29729752.0 \t loss_valid = 25732642.0 \n",
      "Model_5_6880 \t loss_train = 30272326.0 \t loss_valid = 26067072.0 \n",
      "Model_5_6890 \t loss_train = 29981372.0 \t loss_valid = 25906540.0 \n",
      "Model_5_6900 \t loss_train = 29966150.0 \t loss_valid = 25839720.0 \n",
      "Model_5_6910 \t loss_train = 29760514.0 \t loss_valid = 25776162.0 \n",
      "Model_5_6920 \t loss_train = 29862796.0 \t loss_valid = 25821608.0 \n",
      "Model_5_6930 \t loss_train = 29988506.0 \t loss_valid = 25847916.0 \n",
      "Model_5_6940 \t loss_train = 29752850.0 \t loss_valid = 25735314.0 \n",
      "Model_5_6950 \t loss_train = 29594804.0 \t loss_valid = 25663722.0 \n",
      "Model_5_6960 \t loss_train = 29368742.0 \t loss_valid = 25533240.0 \n",
      "Model_5_6970 \t loss_train = 29677888.0 \t loss_valid = 25672204.0 \n",
      "Model_5_6980 \t loss_train = 29958342.0 \t loss_valid = 25853842.0 \n",
      "Model_5_6990 \t loss_train = 29782342.0 \t loss_valid = 25737016.0 \n",
      "Model_5_7000 \t loss_train = 29486154.0 \t loss_valid = 25544780.0 \n",
      "Model_5_7010 \t loss_train = 29321186.0 \t loss_valid = 25501450.0 \n",
      "Model_5_7020 \t loss_train = 29701562.0 \t loss_valid = 25665994.0 \n",
      "Model_5_7030 \t loss_train = 29974102.0 \t loss_valid = 25885566.0 \n",
      "Model_5_7040 \t loss_train = 29183120.0 \t loss_valid = 25434108.0 \n",
      "Model_5_7050 \t loss_train = 29459604.0 \t loss_valid = 25535006.0 \n",
      "Model_5_7060 \t loss_train = 29533368.0 \t loss_valid = 25574546.0 \n",
      "Model_5_7070 \t loss_train = 29452960.0 \t loss_valid = 25591012.0 \n",
      "Model_5_7080 \t loss_train = 29568524.0 \t loss_valid = 25628706.0 \n",
      "Model_5_7090 \t loss_train = 29729046.0 \t loss_valid = 25710912.0 \n",
      "Model_5_7100 \t loss_train = 29586414.0 \t loss_valid = 25716978.0 \n",
      "Model_5_7110 \t loss_train = 29398654.0 \t loss_valid = 25513624.0 \n",
      "Model_5_7120 \t loss_train = 29376962.0 \t loss_valid = 25519818.0 \n",
      "Model_5_7130 \t loss_train = 29291072.0 \t loss_valid = 25483538.0 \n",
      "Model_5_7140 \t loss_train = 29342116.0 \t loss_valid = 25546986.0 \n",
      "Model_5_7150 \t loss_train = 29105186.0 \t loss_valid = 25414350.0 \n",
      "Model_5_7160 \t loss_train = 29606416.0 \t loss_valid = 25631756.0 \n",
      "Model_5_7170 \t loss_train = 29943068.0 \t loss_valid = 25819178.0 \n",
      "Model_5_7180 \t loss_train = 29535466.0 \t loss_valid = 25682650.0 \n",
      "Model_5_7190 \t loss_train = 29453350.0 \t loss_valid = 25559622.0 \n",
      "Model_5_7200 \t loss_train = 29321746.0 \t loss_valid = 25527346.0 \n",
      "Model_5_7210 \t loss_train = 29606928.0 \t loss_valid = 25671010.0 \n",
      "Model_5_7220 \t loss_train = 29956214.0 \t loss_valid = 25836270.0 \n",
      "Model_5_7230 \t loss_train = 29485222.0 \t loss_valid = 25573876.0 \n",
      "Model_5_7240 \t loss_train = 29472832.0 \t loss_valid = 25573608.0 \n",
      "Model_5_7250 \t loss_train = 29447872.0 \t loss_valid = 25557522.0 \n",
      "Model_5_7260 \t loss_train = 29632572.0 \t loss_valid = 25671244.0 \n",
      "Model_5_7270 \t loss_train = 29503298.0 \t loss_valid = 25590232.0 \n",
      "Model_5_7280 \t loss_train = 29498844.0 \t loss_valid = 25596080.0 \n",
      "Model_5_7290 \t loss_train = 29562546.0 \t loss_valid = 25605216.0 \n",
      "Model_5_7300 \t loss_train = 29727210.0 \t loss_valid = 25685488.0 \n",
      "Model_5_7310 \t loss_train = 30270360.0 \t loss_valid = 26099018.0 \n",
      "Model_5_7320 \t loss_train = 30093900.0 \t loss_valid = 25976246.0 \n",
      "Model_5_7330 \t loss_train = 29993156.0 \t loss_valid = 25826844.0 \n",
      "Model_5_7340 \t loss_train = 29368116.0 \t loss_valid = 25536644.0 \n",
      "Model_5_7350 \t loss_train = 30016298.0 \t loss_valid = 25851390.0 \n",
      "Model_5_7360 \t loss_train = 29897746.0 \t loss_valid = 25826566.0 \n",
      "Model_5_7370 \t loss_train = 29505192.0 \t loss_valid = 25599394.0 \n",
      "Model_5_7380 \t loss_train = 29516464.0 \t loss_valid = 25576384.0 \n",
      "Model_5_7390 \t loss_train = 29584102.0 \t loss_valid = 25648866.0 \n",
      "Model_5_7400 \t loss_train = 29913318.0 \t loss_valid = 25799192.0 \n",
      "Model_5_7410 \t loss_train = 30197932.0 \t loss_valid = 25999392.0 \n",
      "Model_5_7420 \t loss_train = 30011570.0 \t loss_valid = 25944022.0 \n",
      "Model_5_7430 \t loss_train = 29939118.0 \t loss_valid = 25837482.0 \n",
      "Model_5_7440 \t loss_train = 29691112.0 \t loss_valid = 25699686.0 \n",
      "Model_5_7450 \t loss_train = 29493484.0 \t loss_valid = 25595750.0 \n",
      "Model_5_7460 \t loss_train = 29522468.0 \t loss_valid = 25579520.0 \n",
      "Model_5_7470 \t loss_train = 29674028.0 \t loss_valid = 25701496.0 \n",
      "Model_5_7480 \t loss_train = 29684402.0 \t loss_valid = 25677274.0 \n",
      "Model_5_7490 \t loss_train = 30070642.0 \t loss_valid = 25922542.0 \n",
      "Model_5_7500 \t loss_train = 29751228.0 \t loss_valid = 25689374.0 \n",
      "Model_5_7510 \t loss_train = 29208380.0 \t loss_valid = 25449838.0 \n",
      "Model_5_7520 \t loss_train = 29665648.0 \t loss_valid = 25632722.0 \n",
      "Model_5_7530 \t loss_train = 29573070.0 \t loss_valid = 25632516.0 \n",
      "Model_5_7540 \t loss_train = 29624854.0 \t loss_valid = 25649036.0 \n",
      "Model_5_7550 \t loss_train = 29743532.0 \t loss_valid = 25753340.0 \n",
      "Model_5_7560 \t loss_train = 29806774.0 \t loss_valid = 25801680.0 \n",
      "Model_5_7570 \t loss_train = 29801554.0 \t loss_valid = 25761574.0 \n",
      "Model_5_7580 \t loss_train = 29923872.0 \t loss_valid = 25797680.0 \n",
      "Model_5_7590 \t loss_train = 29904086.0 \t loss_valid = 25777610.0 \n",
      "Model_5_7600 \t loss_train = 29589428.0 \t loss_valid = 25601780.0 \n",
      "Model_5_7610 \t loss_train = 29458584.0 \t loss_valid = 25566250.0 \n",
      "Model_5_7620 \t loss_train = 29428202.0 \t loss_valid = 25538248.0 \n",
      "Model_5_7630 \t loss_train = 29527278.0 \t loss_valid = 25611990.0 \n",
      "Model_5_7640 \t loss_train = 29368478.0 \t loss_valid = 25510400.0 \n",
      "Model_5_7650 \t loss_train = 29498322.0 \t loss_valid = 25610578.0 \n",
      "Model_5_7660 \t loss_train = 29613828.0 \t loss_valid = 25642550.0 \n",
      "Model_5_7670 \t loss_train = 29477260.0 \t loss_valid = 25576664.0 \n",
      "Model_5_7680 \t loss_train = 29658622.0 \t loss_valid = 25690266.0 \n",
      "Model_5_7690 \t loss_train = 29927142.0 \t loss_valid = 25839578.0 \n",
      "Model_5_7700 \t loss_train = 29988554.0 \t loss_valid = 25876604.0 \n",
      "Model_5_7710 \t loss_train = 29760580.0 \t loss_valid = 25703702.0 \n",
      "Model_5_7720 \t loss_train = 29790682.0 \t loss_valid = 25741572.0 \n",
      "Model_5_7730 \t loss_train = 29742954.0 \t loss_valid = 25700296.0 \n",
      "Model_5_7740 \t loss_train = 29333494.0 \t loss_valid = 25498196.0 \n",
      "Model_5_7750 \t loss_train = 28994474.0 \t loss_valid = 25370288.0 \n",
      "Model_5_7760 \t loss_train = 29350478.0 \t loss_valid = 25489002.0 \n",
      "Model_5_7770 \t loss_train = 29527574.0 \t loss_valid = 25586172.0 \n",
      "Model_5_7780 \t loss_train = 29792434.0 \t loss_valid = 25763146.0 \n",
      "Model_5_7790 \t loss_train = 30106646.0 \t loss_valid = 25942882.0 \n",
      "Model_5_7800 \t loss_train = 29887366.0 \t loss_valid = 25823176.0 \n",
      "Model_5_7810 \t loss_train = 29702116.0 \t loss_valid = 25728516.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_5_7820 \t loss_train = 29696600.0 \t loss_valid = 25677222.0 \n",
      "Model_5_7830 \t loss_train = 29734472.0 \t loss_valid = 25688690.0 \n",
      "Model_5_7840 \t loss_train = 29324400.0 \t loss_valid = 25503288.0 \n",
      "Model_5_7850 \t loss_train = 29703422.0 \t loss_valid = 25655390.0 \n",
      "Model_5_7860 \t loss_train = 29613382.0 \t loss_valid = 25676814.0 \n",
      "Model_5_7870 \t loss_train = 29897750.0 \t loss_valid = 25818200.0 \n",
      "Model_5_7880 \t loss_train = 29915552.0 \t loss_valid = 25781482.0 \n",
      "Model_5_7890 \t loss_train = 29675184.0 \t loss_valid = 25643960.0 \n",
      "Model_5_7900 \t loss_train = 29983502.0 \t loss_valid = 25846110.0 \n",
      "Model_5_7910 \t loss_train = 30093226.0 \t loss_valid = 25927768.0 \n",
      "Model_5_7920 \t loss_train = 30070168.0 \t loss_valid = 25927704.0 \n",
      "Model_5_7930 \t loss_train = 29484032.0 \t loss_valid = 25556488.0 \n",
      "Model_5_7940 \t loss_train = 29411272.0 \t loss_valid = 25524462.0 \n",
      "Model_5_7950 \t loss_train = 29589580.0 \t loss_valid = 25605320.0 \n",
      "Model_5_7960 \t loss_train = 30145506.0 \t loss_valid = 25855726.0 \n",
      "Model_5_7970 \t loss_train = 29663602.0 \t loss_valid = 25651250.0 \n",
      "Model_5_7980 \t loss_train = 29191680.0 \t loss_valid = 25421476.0 \n",
      "Model_5_7990 \t loss_train = 29534052.0 \t loss_valid = 25593938.0 \n",
      "Model_5_8000 \t loss_train = 29729966.0 \t loss_valid = 25644294.0 \n",
      "Model_5_8010 \t loss_train = 29441876.0 \t loss_valid = 25526052.0 \n",
      "Model_5_8020 \t loss_train = 29397510.0 \t loss_valid = 25507080.0 \n",
      "Model_5_8030 \t loss_train = 29261034.0 \t loss_valid = 25484338.0 \n",
      "Model_5_8040 \t loss_train = 29884714.0 \t loss_valid = 25749674.0 \n",
      "Model_5_8050 \t loss_train = 29658606.0 \t loss_valid = 25644436.0 \n",
      "Model_5_8060 \t loss_train = 29581964.0 \t loss_valid = 25617146.0 \n",
      "Model_5_8070 \t loss_train = 29912540.0 \t loss_valid = 25790018.0 \n",
      "Model_5_8080 \t loss_train = 29973268.0 \t loss_valid = 25789506.0 \n",
      "Model_5_8090 \t loss_train = 29663806.0 \t loss_valid = 25701182.0 \n",
      "Model_5_8100 \t loss_train = 29271858.0 \t loss_valid = 25479910.0 \n",
      "Model_5_8110 \t loss_train = 29514180.0 \t loss_valid = 25588600.0 \n",
      "Model_5_8120 \t loss_train = 29663940.0 \t loss_valid = 25653554.0 \n",
      "Model_5_8130 \t loss_train = 29605638.0 \t loss_valid = 25600022.0 \n",
      "Model_5_8140 \t loss_train = 29625302.0 \t loss_valid = 25665268.0 \n",
      "Model_5_8150 \t loss_train = 29849558.0 \t loss_valid = 25756658.0 \n",
      "Model_5_8160 \t loss_train = 29684394.0 \t loss_valid = 25718760.0 \n",
      "Model_5_8170 \t loss_train = 29813406.0 \t loss_valid = 25743032.0 \n",
      "Model_5_8180 \t loss_train = 29912324.0 \t loss_valid = 25802404.0 \n",
      "Model_5_8190 \t loss_train = 29694418.0 \t loss_valid = 25677038.0 \n",
      "Model_5_8200 \t loss_train = 29711938.0 \t loss_valid = 25691862.0 \n",
      "Model_5_8210 \t loss_train = 29723796.0 \t loss_valid = 25687998.0 \n",
      "Model_5_8220 \t loss_train = 29860528.0 \t loss_valid = 25781826.0 \n",
      "Model_5_8230 \t loss_train = 29919874.0 \t loss_valid = 25817790.0 \n",
      "Model_5_8240 \t loss_train = 30106066.0 \t loss_valid = 25929664.0 \n",
      "Model_5_8250 \t loss_train = 29940592.0 \t loss_valid = 25831412.0 \n",
      "Model_5_8260 \t loss_train = 29763194.0 \t loss_valid = 25714144.0 \n",
      "Model_5_8270 \t loss_train = 29807772.0 \t loss_valid = 25709324.0 \n",
      "Model_5_8280 \t loss_train = 29899514.0 \t loss_valid = 25790666.0 \n",
      "Model_5_8290 \t loss_train = 29850408.0 \t loss_valid = 25829270.0 \n",
      "Model_5_8300 \t loss_train = 29969364.0 \t loss_valid = 25827536.0 \n",
      "Model_5_8310 \t loss_train = 29575146.0 \t loss_valid = 25636854.0 \n",
      "Model_5_8320 \t loss_train = 29541492.0 \t loss_valid = 25635956.0 \n",
      "Model_5_8330 \t loss_train = 29949494.0 \t loss_valid = 25815330.0 \n",
      "Model_5_8340 \t loss_train = 30034028.0 \t loss_valid = 25860576.0 \n",
      "Model_5_8350 \t loss_train = 29679564.0 \t loss_valid = 25641422.0 \n",
      "Model_5_8360 \t loss_train = 29501064.0 \t loss_valid = 25601722.0 \n",
      "Model_5_8370 \t loss_train = 29774414.0 \t loss_valid = 25761426.0 \n",
      "Model_5_8380 \t loss_train = 29681652.0 \t loss_valid = 25657840.0 \n",
      "Model_5_8390 \t loss_train = 29595738.0 \t loss_valid = 25623012.0 \n",
      "Model_5_8400 \t loss_train = 29889688.0 \t loss_valid = 25806770.0 \n",
      "Model_5_8410 \t loss_train = 29824944.0 \t loss_valid = 25752052.0 \n",
      "Model_5_8420 \t loss_train = 29919092.0 \t loss_valid = 25833538.0 \n",
      "Model_5_8430 \t loss_train = 29976934.0 \t loss_valid = 25887668.0 \n",
      "Model_5_8440 \t loss_train = 29708416.0 \t loss_valid = 25673630.0 \n",
      "Model_5_8450 \t loss_train = 29691018.0 \t loss_valid = 25692154.0 \n",
      "Model_5_8460 \t loss_train = 29377418.0 \t loss_valid = 25523754.0 \n",
      "Model_5_8470 \t loss_train = 29291448.0 \t loss_valid = 25473306.0 \n",
      "Model_5_8480 \t loss_train = 29752046.0 \t loss_valid = 25688500.0 \n",
      "Model_5_8490 \t loss_train = 29492804.0 \t loss_valid = 25576476.0 \n",
      "Model_5_8500 \t loss_train = 29382046.0 \t loss_valid = 25544730.0 \n",
      "Model_5_8510 \t loss_train = 29685272.0 \t loss_valid = 25662360.0 \n",
      "Model_5_8520 \t loss_train = 29558466.0 \t loss_valid = 25581864.0 \n",
      "Model_5_8530 \t loss_train = 29364846.0 \t loss_valid = 25514062.0 \n",
      "Model_5_8540 \t loss_train = 29601600.0 \t loss_valid = 25601922.0 \n",
      "Model_5_8550 \t loss_train = 29691426.0 \t loss_valid = 25703064.0 \n",
      "Model_5_8560 \t loss_train = 29565518.0 \t loss_valid = 25570024.0 \n",
      "Model_5_8570 \t loss_train = 29313428.0 \t loss_valid = 25480512.0 \n",
      "Model_5_8580 \t loss_train = 29610072.0 \t loss_valid = 25649800.0 \n",
      "Model_5_8590 \t loss_train = 29828304.0 \t loss_valid = 25765274.0 \n",
      "Model_5_8600 \t loss_train = 29728196.0 \t loss_valid = 25653094.0 \n",
      "Model_5_8610 \t loss_train = 29701738.0 \t loss_valid = 25685046.0 \n",
      "Model_5_8620 \t loss_train = 29437778.0 \t loss_valid = 25549612.0 \n",
      "Model_5_8630 \t loss_train = 29448166.0 \t loss_valid = 25573012.0 \n",
      "Model_5_8640 \t loss_train = 29582388.0 \t loss_valid = 25602462.0 \n",
      "Model_5_8650 \t loss_train = 29182548.0 \t loss_valid = 25446616.0 \n",
      "Model_5_8660 \t loss_train = 29344042.0 \t loss_valid = 25496158.0 \n",
      "Model_5_8670 \t loss_train = 29651176.0 \t loss_valid = 25633980.0 \n",
      "Model_5_8680 \t loss_train = 29829542.0 \t loss_valid = 25773796.0 \n",
      "Model_5_8690 \t loss_train = 29672252.0 \t loss_valid = 25690272.0 \n",
      "Model_5_8700 \t loss_train = 29538372.0 \t loss_valid = 25554760.0 \n",
      "Model_5_8710 \t loss_train = 29738190.0 \t loss_valid = 25692468.0 \n",
      "Model_5_8720 \t loss_train = 29725564.0 \t loss_valid = 25705042.0 \n",
      "Model_5_8730 \t loss_train = 29382282.0 \t loss_valid = 25552674.0 \n",
      "Model_5_8740 \t loss_train = 29807928.0 \t loss_valid = 25711796.0 \n",
      "Model_5_8750 \t loss_train = 29668894.0 \t loss_valid = 25746330.0 \n",
      "Model_5_8760 \t loss_train = 29496120.0 \t loss_valid = 25578606.0 \n",
      "Model_5_8770 \t loss_train = 29774658.0 \t loss_valid = 25687690.0 \n",
      "Model_5_8780 \t loss_train = 29568532.0 \t loss_valid = 25644156.0 \n",
      "Model_5_8790 \t loss_train = 29403460.0 \t loss_valid = 25529144.0 \n",
      "Model_5_8800 \t loss_train = 29616018.0 \t loss_valid = 25632248.0 \n",
      "Model_5_8810 \t loss_train = 29777142.0 \t loss_valid = 25721252.0 \n",
      "Model_5_8820 \t loss_train = 29615762.0 \t loss_valid = 25625066.0 \n",
      "Model_5_8830 \t loss_train = 29573414.0 \t loss_valid = 25608956.0 \n",
      "Model_5_8840 \t loss_train = 29395252.0 \t loss_valid = 25512432.0 \n",
      "Model_5_8850 \t loss_train = 29469506.0 \t loss_valid = 25547996.0 \n",
      "Model_5_8860 \t loss_train = 29749380.0 \t loss_valid = 25710280.0 \n",
      "Model_5_8870 \t loss_train = 29929114.0 \t loss_valid = 25814518.0 \n",
      "Model_5_8880 \t loss_train = 29583568.0 \t loss_valid = 25616350.0 \n",
      "Model_5_8890 \t loss_train = 29927736.0 \t loss_valid = 25819094.0 \n",
      "Model_5_8900 \t loss_train = 29516776.0 \t loss_valid = 25593664.0 \n",
      "Model_5_8910 \t loss_train = 29455718.0 \t loss_valid = 25559038.0 \n",
      "Model_5_8920 \t loss_train = 29715352.0 \t loss_valid = 25672814.0 \n",
      "Model_5_8930 \t loss_train = 29852590.0 \t loss_valid = 25730564.0 \n",
      "Model_5_8940 \t loss_train = 29294840.0 \t loss_valid = 25504652.0 \n",
      "Model_5_8950 \t loss_train = 29581230.0 \t loss_valid = 25570978.0 \n",
      "Model_5_8960 \t loss_train = 29244718.0 \t loss_valid = 25446150.0 \n",
      "Model_5_8970 \t loss_train = 29103090.0 \t loss_valid = 25400800.0 \n",
      "Model_5_8980 \t loss_train = 29403128.0 \t loss_valid = 25517764.0 \n",
      "Model_5_8990 \t loss_train = 29621132.0 \t loss_valid = 25633336.0 \n",
      "Model_5_9000 \t loss_train = 30006156.0 \t loss_valid = 25872530.0 \n",
      "Model_5_9010 \t loss_train = 29643864.0 \t loss_valid = 25667860.0 \n",
      "Model_5_9020 \t loss_train = 29432670.0 \t loss_valid = 25549356.0 \n",
      "Model_5_9030 \t loss_train = 29571012.0 \t loss_valid = 25605854.0 \n",
      "Model_5_9040 \t loss_train = 29594120.0 \t loss_valid = 25655692.0 \n",
      "Model_5_9050 \t loss_train = 29712154.0 \t loss_valid = 25642434.0 \n",
      "Model_5_9060 \t loss_train = 29327948.0 \t loss_valid = 25502560.0 \n",
      "Model_5_9070 \t loss_train = 29462070.0 \t loss_valid = 25542750.0 \n",
      "Model_5_9080 \t loss_train = 29436990.0 \t loss_valid = 25549730.0 \n",
      "Model_5_9090 \t loss_train = 29642894.0 \t loss_valid = 25695900.0 \n",
      "Model_5_9100 \t loss_train = 29524598.0 \t loss_valid = 25577510.0 \n",
      "Model_5_9110 \t loss_train = 29342494.0 \t loss_valid = 25487446.0 \n",
      "Model_5_9120 \t loss_train = 29359558.0 \t loss_valid = 25489750.0 \n",
      "Model_5_9130 \t loss_train = 29512214.0 \t loss_valid = 25611132.0 \n",
      "Model_5_9140 \t loss_train = 29459026.0 \t loss_valid = 25556290.0 \n",
      "Model_5_9150 \t loss_train = 29494280.0 \t loss_valid = 25590212.0 \n",
      "Model_5_9160 \t loss_train = 29855198.0 \t loss_valid = 25750840.0 \n",
      "Model_5_9170 \t loss_train = 29688180.0 \t loss_valid = 25706330.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_5_9180 \t loss_train = 29370156.0 \t loss_valid = 25529118.0 \n",
      "Model_5_9190 \t loss_train = 29531920.0 \t loss_valid = 25623810.0 \n",
      "Model_5_9200 \t loss_train = 29505662.0 \t loss_valid = 25596672.0 \n",
      "Model_5_9210 \t loss_train = 29377688.0 \t loss_valid = 25547922.0 \n",
      "Model_5_9220 \t loss_train = 29662748.0 \t loss_valid = 25637052.0 \n",
      "Model_5_9230 \t loss_train = 29590918.0 \t loss_valid = 25712876.0 \n",
      "Model_5_9240 \t loss_train = 29611974.0 \t loss_valid = 25634864.0 \n",
      "Model_5_9250 \t loss_train = 29309762.0 \t loss_valid = 25489574.0 \n",
      "Model_5_9260 \t loss_train = 29311024.0 \t loss_valid = 25485264.0 \n",
      "Model_5_9270 \t loss_train = 29439924.0 \t loss_valid = 25550270.0 \n",
      "Model_5_9280 \t loss_train = 29342722.0 \t loss_valid = 25498832.0 \n",
      "Model_5_9290 \t loss_train = 29436256.0 \t loss_valid = 25549834.0 \n",
      "Model_5_9300 \t loss_train = 29224464.0 \t loss_valid = 25448272.0 \n",
      "Model_5_9310 \t loss_train = 29547296.0 \t loss_valid = 25599946.0 \n",
      "Model_5_9320 \t loss_train = 29744028.0 \t loss_valid = 25740090.0 \n",
      "Model_5_9330 \t loss_train = 29582820.0 \t loss_valid = 25607764.0 \n",
      "Model_5_9340 \t loss_train = 29672874.0 \t loss_valid = 25673274.0 \n",
      "Model_5_9350 \t loss_train = 29590928.0 \t loss_valid = 25610120.0 \n",
      "Model_5_9360 \t loss_train = 29359062.0 \t loss_valid = 25548944.0 \n",
      "Model_5_9370 \t loss_train = 29651902.0 \t loss_valid = 25694708.0 \n",
      "Model_5_9380 \t loss_train = 29522862.0 \t loss_valid = 25617632.0 \n",
      "Model_5_9390 \t loss_train = 29482706.0 \t loss_valid = 25621924.0 \n",
      "Model_5_9400 \t loss_train = 29405054.0 \t loss_valid = 25515396.0 \n",
      "Model_5_9410 \t loss_train = 29066190.0 \t loss_valid = 25372488.0 \n",
      "Model_5_9420 \t loss_train = 29134596.0 \t loss_valid = 25423830.0 \n",
      "Model_5_9430 \t loss_train = 29214444.0 \t loss_valid = 25455114.0 \n",
      "Model_5_9440 \t loss_train = 29390778.0 \t loss_valid = 25535536.0 \n",
      "Model_5_9450 \t loss_train = 29726506.0 \t loss_valid = 25767646.0 \n",
      "Model_5_9460 \t loss_train = 29623252.0 \t loss_valid = 25613486.0 \n",
      "Model_5_9470 \t loss_train = 29290852.0 \t loss_valid = 25489840.0 \n",
      "Model_5_9480 \t loss_train = 29358872.0 \t loss_valid = 25516678.0 \n",
      "Model_5_9490 \t loss_train = 29454370.0 \t loss_valid = 25529172.0 \n",
      "Model_5_9500 \t loss_train = 29317946.0 \t loss_valid = 25498974.0 \n",
      "Model_5_9510 \t loss_train = 29322084.0 \t loss_valid = 25502066.0 \n",
      "Model_5_9520 \t loss_train = 29368838.0 \t loss_valid = 25525424.0 \n",
      "Model_5_9530 \t loss_train = 29196410.0 \t loss_valid = 25439582.0 \n",
      "Model_5_9540 \t loss_train = 29299202.0 \t loss_valid = 25484760.0 \n",
      "Model_5_9550 \t loss_train = 29093140.0 \t loss_valid = 25419012.0 \n",
      "Model_5_9560 \t loss_train = 29491394.0 \t loss_valid = 25550162.0 \n",
      "Model_5_9570 \t loss_train = 29303500.0 \t loss_valid = 25464882.0 \n",
      "Model_5_9580 \t loss_train = 29392752.0 \t loss_valid = 25516680.0 \n",
      "Model_5_9590 \t loss_train = 29656448.0 \t loss_valid = 25660480.0 \n",
      "Model_5_9600 \t loss_train = 29372332.0 \t loss_valid = 25544364.0 \n",
      "Model_5_9610 \t loss_train = 29180202.0 \t loss_valid = 25461836.0 \n",
      "Model_5_9620 \t loss_train = 28979702.0 \t loss_valid = 25358226.0 \n",
      "Model_5_9630 \t loss_train = 29101206.0 \t loss_valid = 25392574.0 \n",
      "Model_5_9640 \t loss_train = 29283662.0 \t loss_valid = 25477244.0 \n",
      "Model_5_9650 \t loss_train = 29324022.0 \t loss_valid = 25497250.0 \n",
      "Model_5_9660 \t loss_train = 29273430.0 \t loss_valid = 25491352.0 \n",
      "Model_5_9670 \t loss_train = 29366454.0 \t loss_valid = 25492314.0 \n",
      "Model_5_9680 \t loss_train = 29131134.0 \t loss_valid = 25429840.0 \n",
      "Model_5_9690 \t loss_train = 29318344.0 \t loss_valid = 25473512.0 \n",
      "Model_5_9700 \t loss_train = 29145598.0 \t loss_valid = 25407978.0 \n",
      "Model_5_9710 \t loss_train = 29264284.0 \t loss_valid = 25465284.0 \n",
      "Model_5_9720 \t loss_train = 29137198.0 \t loss_valid = 25424756.0 \n",
      "Model_5_9730 \t loss_train = 28966590.0 \t loss_valid = 25359656.0 \n",
      "Model_5_9740 \t loss_train = 28899158.0 \t loss_valid = 25318214.0 \n",
      "Model_5_9750 \t loss_train = 28998448.0 \t loss_valid = 25367590.0 \n",
      "Model_5_9760 \t loss_train = 29331670.0 \t loss_valid = 25494988.0 \n",
      "Model_5_9770 \t loss_train = 29219776.0 \t loss_valid = 25468546.0 \n",
      "Model_5_9780 \t loss_train = 29105550.0 \t loss_valid = 25399540.0 \n",
      "Model_5_9790 \t loss_train = 29112874.0 \t loss_valid = 25401606.0 \n",
      "Model_5_9800 \t loss_train = 29254588.0 \t loss_valid = 25480038.0 \n",
      "Model_5_9810 \t loss_train = 29344762.0 \t loss_valid = 25512912.0 \n",
      "Model_5_9820 \t loss_train = 29070624.0 \t loss_valid = 25392750.0 \n",
      "Model_5_9830 \t loss_train = 29032192.0 \t loss_valid = 25399482.0 \n",
      "Model_5_9840 \t loss_train = 29105108.0 \t loss_valid = 25406058.0 \n",
      "Model_5_9850 \t loss_train = 28891918.0 \t loss_valid = 25325384.0 \n",
      "Model_5_9860 \t loss_train = 29039756.0 \t loss_valid = 25383126.0 \n",
      "Model_5_9870 \t loss_train = 29151418.0 \t loss_valid = 25414170.0 \n",
      "Model_5_9880 \t loss_train = 29220448.0 \t loss_valid = 25446544.0 \n",
      "Model_5_9890 \t loss_train = 29090858.0 \t loss_valid = 25407694.0 \n",
      "Model_5_9900 \t loss_train = 28996036.0 \t loss_valid = 25363602.0 \n",
      "Model_5_9910 \t loss_train = 28857214.0 \t loss_valid = 25316266.0 \n",
      "Model_5_9920 \t loss_train = 29234688.0 \t loss_valid = 25472148.0 \n",
      "Model_5_9930 \t loss_train = 29089082.0 \t loss_valid = 25415066.0 \n",
      "Model_5_9940 \t loss_train = 29187904.0 \t loss_valid = 25440508.0 \n",
      "Model_5_9950 \t loss_train = 29085592.0 \t loss_valid = 25407560.0 \n",
      "Model_5_9960 \t loss_train = 29072294.0 \t loss_valid = 25391720.0 \n",
      "Model_5_9970 \t loss_train = 29214392.0 \t loss_valid = 25479780.0 \n",
      "Model_5_9980 \t loss_train = 29082302.0 \t loss_valid = 25382940.0 \n",
      "Model_5_9990 \t loss_train = 28762736.0 \t loss_valid = 25293642.0 \n",
      "Model_5_10000 \t loss_train = 28920426.0 \t loss_valid = 25347282.0 \n",
      "Model_5_10010 \t loss_train = 29246270.0 \t loss_valid = 25476762.0 \n",
      "Model_5_10020 \t loss_train = 28892344.0 \t loss_valid = 25328764.0 \n",
      "Model_5_10030 \t loss_train = 29216556.0 \t loss_valid = 25432156.0 \n",
      "Model_5_10040 \t loss_train = 29262844.0 \t loss_valid = 25470536.0 \n",
      "Model_5_10050 \t loss_train = 29179406.0 \t loss_valid = 25454924.0 \n",
      "Model_5_10060 \t loss_train = 29293034.0 \t loss_valid = 25475124.0 \n",
      "Model_5_10070 \t loss_train = 28948930.0 \t loss_valid = 25346054.0 \n",
      "Model_5_10080 \t loss_train = 28976250.0 \t loss_valid = 25374566.0 \n",
      "Model_5_10090 \t loss_train = 28990268.0 \t loss_valid = 25348304.0 \n",
      "Model_5_10100 \t loss_train = 29078934.0 \t loss_valid = 25403324.0 \n",
      "Model_5_10110 \t loss_train = 28792808.0 \t loss_valid = 25304856.0 \n",
      "Model_5_10120 \t loss_train = 28761526.0 \t loss_valid = 25309052.0 \n",
      "Model_5_10130 \t loss_train = 29013596.0 \t loss_valid = 25378240.0 \n",
      "Model_5_10140 \t loss_train = 29012306.0 \t loss_valid = 25365710.0 \n",
      "Model_5_10150 \t loss_train = 28936252.0 \t loss_valid = 25350482.0 \n",
      "Model_5_10160 \t loss_train = 28854446.0 \t loss_valid = 25320460.0 \n",
      "Model_5_10170 \t loss_train = 28932988.0 \t loss_valid = 25336354.0 \n",
      "Model_5_10180 \t loss_train = 28822124.0 \t loss_valid = 25313992.0 \n",
      "Model_5_10190 \t loss_train = 28942600.0 \t loss_valid = 25365564.0 \n",
      "Model_5_10200 \t loss_train = 28961152.0 \t loss_valid = 25352602.0 \n",
      "Model_5_10210 \t loss_train = 28814886.0 \t loss_valid = 25303564.0 \n",
      "Model_5_10220 \t loss_train = 28871576.0 \t loss_valid = 25318726.0 \n",
      "Model_5_10230 \t loss_train = 29095778.0 \t loss_valid = 25401716.0 \n",
      "Model_5_10240 \t loss_train = 28908530.0 \t loss_valid = 25350588.0 \n",
      "Model_5_10250 \t loss_train = 28931780.0 \t loss_valid = 25331196.0 \n",
      "Model_5_10260 \t loss_train = 29052802.0 \t loss_valid = 25392516.0 \n",
      "Model_5_10270 \t loss_train = 29178566.0 \t loss_valid = 25463738.0 \n",
      "Model_5_10280 \t loss_train = 28914564.0 \t loss_valid = 25334926.0 \n",
      "Model_5_10290 \t loss_train = 28766112.0 \t loss_valid = 25294540.0 \n",
      "Model_5_10300 \t loss_train = 28679974.0 \t loss_valid = 25284328.0 \n",
      "Model_5_10310 \t loss_train = 28923216.0 \t loss_valid = 25344570.0 \n",
      "Model_5_10320 \t loss_train = 29074862.0 \t loss_valid = 25394798.0 \n",
      "Model_5_10330 \t loss_train = 28836958.0 \t loss_valid = 25315840.0 \n",
      "Model_5_10340 \t loss_train = 28916968.0 \t loss_valid = 25345556.0 \n",
      "Model_5_10350 \t loss_train = 28791474.0 \t loss_valid = 25296758.0 \n",
      "Model_5_10360 \t loss_train = 28990128.0 \t loss_valid = 25366532.0 \n",
      "Model_5_10370 \t loss_train = 28893690.0 \t loss_valid = 25332382.0 \n",
      "Model_5_10380 \t loss_train = 28923904.0 \t loss_valid = 25343122.0 \n",
      "Model_5_10390 \t loss_train = 28976874.0 \t loss_valid = 25369664.0 \n",
      "Model_5_10400 \t loss_train = 28807068.0 \t loss_valid = 25307808.0 \n",
      "Model_5_10410 \t loss_train = 28745934.0 \t loss_valid = 25285256.0 \n",
      "Model_5_10420 \t loss_train = 28686296.0 \t loss_valid = 25275614.0 \n",
      "Model_5_10430 \t loss_train = 29067566.0 \t loss_valid = 25408336.0 \n",
      "Model_5_10440 \t loss_train = 28712136.0 \t loss_valid = 25293700.0 \n",
      "Model_5_10450 \t loss_train = 28692010.0 \t loss_valid = 25280158.0 \n",
      "Model_5_10460 \t loss_train = 28676518.0 \t loss_valid = 25279468.0 \n",
      "Model_5_10470 \t loss_train = 28913518.0 \t loss_valid = 25347480.0 \n",
      "Model_5_10480 \t loss_train = 29142242.0 \t loss_valid = 25433302.0 \n",
      "Model_5_10490 \t loss_train = 28646414.0 \t loss_valid = 25267952.0 \n",
      "Model_5_10500 \t loss_train = 28824846.0 \t loss_valid = 25319234.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_5_10510 \t loss_train = 28679018.0 \t loss_valid = 25287118.0 \n",
      "Model_5_10520 \t loss_train = 28778160.0 \t loss_valid = 25299774.0 \n",
      "Model_5_10530 \t loss_train = 28857120.0 \t loss_valid = 25332266.0 \n",
      "Model_5_10540 \t loss_train = 28720630.0 \t loss_valid = 25284838.0 \n",
      "Model_5_10550 \t loss_train = 28739480.0 \t loss_valid = 25287616.0 \n",
      "Model_5_10560 \t loss_train = 28715998.0 \t loss_valid = 25282156.0 \n",
      "Model_5_10570 \t loss_train = 28764680.0 \t loss_valid = 25295092.0 \n",
      "Model_5_10580 \t loss_train = 28748794.0 \t loss_valid = 25292202.0 \n",
      "Model_5_10590 \t loss_train = 28936542.0 \t loss_valid = 25343804.0 \n",
      "Model_5_10600 \t loss_train = 28794306.0 \t loss_valid = 25306134.0 \n",
      "Model_5_10610 \t loss_train = 28683274.0 \t loss_valid = 25280506.0 \n",
      "Model_5_10620 \t loss_train = 28646312.0 \t loss_valid = 25274304.0 \n",
      "Model_5_10630 \t loss_train = 28806794.0 \t loss_valid = 25305784.0 \n",
      "Model_5_10640 \t loss_train = 28804702.0 \t loss_valid = 25312366.0 \n",
      "Model_5_10650 \t loss_train = 28773090.0 \t loss_valid = 25306270.0 \n",
      "Model_5_10660 \t loss_train = 28766362.0 \t loss_valid = 25293816.0 \n",
      "Model_5_10670 \t loss_train = 28718572.0 \t loss_valid = 25286410.0 \n",
      "Model_5_10680 \t loss_train = 28761764.0 \t loss_valid = 25305202.0 \n",
      "Model_5_10690 \t loss_train = 28626936.0 \t loss_valid = 25266068.0 \n",
      "Model_5_10700 \t loss_train = 28684600.0 \t loss_valid = 25274328.0 \n",
      "Model_5_10710 \t loss_train = 28852768.0 \t loss_valid = 25323576.0 \n",
      "Model_5_10720 \t loss_train = 28944246.0 \t loss_valid = 25359212.0 \n",
      "Model_5_10730 \t loss_train = 28561792.0 \t loss_valid = 25260262.0 \n",
      "Model_5_10740 \t loss_train = 28743602.0 \t loss_valid = 25293068.0 \n",
      "Model_5_10750 \t loss_train = 28685948.0 \t loss_valid = 25279880.0 \n",
      "Model_5_10760 \t loss_train = 28598318.0 \t loss_valid = 25262124.0 \n",
      "Model_5_10770 \t loss_train = 28841064.0 \t loss_valid = 25325812.0 \n",
      "Model_5_10780 \t loss_train = 28824010.0 \t loss_valid = 25328282.0 \n",
      "Model_5_10790 \t loss_train = 28683926.0 \t loss_valid = 25284000.0 \n",
      "Model_5_10800 \t loss_train = 28607364.0 \t loss_valid = 25263290.0 \n",
      "Model_5_10810 \t loss_train = 28748570.0 \t loss_valid = 25293460.0 \n",
      "Model_5_10820 \t loss_train = 28749342.0 \t loss_valid = 25311838.0 \n",
      "Model_5_10830 \t loss_train = 28710208.0 \t loss_valid = 25285634.0 \n",
      "Model_5_10840 \t loss_train = 28497606.0 \t loss_valid = 25251462.0 \n",
      "Model_5_10850 \t loss_train = 28599396.0 \t loss_valid = 25264656.0 \n",
      "Model_5_10860 \t loss_train = 28596904.0 \t loss_valid = 25263176.0 \n",
      "Model_5_10870 \t loss_train = 28582648.0 \t loss_valid = 25259480.0 \n",
      "Model_5_10880 \t loss_train = 28599826.0 \t loss_valid = 25263622.0 \n",
      "Model_5_10890 \t loss_train = 28637216.0 \t loss_valid = 25267284.0 \n",
      "Model_5_10900 \t loss_train = 28627778.0 \t loss_valid = 25264892.0 \n",
      "Model_5_10910 \t loss_train = 28643592.0 \t loss_valid = 25277324.0 \n",
      "Model_5_10920 \t loss_train = 28593530.0 \t loss_valid = 25263568.0 \n",
      "Model_5_10930 \t loss_train = 28792436.0 \t loss_valid = 25318780.0 \n",
      "Model_5_10940 \t loss_train = 28756484.0 \t loss_valid = 25303068.0 \n",
      "Model_5_10950 \t loss_train = 28518662.0 \t loss_valid = 25262446.0 \n",
      "Model_5_10960 \t loss_train = 28540972.0 \t loss_valid = 25254302.0 \n",
      "Model_5_10970 \t loss_train = 28588542.0 \t loss_valid = 25263980.0 \n",
      "Model_5_10980 \t loss_train = 28731754.0 \t loss_valid = 25286882.0 \n",
      "Model_5_10990 \t loss_train = 28766028.0 \t loss_valid = 25314964.0 \n",
      "Model_5_11000 \t loss_train = 28574286.0 \t loss_valid = 25261728.0 \n",
      "Model_5_11010 \t loss_train = 28418112.0 \t loss_valid = 25251392.0 \n",
      "Model_5_11020 \t loss_train = 28631634.0 \t loss_valid = 25265068.0 \n",
      "Model_5_11030 \t loss_train = 28878532.0 \t loss_valid = 25344118.0 \n",
      "Model_5_11040 \t loss_train = 28747798.0 \t loss_valid = 25304316.0 \n",
      "Model_5_11050 \t loss_train = 28498416.0 \t loss_valid = 25251688.0 \n",
      "Model_5_11060 \t loss_train = 28511412.0 \t loss_valid = 25252752.0 \n",
      "Model_5_11070 \t loss_train = 28585360.0 \t loss_valid = 25264008.0 \n",
      "Model_5_11080 \t loss_train = 28548170.0 \t loss_valid = 25256218.0 \n",
      "Model_5_11090 \t loss_train = 28644760.0 \t loss_valid = 25273724.0 \n",
      "Model_5_11100 \t loss_train = 28673542.0 \t loss_valid = 25283444.0 \n",
      "Model_5_11110 \t loss_train = 28614202.0 \t loss_valid = 25264110.0 \n",
      "Model_5_11120 \t loss_train = 28649386.0 \t loss_valid = 25273480.0 \n",
      "Model_5_11130 \t loss_train = 28539256.0 \t loss_valid = 25257166.0 \n",
      "Model_5_11140 \t loss_train = 28574684.0 \t loss_valid = 25261002.0 \n",
      "Model_5_11150 \t loss_train = 28401628.0 \t loss_valid = 25249544.0 \n",
      "Model_5_11160 \t loss_train = 28671600.0 \t loss_valid = 25287814.0 \n",
      "Model_5_11170 \t loss_train = 28812360.0 \t loss_valid = 25302876.0 \n",
      "Model_5_11180 \t loss_train = 28496312.0 \t loss_valid = 25253268.0 \n",
      "Model_5_11190 \t loss_train = 28460578.0 \t loss_valid = 25249764.0 \n",
      "Model_5_11200 \t loss_train = 28700036.0 \t loss_valid = 25302408.0 \n",
      "Model_5_11210 \t loss_train = 28474950.0 \t loss_valid = 25250636.0 \n",
      "Model_5_11220 \t loss_train = 28487566.0 \t loss_valid = 25250746.0 \n",
      "Model_5_11230 \t loss_train = 28644830.0 \t loss_valid = 25269008.0 \n",
      "Model_5_11240 \t loss_train = 28623544.0 \t loss_valid = 25269688.0 \n",
      "Model_5_11250 \t loss_train = 28410298.0 \t loss_valid = 25248590.0 \n",
      "Model_5_11260 \t loss_train = 28512892.0 \t loss_valid = 25252308.0 \n",
      "Model_5_11270 \t loss_train = 28567580.0 \t loss_valid = 25257218.0 \n",
      "Model_5_11280 \t loss_train = 28525018.0 \t loss_valid = 25252902.0 \n",
      "Model_5_11290 \t loss_train = 28559660.0 \t loss_valid = 25260184.0 \n",
      "Model_5_11300 \t loss_train = 28595580.0 \t loss_valid = 25262196.0 \n",
      "Model_5_11310 \t loss_train = 28414814.0 \t loss_valid = 25249170.0 \n",
      "Model_5_11320 \t loss_train = 28534724.0 \t loss_valid = 25255774.0 \n",
      "Model_5_11330 \t loss_train = 28490794.0 \t loss_valid = 25251134.0 \n",
      "Model_5_11340 \t loss_train = 28691692.0 \t loss_valid = 25278890.0 \n",
      "Model_5_11350 \t loss_train = 28461306.0 \t loss_valid = 25249698.0 \n",
      "Model_5_11360 \t loss_train = 28461330.0 \t loss_valid = 25249238.0 \n",
      "Model_5_11370 \t loss_train = 28640132.0 \t loss_valid = 25279244.0 \n",
      "Model_5_11380 \t loss_train = 28358528.0 \t loss_valid = 25257778.0 \n",
      "Model_5_11390 \t loss_train = 28496850.0 \t loss_valid = 25252014.0 \n",
      "Model_5_11400 \t loss_train = 28526026.0 \t loss_valid = 25258604.0 \n",
      "Model_5_11410 \t loss_train = 28451392.0 \t loss_valid = 25249204.0 \n",
      "Model_5_11420 \t loss_train = 28416014.0 \t loss_valid = 25249948.0 \n",
      "Model_5_11430 \t loss_train = 28592202.0 \t loss_valid = 25260044.0 \n",
      "Model_5_11440 \t loss_train = 28450768.0 \t loss_valid = 25248694.0 \n",
      "Model_5_11450 \t loss_train = 28451228.0 \t loss_valid = 25252296.0 \n",
      "Model_5_11460 \t loss_train = 28580752.0 \t loss_valid = 25264848.0 \n",
      "Model_5_11470 \t loss_train = 28517452.0 \t loss_valid = 25264574.0 \n",
      "Model_5_11480 \t loss_train = 28495176.0 \t loss_valid = 25251312.0 \n",
      "Model_5_11490 \t loss_train = 28489640.0 \t loss_valid = 25256910.0 \n",
      "Model_5_11500 \t loss_train = 28521228.0 \t loss_valid = 25253506.0 \n",
      "Model_5_11510 \t loss_train = 28478008.0 \t loss_valid = 25250052.0 \n",
      "Model_5_11520 \t loss_train = 28546122.0 \t loss_valid = 25259108.0 \n",
      "Model_5_11530 \t loss_train = 28445372.0 \t loss_valid = 25248504.0 \n",
      "Model_5_11540 \t loss_train = 28464174.0 \t loss_valid = 25249616.0 \n",
      "Model_5_11550 \t loss_train = 28525836.0 \t loss_valid = 25262936.0 \n",
      "Model_5_11560 \t loss_train = 28438970.0 \t loss_valid = 25248534.0 \n",
      "Model_5_11570 \t loss_train = 28562570.0 \t loss_valid = 25257950.0 \n",
      "Model_5_11580 \t loss_train = 28434856.0 \t loss_valid = 25248750.0 \n",
      "Model_5_11590 \t loss_train = 28433690.0 \t loss_valid = 25250442.0 \n",
      "Model_5_11600 \t loss_train = 28408750.0 \t loss_valid = 25249412.0 \n",
      "Model_5_11610 \t loss_train = 28502972.0 \t loss_valid = 25255850.0 \n",
      "Model_5_11620 \t loss_train = 28479298.0 \t loss_valid = 25249844.0 \n",
      "Model_5_11630 \t loss_train = 28352358.0 \t loss_valid = 25254624.0 \n",
      "Model_5_11640 \t loss_train = 28402104.0 \t loss_valid = 25248562.0 \n",
      "Model_5_11650 \t loss_train = 28564300.0 \t loss_valid = 25266982.0 \n",
      "Model_5_11660 \t loss_train = 28385186.0 \t loss_valid = 25249402.0 \n",
      "Model_5_11670 \t loss_train = 28440462.0 \t loss_valid = 25248616.0 \n",
      "Model_5_11680 \t loss_train = 28494598.0 \t loss_valid = 25250322.0 \n",
      "Model_5_11690 \t loss_train = 28345944.0 \t loss_valid = 25252674.0 \n",
      "Model_5_11700 \t loss_train = 28477444.0 \t loss_valid = 25249934.0 \n",
      "Model_5_11710 \t loss_train = 28458122.0 \t loss_valid = 25250564.0 \n",
      "Model_5_11720 \t loss_train = 28358424.0 \t loss_valid = 25252652.0 \n",
      "Model_5_11730 \t loss_train = 28405036.0 \t loss_valid = 25251692.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_5_11740 \t loss_train = 28404020.0 \t loss_valid = 25248938.0 \n",
      "Model_5_11750 \t loss_train = 28419650.0 \t loss_valid = 25248670.0 \n",
      "Model_5_11760 \t loss_train = 28284752.0 \t loss_valid = 25281236.0 \n",
      "Model_5_11770 \t loss_train = 28511652.0 \t loss_valid = 25252942.0 \n",
      "Model_5_11780 \t loss_train = 28488128.0 \t loss_valid = 25257502.0 \n",
      "Model_5_11790 \t loss_train = 28396324.0 \t loss_valid = 25248604.0 \n",
      "Model_5_11800 \t loss_train = 28371428.0 \t loss_valid = 25250224.0 \n",
      "Model_5_11810 \t loss_train = 28402086.0 \t loss_valid = 25249456.0 \n",
      "Model_5_11820 \t loss_train = 28387390.0 \t loss_valid = 25249780.0 \n",
      "Model_5_11830 \t loss_train = 28431062.0 \t loss_valid = 25249244.0 \n",
      "Model_5_11840 \t loss_train = 28268082.0 \t loss_valid = 25262130.0 \n",
      "Model_5_11850 \t loss_train = 28273816.0 \t loss_valid = 25261238.0 \n",
      "Model_5_11860 \t loss_train = 28447416.0 \t loss_valid = 25251016.0 \n",
      "Model_5_11870 \t loss_train = 28377742.0 \t loss_valid = 25249084.0 \n",
      "Model_5_11880 \t loss_train = 28467868.0 \t loss_valid = 25249888.0 \n",
      "Model_5_11890 \t loss_train = 28428416.0 \t loss_valid = 25248726.0 \n",
      "Model_5_11900 \t loss_train = 28414442.0 \t loss_valid = 25248666.0 \n",
      "Model_5_11910 \t loss_train = 28454762.0 \t loss_valid = 25255586.0 \n",
      "Model_5_11920 \t loss_train = 28411064.0 \t loss_valid = 25249132.0 \n",
      "Model_5_11930 \t loss_train = 28384882.0 \t loss_valid = 25249472.0 \n",
      "Model_5_11940 \t loss_train = 28313214.0 \t loss_valid = 25262890.0 \n",
      "Model_5_11950 \t loss_train = 28414780.0 \t loss_valid = 25250444.0 \n",
      "Model_5_11960 \t loss_train = 28399662.0 \t loss_valid = 25249514.0 \n",
      "Model_5_11970 \t loss_train = 28357448.0 \t loss_valid = 25254682.0 \n",
      "Model_5_11980 \t loss_train = 28347024.0 \t loss_valid = 25254224.0 \n",
      "Model_5_11990 \t loss_train = 28374422.0 \t loss_valid = 25250354.0 \n",
      "Model_5_12000 \t loss_train = 28425756.0 \t loss_valid = 25250896.0 \n",
      "Model_5_12010 \t loss_train = 28293706.0 \t loss_valid = 25266400.0 \n",
      "Model_5_12020 \t loss_train = 28406916.0 \t loss_valid = 25248644.0 \n",
      "Model_5_12030 \t loss_train = 28495398.0 \t loss_valid = 25253386.0 \n",
      "Model_5_12040 \t loss_train = 28325158.0 \t loss_valid = 25259624.0 \n",
      "Model_5_12050 \t loss_train = 28364318.0 \t loss_valid = 25253308.0 \n",
      "Model_5_12060 \t loss_train = 28484740.0 \t loss_valid = 25250892.0 \n",
      "Model_5_12070 \t loss_train = 28356956.0 \t loss_valid = 25250812.0 \n",
      "Model_5_12080 \t loss_train = 28354712.0 \t loss_valid = 25253468.0 \n",
      "Model_5_12090 \t loss_train = 28414330.0 \t loss_valid = 25248868.0 \n",
      "Model_5_12100 \t loss_train = 28293166.0 \t loss_valid = 25281022.0 \n",
      "Model_5_12110 \t loss_train = 28383044.0 \t loss_valid = 25249388.0 \n",
      "Model_5_12120 \t loss_train = 28363582.0 \t loss_valid = 25251284.0 \n",
      "Model_5_12130 \t loss_train = 28329582.0 \t loss_valid = 25256702.0 \n",
      "Model_5_12140 \t loss_train = 28378742.0 \t loss_valid = 25251678.0 \n",
      "Model_5_12150 \t loss_train = 28325012.0 \t loss_valid = 25254890.0 \n",
      "Model_5_12160 \t loss_train = 28312190.0 \t loss_valid = 25258748.0 \n",
      "Model_5_12170 \t loss_train = 28323070.0 \t loss_valid = 25254148.0 \n",
      "Model_5_12180 \t loss_train = 28297378.0 \t loss_valid = 25257784.0 \n",
      "Model_5_12190 \t loss_train = 28447780.0 \t loss_valid = 25248432.0 \n",
      "Model_5_12200 \t loss_train = 28458818.0 \t loss_valid = 25248816.0 \n",
      "Model_5_12210 \t loss_train = 28219928.0 \t loss_valid = 25286172.0 \n",
      "Model_5_12220 \t loss_train = 28323192.0 \t loss_valid = 25254324.0 \n",
      "Model_5_12230 \t loss_train = 28352248.0 \t loss_valid = 25251822.0 \n",
      "Model_5_12240 \t loss_train = 28274572.0 \t loss_valid = 25270148.0 \n",
      "Model_5_12250 \t loss_train = 28396596.0 \t loss_valid = 25248650.0 \n",
      "Model_5_12260 \t loss_train = 28392346.0 \t loss_valid = 25250178.0 \n",
      "Model_5_12270 \t loss_train = 28269582.0 \t loss_valid = 25270030.0 \n",
      "Model_5_12280 \t loss_train = 28337980.0 \t loss_valid = 25254842.0 \n",
      "Model_5_12290 \t loss_train = 28370840.0 \t loss_valid = 25249572.0 \n",
      "Model_5_12300 \t loss_train = 28222838.0 \t loss_valid = 25287438.0 \n",
      "Model_5_12310 \t loss_train = 28364758.0 \t loss_valid = 25254874.0 \n",
      "Model_5_12320 \t loss_train = 28373510.0 \t loss_valid = 25249264.0 \n",
      "Model_5_12330 \t loss_train = 28263472.0 \t loss_valid = 25265050.0 \n",
      "Model_5_12340 \t loss_train = 28286292.0 \t loss_valid = 25257642.0 \n",
      "Model_5_12350 \t loss_train = 28293324.0 \t loss_valid = 25256950.0 \n",
      "Model_5_12360 \t loss_train = 28477218.0 \t loss_valid = 25257548.0 \n",
      "Model_5_12370 \t loss_train = 28257094.0 \t loss_valid = 25282866.0 \n",
      "Model_5_12380 \t loss_train = 28351640.0 \t loss_valid = 25250714.0 \n",
      "Model_5_12390 \t loss_train = 28345640.0 \t loss_valid = 25251738.0 \n",
      "Model_5_12400 \t loss_train = 28272902.0 \t loss_valid = 25273318.0 \n",
      "Model_5_12410 \t loss_train = 28363734.0 \t loss_valid = 25252112.0 \n",
      "Model_5_12420 \t loss_train = 28238194.0 \t loss_valid = 25283618.0 \n",
      "Model_5_12430 \t loss_train = 28239090.0 \t loss_valid = 25276164.0 \n",
      "Model_5_12440 \t loss_train = 28309210.0 \t loss_valid = 25256420.0 \n",
      "Model_5_12450 \t loss_train = 28324440.0 \t loss_valid = 25253506.0 \n",
      "Model_5_12460 \t loss_train = 28242696.0 \t loss_valid = 25271174.0 \n",
      "Model_5_12470 \t loss_train = 28300562.0 \t loss_valid = 25258206.0 \n",
      "Model_5_12480 \t loss_train = 28257624.0 \t loss_valid = 25274416.0 \n",
      "Model_5_12490 \t loss_train = 28328148.0 \t loss_valid = 25253666.0 \n",
      "Model_5_12500 \t loss_train = 28327626.0 \t loss_valid = 25253194.0 \n",
      "Model_5_12510 \t loss_train = 28259030.0 \t loss_valid = 25267782.0 \n",
      "Model_5_12520 \t loss_train = 28348484.0 \t loss_valid = 25250554.0 \n",
      "Model_5_12530 \t loss_train = 28319726.0 \t loss_valid = 25254478.0 \n",
      "Model_5_12540 \t loss_train = 28319242.0 \t loss_valid = 25253282.0 \n",
      "Model_5_12550 \t loss_train = 28227770.0 \t loss_valid = 25281034.0 \n",
      "Model_5_12560 \t loss_train = 28348736.0 \t loss_valid = 25253114.0 \n",
      "Model_5_12570 \t loss_train = 28282432.0 \t loss_valid = 25259012.0 \n",
      "Model_5_12580 \t loss_train = 28295284.0 \t loss_valid = 25257996.0 \n",
      "Model_5_12590 \t loss_train = 28280904.0 \t loss_valid = 25259742.0 \n",
      "Model_5_12600 \t loss_train = 28289884.0 \t loss_valid = 25259118.0 \n",
      "Model_5_12610 \t loss_train = 28343964.0 \t loss_valid = 25252576.0 \n",
      "Model_5_12620 \t loss_train = 28295216.0 \t loss_valid = 25258808.0 \n",
      "Model_5_12630 \t loss_train = 28281922.0 \t loss_valid = 25263214.0 \n",
      "Model_5_12640 \t loss_train = 28305588.0 \t loss_valid = 25257808.0 \n",
      "Model_5_12650 \t loss_train = 28281380.0 \t loss_valid = 25261224.0 \n",
      "Model_5_12660 \t loss_train = 28259102.0 \t loss_valid = 25264940.0 \n",
      "Model_5_12670 \t loss_train = 28219730.0 \t loss_valid = 25281760.0 \n",
      "Model_5_12680 \t loss_train = 28238208.0 \t loss_valid = 25271668.0 \n",
      "Model_5_12690 \t loss_train = 28476994.0 \t loss_valid = 25253778.0 \n",
      "Model_5_12700 \t loss_train = 28221514.0 \t loss_valid = 25295756.0 \n",
      "Model_5_12710 \t loss_train = 28208210.0 \t loss_valid = 25309402.0 \n",
      "Model_5_12720 \t loss_train = 28372110.0 \t loss_valid = 25249352.0 \n",
      "Model_5_12730 \t loss_train = 28249052.0 \t loss_valid = 25266582.0 \n",
      "Model_5_12740 \t loss_train = 28282026.0 \t loss_valid = 25260846.0 \n",
      "Model_5_12750 \t loss_train = 28269502.0 \t loss_valid = 25264596.0 \n",
      "Model_5_12760 \t loss_train = 28266608.0 \t loss_valid = 25265298.0 \n",
      "Model_5_12770 \t loss_train = 28269440.0 \t loss_valid = 25265608.0 \n",
      "Model_5_12780 \t loss_train = 28269464.0 \t loss_valid = 25267874.0 \n",
      "Model_5_12790 \t loss_train = 28330036.0 \t loss_valid = 25253088.0 \n",
      "Model_5_12800 \t loss_train = 28233348.0 \t loss_valid = 25273642.0 \n",
      "Model_5_12810 \t loss_train = 28324454.0 \t loss_valid = 25254178.0 \n",
      "Model_5_12820 \t loss_train = 28262758.0 \t loss_valid = 25272120.0 \n",
      "Model_5_12830 \t loss_train = 28315078.0 \t loss_valid = 25255026.0 \n",
      "Model_5_12840 \t loss_train = 28177010.0 \t loss_valid = 25297432.0 \n",
      "Model_5_12850 \t loss_train = 28367586.0 \t loss_valid = 25249932.0 \n",
      "Model_5_12860 \t loss_train = 28267264.0 \t loss_valid = 25266202.0 \n",
      "Model_5_12870 \t loss_train = 28129882.0 \t loss_valid = 25329954.0 \n",
      "Model_5_12880 \t loss_train = 28373732.0 \t loss_valid = 25251802.0 \n",
      "Model_5_12890 \t loss_train = 28167898.0 \t loss_valid = 25313796.0 \n",
      "Model_5_12900 \t loss_train = 28199850.0 \t loss_valid = 25292810.0 \n",
      "Model_5_12910 \t loss_train = 28389588.0 \t loss_valid = 25249480.0 \n",
      "Model_5_12920 \t loss_train = 28100150.0 \t loss_valid = 25387102.0 \n",
      "Model_5_12930 \t loss_train = 28238118.0 \t loss_valid = 25272516.0 \n",
      "Model_5_12940 \t loss_train = 28260340.0 \t loss_valid = 25265382.0 \n",
      "Model_5_12950 \t loss_train = 28181936.0 \t loss_valid = 25317446.0 \n",
      "Model_5_12960 \t loss_train = 28338172.0 \t loss_valid = 25253474.0 \n",
      "Model_5_12970 \t loss_train = 28214366.0 \t loss_valid = 25285392.0 \n",
      "Model_5_12980 \t loss_train = 28334520.0 \t loss_valid = 25253986.0 \n",
      "Model_5_12990 \t loss_train = 28198280.0 \t loss_valid = 25299370.0 \n",
      "Model_5_13000 \t loss_train = 28278328.0 \t loss_valid = 25262768.0 \n",
      "Model_5_13010 \t loss_train = 28278562.0 \t loss_valid = 25261520.0 \n",
      "Model_5_13020 \t loss_train = 28315780.0 \t loss_valid = 25258404.0 \n",
      "Model_5_13030 \t loss_train = 28182134.0 \t loss_valid = 25301766.0 \n",
      "Model_5_13040 \t loss_train = 28330950.0 \t loss_valid = 25252864.0 \n",
      "Model_5_13050 \t loss_train = 28177856.0 \t loss_valid = 25312046.0 \n",
      "Model_5_13060 \t loss_train = 28229568.0 \t loss_valid = 25279698.0 \n",
      "Model_5_13070 \t loss_train = 28251960.0 \t loss_valid = 25267174.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_5_13080 \t loss_train = 28227762.0 \t loss_valid = 25273822.0 \n",
      "Model_5_13090 \t loss_train = 28243214.0 \t loss_valid = 25272570.0 \n",
      "Model_5_13100 \t loss_train = 28233288.0 \t loss_valid = 25278926.0 \n",
      "Model_5_13110 \t loss_train = 28222824.0 \t loss_valid = 25274760.0 \n",
      "Model_5_13120 \t loss_train = 28184062.0 \t loss_valid = 25292642.0 \n",
      "Model_5_13130 \t loss_train = 28333964.0 \t loss_valid = 25254366.0 \n",
      "Model_5_13140 \t loss_train = 28142706.0 \t loss_valid = 25337524.0 \n",
      "Model_5_13150 \t loss_train = 28330428.0 \t loss_valid = 25253116.0 \n",
      "Model_5_13160 \t loss_train = 28193028.0 \t loss_valid = 25292596.0 \n",
      "Model_5_13170 \t loss_train = 28298760.0 \t loss_valid = 25257544.0 \n",
      "Model_5_13180 \t loss_train = 28158808.0 \t loss_valid = 25317736.0 \n",
      "Model_5_13190 \t loss_train = 28238664.0 \t loss_valid = 25276806.0 \n",
      "Model_5_13200 \t loss_train = 28188516.0 \t loss_valid = 25297382.0 \n",
      "Model_5_13210 \t loss_train = 28256766.0 \t loss_valid = 25267564.0 \n",
      "Model_5_13220 \t loss_train = 28227526.0 \t loss_valid = 25276670.0 \n",
      "Model_5_13230 \t loss_train = 28248572.0 \t loss_valid = 25282808.0 \n",
      "Model_5_13240 \t loss_train = 28202576.0 \t loss_valid = 25291538.0 \n",
      "Model_5_13250 \t loss_train = 28293288.0 \t loss_valid = 25258058.0 \n",
      "Model_5_13260 \t loss_train = 28171126.0 \t loss_valid = 25321296.0 \n",
      "Model_5_13270 \t loss_train = 28231440.0 \t loss_valid = 25275856.0 \n",
      "Model_5_13280 \t loss_train = 28193536.0 \t loss_valid = 25298468.0 \n",
      "Model_5_13290 \t loss_train = 28233098.0 \t loss_valid = 25280838.0 \n",
      "Model_5_13300 \t loss_train = 28236066.0 \t loss_valid = 25269770.0 \n",
      "Model_5_13310 \t loss_train = 28147426.0 \t loss_valid = 25319864.0 \n",
      "Model_5_13320 \t loss_train = 28305688.0 \t loss_valid = 25256840.0 \n",
      "Model_5_13330 \t loss_train = 28127274.0 \t loss_valid = 25345056.0 \n",
      "Model_5_13340 \t loss_train = 28301956.0 \t loss_valid = 25256236.0 \n",
      "Model_5_13350 \t loss_train = 28162984.0 \t loss_valid = 25309264.0 \n",
      "Model_5_13360 \t loss_train = 28173142.0 \t loss_valid = 25306216.0 \n",
      "Model_5_13370 \t loss_train = 28272910.0 \t loss_valid = 25262128.0 \n",
      "Model_5_13380 \t loss_train = 28195542.0 \t loss_valid = 25299426.0 \n",
      "Model_5_13390 \t loss_train = 28218066.0 \t loss_valid = 25284248.0 \n",
      "Model_5_13400 \t loss_train = 28185382.0 \t loss_valid = 25292664.0 \n",
      "Model_5_13410 \t loss_train = 28246708.0 \t loss_valid = 25271494.0 \n",
      "Model_5_13420 \t loss_train = 28119422.0 \t loss_valid = 25343176.0 \n",
      "Model_5_13430 \t loss_train = 28251112.0 \t loss_valid = 25267648.0 \n",
      "Model_5_13440 \t loss_train = 28246008.0 \t loss_valid = 25273588.0 \n",
      "Model_5_13450 \t loss_train = 28165580.0 \t loss_valid = 25321662.0 \n",
      "Model_5_13460 \t loss_train = 28245910.0 \t loss_valid = 25273334.0 \n",
      "Model_5_13470 \t loss_train = 28174818.0 \t loss_valid = 25294636.0 \n",
      "Model_5_13480 \t loss_train = 28224256.0 \t loss_valid = 25274018.0 \n",
      "Model_5_13490 \t loss_train = 28165080.0 \t loss_valid = 25301628.0 \n",
      "Model_5_13500 \t loss_train = 28191254.0 \t loss_valid = 25292300.0 \n",
      "Model_5_13510 \t loss_train = 28158086.0 \t loss_valid = 25318570.0 \n",
      "Model_5_13520 \t loss_train = 28201860.0 \t loss_valid = 25286322.0 \n",
      "Model_5_13530 \t loss_train = 28313200.0 \t loss_valid = 25254516.0 \n",
      "Model_5_13540 \t loss_train = 28117924.0 \t loss_valid = 25335894.0 \n",
      "Model_5_13550 \t loss_train = 28216698.0 \t loss_valid = 25291580.0 \n",
      "Model_5_13560 \t loss_train = 28212818.0 \t loss_valid = 25298018.0 \n",
      "Model_5_13570 \t loss_train = 28211694.0 \t loss_valid = 25283218.0 \n",
      "Model_5_13580 \t loss_train = 28147200.0 \t loss_valid = 25312432.0 \n",
      "Model_5_13590 \t loss_train = 28170280.0 \t loss_valid = 25297780.0 \n",
      "Model_5_13600 \t loss_train = 28149478.0 \t loss_valid = 25312386.0 \n",
      "Model_5_13610 \t loss_train = 28125620.0 \t loss_valid = 25350848.0 \n",
      "Model_5_13620 \t loss_train = 28213596.0 \t loss_valid = 25285478.0 \n",
      "Model_5_13630 \t loss_train = 28252424.0 \t loss_valid = 25265488.0 \n",
      "Model_5_13640 \t loss_train = 28094456.0 \t loss_valid = 25368234.0 \n",
      "Model_5_13650 \t loss_train = 28301074.0 \t loss_valid = 25261504.0 \n",
      "Model_5_13660 \t loss_train = 28175088.0 \t loss_valid = 25304026.0 \n",
      "Model_5_13670 \t loss_train = 28179522.0 \t loss_valid = 25296128.0 \n",
      "Model_5_13680 \t loss_train = 28210096.0 \t loss_valid = 25288862.0 \n",
      "Model_5_13690 \t loss_train = 28122718.0 \t loss_valid = 25343820.0 \n",
      "Model_5_13700 \t loss_train = 28210932.0 \t loss_valid = 25282572.0 \n",
      "Model_5_13710 \t loss_train = 28165036.0 \t loss_valid = 25301520.0 \n",
      "Model_5_13720 \t loss_train = 28191438.0 \t loss_valid = 25288282.0 \n",
      "Model_5_13730 \t loss_train = 28218384.0 \t loss_valid = 25283714.0 \n",
      "Model_5_13740 \t loss_train = 28219316.0 \t loss_valid = 25282856.0 \n",
      "Model_5_13750 \t loss_train = 28160558.0 \t loss_valid = 25312056.0 \n",
      "Model_5_13760 \t loss_train = 28170800.0 \t loss_valid = 25305242.0 \n",
      "Model_5_13770 \t loss_train = 28197624.0 \t loss_valid = 25290388.0 \n",
      "Model_5_13780 \t loss_train = 28167644.0 \t loss_valid = 25303710.0 \n",
      "Model_5_13790 \t loss_train = 28130798.0 \t loss_valid = 25331320.0 \n",
      "Model_5_13800 \t loss_train = 28233520.0 \t loss_valid = 25276102.0 \n",
      "Model_5_13810 \t loss_train = 28223642.0 \t loss_valid = 25278378.0 \n",
      "Model_5_13820 \t loss_train = 28140270.0 \t loss_valid = 25331264.0 \n",
      "Model_5_13830 \t loss_train = 28187482.0 \t loss_valid = 25300566.0 \n",
      "Model_5_13840 \t loss_train = 28162320.0 \t loss_valid = 25308766.0 \n",
      "Model_5_13850 \t loss_train = 28132188.0 \t loss_valid = 25318020.0 \n",
      "Model_5_13860 \t loss_train = 28203116.0 \t loss_valid = 25284906.0 \n",
      "Model_5_13870 \t loss_train = 28179348.0 \t loss_valid = 25300954.0 \n",
      "Model_5_13880 \t loss_train = 28195340.0 \t loss_valid = 25293256.0 \n",
      "Model_5_13890 \t loss_train = 28147228.0 \t loss_valid = 25320728.0 \n",
      "Model_5_13900 \t loss_train = 28245932.0 \t loss_valid = 25269930.0 \n",
      "Model_5_13910 \t loss_train = 28139746.0 \t loss_valid = 25319518.0 \n",
      "Model_5_13920 \t loss_train = 28134954.0 \t loss_valid = 25328410.0 \n",
      "Model_5_13930 \t loss_train = 28236018.0 \t loss_valid = 25281208.0 \n",
      "Model_5_13940 \t loss_train = 28174612.0 \t loss_valid = 25307030.0 \n",
      "Model_5_13950 \t loss_train = 28143392.0 \t loss_valid = 25316226.0 \n",
      "Model_5_13960 \t loss_train = 28114778.0 \t loss_valid = 25334402.0 \n",
      "Model_5_13970 \t loss_train = 28198732.0 \t loss_valid = 25290798.0 \n",
      "Model_5_13980 \t loss_train = 28137384.0 \t loss_valid = 25329926.0 \n",
      "Model_5_13990 \t loss_train = 28186680.0 \t loss_valid = 25287452.0 \n",
      "Model_5_14000 \t loss_train = 28118798.0 \t loss_valid = 25336250.0 \n",
      "Model_5_14010 \t loss_train = 28131634.0 \t loss_valid = 25322804.0 \n",
      "Model_5_14020 \t loss_train = 28190658.0 \t loss_valid = 25284740.0 \n",
      "Model_5_14030 \t loss_train = 28175946.0 \t loss_valid = 25297998.0 \n",
      "Model_5_14040 \t loss_train = 28164370.0 \t loss_valid = 25300512.0 \n",
      "Model_5_14050 \t loss_train = 28171806.0 \t loss_valid = 25296498.0 \n",
      "Model_5_14060 \t loss_train = 28263730.0 \t loss_valid = 25264096.0 \n",
      "Model_5_14070 \t loss_train = 28152262.0 \t loss_valid = 25328762.0 \n",
      "Model_5_14080 \t loss_train = 28168500.0 \t loss_valid = 25298872.0 \n",
      "Model_5_14090 \t loss_train = 28176666.0 \t loss_valid = 25298790.0 \n",
      "Model_5_14100 \t loss_train = 28185602.0 \t loss_valid = 25302762.0 \n",
      "Model_5_14110 \t loss_train = 28143890.0 \t loss_valid = 25326046.0 \n",
      "Model_5_14120 \t loss_train = 28241704.0 \t loss_valid = 25273144.0 \n",
      "Model_5_14130 \t loss_train = 28095014.0 \t loss_valid = 25379510.0 \n",
      "Model_5_14140 \t loss_train = 28146384.0 \t loss_valid = 25321882.0 \n",
      "Model_5_14150 \t loss_train = 28168416.0 \t loss_valid = 25302942.0 \n",
      "Model_5_14160 \t loss_train = 28157692.0 \t loss_valid = 25309704.0 \n",
      "Model_5_14170 \t loss_train = 28130742.0 \t loss_valid = 25328804.0 \n",
      "Model_5_14180 \t loss_train = 28232702.0 \t loss_valid = 25271042.0 \n",
      "Model_5_14190 \t loss_train = 28138324.0 \t loss_valid = 25314534.0 \n",
      "Model_5_14200 \t loss_train = 28229216.0 \t loss_valid = 25277232.0 \n",
      "Model_5_14210 \t loss_train = 28167826.0 \t loss_valid = 25322936.0 \n",
      "Model_5_14220 \t loss_train = 28218498.0 \t loss_valid = 25281676.0 \n",
      "Model_5_14230 \t loss_train = 28101906.0 \t loss_valid = 25351186.0 \n",
      "Model_5_14240 \t loss_train = 28202206.0 \t loss_valid = 25282612.0 \n",
      "Model_5_14250 \t loss_train = 28139200.0 \t loss_valid = 25320638.0 \n",
      "Model_5_14260 \t loss_train = 28151122.0 \t loss_valid = 25309748.0 \n",
      "Model_5_14270 \t loss_train = 28186376.0 \t loss_valid = 25292430.0 \n",
      "Model_5_14280 \t loss_train = 28103664.0 \t loss_valid = 25349990.0 \n",
      "Model_5_14290 \t loss_train = 28304078.0 \t loss_valid = 25257422.0 \n",
      "Model_5_14300 \t loss_train = 28119428.0 \t loss_valid = 25341052.0 \n",
      "Model_5_14310 \t loss_train = 28142580.0 \t loss_valid = 25332964.0 \n",
      "Model_5_14320 \t loss_train = 28135718.0 \t loss_valid = 25327032.0 \n",
      "Model_5_14330 \t loss_train = 28137912.0 \t loss_valid = 25326586.0 \n",
      "Model_5_14340 \t loss_train = 28197334.0 \t loss_valid = 25289700.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_5_14350 \t loss_train = 28209298.0 \t loss_valid = 25287412.0 \n",
      "Model_5_14360 \t loss_train = 28122024.0 \t loss_valid = 25337260.0 \n",
      "Model_5_14370 \t loss_train = 28205348.0 \t loss_valid = 25284242.0 \n",
      "Model_5_14380 \t loss_train = 28075494.0 \t loss_valid = 25390816.0 \n",
      "Model_5_14390 \t loss_train = 28233752.0 \t loss_valid = 25271414.0 \n",
      "Model_5_14400 \t loss_train = 28119586.0 \t loss_valid = 25325210.0 \n",
      "Model_5_14410 \t loss_train = 28150288.0 \t loss_valid = 25312368.0 \n",
      "Model_5_14420 \t loss_train = 28219972.0 \t loss_valid = 25281766.0 \n",
      "Model_5_14430 \t loss_train = 28080256.0 \t loss_valid = 25402952.0 \n",
      "Model_5_14440 \t loss_train = 28177196.0 \t loss_valid = 25294218.0 \n",
      "Model_5_14450 \t loss_train = 28120364.0 \t loss_valid = 25332898.0 \n",
      "Model_5_14460 \t loss_train = 28092140.0 \t loss_valid = 25373524.0 \n",
      "Model_5_14470 \t loss_train = 28186344.0 \t loss_valid = 25306782.0 \n",
      "Model_5_14480 \t loss_train = 28119820.0 \t loss_valid = 25340104.0 \n",
      "Model_5_14490 \t loss_train = 28143142.0 \t loss_valid = 25309520.0 \n",
      "Model_5_14500 \t loss_train = 28086190.0 \t loss_valid = 25363128.0 \n",
      "Model_5_14510 \t loss_train = 28128638.0 \t loss_valid = 25333106.0 \n",
      "Model_5_14520 \t loss_train = 28128072.0 \t loss_valid = 25337100.0 \n",
      "Model_5_14530 \t loss_train = 28199652.0 \t loss_valid = 25288136.0 \n",
      "Model_5_14540 \t loss_train = 28087522.0 \t loss_valid = 25389550.0 \n",
      "Model_5_14550 \t loss_train = 28161748.0 \t loss_valid = 25311210.0 \n",
      "Model_5_14560 \t loss_train = 28123804.0 \t loss_valid = 25330864.0 \n",
      "Model_5_14570 \t loss_train = 28114730.0 \t loss_valid = 25332098.0 \n",
      "Model_5_14580 \t loss_train = 28135652.0 \t loss_valid = 25315218.0 \n",
      "Model_5_14590 \t loss_train = 28130068.0 \t loss_valid = 25344576.0 \n",
      "Model_5_14600 \t loss_train = 28178848.0 \t loss_valid = 25307388.0 \n",
      "Model_5_14610 \t loss_train = 28091396.0 \t loss_valid = 25371344.0 \n",
      "Model_5_14620 \t loss_train = 28146330.0 \t loss_valid = 25312960.0 \n",
      "Model_5_14630 \t loss_train = 28145604.0 \t loss_valid = 25315432.0 \n",
      "Model_5_14640 \t loss_train = 28171516.0 \t loss_valid = 25301748.0 \n",
      "Model_5_14650 \t loss_train = 28109134.0 \t loss_valid = 25345674.0 \n",
      "Model_5_14660 \t loss_train = 28217628.0 \t loss_valid = 25275652.0 \n",
      "Model_5_14670 \t loss_train = 28103254.0 \t loss_valid = 25350034.0 \n",
      "Model_5_14680 \t loss_train = 28123158.0 \t loss_valid = 25333948.0 \n",
      "Model_5_14690 \t loss_train = 28135428.0 \t loss_valid = 25326392.0 \n",
      "Model_5_14700 \t loss_train = 28107550.0 \t loss_valid = 25360308.0 \n",
      "Model_5_14710 \t loss_train = 28093694.0 \t loss_valid = 25377436.0 \n",
      "Model_5_14720 \t loss_train = 28194284.0 \t loss_valid = 25289170.0 \n",
      "Model_5_14730 \t loss_train = 28078638.0 \t loss_valid = 25387348.0 \n",
      "Model_5_14740 \t loss_train = 28137328.0 \t loss_valid = 25323770.0 \n",
      "Model_5_14750 \t loss_train = 28210410.0 \t loss_valid = 25282336.0 \n",
      "Model_5_14760 \t loss_train = 28120880.0 \t loss_valid = 25337264.0 \n",
      "Model_5_14770 \t loss_train = 28063772.0 \t loss_valid = 25418222.0 \n",
      "Model_5_14780 \t loss_train = 28236916.0 \t loss_valid = 25271716.0 \n",
      "Model_5_14790 \t loss_train = 28103706.0 \t loss_valid = 25370058.0 \n",
      "Model_5_14800 \t loss_train = 28170646.0 \t loss_valid = 25312816.0 \n",
      "Model_5_14810 \t loss_train = 28159792.0 \t loss_valid = 25309482.0 \n",
      "Model_5_14820 \t loss_train = 28123448.0 \t loss_valid = 25341934.0 \n",
      "Model_5_14830 \t loss_train = 28108658.0 \t loss_valid = 25363606.0 \n",
      "Model_5_14840 \t loss_train = 28138006.0 \t loss_valid = 25324480.0 \n",
      "Model_5_14850 \t loss_train = 28076738.0 \t loss_valid = 25383504.0 \n",
      "Model_5_14860 \t loss_train = 28173900.0 \t loss_valid = 25296304.0 \n",
      "Model_5_14870 \t loss_train = 28061114.0 \t loss_valid = 25406808.0 \n",
      "Model_5_14880 \t loss_train = 28157088.0 \t loss_valid = 25306002.0 \n",
      "Model_5_14890 \t loss_train = 28133450.0 \t loss_valid = 25320170.0 \n",
      "Model_5_14900 \t loss_train = 28110716.0 \t loss_valid = 25337714.0 \n",
      "Model_5_14910 \t loss_train = 28151734.0 \t loss_valid = 25309318.0 \n",
      "Model_5_14920 \t loss_train = 28136642.0 \t loss_valid = 25324048.0 \n",
      "Model_5_14930 \t loss_train = 28112078.0 \t loss_valid = 25340736.0 \n",
      "Model_5_14940 \t loss_train = 28181838.0 \t loss_valid = 25296102.0 \n",
      "Model_5_14950 \t loss_train = 28134806.0 \t loss_valid = 25337972.0 \n",
      "Model_5_14960 \t loss_train = 28105822.0 \t loss_valid = 25353570.0 \n",
      "Model_5_14970 \t loss_train = 28136836.0 \t loss_valid = 25316228.0 \n",
      "Model_5_14980 \t loss_train = 28092064.0 \t loss_valid = 25357444.0 \n",
      "Model_5_14990 \t loss_train = 28165656.0 \t loss_valid = 25311926.0 \n",
      "Model_5_15000 \t loss_train = 28096160.0 \t loss_valid = 25369094.0 \n",
      "Model_5_15010 \t loss_train = 28090180.0 \t loss_valid = 25369192.0 \n",
      "Model_5_15020 \t loss_train = 28122736.0 \t loss_valid = 25336064.0 \n",
      "Model_5_15030 \t loss_train = 28107530.0 \t loss_valid = 25355624.0 \n",
      "Model_5_15040 \t loss_train = 28160252.0 \t loss_valid = 25317720.0 \n",
      "Model_5_15050 \t loss_train = 28142486.0 \t loss_valid = 25332836.0 \n",
      "Model_5_15060 \t loss_train = 28073516.0 \t loss_valid = 25423114.0 \n",
      "Model_5_15070 \t loss_train = 28191844.0 \t loss_valid = 25289830.0 \n",
      "Model_5_15080 \t loss_train = 28088444.0 \t loss_valid = 25358058.0 \n",
      "Model_5_15090 \t loss_train = 28115862.0 \t loss_valid = 25341052.0 \n",
      "Model_5_15100 \t loss_train = 28133642.0 \t loss_valid = 25337844.0 \n",
      "Model_5_15110 \t loss_train = 28119452.0 \t loss_valid = 25341768.0 \n",
      "Model_5_15120 \t loss_train = 28115730.0 \t loss_valid = 25337294.0 \n",
      "Model_5_15130 \t loss_train = 28137560.0 \t loss_valid = 25322954.0 \n",
      "Model_5_15140 \t loss_train = 28125414.0 \t loss_valid = 25341332.0 \n",
      "Model_5_15150 \t loss_train = 28112744.0 \t loss_valid = 25353478.0 \n",
      "Model_5_15160 \t loss_train = 28080206.0 \t loss_valid = 25385198.0 \n",
      "Model_5_15170 \t loss_train = 28166504.0 \t loss_valid = 25305708.0 \n",
      "Model_5_15180 \t loss_train = 28142690.0 \t loss_valid = 25320826.0 \n",
      "Model_5_15190 \t loss_train = 28118704.0 \t loss_valid = 25334928.0 \n",
      "Model_5_15200 \t loss_train = 28090858.0 \t loss_valid = 25362836.0 \n",
      "Model_5_15210 \t loss_train = 28143850.0 \t loss_valid = 25323556.0 \n",
      "Model_5_15220 \t loss_train = 28097376.0 \t loss_valid = 25367918.0 \n",
      "Model_5_15230 \t loss_train = 28070704.0 \t loss_valid = 25386944.0 \n",
      "Model_5_15240 \t loss_train = 28126780.0 \t loss_valid = 25328586.0 \n",
      "Model_5_15250 \t loss_train = 28058104.0 \t loss_valid = 25422066.0 \n",
      "Model_5_15260 \t loss_train = 28126468.0 \t loss_valid = 25343220.0 \n",
      "Model_5_15270 \t loss_train = 28076548.0 \t loss_valid = 25389580.0 \n",
      "Model_5_15280 \t loss_train = 28056054.0 \t loss_valid = 25420290.0 \n",
      "Model_5_15290 \t loss_train = 28118494.0 \t loss_valid = 25352248.0 \n",
      "Model_5_15300 \t loss_train = 28048898.0 \t loss_valid = 25442070.0 \n",
      "Model_5_15310 \t loss_train = 28076396.0 \t loss_valid = 25394028.0 \n",
      "Model_5_15320 \t loss_train = 28114084.0 \t loss_valid = 25356088.0 \n",
      "Model_5_15330 \t loss_train = 28073816.0 \t loss_valid = 25405354.0 \n",
      "Model_5_15340 \t loss_train = 28108488.0 \t loss_valid = 25370798.0 \n",
      "Model_5_15350 \t loss_train = 28047208.0 \t loss_valid = 25458414.0 \n",
      "Model_5_15360 \t loss_train = 28119372.0 \t loss_valid = 25356058.0 \n",
      "Model_5_15370 \t loss_train = 28056184.0 \t loss_valid = 25430440.0 \n",
      "Model_5_15380 \t loss_train = 28144652.0 \t loss_valid = 25332732.0 \n",
      "Model_5_15390 \t loss_train = 28068482.0 \t loss_valid = 25410756.0 \n",
      "Model_5_15400 \t loss_train = 28151472.0 \t loss_valid = 25320480.0 \n",
      "Model_5_15410 \t loss_train = 28028978.0 \t loss_valid = 25468656.0 \n",
      "Model_5_15420 \t loss_train = 28078668.0 \t loss_valid = 25380204.0 \n",
      "Model_5_15430 \t loss_train = 28097178.0 \t loss_valid = 25376166.0 \n",
      "Model_5_15440 \t loss_train = 28060980.0 \t loss_valid = 25454046.0 \n",
      "Model_5_15450 \t loss_train = 28120472.0 \t loss_valid = 25361710.0 \n",
      "Model_5_15460 \t loss_train = 28079974.0 \t loss_valid = 25382720.0 \n",
      "Model_5_15470 \t loss_train = 28107902.0 \t loss_valid = 25344424.0 \n",
      "Model_5_15480 \t loss_train = 28043874.0 \t loss_valid = 25440336.0 \n",
      "Model_5_15490 \t loss_train = 28114946.0 \t loss_valid = 25359284.0 \n",
      "Model_5_15500 \t loss_train = 28067968.0 \t loss_valid = 25415514.0 \n",
      "Model_5_15510 \t loss_train = 28100520.0 \t loss_valid = 25357924.0 \n",
      "Model_5_15520 \t loss_train = 28070786.0 \t loss_valid = 25386534.0 \n",
      "Model_5_15530 \t loss_train = 28097560.0 \t loss_valid = 25356354.0 \n",
      "Model_5_15540 \t loss_train = 28076564.0 \t loss_valid = 25383072.0 \n",
      "Model_5_15550 \t loss_train = 28080706.0 \t loss_valid = 25387116.0 \n",
      "Model_5_15560 \t loss_train = 28106718.0 \t loss_valid = 25364792.0 \n",
      "Model_5_15570 \t loss_train = 28087188.0 \t loss_valid = 25386538.0 \n",
      "Model_5_15580 \t loss_train = 28108630.0 \t loss_valid = 25358530.0 \n",
      "Model_5_15590 \t loss_train = 28024068.0 \t loss_valid = 25501410.0 \n",
      "Model_5_15600 \t loss_train = 28093782.0 \t loss_valid = 25370924.0 \n",
      "Model_5_15610 \t loss_train = 28052538.0 \t loss_valid = 25418998.0 \n",
      "Model_5_15620 \t loss_train = 28029328.0 \t loss_valid = 25470214.0 \n",
      "Model_5_15630 \t loss_train = 28050352.0 \t loss_valid = 25425788.0 \n",
      "Model_5_15640 \t loss_train = 28015308.0 \t loss_valid = 25511674.0 \n",
      "Model_5_15650 \t loss_train = 28082158.0 \t loss_valid = 25382592.0 \n",
      "Model_5_15660 \t loss_train = 27998838.0 \t loss_valid = 25587778.0 \n",
      "Model_5_15670 \t loss_train = 28087110.0 \t loss_valid = 25371320.0 \n",
      "Model_5_15680 \t loss_train = 28022056.0 \t loss_valid = 25489852.0 \n",
      "Model_5_15690 \t loss_train = 28037746.0 \t loss_valid = 25448920.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_5_15700 \t loss_train = 28033990.0 \t loss_valid = 25450002.0 \n",
      "Model_5_15710 \t loss_train = 28063622.0 \t loss_valid = 25399328.0 \n",
      "Model_5_15720 \t loss_train = 28002756.0 \t loss_valid = 25544502.0 \n",
      "Model_5_15730 \t loss_train = 28115910.0 \t loss_valid = 25336936.0 \n",
      "Model_5_15740 \t loss_train = 28024544.0 \t loss_valid = 25467620.0 \n",
      "Model_5_15750 \t loss_train = 28076104.0 \t loss_valid = 25383110.0 \n",
      "Model_5_15760 \t loss_train = 28032210.0 \t loss_valid = 25479904.0 \n",
      "Model_5_15770 \t loss_train = 28067024.0 \t loss_valid = 25415500.0 \n",
      "Model_5_15780 \t loss_train = 28039124.0 \t loss_valid = 25445606.0 \n",
      "Model_5_15790 \t loss_train = 28033102.0 \t loss_valid = 25449950.0 \n",
      "Model_5_15800 \t loss_train = 28061336.0 \t loss_valid = 25400784.0 \n",
      "Model_5_15810 \t loss_train = 28021122.0 \t loss_valid = 25483002.0 \n",
      "Model_5_15820 \t loss_train = 28026490.0 \t loss_valid = 25463872.0 \n",
      "Model_5_15830 \t loss_train = 28085942.0 \t loss_valid = 25372220.0 \n",
      "Model_5_15840 \t loss_train = 28023234.0 \t loss_valid = 25492428.0 \n",
      "Model_5_15850 \t loss_train = 28055344.0 \t loss_valid = 25419506.0 \n",
      "Model_5_15860 \t loss_train = 28021558.0 \t loss_valid = 25486450.0 \n",
      "Model_5_15870 \t loss_train = 28082956.0 \t loss_valid = 25380626.0 \n",
      "Model_5_15880 \t loss_train = 28027854.0 \t loss_valid = 25481176.0 \n",
      "Model_5_15890 \t loss_train = 28076176.0 \t loss_valid = 25397604.0 \n",
      "Model_5_15900 \t loss_train = 28034548.0 \t loss_valid = 25466934.0 \n",
      "Model_5_15910 \t loss_train = 28044590.0 \t loss_valid = 25437158.0 \n",
      "Model_5_15920 \t loss_train = 28027958.0 \t loss_valid = 25463854.0 \n",
      "Model_5_15930 \t loss_train = 28077210.0 \t loss_valid = 25388362.0 \n",
      "Model_5_15940 \t loss_train = 28034610.0 \t loss_valid = 25472990.0 \n",
      "Model_5_15950 \t loss_train = 28038088.0 \t loss_valid = 25459076.0 \n",
      "Model_5_15960 \t loss_train = 28079848.0 \t loss_valid = 25384126.0 \n",
      "Model_5_15970 \t loss_train = 28059320.0 \t loss_valid = 25412072.0 \n",
      "Model_5_15980 \t loss_train = 28046094.0 \t loss_valid = 25433098.0 \n",
      "Model_5_15990 \t loss_train = 28043294.0 \t loss_valid = 25448820.0 \n",
      "Model_5_16000 \t loss_train = 28059828.0 \t loss_valid = 25422672.0 \n",
      "Model_5_16010 \t loss_train = 28037978.0 \t loss_valid = 25463748.0 \n",
      "Model_5_16020 \t loss_train = 28102092.0 \t loss_valid = 25364950.0 \n",
      "Model_5_16030 \t loss_train = 28040934.0 \t loss_valid = 25451478.0 \n",
      "Model_5_16040 \t loss_train = 28067426.0 \t loss_valid = 25400026.0 \n",
      "Model_5_16050 \t loss_train = 28038500.0 \t loss_valid = 25444898.0 \n",
      "Model_5_16060 \t loss_train = 28038484.0 \t loss_valid = 25459492.0 \n",
      "Model_5_16070 \t loss_train = 28066006.0 \t loss_valid = 25426214.0 \n",
      "Model_5_16080 \t loss_train = 28036400.0 \t loss_valid = 25471314.0 \n",
      "Model_5_16090 \t loss_train = 28095124.0 \t loss_valid = 25369360.0 \n",
      "Model_5_16100 \t loss_train = 28035534.0 \t loss_valid = 25463536.0 \n",
      "Model_5_16110 \t loss_train = 28119214.0 \t loss_valid = 25354366.0 \n",
      "Model_5_16120 \t loss_train = 28043548.0 \t loss_valid = 25481534.0 \n",
      "Model_5_16130 \t loss_train = 28029972.0 \t loss_valid = 25497098.0 \n",
      "Model_5_16140 \t loss_train = 28050168.0 \t loss_valid = 25436630.0 \n",
      "Model_5_16150 \t loss_train = 28030222.0 \t loss_valid = 25469720.0 \n",
      "Model_5_16160 \t loss_train = 28063190.0 \t loss_valid = 25419194.0 \n",
      "Model_5_16170 \t loss_train = 28037406.0 \t loss_valid = 25464886.0 \n",
      "Model_5_16180 \t loss_train = 28044612.0 \t loss_valid = 25447342.0 \n",
      "Model_5_16190 \t loss_train = 28038722.0 \t loss_valid = 25456132.0 \n",
      "Model_5_16200 \t loss_train = 28012710.0 \t loss_valid = 25519144.0 \n",
      "Model_5_16210 \t loss_train = 28068988.0 \t loss_valid = 25408274.0 \n",
      "Model_5_16220 \t loss_train = 28036702.0 \t loss_valid = 25454348.0 \n",
      "Model_5_16230 \t loss_train = 28028070.0 \t loss_valid = 25464368.0 \n",
      "Model_5_16240 \t loss_train = 28071740.0 \t loss_valid = 25393952.0 \n",
      "Model_5_16250 \t loss_train = 28013092.0 \t loss_valid = 25541366.0 \n",
      "Model_5_16260 \t loss_train = 28058882.0 \t loss_valid = 25419012.0 \n",
      "Model_5_16270 \t loss_train = 28029202.0 \t loss_valid = 25466876.0 \n",
      "Model_5_16280 \t loss_train = 28053990.0 \t loss_valid = 25417978.0 \n",
      "Model_5_16290 \t loss_train = 28039242.0 \t loss_valid = 25448448.0 \n",
      "Model_5_16300 \t loss_train = 28052236.0 \t loss_valid = 25435606.0 \n",
      "Model_5_16310 \t loss_train = 28027288.0 \t loss_valid = 25492198.0 \n",
      "Model_5_16320 \t loss_train = 28053458.0 \t loss_valid = 25439018.0 \n",
      "Model_5_16330 \t loss_train = 28052282.0 \t loss_valid = 25436068.0 \n",
      "Model_5_16340 \t loss_train = 28007424.0 \t loss_valid = 25559902.0 \n",
      "Model_5_16350 \t loss_train = 28033188.0 \t loss_valid = 25487726.0 \n",
      "Model_5_16360 \t loss_train = 28024710.0 \t loss_valid = 25483546.0 \n",
      "Model_5_16370 \t loss_train = 28037796.0 \t loss_valid = 25446932.0 \n",
      "Model_5_16380 \t loss_train = 28022768.0 \t loss_valid = 25484954.0 \n",
      "Model_5_16390 \t loss_train = 28045132.0 \t loss_valid = 25436052.0 \n",
      "Model_5_16400 \t loss_train = 28055036.0 \t loss_valid = 25421072.0 \n",
      "Model_5_16410 \t loss_train = 28008314.0 \t loss_valid = 25549726.0 \n",
      "Model_5_16420 \t loss_train = 28064118.0 \t loss_valid = 25409180.0 \n",
      "Model_5_16430 \t loss_train = 28020248.0 \t loss_valid = 25484420.0 \n",
      "Model_5_16440 \t loss_train = 28018394.0 \t loss_valid = 25490542.0 \n",
      "Model_5_16450 \t loss_train = 28050606.0 \t loss_valid = 25426022.0 \n",
      "Model_5_16460 \t loss_train = 28077108.0 \t loss_valid = 25386458.0 \n",
      "Model_5_16470 \t loss_train = 28034906.0 \t loss_valid = 25471000.0 \n",
      "Model_5_16480 \t loss_train = 28029578.0 \t loss_valid = 25482624.0 \n",
      "Model_5_16490 \t loss_train = 28019244.0 \t loss_valid = 25498390.0 \n",
      "Model_5_16500 \t loss_train = 28058452.0 \t loss_valid = 25408874.0 \n",
      "Model_5_16510 \t loss_train = 28004278.0 \t loss_valid = 25545074.0 \n",
      "Model_5_16520 \t loss_train = 28055466.0 \t loss_valid = 25422264.0 \n",
      "Model_5_16530 \t loss_train = 28008144.0 \t loss_valid = 25550576.0 \n",
      "Model_5_16540 \t loss_train = 28051676.0 \t loss_valid = 25424492.0 \n",
      "Model_5_16550 \t loss_train = 28031248.0 \t loss_valid = 25461968.0 \n",
      "Model_5_16560 \t loss_train = 28061748.0 \t loss_valid = 25408806.0 \n",
      "Model_5_16570 \t loss_train = 28003632.0 \t loss_valid = 25570064.0 \n",
      "Model_5_16580 \t loss_train = 28019014.0 \t loss_valid = 25489510.0 \n",
      "Model_5_16590 \t loss_train = 28040036.0 \t loss_valid = 25436142.0 \n",
      "Model_5_16600 \t loss_train = 28005412.0 \t loss_valid = 25533212.0 \n",
      "Model_5_16610 \t loss_train = 28046098.0 \t loss_valid = 25428622.0 \n",
      "Model_5_16620 \t loss_train = 28045742.0 \t loss_valid = 25434460.0 \n",
      "Model_5_16630 \t loss_train = 28019942.0 \t loss_valid = 25491218.0 \n",
      "Model_5_16640 \t loss_train = 28035728.0 \t loss_valid = 25459956.0 \n",
      "Model_5_16650 \t loss_train = 28012036.0 \t loss_valid = 25532168.0 \n",
      "Model_5_16660 \t loss_train = 28052494.0 \t loss_valid = 25432216.0 \n",
      "Model_5_16670 \t loss_train = 28008396.0 \t loss_valid = 25548736.0 \n",
      "Model_5_16680 \t loss_train = 28072572.0 \t loss_valid = 25400164.0 \n",
      "Model_5_16690 \t loss_train = 28000790.0 \t loss_valid = 25571944.0 \n",
      "Model_5_16700 \t loss_train = 28088686.0 \t loss_valid = 25369332.0 \n",
      "Model_5_16710 \t loss_train = 27995534.0 \t loss_valid = 25586992.0 \n",
      "Model_5_16720 \t loss_train = 28079748.0 \t loss_valid = 25376614.0 \n",
      "Model_5_16730 \t loss_train = 28030196.0 \t loss_valid = 25466722.0 \n",
      "Model_5_16740 \t loss_train = 28041108.0 \t loss_valid = 25445056.0 \n",
      "Model_5_16750 \t loss_train = 28011120.0 \t loss_valid = 25534812.0 \n",
      "Model_5_16760 \t loss_train = 28025092.0 \t loss_valid = 25479302.0 \n",
      "Model_5_16770 \t loss_train = 28015650.0 \t loss_valid = 25495206.0 \n",
      "Model_5_16780 \t loss_train = 28044292.0 \t loss_valid = 25431678.0 \n",
      "Model_5_16790 \t loss_train = 28032944.0 \t loss_valid = 25469888.0 \n",
      "Model_5_16800 \t loss_train = 28063886.0 \t loss_valid = 25405142.0 \n",
      "Model_5_16810 \t loss_train = 28012224.0 \t loss_valid = 25502378.0 \n",
      "Model_5_16820 \t loss_train = 28046458.0 \t loss_valid = 25419738.0 \n",
      "Model_5_16830 \t loss_train = 28002624.0 \t loss_valid = 25538586.0 \n",
      "Model_5_16840 \t loss_train = 28065658.0 \t loss_valid = 25393084.0 \n",
      "Model_5_16850 \t loss_train = 27997266.0 \t loss_valid = 25576116.0 \n",
      "Model_5_16860 \t loss_train = 28057712.0 \t loss_valid = 25410166.0 \n",
      "Model_5_16870 \t loss_train = 28014158.0 \t loss_valid = 25503398.0 \n",
      "Model_5_16880 \t loss_train = 28046916.0 \t loss_valid = 25427868.0 \n",
      "Model_5_16890 \t loss_train = 28007644.0 \t loss_valid = 25538352.0 \n",
      "Model_5_16900 \t loss_train = 28060042.0 \t loss_valid = 25408484.0 \n",
      "Model_5_16910 \t loss_train = 28003080.0 \t loss_valid = 25541256.0 \n",
      "Model_5_16920 \t loss_train = 28062478.0 \t loss_valid = 25402288.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_5_16930 \t loss_train = 27993792.0 \t loss_valid = 25621630.0 \n",
      "Model_5_16940 \t loss_train = 28052038.0 \t loss_valid = 25422418.0 \n",
      "Model_5_16950 \t loss_train = 28024404.0 \t loss_valid = 25473728.0 \n",
      "Model_5_16960 \t loss_train = 28037006.0 \t loss_valid = 25451320.0 \n",
      "Model_5_16970 \t loss_train = 28067010.0 \t loss_valid = 25413812.0 \n",
      "Model_5_16980 \t loss_train = 27998058.0 \t loss_valid = 25598250.0 \n",
      "Model_5_16990 \t loss_train = 28048238.0 \t loss_valid = 25428778.0 \n",
      "Model_5_17000 \t loss_train = 28023220.0 \t loss_valid = 25475730.0 \n",
      "Model_5_17010 \t loss_train = 28019074.0 \t loss_valid = 25485954.0 \n",
      "Model_5_17020 \t loss_train = 28029626.0 \t loss_valid = 25456110.0 \n",
      "Model_5_17030 \t loss_train = 28016546.0 \t loss_valid = 25487854.0 \n",
      "Model_5_17040 \t loss_train = 28035054.0 \t loss_valid = 25443980.0 \n",
      "Model_5_17050 \t loss_train = 28012714.0 \t loss_valid = 25501194.0 \n",
      "Model_5_17060 \t loss_train = 28010246.0 \t loss_valid = 25522168.0 \n",
      "Model_5_17070 \t loss_train = 28030664.0 \t loss_valid = 25462600.0 \n",
      "Model_5_17080 \t loss_train = 28018440.0 \t loss_valid = 25492234.0 \n",
      "Model_5_17090 \t loss_train = 28029788.0 \t loss_valid = 25464848.0 \n",
      "Model_5_17100 \t loss_train = 28026446.0 \t loss_valid = 25472528.0 \n",
      "Model_5_17110 \t loss_train = 28008628.0 \t loss_valid = 25534068.0 \n",
      "Model_5_17120 \t loss_train = 28015084.0 \t loss_valid = 25519440.0 \n",
      "Model_5_17130 \t loss_train = 28018498.0 \t loss_valid = 25511470.0 \n",
      "Model_5_17140 \t loss_train = 28046348.0 \t loss_valid = 25435200.0 \n",
      "Model_5_17150 \t loss_train = 28007174.0 \t loss_valid = 25523482.0 \n",
      "Model_5_17160 \t loss_train = 28032536.0 \t loss_valid = 25444556.0 \n",
      "Model_5_17170 \t loss_train = 28015624.0 \t loss_valid = 25486092.0 \n",
      "Model_5_17180 \t loss_train = 28028046.0 \t loss_valid = 25452822.0 \n",
      "Model_5_17190 \t loss_train = 28015378.0 \t loss_valid = 25491926.0 \n",
      "Model_5_17200 \t loss_train = 28031586.0 \t loss_valid = 25458586.0 \n",
      "Model_5_17210 \t loss_train = 27997014.0 \t loss_valid = 25589488.0 \n",
      "Model_5_17220 \t loss_train = 28034994.0 \t loss_valid = 25451912.0 \n",
      "Model_5_17230 \t loss_train = 28010126.0 \t loss_valid = 25511368.0 \n",
      "Model_5_17240 \t loss_train = 28023094.0 \t loss_valid = 25471680.0 \n",
      "Model_5_17250 \t loss_train = 28042632.0 \t loss_valid = 25429162.0 \n",
      "Model_5_17260 \t loss_train = 27996200.0 \t loss_valid = 25575466.0 \n",
      "Model_5_17270 \t loss_train = 28030130.0 \t loss_valid = 25459842.0 \n",
      "Model_5_17280 \t loss_train = 28017638.0 \t loss_valid = 25499264.0 \n",
      "Model_5_17290 \t loss_train = 28030954.0 \t loss_valid = 25459088.0 \n",
      "Model_5_17300 \t loss_train = 28006400.0 \t loss_valid = 25521614.0 \n",
      "Model_5_17310 \t loss_train = 28033138.0 \t loss_valid = 25450878.0 \n",
      "Model_5_17320 \t loss_train = 28008146.0 \t loss_valid = 25525826.0 \n",
      "Model_5_17330 \t loss_train = 28016710.0 \t loss_valid = 25488512.0 \n",
      "Model_5_17340 \t loss_train = 28056746.0 \t loss_valid = 25405282.0 \n",
      "Model_5_17350 \t loss_train = 28008780.0 \t loss_valid = 25511180.0 \n",
      "Model_5_17360 \t loss_train = 28028430.0 \t loss_valid = 25454446.0 \n",
      "Model_5_17370 \t loss_train = 28029690.0 \t loss_valid = 25453632.0 \n",
      "Model_5_17380 \t loss_train = 28012526.0 \t loss_valid = 25506868.0 \n",
      "Model_5_17390 \t loss_train = 28023400.0 \t loss_valid = 25490366.0 \n",
      "Model_5_17400 \t loss_train = 28012146.0 \t loss_valid = 25521072.0 \n",
      "Model_5_17410 \t loss_train = 28017188.0 \t loss_valid = 25491688.0 \n",
      "Model_5_17420 \t loss_train = 28015044.0 \t loss_valid = 25493556.0 \n",
      "Model_5_17430 \t loss_train = 28004296.0 \t loss_valid = 25542132.0 \n",
      "Model_5_17440 \t loss_train = 28022610.0 \t loss_valid = 25481434.0 \n",
      "Model_5_17450 \t loss_train = 28019566.0 \t loss_valid = 25480260.0 \n",
      "Model_5_17460 \t loss_train = 27996112.0 \t loss_valid = 25579772.0 \n",
      "Model_5_17470 \t loss_train = 28064976.0 \t loss_valid = 25403754.0 \n",
      "Model_5_17480 \t loss_train = 27991590.0 \t loss_valid = 25629422.0 \n",
      "Model_5_17490 \t loss_train = 28046994.0 \t loss_valid = 25424680.0 \n",
      "Model_5_17500 \t loss_train = 28019548.0 \t loss_valid = 25486090.0 \n",
      "Model_5_17510 \t loss_train = 28014588.0 \t loss_valid = 25501114.0 \n",
      "Model_5_17520 \t loss_train = 28023622.0 \t loss_valid = 25472304.0 \n",
      "Model_5_17530 \t loss_train = 28007074.0 \t loss_valid = 25529438.0 \n",
      "Model_5_17540 \t loss_train = 28022142.0 \t loss_valid = 25484064.0 \n",
      "Model_5_17550 \t loss_train = 28013042.0 \t loss_valid = 25505644.0 \n",
      "Model_5_17560 \t loss_train = 28013580.0 \t loss_valid = 25498356.0 \n",
      "Model_5_17570 \t loss_train = 28011802.0 \t loss_valid = 25510444.0 \n",
      "Model_5_17580 \t loss_train = 28010624.0 \t loss_valid = 25519520.0 \n",
      "Model_5_17590 \t loss_train = 28017236.0 \t loss_valid = 25490234.0 \n",
      "Model_5_17600 \t loss_train = 28008180.0 \t loss_valid = 25521926.0 \n",
      "Model_5_17610 \t loss_train = 28017154.0 \t loss_valid = 25500116.0 \n",
      "Model_5_17620 \t loss_train = 28008906.0 \t loss_valid = 25530010.0 \n",
      "Model_5_17630 \t loss_train = 28007748.0 \t loss_valid = 25529044.0 \n",
      "Model_5_17640 \t loss_train = 28019998.0 \t loss_valid = 25482896.0 \n",
      "Model_5_17650 \t loss_train = 28003750.0 \t loss_valid = 25538016.0 \n",
      "Model_5_17660 \t loss_train = 28045378.0 \t loss_valid = 25423006.0 \n",
      "Model_5_17670 \t loss_train = 28003344.0 \t loss_valid = 25540756.0 \n",
      "Model_5_17680 \t loss_train = 28016134.0 \t loss_valid = 25506990.0 \n",
      "Model_5_17690 \t loss_train = 28028806.0 \t loss_valid = 25480732.0 \n",
      "Model_5_17700 \t loss_train = 28011410.0 \t loss_valid = 25523196.0 \n",
      "Model_5_17710 \t loss_train = 28010226.0 \t loss_valid = 25521796.0 \n",
      "Model_5_17720 \t loss_train = 28014004.0 \t loss_valid = 25510584.0 \n",
      "Model_5_17730 \t loss_train = 28021524.0 \t loss_valid = 25484940.0 \n",
      "Model_5_17740 \t loss_train = 28005514.0 \t loss_valid = 25536002.0 \n",
      "Model_5_17750 \t loss_train = 28002910.0 \t loss_valid = 25544580.0 \n",
      "Model_5_17760 \t loss_train = 28032670.0 \t loss_valid = 25450304.0 \n",
      "Model_5_17770 \t loss_train = 27995608.0 \t loss_valid = 25589978.0 \n",
      "Model_5_17780 \t loss_train = 28072874.0 \t loss_valid = 25383596.0 \n",
      "Model_5_17790 \t loss_train = 27990714.0 \t loss_valid = 25622820.0 \n",
      "Model_5_17800 \t loss_train = 28051896.0 \t loss_valid = 25413756.0 \n",
      "Model_5_17810 \t loss_train = 28004124.0 \t loss_valid = 25546394.0 \n",
      "Model_5_17820 \t loss_train = 28012132.0 \t loss_valid = 25517624.0 \n",
      "Model_5_17830 \t loss_train = 28024142.0 \t loss_valid = 25479376.0 \n",
      "Model_5_17840 \t loss_train = 27998822.0 \t loss_valid = 25566530.0 \n",
      "Model_5_17850 \t loss_train = 28027784.0 \t loss_valid = 25459678.0 \n",
      "Model_5_17860 \t loss_train = 27999232.0 \t loss_valid = 25562336.0 \n",
      "Model_5_17870 \t loss_train = 28031260.0 \t loss_valid = 25463870.0 \n",
      "Model_5_17880 \t loss_train = 28009820.0 \t loss_valid = 25523008.0 \n",
      "Model_5_17890 \t loss_train = 28019484.0 \t loss_valid = 25487986.0 \n",
      "Model_5_17900 \t loss_train = 28015228.0 \t loss_valid = 25504854.0 \n",
      "Model_5_17910 \t loss_train = 28007604.0 \t loss_valid = 25521852.0 \n",
      "Model_5_17920 \t loss_train = 28024824.0 \t loss_valid = 25469054.0 \n",
      "Model_5_17930 \t loss_train = 28008764.0 \t loss_valid = 25517642.0 \n",
      "Model_5_17940 \t loss_train = 28010548.0 \t loss_valid = 25508364.0 \n",
      "Model_5_17950 \t loss_train = 28022898.0 \t loss_valid = 25468706.0 \n",
      "Model_5_17960 \t loss_train = 28006608.0 \t loss_valid = 25519552.0 \n",
      "Model_5_17970 \t loss_train = 28035194.0 \t loss_valid = 25443264.0 \n",
      "Model_5_17980 \t loss_train = 28006364.0 \t loss_valid = 25532302.0 \n",
      "Model_5_17990 \t loss_train = 28054596.0 \t loss_valid = 25413428.0 \n",
      "Model_5_18000 \t loss_train = 28000906.0 \t loss_valid = 25555204.0 \n",
      "Model_5_18010 \t loss_train = 28039156.0 \t loss_valid = 25442604.0 \n",
      "Model_5_18020 \t loss_train = 28012728.0 \t loss_valid = 25513172.0 \n",
      "Model_5_18030 \t loss_train = 28013978.0 \t loss_valid = 25503952.0 \n",
      "Model_5_18040 \t loss_train = 28021256.0 \t loss_valid = 25475764.0 \n",
      "Model_5_18050 \t loss_train = 27995380.0 \t loss_valid = 25580518.0 \n",
      "Model_5_18060 \t loss_train = 28028662.0 \t loss_valid = 25465418.0 \n",
      "Model_5_18070 \t loss_train = 28005082.0 \t loss_valid = 25537760.0 \n",
      "Model_5_18080 \t loss_train = 28025676.0 \t loss_valid = 25469134.0 \n",
      "Model_5_18090 \t loss_train = 28020204.0 \t loss_valid = 25484416.0 \n",
      "Model_5_18100 \t loss_train = 28013180.0 \t loss_valid = 25505900.0 \n",
      "Model_5_18110 \t loss_train = 28036458.0 \t loss_valid = 25448670.0 \n",
      "Model_5_18120 \t loss_train = 28011122.0 \t loss_valid = 25516724.0 \n",
      "Model_5_18130 \t loss_train = 28026568.0 \t loss_valid = 25476568.0 \n",
      "Model_5_18140 \t loss_train = 28013044.0 \t loss_valid = 25515914.0 \n",
      "Model_5_18150 \t loss_train = 28000398.0 \t loss_valid = 25562536.0 \n",
      "Model_5_18160 \t loss_train = 28034210.0 \t loss_valid = 25450410.0 \n",
      "Model_5_18170 \t loss_train = 28002166.0 \t loss_valid = 25546076.0 \n",
      "Model_5_18180 \t loss_train = 28035604.0 \t loss_valid = 25446518.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_5_18190 \t loss_train = 28020842.0 \t loss_valid = 25484420.0 \n",
      "Model_5_18200 \t loss_train = 28054680.0 \t loss_valid = 25419426.0 \n",
      "Model_5_18210 \t loss_train = 28000400.0 \t loss_valid = 25573214.0 \n",
      "Model_5_18220 \t loss_train = 28034280.0 \t loss_valid = 25467362.0 \n",
      "Model_5_18230 \t loss_train = 28000342.0 \t loss_valid = 25564308.0 \n",
      "Model_5_18240 \t loss_train = 28022658.0 \t loss_valid = 25477370.0 \n",
      "Model_5_18250 \t loss_train = 28003614.0 \t loss_valid = 25538240.0 \n",
      "Model_5_18260 \t loss_train = 28031050.0 \t loss_valid = 25457222.0 \n",
      "Model_5_18270 \t loss_train = 28018276.0 \t loss_valid = 25497318.0 \n",
      "Model_5_18280 \t loss_train = 28014096.0 \t loss_valid = 25512528.0 \n",
      "Model_5_18290 \t loss_train = 28027588.0 \t loss_valid = 25481732.0 \n",
      "Model_5_18300 \t loss_train = 28019136.0 \t loss_valid = 25496098.0 \n",
      "Model_5_18310 \t loss_train = 28013992.0 \t loss_valid = 25500158.0 \n",
      "Model_5_18320 \t loss_train = 28029414.0 \t loss_valid = 25460346.0 \n",
      "Model_5_18330 \t loss_train = 28007232.0 \t loss_valid = 25528400.0 \n",
      "Model_5_18340 \t loss_train = 28030430.0 \t loss_valid = 25467614.0 \n",
      "Model_5_18350 \t loss_train = 27993648.0 \t loss_valid = 25607956.0 \n",
      "Model_5_18360 \t loss_train = 28016896.0 \t loss_valid = 25504762.0 \n",
      "Model_5_18370 \t loss_train = 28012446.0 \t loss_valid = 25520650.0 \n",
      "Model_5_18380 \t loss_train = 27992790.0 \t loss_valid = 25616870.0 \n",
      "Model_5_18390 \t loss_train = 28011274.0 \t loss_valid = 25517380.0 \n",
      "Model_5_18400 \t loss_train = 28007408.0 \t loss_valid = 25528302.0 \n",
      "Model_5_18410 \t loss_train = 28006808.0 \t loss_valid = 25531794.0 \n",
      "Model_5_18420 \t loss_train = 28003250.0 \t loss_valid = 25543134.0 \n",
      "Model_5_18430 \t loss_train = 28035444.0 \t loss_valid = 25449378.0 \n",
      "Model_5_18440 \t loss_train = 27996554.0 \t loss_valid = 25577800.0 \n",
      "Model_5_18450 \t loss_train = 28009648.0 \t loss_valid = 25518162.0 \n",
      "Model_5_18460 \t loss_train = 28023010.0 \t loss_valid = 25475144.0 \n",
      "Model_5_18470 \t loss_train = 28011578.0 \t loss_valid = 25506322.0 \n",
      "Model_5_18480 \t loss_train = 28003372.0 \t loss_valid = 25540724.0 \n",
      "Model_5_18490 \t loss_train = 27999642.0 \t loss_valid = 25559814.0 \n",
      "Model_5_18500 \t loss_train = 27997792.0 \t loss_valid = 25571004.0 \n",
      "Model_5_18510 \t loss_train = 28006212.0 \t loss_valid = 25532526.0 \n",
      "Model_5_18520 \t loss_train = 28003538.0 \t loss_valid = 25545808.0 \n",
      "Model_5_18530 \t loss_train = 27995164.0 \t loss_valid = 25598202.0 \n",
      "Model_5_18540 \t loss_train = 28015956.0 \t loss_valid = 25503446.0 \n",
      "Model_5_18550 \t loss_train = 28001674.0 \t loss_valid = 25556240.0 \n",
      "Model_5_18560 \t loss_train = 28025832.0 \t loss_valid = 25480488.0 \n",
      "Model_5_18570 \t loss_train = 28007030.0 \t loss_valid = 25539536.0 \n",
      "Model_5_18580 \t loss_train = 27995146.0 \t loss_valid = 25590790.0 \n",
      "Model_5_18590 \t loss_train = 28031104.0 \t loss_valid = 25456524.0 \n",
      "Model_5_18600 \t loss_train = 28007170.0 \t loss_valid = 25526294.0 \n",
      "Model_5_18610 \t loss_train = 27999314.0 \t loss_valid = 25561618.0 \n",
      "Model_5_18620 \t loss_train = 28011442.0 \t loss_valid = 25517804.0 \n",
      "Model_5_18630 \t loss_train = 27999366.0 \t loss_valid = 25577522.0 \n",
      "Model_5_18640 \t loss_train = 28016196.0 \t loss_valid = 25507982.0 \n",
      "Model_5_18650 \t loss_train = 28017056.0 \t loss_valid = 25496676.0 \n",
      "Model_5_18660 \t loss_train = 27995138.0 \t loss_valid = 25587372.0 \n",
      "Model_5_18670 \t loss_train = 28040304.0 \t loss_valid = 25438136.0 \n",
      "Model_5_18680 \t loss_train = 27989188.0 \t loss_valid = 25660558.0 \n",
      "Model_5_18690 \t loss_train = 28030098.0 \t loss_valid = 25470950.0 \n",
      "Model_5_18700 \t loss_train = 27990754.0 \t loss_valid = 25645216.0 \n",
      "Model_5_18710 \t loss_train = 28042426.0 \t loss_valid = 25441450.0 \n",
      "Model_5_18720 \t loss_train = 27998408.0 \t loss_valid = 25566958.0 \n",
      "Model_5_18730 \t loss_train = 28010826.0 \t loss_valid = 25511752.0 \n",
      "Model_5_18740 \t loss_train = 27990372.0 \t loss_valid = 25632878.0 \n",
      "Model_5_18750 \t loss_train = 28027328.0 \t loss_valid = 25466194.0 \n",
      "Model_5_18760 \t loss_train = 27994706.0 \t loss_valid = 25589176.0 \n",
      "Model_5_18770 \t loss_train = 28017728.0 \t loss_valid = 25490700.0 \n",
      "Model_5_18780 \t loss_train = 28014218.0 \t loss_valid = 25503176.0 \n",
      "Model_5_18790 \t loss_train = 27999018.0 \t loss_valid = 25567510.0 \n",
      "Model_5_18800 \t loss_train = 28023666.0 \t loss_valid = 25478290.0 \n",
      "Model_5_18810 \t loss_train = 27999604.0 \t loss_valid = 25564284.0 \n",
      "Model_5_18820 \t loss_train = 28026574.0 \t loss_valid = 25472642.0 \n",
      "Model_5_18830 \t loss_train = 28005956.0 \t loss_valid = 25540872.0 \n",
      "Model_5_18840 \t loss_train = 28004092.0 \t loss_valid = 25552636.0 \n",
      "Model_5_18850 \t loss_train = 28006316.0 \t loss_valid = 25543672.0 \n",
      "Model_5_18860 \t loss_train = 27994606.0 \t loss_valid = 25603090.0 \n",
      "Model_5_18870 \t loss_train = 27998814.0 \t loss_valid = 25571862.0 \n",
      "Model_5_18880 \t loss_train = 28011482.0 \t loss_valid = 25516562.0 \n",
      "Model_5_18890 \t loss_train = 28002992.0 \t loss_valid = 25547174.0 \n",
      "Model_5_18900 \t loss_train = 28001308.0 \t loss_valid = 25555324.0 \n",
      "Model_5_18910 \t loss_train = 27993250.0 \t loss_valid = 25610820.0 \n",
      "Model_5_18920 \t loss_train = 28006320.0 \t loss_valid = 25542378.0 \n",
      "Model_5_18930 \t loss_train = 27995068.0 \t loss_valid = 25597328.0 \n",
      "Model_5_18940 \t loss_train = 27995454.0 \t loss_valid = 25584576.0 \n",
      "Model_5_18950 \t loss_train = 28006564.0 \t loss_valid = 25528496.0 \n",
      "Model_5_18960 \t loss_train = 27996202.0 \t loss_valid = 25588680.0 \n",
      "Model_5_18970 \t loss_train = 27989842.0 \t loss_valid = 25651864.0 \n",
      "Model_5_18980 \t loss_train = 28010232.0 \t loss_valid = 25519138.0 \n",
      "Model_5_18990 \t loss_train = 28002736.0 \t loss_valid = 25543322.0 \n",
      "Model_5_19000 \t loss_train = 27993768.0 \t loss_valid = 25597876.0 \n",
      "Model_5_19010 \t loss_train = 28018406.0 \t loss_valid = 25487222.0 \n",
      "Model_5_19020 \t loss_train = 27997318.0 \t loss_valid = 25565330.0 \n",
      "Model_5_19030 \t loss_train = 27997528.0 \t loss_valid = 25565188.0 \n",
      "Model_5_19040 \t loss_train = 27998330.0 \t loss_valid = 25561190.0 \n",
      "Model_5_19050 \t loss_train = 27996926.0 \t loss_valid = 25570892.0 \n",
      "Model_5_19060 \t loss_train = 27993554.0 \t loss_valid = 25598056.0 \n",
      "Model_5_19070 \t loss_train = 28005256.0 \t loss_valid = 25542940.0 \n",
      "Model_5_19080 \t loss_train = 27997284.0 \t loss_valid = 25590938.0 \n",
      "Model_5_19090 \t loss_train = 27998360.0 \t loss_valid = 25574604.0 \n",
      "Model_5_19100 \t loss_train = 28003570.0 \t loss_valid = 25542034.0 \n",
      "Model_5_19110 \t loss_train = 28010936.0 \t loss_valid = 25515510.0 \n",
      "Model_5_19120 \t loss_train = 28007036.0 \t loss_valid = 25534362.0 \n",
      "Model_5_19130 \t loss_train = 27997522.0 \t loss_valid = 25580694.0 \n",
      "Model_5_19140 \t loss_train = 27996228.0 \t loss_valid = 25586202.0 \n",
      "Model_5_19150 \t loss_train = 28003262.0 \t loss_valid = 25542480.0 \n",
      "Model_5_19160 \t loss_train = 27989546.0 \t loss_valid = 25649882.0 \n",
      "Model_5_19170 \t loss_train = 27993090.0 \t loss_valid = 25607232.0 \n",
      "Model_5_19180 \t loss_train = 27996488.0 \t loss_valid = 25577162.0 \n",
      "Model_5_19190 \t loss_train = 28015468.0 \t loss_valid = 25495706.0 \n",
      "Model_5_19200 \t loss_train = 28012036.0 \t loss_valid = 25511270.0 \n",
      "Model_5_19210 \t loss_train = 27990536.0 \t loss_valid = 25635496.0 \n",
      "Model_5_19220 \t loss_train = 28014226.0 \t loss_valid = 25503488.0 \n",
      "Model_5_19230 \t loss_train = 27992724.0 \t loss_valid = 25607172.0 \n",
      "Model_5_19240 \t loss_train = 27997686.0 \t loss_valid = 25568050.0 \n",
      "Model_5_19250 \t loss_train = 28015946.0 \t loss_valid = 25492332.0 \n",
      "Model_5_19260 \t loss_train = 28003578.0 \t loss_valid = 25534568.0 \n",
      "Model_5_19270 \t loss_train = 27993858.0 \t loss_valid = 25592850.0 \n",
      "Model_5_19280 \t loss_train = 27999908.0 \t loss_valid = 25552614.0 \n",
      "Model_5_19290 \t loss_train = 28001112.0 \t loss_valid = 25547226.0 \n",
      "Model_5_19300 \t loss_train = 27996320.0 \t loss_valid = 25582278.0 \n",
      "Model_5_19310 \t loss_train = 28004046.0 \t loss_valid = 25538294.0 \n",
      "Model_5_19320 \t loss_train = 28001508.0 \t loss_valid = 25548518.0 \n",
      "Model_5_19330 \t loss_train = 27998064.0 \t loss_valid = 25572860.0 \n",
      "Model_5_19340 \t loss_train = 27999636.0 \t loss_valid = 25564438.0 \n",
      "Model_5_19350 \t loss_train = 27999296.0 \t loss_valid = 25571248.0 \n",
      "Model_5_19360 \t loss_train = 27999470.0 \t loss_valid = 25578310.0 \n",
      "Model_5_19370 \t loss_train = 27990590.0 \t loss_valid = 25659072.0 \n",
      "Model_5_19380 \t loss_train = 28004936.0 \t loss_valid = 25534706.0 \n",
      "Model_5_19390 \t loss_train = 27996400.0 \t loss_valid = 25573510.0 \n",
      "Model_5_19400 \t loss_train = 28003520.0 \t loss_valid = 25538786.0 \n",
      "Model_5_19410 \t loss_train = 27990974.0 \t loss_valid = 25627232.0 \n",
      "Model_5_19420 \t loss_train = 27995216.0 \t loss_valid = 25584644.0 \n",
      "Model_5_19430 \t loss_train = 27995018.0 \t loss_valid = 25581264.0 \n",
      "Model_5_19440 \t loss_train = 27998390.0 \t loss_valid = 25556536.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_5_19450 \t loss_train = 28019904.0 \t loss_valid = 25475710.0 \n",
      "Model_5_19460 \t loss_train = 27991858.0 \t loss_valid = 25608844.0 \n",
      "Model_5_19470 \t loss_train = 28020614.0 \t loss_valid = 25476538.0 \n",
      "Model_5_19480 \t loss_train = 27995160.0 \t loss_valid = 25582030.0 \n",
      "Model_5_19490 \t loss_train = 28015846.0 \t loss_valid = 25492846.0 \n",
      "Model_5_19500 \t loss_train = 27993538.0 \t loss_valid = 25598324.0 \n",
      "Model_5_19510 \t loss_train = 28017148.0 \t loss_valid = 25492020.0 \n",
      "Model_5_19520 \t loss_train = 27993542.0 \t loss_valid = 25603446.0 \n",
      "Model_5_19530 \t loss_train = 28014700.0 \t loss_valid = 25507942.0 \n",
      "Model_5_19540 \t loss_train = 27992364.0 \t loss_valid = 25631374.0 \n",
      "Model_5_19550 \t loss_train = 27991352.0 \t loss_valid = 25636356.0 \n",
      "Model_5_19560 \t loss_train = 28010986.0 \t loss_valid = 25516654.0 \n",
      "Model_5_19570 \t loss_train = 27991498.0 \t loss_valid = 25627124.0 \n",
      "Model_5_19580 \t loss_train = 28013874.0 \t loss_valid = 25504188.0 \n",
      "Model_5_19590 \t loss_train = 27995630.0 \t loss_valid = 25581438.0 \n",
      "Model_5_19600 \t loss_train = 27996822.0 \t loss_valid = 25570244.0 \n",
      "Model_5_19610 \t loss_train = 28013236.0 \t loss_valid = 25501204.0 \n",
      "Model_5_19620 \t loss_train = 28003824.0 \t loss_valid = 25535556.0 \n",
      "Model_5_19630 \t loss_train = 28000822.0 \t loss_valid = 25548102.0 \n",
      "Model_5_19640 \t loss_train = 27998398.0 \t loss_valid = 25558622.0 \n",
      "Model_5_19650 \t loss_train = 27999660.0 \t loss_valid = 25553916.0 \n",
      "Model_5_19660 \t loss_train = 27991416.0 \t loss_valid = 25619968.0 \n",
      "Model_5_19670 \t loss_train = 27993586.0 \t loss_valid = 25610862.0 \n",
      "Model_5_19680 \t loss_train = 28019664.0 \t loss_valid = 25494286.0 \n",
      "Model_5_19690 \t loss_train = 27989760.0 \t loss_valid = 25669350.0 \n",
      "Model_5_19700 \t loss_train = 28001758.0 \t loss_valid = 25555814.0 \n",
      "Model_5_19710 \t loss_train = 28008096.0 \t loss_valid = 25523984.0 \n",
      "Model_5_19720 \t loss_train = 27997390.0 \t loss_valid = 25576394.0 \n",
      "Model_5_19730 \t loss_train = 27996860.0 \t loss_valid = 25578600.0 \n",
      "Model_5_19740 \t loss_train = 28016312.0 \t loss_valid = 25492104.0 \n",
      "Model_5_19750 \t loss_train = 27988980.0 \t loss_valid = 25672488.0 \n",
      "Model_5_19760 \t loss_train = 28018662.0 \t loss_valid = 25481980.0 \n",
      "Model_5_19770 \t loss_train = 27992560.0 \t loss_valid = 25602692.0 \n",
      "Model_5_19780 \t loss_train = 27994640.0 \t loss_valid = 25591558.0 \n",
      "Model_5_19790 \t loss_train = 27993138.0 \t loss_valid = 25610566.0 \n",
      "Model_5_19800 \t loss_train = 27990798.0 \t loss_valid = 25631854.0 \n",
      "Model_5_19810 \t loss_train = 27997600.0 \t loss_valid = 25569520.0 \n",
      "Model_5_19820 \t loss_train = 27996600.0 \t loss_valid = 25573358.0 \n",
      "Model_5_19830 \t loss_train = 27999912.0 \t loss_valid = 25554994.0 \n",
      "Model_5_19840 \t loss_train = 27998944.0 \t loss_valid = 25562694.0 \n",
      "Model_5_19850 \t loss_train = 27991942.0 \t loss_valid = 25615508.0 \n",
      "Model_5_19860 \t loss_train = 28034016.0 \t loss_valid = 25449698.0 \n",
      "Model_5_19870 \t loss_train = 27996112.0 \t loss_valid = 25580806.0 \n",
      "Model_5_19880 \t loss_train = 28013548.0 \t loss_valid = 25502992.0 \n",
      "Model_5_19890 \t loss_train = 28000846.0 \t loss_valid = 25548174.0 \n",
      "Model_5_19900 \t loss_train = 27993268.0 \t loss_valid = 25598354.0 \n",
      "Model_5_19910 \t loss_train = 28021744.0 \t loss_valid = 25475514.0 \n",
      "Model_5_19920 \t loss_train = 27990674.0 \t loss_valid = 25625668.0 \n",
      "Model_5_19930 \t loss_train = 27997506.0 \t loss_valid = 25565694.0 \n",
      "Model_5_19940 \t loss_train = 27994476.0 \t loss_valid = 25587512.0 \n",
      "Model_5_19950 \t loss_train = 27994500.0 \t loss_valid = 25590508.0 \n",
      "Model_5_19960 \t loss_train = 28022610.0 \t loss_valid = 25476536.0 \n",
      "Model_5_19970 \t loss_train = 27991158.0 \t loss_valid = 25622788.0 \n",
      "Model_5_19980 \t loss_train = 27997862.0 \t loss_valid = 25565190.0 \n",
      "Model_5_19990 \t loss_train = 28005460.0 \t loss_valid = 25529468.0 \n",
      "Model_5_20000 \t loss_train = 27999996.0 \t loss_valid = 25557204.0 \n",
      "Model_5_20010 \t loss_train = 27994104.0 \t loss_valid = 25598910.0 \n",
      "Model_5_20020 \t loss_train = 27998818.0 \t loss_valid = 25566980.0 \n",
      "Model_5_20030 \t loss_train = 28005350.0 \t loss_valid = 25535080.0 \n",
      "Model_5_20040 \t loss_train = 27992184.0 \t loss_valid = 25613742.0 \n",
      "Model_5_20050 \t loss_train = 28000928.0 \t loss_valid = 25549248.0 \n",
      "Model_5_20060 \t loss_train = 27990544.0 \t loss_valid = 25625606.0 \n",
      "Model_5_20070 \t loss_train = 27994742.0 \t loss_valid = 25582612.0 \n",
      "Model_5_20080 \t loss_train = 27995004.0 \t loss_valid = 25582522.0 \n",
      "Model_5_20090 \t loss_train = 28002998.0 \t loss_valid = 25541350.0 \n",
      "Model_5_20100 \t loss_train = 27997752.0 \t loss_valid = 25566176.0 \n",
      "Model_5_20110 \t loss_train = 28003238.0 \t loss_valid = 25539142.0 \n",
      "Model_5_20120 \t loss_train = 27996910.0 \t loss_valid = 25575834.0 \n",
      "Model_5_20130 \t loss_train = 28000400.0 \t loss_valid = 25553194.0 \n",
      "Model_5_20140 \t loss_train = 27989476.0 \t loss_valid = 25648296.0 \n",
      "Model_5_20150 \t loss_train = 28010072.0 \t loss_valid = 25511164.0 \n",
      "Model_5_20160 \t loss_train = 27990874.0 \t loss_valid = 25624768.0 \n",
      "Model_5_20170 \t loss_train = 28005760.0 \t loss_valid = 25529724.0 \n",
      "Model_5_20180 \t loss_train = 27993338.0 \t loss_valid = 25603438.0 \n",
      "Model_5_20190 \t loss_train = 28009222.0 \t loss_valid = 25518434.0 \n",
      "Model_5_20200 \t loss_train = 28002742.0 \t loss_valid = 25545562.0 \n",
      "Model_5_20210 \t loss_train = 27999010.0 \t loss_valid = 25564182.0 \n",
      "Model_5_20220 \t loss_train = 28018716.0 \t loss_valid = 25485624.0 \n",
      "Model_5_20230 \t loss_train = 27995916.0 \t loss_valid = 25580386.0 \n",
      "Model_5_20240 \t loss_train = 28008288.0 \t loss_valid = 25517308.0 \n",
      "Model_5_20250 \t loss_train = 27993538.0 \t loss_valid = 25595752.0 \n",
      "Model_5_20260 \t loss_train = 27994558.0 \t loss_valid = 25589538.0 \n",
      "Model_5_20270 \t loss_train = 28014468.0 \t loss_valid = 25500126.0 \n",
      "Model_5_20280 \t loss_train = 27998460.0 \t loss_valid = 25565194.0 \n",
      "Model_5_20290 \t loss_train = 28004234.0 \t loss_valid = 25535034.0 \n",
      "Model_5_20300 \t loss_train = 27995378.0 \t loss_valid = 25583758.0 \n",
      "Model_5_20310 \t loss_train = 27995366.0 \t loss_valid = 25586390.0 \n",
      "Model_5_20320 \t loss_train = 27993258.0 \t loss_valid = 25600116.0 \n",
      "Model_5_20330 \t loss_train = 28017172.0 \t loss_valid = 25491032.0 \n",
      "Model_5_20340 \t loss_train = 27997286.0 \t loss_valid = 25576180.0 \n",
      "Model_5_20350 \t loss_train = 27997198.0 \t loss_valid = 25577354.0 \n",
      "Model_5_20360 \t loss_train = 28006298.0 \t loss_valid = 25532456.0 \n",
      "Model_5_20370 \t loss_train = 27990488.0 \t loss_valid = 25639370.0 \n",
      "Model_5_20380 \t loss_train = 27994070.0 \t loss_valid = 25599934.0 \n",
      "Model_5_20390 \t loss_train = 27997846.0 \t loss_valid = 25571640.0 \n",
      "Model_5_20400 \t loss_train = 27999094.0 \t loss_valid = 25563212.0 \n",
      "Model_5_20410 \t loss_train = 27989022.0 \t loss_valid = 25702210.0 \n",
      "Model_5_20420 \t loss_train = 28014116.0 \t loss_valid = 25500362.0 \n",
      "Model_5_20430 \t loss_train = 27992140.0 \t loss_valid = 25614398.0 \n",
      "Model_5_20440 \t loss_train = 27993832.0 \t loss_valid = 25602526.0 \n",
      "Model_5_20450 \t loss_train = 28016278.0 \t loss_valid = 25496552.0 \n",
      "Model_5_20460 \t loss_train = 27989682.0 \t loss_valid = 25723502.0 \n",
      "Model_5_20470 \t loss_train = 28018644.0 \t loss_valid = 25487082.0 \n",
      "Model_5_20480 \t loss_train = 27988930.0 \t loss_valid = 25668934.0 \n",
      "Model_5_20490 \t loss_train = 28020850.0 \t loss_valid = 25479066.0 \n",
      "Model_5_20500 \t loss_train = 28008316.0 \t loss_valid = 25520034.0 \n",
      "Model_5_20510 \t loss_train = 27996464.0 \t loss_valid = 25580014.0 \n",
      "Model_5_20520 \t loss_train = 27991970.0 \t loss_valid = 25619994.0 \n",
      "Model_5_20530 \t loss_train = 28001648.0 \t loss_valid = 25551656.0 \n",
      "Model_5_20540 \t loss_train = 27995274.0 \t loss_valid = 25588392.0 \n",
      "Model_5_20550 \t loss_train = 28000400.0 \t loss_valid = 25559852.0 \n",
      "Model_5_20560 \t loss_train = 28004264.0 \t loss_valid = 25542208.0 \n",
      "Model_5_20570 \t loss_train = 27996042.0 \t loss_valid = 25585850.0 \n",
      "Model_5_20580 \t loss_train = 27994056.0 \t loss_valid = 25595420.0 \n",
      "Model_5_20590 \t loss_train = 27995778.0 \t loss_valid = 25580902.0 \n",
      "Model_5_20600 \t loss_train = 27990566.0 \t loss_valid = 25631928.0 \n",
      "Model_5_20610 \t loss_train = 28002316.0 \t loss_valid = 25544466.0 \n",
      "Model_5_20620 \t loss_train = 27995030.0 \t loss_valid = 25587318.0 \n",
      "Model_5_20630 \t loss_train = 27989506.0 \t loss_valid = 25651740.0 \n",
      "Model_5_20640 \t loss_train = 28004188.0 \t loss_valid = 25538496.0 \n",
      "Model_5_20650 \t loss_train = 27992364.0 \t loss_valid = 25610692.0 \n",
      "Model_5_20660 \t loss_train = 27997368.0 \t loss_valid = 25572180.0 \n",
      "Model_5_20670 \t loss_train = 28001196.0 \t loss_valid = 25552626.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_5_20680 \t loss_train = 27990230.0 \t loss_valid = 25640742.0 \n",
      "Model_5_20690 \t loss_train = 27994878.0 \t loss_valid = 25588144.0 \n",
      "Model_5_20700 \t loss_train = 27998986.0 \t loss_valid = 25560334.0 \n",
      "Model_5_20710 \t loss_train = 28003050.0 \t loss_valid = 25538736.0 \n",
      "Model_5_20720 \t loss_train = 27991878.0 \t loss_valid = 25609666.0 \n",
      "Model_5_20730 \t loss_train = 27993410.0 \t loss_valid = 25594890.0 \n",
      "Model_5_20740 \t loss_train = 28000712.0 \t loss_valid = 25550906.0 \n",
      "Model_5_20750 \t loss_train = 28001912.0 \t loss_valid = 25548240.0 \n",
      "Model_5_20760 \t loss_train = 27998628.0 \t loss_valid = 25567600.0 \n",
      "Model_5_20770 \t loss_train = 27993906.0 \t loss_valid = 25600172.0 \n",
      "Model_5_20780 \t loss_train = 28023290.0 \t loss_valid = 25476322.0 \n",
      "Model_5_20790 \t loss_train = 27990858.0 \t loss_valid = 25630718.0 \n",
      "Model_5_20800 \t loss_train = 28014416.0 \t loss_valid = 25502686.0 \n",
      "Model_5_20810 \t loss_train = 27992210.0 \t loss_valid = 25611880.0 \n",
      "Model_5_20820 \t loss_train = 27996050.0 \t loss_valid = 25578846.0 \n",
      "Model_5_20830 \t loss_train = 28000430.0 \t loss_valid = 25552062.0 \n",
      "Model_5_20840 \t loss_train = 27997276.0 \t loss_valid = 25569036.0 \n",
      "Model_5_20850 \t loss_train = 27993308.0 \t loss_valid = 25598206.0 \n",
      "Model_5_20860 \t loss_train = 28017010.0 \t loss_valid = 25489992.0 \n",
      "Model_5_20870 \t loss_train = 27991598.0 \t loss_valid = 25617156.0 \n",
      "Model_5_20880 \t loss_train = 27999474.0 \t loss_valid = 25558494.0 \n",
      "Model_5_20890 \t loss_train = 27992372.0 \t loss_valid = 25608286.0 \n",
      "Model_5_20900 \t loss_train = 27993580.0 \t loss_valid = 25597358.0 \n",
      "Model_5_20910 \t loss_train = 28011716.0 \t loss_valid = 25505692.0 \n",
      "Model_5_20920 \t loss_train = 27989088.0 \t loss_valid = 25659200.0 \n",
      "Model_5_20930 \t loss_train = 28007222.0 \t loss_valid = 25523804.0 \n",
      "Model_5_20940 \t loss_train = 27989662.0 \t loss_valid = 25652476.0 \n",
      "Model_5_20950 \t loss_train = 28022942.0 \t loss_valid = 25478690.0 \n",
      "Model_5_20960 \t loss_train = 27998996.0 \t loss_valid = 25566328.0 \n",
      "Model_5_20970 \t loss_train = 27994084.0 \t loss_valid = 25597302.0 \n",
      "Model_5_20980 \t loss_train = 28000620.0 \t loss_valid = 25555068.0 \n",
      "Model_5_20990 \t loss_train = 28007978.0 \t loss_valid = 25521424.0 \n",
      "Model_5_21000 \t loss_train = 27993146.0 \t loss_valid = 25601954.0 \n",
      "Model_5_21010 \t loss_train = 27989188.0 \t loss_valid = 25658236.0 \n",
      "Model_5_21020 \t loss_train = 28006250.0 \t loss_valid = 25528760.0 \n",
      "Model_5_21030 \t loss_train = 27997674.0 \t loss_valid = 25574248.0 \n",
      "Model_5_21040 \t loss_train = 28020546.0 \t loss_valid = 25484328.0 \n",
      "Model_5_21050 \t loss_train = 27989986.0 \t loss_valid = 25641080.0 \n",
      "Model_5_21060 \t loss_train = 27997288.0 \t loss_valid = 25569434.0 \n",
      "Model_5_21070 \t loss_train = 28006254.0 \t loss_valid = 25523966.0 \n",
      "Model_5_21080 \t loss_train = 27993180.0 \t loss_valid = 25600082.0 \n",
      "Model_5_21090 \t loss_train = 28011372.0 \t loss_valid = 25509398.0 \n",
      "Model_5_21100 \t loss_train = 27991204.0 \t loss_valid = 25625318.0 \n",
      "Model_5_21110 \t loss_train = 28007250.0 \t loss_valid = 25525384.0 \n",
      "Model_5_21120 \t loss_train = 27992590.0 \t loss_valid = 25609130.0 \n",
      "Model_5_21130 \t loss_train = 27998188.0 \t loss_valid = 25566830.0 \n",
      "Model_5_21140 \t loss_train = 28001220.0 \t loss_valid = 25549056.0 \n",
      "Model_5_21150 \t loss_train = 27991372.0 \t loss_valid = 25620274.0 \n",
      "Model_5_21160 \t loss_train = 28011770.0 \t loss_valid = 25507742.0 \n",
      "Model_5_21170 \t loss_train = 27993610.0 \t loss_valid = 25597896.0 \n",
      "Model_5_21180 \t loss_train = 28002468.0 \t loss_valid = 25544038.0 \n",
      "Model_5_21190 \t loss_train = 28004056.0 \t loss_valid = 25535802.0 \n",
      "Model_5_21200 \t loss_train = 28001732.0 \t loss_valid = 25549576.0 \n",
      "Model_5_21210 \t loss_train = 27999590.0 \t loss_valid = 25560612.0 \n",
      "Model_5_21220 \t loss_train = 28002242.0 \t loss_valid = 25545696.0 \n",
      "Model_5_21230 \t loss_train = 27995504.0 \t loss_valid = 25583496.0 \n",
      "Model_5_21240 \t loss_train = 27990920.0 \t loss_valid = 25626116.0 \n",
      "Model_5_21250 \t loss_train = 27995976.0 \t loss_valid = 25579986.0 \n",
      "Model_5_21260 \t loss_train = 28004294.0 \t loss_valid = 25536876.0 \n",
      "Model_5_21270 \t loss_train = 27992458.0 \t loss_valid = 25609548.0 \n",
      "Model_5_21280 \t loss_train = 28017586.0 \t loss_valid = 25489200.0 \n",
      "Model_5_21290 \t loss_train = 27989964.0 \t loss_valid = 25637816.0 \n",
      "Model_5_21300 \t loss_train = 28023748.0 \t loss_valid = 25470502.0 \n",
      "Model_5_21310 \t loss_train = 28002548.0 \t loss_valid = 25543796.0 \n",
      "Model_5_21320 \t loss_train = 27988798.0 \t loss_valid = 25677552.0 \n",
      "Model_5_21330 \t loss_train = 28001506.0 \t loss_valid = 25549418.0 \n",
      "Model_5_21340 \t loss_train = 28003142.0 \t loss_valid = 25540818.0 \n",
      "Model_5_21350 \t loss_train = 27999916.0 \t loss_valid = 25554602.0 \n",
      "Model_5_21360 \t loss_train = 28003744.0 \t loss_valid = 25533964.0 \n",
      "Model_5_21370 \t loss_train = 27989150.0 \t loss_valid = 25656058.0 \n",
      "Model_5_21380 \t loss_train = 28016360.0 \t loss_valid = 25490654.0 \n",
      "Model_5_21390 \t loss_train = 27998486.0 \t loss_valid = 25565070.0 \n",
      "Model_5_21400 \t loss_train = 28014736.0 \t loss_valid = 25497566.0 \n",
      "Model_5_21410 \t loss_train = 27994526.0 \t loss_valid = 25588388.0 \n",
      "Model_5_21420 \t loss_train = 27993570.0 \t loss_valid = 25594816.0 \n",
      "Model_5_21430 \t loss_train = 28008616.0 \t loss_valid = 25514972.0 \n",
      "Model_5_21440 \t loss_train = 27992746.0 \t loss_valid = 25601088.0 \n",
      "Model_5_21450 \t loss_train = 28009390.0 \t loss_valid = 25510796.0 \n",
      "Model_5_21460 \t loss_train = 27993382.0 \t loss_valid = 25595068.0 \n",
      "Model_5_21470 \t loss_train = 27999806.0 \t loss_valid = 25553832.0 \n",
      "Model_5_21480 \t loss_train = 27997072.0 \t loss_valid = 25570242.0 \n",
      "Model_5_21490 \t loss_train = 27993428.0 \t loss_valid = 25597448.0 \n",
      "Model_5_21500 \t loss_train = 27999552.0 \t loss_valid = 25558584.0 \n",
      "Model_5_21510 \t loss_train = 28000150.0 \t loss_valid = 25557786.0 \n",
      "Model_5_21520 \t loss_train = 27993494.0 \t loss_valid = 25602866.0 \n",
      "Model_5_21530 \t loss_train = 28000298.0 \t loss_valid = 25556392.0 \n",
      "Model_5_21540 \t loss_train = 27996974.0 \t loss_valid = 25574080.0 \n",
      "Model_5_21550 \t loss_train = 28001108.0 \t loss_valid = 25550156.0 \n",
      "Model_5_21560 \t loss_train = 28009350.0 \t loss_valid = 25516208.0 \n",
      "Model_5_21570 \t loss_train = 27995056.0 \t loss_valid = 25590138.0 \n",
      "Model_5_21580 \t loss_train = 27993318.0 \t loss_valid = 25607254.0 \n",
      "Model_5_21590 \t loss_train = 28004844.0 \t loss_valid = 25538542.0 \n",
      "Model_5_21600 \t loss_train = 27995636.0 \t loss_valid = 25586362.0 \n",
      "Model_5_21610 \t loss_train = 27990938.0 \t loss_valid = 25628384.0 \n",
      "Model_5_21620 \t loss_train = 28003554.0 \t loss_valid = 25541110.0 \n",
      "Model_5_21630 \t loss_train = 28001046.0 \t loss_valid = 25552166.0 \n",
      "Model_5_21640 \t loss_train = 27995644.0 \t loss_valid = 25580826.0 \n",
      "Model_5_21650 \t loss_train = 27992934.0 \t loss_valid = 25601982.0 \n",
      "Model_5_21660 \t loss_train = 27998276.0 \t loss_valid = 25563682.0 \n",
      "Model_5_21670 \t loss_train = 28003134.0 \t loss_valid = 25541118.0 \n",
      "Model_5_21680 \t loss_train = 27999296.0 \t loss_valid = 25561704.0 \n",
      "Model_5_21690 \t loss_train = 27997832.0 \t loss_valid = 25569738.0 \n",
      "Model_5_21700 \t loss_train = 28000614.0 \t loss_valid = 25553766.0 \n",
      "Model_5_21710 \t loss_train = 27992206.0 \t loss_valid = 25613656.0 \n",
      "Model_5_21720 \t loss_train = 28007544.0 \t loss_valid = 25526374.0 \n",
      "Model_5_21730 \t loss_train = 28005090.0 \t loss_valid = 25537564.0 \n",
      "Model_5_21740 \t loss_train = 27993590.0 \t loss_valid = 25602210.0 \n",
      "Model_5_21750 \t loss_train = 28008448.0 \t loss_valid = 25520802.0 \n",
      "Model_5_21760 \t loss_train = 28003134.0 \t loss_valid = 25541628.0 \n",
      "Model_5_21770 \t loss_train = 27990522.0 \t loss_valid = 25630186.0 \n",
      "Model_5_21780 \t loss_train = 27996636.0 \t loss_valid = 25572490.0 \n",
      "Model_5_21790 \t loss_train = 27996918.0 \t loss_valid = 25570000.0 \n",
      "Model_5_21800 \t loss_train = 27993362.0 \t loss_valid = 25597556.0 \n",
      "Model_5_21810 \t loss_train = 28015518.0 \t loss_valid = 25494774.0 \n",
      "Model_5_21820 \t loss_train = 27989190.0 \t loss_valid = 25713844.0 \n",
      "Model_5_21830 \t loss_train = 28020582.0 \t loss_valid = 25483652.0 \n",
      "Model_5_21840 \t loss_train = 27994728.0 \t loss_valid = 25591350.0 \n",
      "Model_5_21850 \t loss_train = 28005108.0 \t loss_valid = 25531314.0 \n",
      "Model_5_21860 \t loss_train = 27993740.0 \t loss_valid = 25594398.0 \n",
      "Model_5_21870 \t loss_train = 28000108.0 \t loss_valid = 25553408.0 \n",
      "Model_5_21880 \t loss_train = 27991440.0 \t loss_valid = 25617788.0 \n",
      "Model_5_21890 \t loss_train = 28008806.0 \t loss_valid = 25517306.0 \n",
      "Model_5_21900 \t loss_train = 28000922.0 \t loss_valid = 25550816.0 \n",
      "Model_5_21910 \t loss_train = 27992992.0 \t loss_valid = 25602748.0 \n",
      "Model_5_21920 \t loss_train = 27993976.0 \t loss_valid = 25593158.0 \n",
      "Model_5_21930 \t loss_train = 28000126.0 \t loss_valid = 25554082.0 \n",
      "Model_5_21940 \t loss_train = 28010838.0 \t loss_valid = 25509914.0 \n",
      "Model_5_21950 \t loss_train = 27995604.0 \t loss_valid = 25580882.0 \n",
      "Model_5_21960 \t loss_train = 28001868.0 \t loss_valid = 25544722.0 \n",
      "Model_5_21970 \t loss_train = 28003724.0 \t loss_valid = 25537314.0 \n",
      "Model_5_21980 \t loss_train = 27990174.0 \t loss_valid = 25635496.0 \n",
      "Model_5_21990 \t loss_train = 27997900.0 \t loss_valid = 25566586.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_5_22000 \t loss_train = 28005472.0 \t loss_valid = 25530760.0 \n",
      "Model_5_22010 \t loss_train = 27991252.0 \t loss_valid = 25622706.0 \n",
      "Model_5_22020 \t loss_train = 28013422.0 \t loss_valid = 25502152.0 \n",
      "Model_5_22030 \t loss_train = 27989536.0 \t loss_valid = 25651810.0 \n",
      "Model_5_22040 \t loss_train = 27995234.0 \t loss_valid = 25586586.0 \n",
      "Model_5_22050 \t loss_train = 27996166.0 \t loss_valid = 25578294.0 \n",
      "Model_5_22060 \t loss_train = 28008784.0 \t loss_valid = 25516622.0 \n",
      "Model_5_22070 \t loss_train = 28001352.0 \t loss_valid = 25548348.0 \n",
      "Model_5_22080 \t loss_train = 28000650.0 \t loss_valid = 25552442.0 \n",
      "Model_5_22090 \t loss_train = 27996430.0 \t loss_valid = 25576716.0 \n",
      "Model_5_22100 \t loss_train = 27992332.0 \t loss_valid = 25609906.0 \n",
      "Model_5_22110 \t loss_train = 27998830.0 \t loss_valid = 25561906.0 \n",
      "Model_5_22120 \t loss_train = 27997198.0 \t loss_valid = 25570248.0 \n",
      "Model_5_22130 \t loss_train = 27999198.0 \t loss_valid = 25558762.0 \n",
      "Model_5_22140 \t loss_train = 27991920.0 \t loss_valid = 25611918.0 \n",
      "Model_5_22150 \t loss_train = 28001104.0 \t loss_valid = 25548084.0 \n",
      "Model_5_22160 \t loss_train = 27997018.0 \t loss_valid = 25570366.0 \n",
      "Model_5_22170 \t loss_train = 27994056.0 \t loss_valid = 25591026.0 \n",
      "Model_5_22180 \t loss_train = 28002350.0 \t loss_valid = 25540344.0 \n",
      "Model_5_22190 \t loss_train = 27991052.0 \t loss_valid = 25621036.0 \n",
      "Model_5_22200 \t loss_train = 28001758.0 \t loss_valid = 25545724.0 \n",
      "Early stopping!\n",
      "Model_6_0 \t loss_train = 119566816.0 \t loss_valid = 104622576.0 \n",
      "Model_6_10 \t loss_train = 117469808.0 \t loss_valid = 101543952.0 \n",
      "Model_6_20 \t loss_train = 112665144.0 \t loss_valid = 94912344.0 \n",
      "Model_6_30 \t loss_train = 101030960.0 \t loss_valid = 79878824.0 \n",
      "Model_6_40 \t loss_train = 77959360.0 \t loss_valid = 56903884.0 \n",
      "Model_6_50 \t loss_train = 70121304.0 \t loss_valid = 74812608.0 \n",
      "Model_6_60 \t loss_train = 66014860.0 \t loss_valid = 57325156.0 \n",
      "Model_6_70 \t loss_train = 63642644.0 \t loss_valid = 52504848.0 \n",
      "Model_6_80 \t loss_train = 60143440.0 \t loss_valid = 51630476.0 \n",
      "Model_6_90 \t loss_train = 57946632.0 \t loss_valid = 47431256.0 \n",
      "Model_6_100 \t loss_train = 56288924.0 \t loss_valid = 44194432.0 \n",
      "Model_6_110 \t loss_train = 54929848.0 \t loss_valid = 42319148.0 \n",
      "Model_6_120 \t loss_train = 54471252.0 \t loss_valid = 40798744.0 \n",
      "Model_6_130 \t loss_train = 53344028.0 \t loss_valid = 40344012.0 \n",
      "Model_6_140 \t loss_train = 53040124.0 \t loss_valid = 39617780.0 \n",
      "Model_6_150 \t loss_train = 52579108.0 \t loss_valid = 39387800.0 \n",
      "Model_6_160 \t loss_train = 52083504.0 \t loss_valid = 39069568.0 \n",
      "Model_6_170 \t loss_train = 51803480.0 \t loss_valid = 38723544.0 \n",
      "Model_6_180 \t loss_train = 51461836.0 \t loss_valid = 38558060.0 \n",
      "Model_6_190 \t loss_train = 50916452.0 \t loss_valid = 38658208.0 \n",
      "Model_6_200 \t loss_train = 50725304.0 \t loss_valid = 38417884.0 \n",
      "Model_6_210 \t loss_train = 50223892.0 \t loss_valid = 38414028.0 \n",
      "Model_6_220 \t loss_train = 49749372.0 \t loss_valid = 38175188.0 \n",
      "Model_6_230 \t loss_train = 49794532.0 \t loss_valid = 37835916.0 \n",
      "Model_6_240 \t loss_train = 48789152.0 \t loss_valid = 37550420.0 \n",
      "Model_6_250 \t loss_train = 48244304.0 \t loss_valid = 37254668.0 \n",
      "Model_6_260 \t loss_train = 47569588.0 \t loss_valid = 37405692.0 \n",
      "Model_6_270 \t loss_train = 47021284.0 \t loss_valid = 36657796.0 \n",
      "Model_6_280 \t loss_train = 46195000.0 \t loss_valid = 37225320.0 \n",
      "Model_6_290 \t loss_train = 45391120.0 \t loss_valid = 35938220.0 \n",
      "Model_6_300 \t loss_train = 44408952.0 \t loss_valid = 35585080.0 \n",
      "Model_6_310 \t loss_train = 43201840.0 \t loss_valid = 35291072.0 \n",
      "Model_6_320 \t loss_train = 42096080.0 \t loss_valid = 35171852.0 \n",
      "Model_6_330 \t loss_train = 41066600.0 \t loss_valid = 34208760.0 \n",
      "Model_6_340 \t loss_train = 39612524.0 \t loss_valid = 33649444.0 \n",
      "Model_6_350 \t loss_train = 38638800.0 \t loss_valid = 32946858.0 \n",
      "Model_6_360 \t loss_train = 36407200.0 \t loss_valid = 32269038.0 \n",
      "Model_6_370 \t loss_train = 34759128.0 \t loss_valid = 31077212.0 \n",
      "Model_6_380 \t loss_train = 33145922.0 \t loss_valid = 31453248.0 \n",
      "Model_6_390 \t loss_train = 32152800.0 \t loss_valid = 29779716.0 \n",
      "Model_6_400 \t loss_train = 30764640.0 \t loss_valid = 29186384.0 \n",
      "Model_6_410 \t loss_train = 30179888.0 \t loss_valid = 28426146.0 \n",
      "Model_6_420 \t loss_train = 29555880.0 \t loss_valid = 27966932.0 \n",
      "Model_6_430 \t loss_train = 29106724.0 \t loss_valid = 28208634.0 \n",
      "Model_6_440 \t loss_train = 29234616.0 \t loss_valid = 27010238.0 \n",
      "Model_6_450 \t loss_train = 28734564.0 \t loss_valid = 28119984.0 \n",
      "Model_6_460 \t loss_train = 28717536.0 \t loss_valid = 27027374.0 \n",
      "Model_6_470 \t loss_train = 28743498.0 \t loss_valid = 26469824.0 \n",
      "Model_6_480 \t loss_train = 28506960.0 \t loss_valid = 26976828.0 \n",
      "Model_6_490 \t loss_train = 28435676.0 \t loss_valid = 26422522.0 \n",
      "Model_6_500 \t loss_train = 28338176.0 \t loss_valid = 26554418.0 \n",
      "Model_6_510 \t loss_train = 28567338.0 \t loss_valid = 26163272.0 \n",
      "Model_6_520 \t loss_train = 28277650.0 \t loss_valid = 26798168.0 \n",
      "Model_6_530 \t loss_train = 28533246.0 \t loss_valid = 25892892.0 \n",
      "Model_6_540 \t loss_train = 28231768.0 \t loss_valid = 26314288.0 \n",
      "Model_6_550 \t loss_train = 28250502.0 \t loss_valid = 26221030.0 \n",
      "Model_6_560 \t loss_train = 28496468.0 \t loss_valid = 25875402.0 \n",
      "Model_6_570 \t loss_train = 28186652.0 \t loss_valid = 25968264.0 \n",
      "Model_6_580 \t loss_train = 28341046.0 \t loss_valid = 25962362.0 \n",
      "Model_6_590 \t loss_train = 28372478.0 \t loss_valid = 25701704.0 \n",
      "Model_6_600 \t loss_train = 28314540.0 \t loss_valid = 25963602.0 \n",
      "Model_6_610 \t loss_train = 28242476.0 \t loss_valid = 25763460.0 \n",
      "Model_6_620 \t loss_train = 28191628.0 \t loss_valid = 26508850.0 \n",
      "Model_6_630 \t loss_train = 28154288.0 \t loss_valid = 25901438.0 \n",
      "Model_6_640 \t loss_train = 28648076.0 \t loss_valid = 25653820.0 \n",
      "Model_6_650 \t loss_train = 28202840.0 \t loss_valid = 26490362.0 \n",
      "Model_6_660 \t loss_train = 28756708.0 \t loss_valid = 25682608.0 \n",
      "Model_6_670 \t loss_train = 28239794.0 \t loss_valid = 25890736.0 \n",
      "Model_6_680 \t loss_train = 28240524.0 \t loss_valid = 25726392.0 \n",
      "Model_6_690 \t loss_train = 28307550.0 \t loss_valid = 25614980.0 \n",
      "Model_6_700 \t loss_train = 28319954.0 \t loss_valid = 25602676.0 \n",
      "Model_6_710 \t loss_train = 28122806.0 \t loss_valid = 26108142.0 \n",
      "Model_6_720 \t loss_train = 28580998.0 \t loss_valid = 25558376.0 \n",
      "Model_6_730 \t loss_train = 28255866.0 \t loss_valid = 25570600.0 \n",
      "Model_6_740 \t loss_train = 28300434.0 \t loss_valid = 25584060.0 \n",
      "Model_6_750 \t loss_train = 28169226.0 \t loss_valid = 25832970.0 \n",
      "Model_6_760 \t loss_train = 28483686.0 \t loss_valid = 25495426.0 \n",
      "Model_6_770 \t loss_train = 28110092.0 \t loss_valid = 26111550.0 \n",
      "Model_6_780 \t loss_train = 28684278.0 \t loss_valid = 25559166.0 \n",
      "Model_6_790 \t loss_train = 28138376.0 \t loss_valid = 25772460.0 \n",
      "Model_6_800 \t loss_train = 28434706.0 \t loss_valid = 25524828.0 \n",
      "Model_6_810 \t loss_train = 28152450.0 \t loss_valid = 25704242.0 \n",
      "Model_6_820 \t loss_train = 28187704.0 \t loss_valid = 25637896.0 \n",
      "Model_6_830 \t loss_train = 28101248.0 \t loss_valid = 25709688.0 \n",
      "Model_6_840 \t loss_train = 28470842.0 \t loss_valid = 25519222.0 \n",
      "Model_6_850 \t loss_train = 28437598.0 \t loss_valid = 25491678.0 \n",
      "Model_6_860 \t loss_train = 28121694.0 \t loss_valid = 25786512.0 \n",
      "Model_6_870 \t loss_train = 28241580.0 \t loss_valid = 25472062.0 \n",
      "Model_6_880 \t loss_train = 28217722.0 \t loss_valid = 25518738.0 \n",
      "Model_6_890 \t loss_train = 28165062.0 \t loss_valid = 25507176.0 \n",
      "Model_6_900 \t loss_train = 28388436.0 \t loss_valid = 25498356.0 \n",
      "Model_6_910 \t loss_train = 28092150.0 \t loss_valid = 25745186.0 \n",
      "Model_6_920 \t loss_train = 28270462.0 \t loss_valid = 25515776.0 \n",
      "Model_6_930 \t loss_train = 28199698.0 \t loss_valid = 25489608.0 \n",
      "Model_6_940 \t loss_train = 28143812.0 \t loss_valid = 25588514.0 \n",
      "Model_6_950 \t loss_train = 28773186.0 \t loss_valid = 25625846.0 \n",
      "Model_6_960 \t loss_train = 28300468.0 \t loss_valid = 25465246.0 \n",
      "Model_6_970 \t loss_train = 28139564.0 \t loss_valid = 25730456.0 \n",
      "Model_6_980 \t loss_train = 28705366.0 \t loss_valid = 25555368.0 \n",
      "Model_6_990 \t loss_train = 28083898.0 \t loss_valid = 26014604.0 \n",
      "Model_6_1000 \t loss_train = 28736974.0 \t loss_valid = 25482310.0 \n",
      "Model_6_1010 \t loss_train = 28120688.0 \t loss_valid = 25598398.0 \n",
      "Model_6_1020 \t loss_train = 28092984.0 \t loss_valid = 26274696.0 \n",
      "Model_6_1030 \t loss_train = 28336864.0 \t loss_valid = 25445974.0 \n",
      "Model_6_1040 \t loss_train = 28321826.0 \t loss_valid = 25439384.0 \n",
      "Model_6_1050 \t loss_train = 28187052.0 \t loss_valid = 25565132.0 \n",
      "Model_6_1060 \t loss_train = 28069504.0 \t loss_valid = 25709776.0 \n",
      "Model_6_1070 \t loss_train = 28097264.0 \t loss_valid = 25734414.0 \n",
      "Model_6_1080 \t loss_train = 28192664.0 \t loss_valid = 25587354.0 \n",
      "Model_6_1090 \t loss_train = 28244944.0 \t loss_valid = 25428958.0 \n",
      "Model_6_1100 \t loss_train = 28169968.0 \t loss_valid = 25530592.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_6_1110 \t loss_train = 28072502.0 \t loss_valid = 25789146.0 \n",
      "Model_6_1120 \t loss_train = 28680256.0 \t loss_valid = 25489066.0 \n",
      "Model_6_1130 \t loss_train = 28091538.0 \t loss_valid = 25606610.0 \n",
      "Model_6_1140 \t loss_train = 28102166.0 \t loss_valid = 25566812.0 \n",
      "Model_6_1150 \t loss_train = 28325844.0 \t loss_valid = 25406226.0 \n",
      "Model_6_1160 \t loss_train = 28245978.0 \t loss_valid = 25405810.0 \n",
      "Model_6_1170 \t loss_train = 28121824.0 \t loss_valid = 25553946.0 \n",
      "Model_6_1180 \t loss_train = 28394778.0 \t loss_valid = 25400004.0 \n",
      "Model_6_1190 \t loss_train = 28170598.0 \t loss_valid = 25471024.0 \n",
      "Model_6_1200 \t loss_train = 28097084.0 \t loss_valid = 25588290.0 \n",
      "Model_6_1210 \t loss_train = 28053598.0 \t loss_valid = 25835918.0 \n",
      "Model_6_1220 \t loss_train = 28095896.0 \t loss_valid = 25823024.0 \n",
      "Model_6_1230 \t loss_train = 28343880.0 \t loss_valid = 25402968.0 \n",
      "Model_6_1240 \t loss_train = 28191970.0 \t loss_valid = 25460900.0 \n",
      "Model_6_1250 \t loss_train = 28080046.0 \t loss_valid = 25579176.0 \n",
      "Model_6_1260 \t loss_train = 28176978.0 \t loss_valid = 25449040.0 \n",
      "Model_6_1270 \t loss_train = 28308198.0 \t loss_valid = 25414110.0 \n",
      "Model_6_1280 \t loss_train = 28053604.0 \t loss_valid = 25789162.0 \n",
      "Model_6_1290 \t loss_train = 28274938.0 \t loss_valid = 25383654.0 \n",
      "Model_6_1300 \t loss_train = 28342604.0 \t loss_valid = 25357572.0 \n",
      "Model_6_1310 \t loss_train = 28188220.0 \t loss_valid = 25406288.0 \n",
      "Model_6_1320 \t loss_train = 28185128.0 \t loss_valid = 25448094.0 \n",
      "Model_6_1330 \t loss_train = 28191976.0 \t loss_valid = 25389390.0 \n",
      "Model_6_1340 \t loss_train = 28263452.0 \t loss_valid = 25433960.0 \n",
      "Model_6_1350 \t loss_train = 28680378.0 \t loss_valid = 25535650.0 \n",
      "Model_6_1360 \t loss_train = 28085764.0 \t loss_valid = 25550346.0 \n",
      "Model_6_1370 \t loss_train = 28058750.0 \t loss_valid = 25650672.0 \n",
      "Model_6_1380 \t loss_train = 28203594.0 \t loss_valid = 25424362.0 \n",
      "Model_6_1390 \t loss_train = 28079448.0 \t loss_valid = 25709974.0 \n",
      "Model_6_1400 \t loss_train = 28484492.0 \t loss_valid = 25417102.0 \n",
      "Model_6_1410 \t loss_train = 28213838.0 \t loss_valid = 26779034.0 \n",
      "Model_6_1420 \t loss_train = 28063634.0 \t loss_valid = 25580642.0 \n",
      "Model_6_1430 \t loss_train = 28447920.0 \t loss_valid = 25383156.0 \n",
      "Model_6_1440 \t loss_train = 28227296.0 \t loss_valid = 25384248.0 \n",
      "Model_6_1450 \t loss_train = 28186112.0 \t loss_valid = 25449348.0 \n",
      "Model_6_1460 \t loss_train = 28386432.0 \t loss_valid = 25405210.0 \n",
      "Model_6_1470 \t loss_train = 28253620.0 \t loss_valid = 25386308.0 \n",
      "Model_6_1480 \t loss_train = 28082248.0 \t loss_valid = 25491716.0 \n",
      "Model_6_1490 \t loss_train = 28229154.0 \t loss_valid = 25429808.0 \n",
      "Model_6_1500 \t loss_train = 28362156.0 \t loss_valid = 25384934.0 \n",
      "Model_6_1510 \t loss_train = 28165148.0 \t loss_valid = 25450326.0 \n",
      "Model_6_1520 \t loss_train = 28428760.0 \t loss_valid = 25369832.0 \n",
      "Model_6_1530 \t loss_train = 28470226.0 \t loss_valid = 25353314.0 \n",
      "Model_6_1540 \t loss_train = 28154772.0 \t loss_valid = 25452726.0 \n",
      "Model_6_1550 \t loss_train = 29244220.0 \t loss_valid = 25961528.0 \n",
      "Model_6_1560 \t loss_train = 28183544.0 \t loss_valid = 25385430.0 \n",
      "Model_6_1570 \t loss_train = 28079046.0 \t loss_valid = 25736680.0 \n",
      "Model_6_1580 \t loss_train = 28408902.0 \t loss_valid = 25374868.0 \n",
      "Model_6_1590 \t loss_train = 28130810.0 \t loss_valid = 25457390.0 \n",
      "Model_6_1600 \t loss_train = 28177710.0 \t loss_valid = 25418834.0 \n",
      "Model_6_1610 \t loss_train = 28640276.0 \t loss_valid = 25408734.0 \n",
      "Model_6_1620 \t loss_train = 28487594.0 \t loss_valid = 25362302.0 \n",
      "Model_6_1630 \t loss_train = 28065844.0 \t loss_valid = 25605720.0 \n",
      "Model_6_1640 \t loss_train = 28146542.0 \t loss_valid = 25527162.0 \n",
      "Model_6_1650 \t loss_train = 28174634.0 \t loss_valid = 25391202.0 \n",
      "Model_6_1660 \t loss_train = 28064342.0 \t loss_valid = 25676698.0 \n",
      "Model_6_1670 \t loss_train = 28390554.0 \t loss_valid = 25358852.0 \n",
      "Model_6_1680 \t loss_train = 28424420.0 \t loss_valid = 25363796.0 \n",
      "Model_6_1690 \t loss_train = 28148286.0 \t loss_valid = 25477004.0 \n",
      "Model_6_1700 \t loss_train = 28618844.0 \t loss_valid = 25379218.0 \n",
      "Model_6_1710 \t loss_train = 28212012.0 \t loss_valid = 25362798.0 \n",
      "Model_6_1720 \t loss_train = 28054618.0 \t loss_valid = 25647140.0 \n",
      "Model_6_1730 \t loss_train = 28147240.0 \t loss_valid = 25544248.0 \n",
      "Model_6_1740 \t loss_train = 28251520.0 \t loss_valid = 25374600.0 \n",
      "Model_6_1750 \t loss_train = 28166636.0 \t loss_valid = 25435720.0 \n",
      "Model_6_1760 \t loss_train = 28108410.0 \t loss_valid = 25455490.0 \n",
      "Model_6_1770 \t loss_train = 28102902.0 \t loss_valid = 25725124.0 \n",
      "Model_6_1780 \t loss_train = 28046310.0 \t loss_valid = 25692856.0 \n",
      "Model_6_1790 \t loss_train = 29012940.0 \t loss_valid = 25693162.0 \n",
      "Model_6_1800 \t loss_train = 28920158.0 \t loss_valid = 25615568.0 \n",
      "Model_6_1810 \t loss_train = 28126296.0 \t loss_valid = 25524890.0 \n",
      "Model_6_1820 \t loss_train = 28087584.0 \t loss_valid = 25464566.0 \n",
      "Model_6_1830 \t loss_train = 28288186.0 \t loss_valid = 25359192.0 \n",
      "Model_6_1840 \t loss_train = 28180494.0 \t loss_valid = 25415442.0 \n",
      "Model_6_1850 \t loss_train = 28227726.0 \t loss_valid = 25377596.0 \n",
      "Model_6_1860 \t loss_train = 28491216.0 \t loss_valid = 25354164.0 \n",
      "Model_6_1870 \t loss_train = 28823668.0 \t loss_valid = 25484906.0 \n",
      "Model_6_1880 \t loss_train = 28734728.0 \t loss_valid = 25458516.0 \n",
      "Model_6_1890 \t loss_train = 28050818.0 \t loss_valid = 25587904.0 \n",
      "Model_6_1900 \t loss_train = 28260002.0 \t loss_valid = 25346820.0 \n",
      "Model_6_1910 \t loss_train = 28670244.0 \t loss_valid = 25428186.0 \n",
      "Model_6_1920 \t loss_train = 28396804.0 \t loss_valid = 25366092.0 \n",
      "Model_6_1930 \t loss_train = 28226068.0 \t loss_valid = 25362474.0 \n",
      "Model_6_1940 \t loss_train = 28253782.0 \t loss_valid = 25357972.0 \n",
      "Model_6_1950 \t loss_train = 28096972.0 \t loss_valid = 25470852.0 \n",
      "Model_6_1960 \t loss_train = 28243618.0 \t loss_valid = 25380176.0 \n",
      "Model_6_1970 \t loss_train = 28365716.0 \t loss_valid = 25347204.0 \n",
      "Model_6_1980 \t loss_train = 28693488.0 \t loss_valid = 25408448.0 \n",
      "Model_6_1990 \t loss_train = 28238812.0 \t loss_valid = 25357436.0 \n",
      "Model_6_2000 \t loss_train = 28192152.0 \t loss_valid = 25594496.0 \n",
      "Model_6_2010 \t loss_train = 28555918.0 \t loss_valid = 25481076.0 \n",
      "Model_6_2020 \t loss_train = 28192564.0 \t loss_valid = 25608734.0 \n",
      "Model_6_2030 \t loss_train = 28395326.0 \t loss_valid = 25347350.0 \n",
      "Model_6_2040 \t loss_train = 28335502.0 \t loss_valid = 25329192.0 \n",
      "Model_6_2050 \t loss_train = 28138206.0 \t loss_valid = 25445024.0 \n",
      "Model_6_2060 \t loss_train = 28378162.0 \t loss_valid = 25331632.0 \n",
      "Model_6_2070 \t loss_train = 28252068.0 \t loss_valid = 25365362.0 \n",
      "Model_6_2080 \t loss_train = 28314702.0 \t loss_valid = 25359874.0 \n",
      "Model_6_2090 \t loss_train = 28755090.0 \t loss_valid = 25511986.0 \n",
      "Model_6_2100 \t loss_train = 28178630.0 \t loss_valid = 25520356.0 \n",
      "Model_6_2110 \t loss_train = 28201986.0 \t loss_valid = 25357452.0 \n",
      "Model_6_2120 \t loss_train = 28532398.0 \t loss_valid = 25337548.0 \n",
      "Model_6_2130 \t loss_train = 28471416.0 \t loss_valid = 25356144.0 \n",
      "Model_6_2140 \t loss_train = 28478612.0 \t loss_valid = 25322360.0 \n",
      "Model_6_2150 \t loss_train = 28236448.0 \t loss_valid = 25347800.0 \n",
      "Model_6_2160 \t loss_train = 28401214.0 \t loss_valid = 25319940.0 \n",
      "Model_6_2170 \t loss_train = 28387940.0 \t loss_valid = 25368282.0 \n",
      "Model_6_2180 \t loss_train = 28400210.0 \t loss_valid = 25353412.0 \n",
      "Model_6_2190 \t loss_train = 28533734.0 \t loss_valid = 25342640.0 \n",
      "Model_6_2200 \t loss_train = 28231738.0 \t loss_valid = 25332968.0 \n",
      "Model_6_2210 \t loss_train = 28191730.0 \t loss_valid = 25372740.0 \n",
      "Model_6_2220 \t loss_train = 28280824.0 \t loss_valid = 25311030.0 \n",
      "Model_6_2230 \t loss_train = 28178186.0 \t loss_valid = 25344546.0 \n",
      "Model_6_2240 \t loss_train = 28395496.0 \t loss_valid = 25312210.0 \n",
      "Model_6_2250 \t loss_train = 28445888.0 \t loss_valid = 25311024.0 \n",
      "Model_6_2260 \t loss_train = 28250222.0 \t loss_valid = 25370532.0 \n",
      "Model_6_2270 \t loss_train = 28080586.0 \t loss_valid = 25611098.0 \n",
      "Model_6_2280 \t loss_train = 28072886.0 \t loss_valid = 25644576.0 \n",
      "Model_6_2290 \t loss_train = 28480470.0 \t loss_valid = 25332288.0 \n",
      "Model_6_2300 \t loss_train = 28309318.0 \t loss_valid = 25354006.0 \n",
      "Model_6_2310 \t loss_train = 28070018.0 \t loss_valid = 25524810.0 \n",
      "Model_6_2320 \t loss_train = 28272488.0 \t loss_valid = 25319500.0 \n",
      "Model_6_2330 \t loss_train = 28830542.0 \t loss_valid = 25526016.0 \n",
      "Model_6_2340 \t loss_train = 28635690.0 \t loss_valid = 25402264.0 \n",
      "Model_6_2350 \t loss_train = 28263258.0 \t loss_valid = 25331438.0 \n",
      "Model_6_2360 \t loss_train = 28381144.0 \t loss_valid = 25325764.0 \n",
      "Model_6_2370 \t loss_train = 28473152.0 \t loss_valid = 25331500.0 \n",
      "Model_6_2380 \t loss_train = 28375806.0 \t loss_valid = 25344312.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_6_2390 \t loss_train = 28577968.0 \t loss_valid = 25448240.0 \n",
      "Model_6_2400 \t loss_train = 29010112.0 \t loss_valid = 25582708.0 \n",
      "Model_6_2410 \t loss_train = 28532984.0 \t loss_valid = 25339456.0 \n",
      "Model_6_2420 \t loss_train = 28428984.0 \t loss_valid = 25310514.0 \n",
      "Model_6_2430 \t loss_train = 28325122.0 \t loss_valid = 25309820.0 \n",
      "Model_6_2440 \t loss_train = 28142528.0 \t loss_valid = 25430476.0 \n",
      "Model_6_2450 \t loss_train = 28608506.0 \t loss_valid = 25397432.0 \n",
      "Model_6_2460 \t loss_train = 29097452.0 \t loss_valid = 25542400.0 \n",
      "Model_6_2470 \t loss_train = 28375690.0 \t loss_valid = 25327890.0 \n",
      "Model_6_2480 \t loss_train = 28365128.0 \t loss_valid = 25318662.0 \n",
      "Model_6_2490 \t loss_train = 28494890.0 \t loss_valid = 25317114.0 \n",
      "Model_6_2500 \t loss_train = 28419354.0 \t loss_valid = 25321942.0 \n",
      "Model_6_2510 \t loss_train = 28437274.0 \t loss_valid = 25291254.0 \n",
      "Model_6_2520 \t loss_train = 28264434.0 \t loss_valid = 25318554.0 \n",
      "Model_6_2530 \t loss_train = 28526284.0 \t loss_valid = 25321520.0 \n",
      "Model_6_2540 \t loss_train = 28560164.0 \t loss_valid = 25359212.0 \n",
      "Model_6_2550 \t loss_train = 28855746.0 \t loss_valid = 25515290.0 \n",
      "Model_6_2560 \t loss_train = 29515384.0 \t loss_valid = 25908386.0 \n",
      "Model_6_2570 \t loss_train = 28915162.0 \t loss_valid = 25483138.0 \n",
      "Model_6_2580 \t loss_train = 28359590.0 \t loss_valid = 25317310.0 \n",
      "Model_6_2590 \t loss_train = 28196444.0 \t loss_valid = 25344816.0 \n",
      "Model_6_2600 \t loss_train = 28164210.0 \t loss_valid = 25535906.0 \n",
      "Model_6_2610 \t loss_train = 28229638.0 \t loss_valid = 25329100.0 \n",
      "Model_6_2620 \t loss_train = 28278624.0 \t loss_valid = 25308924.0 \n",
      "Model_6_2630 \t loss_train = 28467740.0 \t loss_valid = 25306260.0 \n",
      "Model_6_2640 \t loss_train = 28907014.0 \t loss_valid = 25562926.0 \n",
      "Model_6_2650 \t loss_train = 29195526.0 \t loss_valid = 25604710.0 \n",
      "Model_6_2660 \t loss_train = 28730224.0 \t loss_valid = 25387838.0 \n",
      "Model_6_2670 \t loss_train = 28575086.0 \t loss_valid = 25404118.0 \n",
      "Model_6_2680 \t loss_train = 29036432.0 \t loss_valid = 25591706.0 \n",
      "Model_6_2690 \t loss_train = 28919712.0 \t loss_valid = 25577104.0 \n",
      "Model_6_2700 \t loss_train = 28774716.0 \t loss_valid = 25364808.0 \n",
      "Model_6_2710 \t loss_train = 28362126.0 \t loss_valid = 25321634.0 \n",
      "Model_6_2720 \t loss_train = 28200882.0 \t loss_valid = 25337042.0 \n",
      "Model_6_2730 \t loss_train = 28167418.0 \t loss_valid = 25360098.0 \n",
      "Model_6_2740 \t loss_train = 28475714.0 \t loss_valid = 25307584.0 \n",
      "Model_6_2750 \t loss_train = 28669280.0 \t loss_valid = 25462010.0 \n",
      "Model_6_2760 \t loss_train = 28788998.0 \t loss_valid = 25385740.0 \n",
      "Model_6_2770 \t loss_train = 28739486.0 \t loss_valid = 25404178.0 \n",
      "Model_6_2780 \t loss_train = 28526218.0 \t loss_valid = 25369392.0 \n",
      "Model_6_2790 \t loss_train = 28913594.0 \t loss_valid = 25495890.0 \n",
      "Model_6_2800 \t loss_train = 28664508.0 \t loss_valid = 25381846.0 \n",
      "Model_6_2810 \t loss_train = 28307986.0 \t loss_valid = 25326114.0 \n",
      "Model_6_2820 \t loss_train = 28397014.0 \t loss_valid = 25388414.0 \n",
      "Model_6_2830 \t loss_train = 28282062.0 \t loss_valid = 25314164.0 \n",
      "Model_6_2840 \t loss_train = 28348138.0 \t loss_valid = 25308698.0 \n",
      "Model_6_2850 \t loss_train = 28418742.0 \t loss_valid = 25302142.0 \n",
      "Model_6_2860 \t loss_train = 28425830.0 \t loss_valid = 25302302.0 \n",
      "Model_6_2870 \t loss_train = 28781978.0 \t loss_valid = 25412526.0 \n",
      "Model_6_2880 \t loss_train = 28994340.0 \t loss_valid = 25619786.0 \n",
      "Model_6_2890 \t loss_train = 28496816.0 \t loss_valid = 25314146.0 \n",
      "Model_6_2900 \t loss_train = 28767366.0 \t loss_valid = 25406340.0 \n",
      "Model_6_2910 \t loss_train = 28723750.0 \t loss_valid = 25451848.0 \n",
      "Model_6_2920 \t loss_train = 28583068.0 \t loss_valid = 25315324.0 \n",
      "Model_6_2930 \t loss_train = 28413966.0 \t loss_valid = 25328944.0 \n",
      "Model_6_2940 \t loss_train = 28291054.0 \t loss_valid = 25310144.0 \n",
      "Model_6_2950 \t loss_train = 28658420.0 \t loss_valid = 25362056.0 \n",
      "Model_6_2960 \t loss_train = 28442984.0 \t loss_valid = 25336544.0 \n",
      "Model_6_2970 \t loss_train = 28505064.0 \t loss_valid = 25295800.0 \n",
      "Model_6_2980 \t loss_train = 28330048.0 \t loss_valid = 25322406.0 \n",
      "Model_6_2990 \t loss_train = 28312576.0 \t loss_valid = 25377590.0 \n",
      "Model_6_3000 \t loss_train = 28217254.0 \t loss_valid = 25334418.0 \n",
      "Model_6_3010 \t loss_train = 28382738.0 \t loss_valid = 25309358.0 \n",
      "Model_6_3020 \t loss_train = 28678592.0 \t loss_valid = 25363522.0 \n",
      "Model_6_3030 \t loss_train = 28722362.0 \t loss_valid = 25434684.0 \n",
      "Model_6_3040 \t loss_train = 28812738.0 \t loss_valid = 25403512.0 \n",
      "Model_6_3050 \t loss_train = 28801296.0 \t loss_valid = 25448698.0 \n",
      "Model_6_3060 \t loss_train = 28978744.0 \t loss_valid = 25472674.0 \n",
      "Model_6_3070 \t loss_train = 28704840.0 \t loss_valid = 25402046.0 \n",
      "Model_6_3080 \t loss_train = 28598718.0 \t loss_valid = 25348120.0 \n",
      "Model_6_3090 \t loss_train = 28323836.0 \t loss_valid = 25334658.0 \n",
      "Model_6_3100 \t loss_train = 28436374.0 \t loss_valid = 25325752.0 \n",
      "Model_6_3110 \t loss_train = 28760934.0 \t loss_valid = 25458352.0 \n",
      "Model_6_3120 \t loss_train = 28687280.0 \t loss_valid = 25446254.0 \n",
      "Model_6_3130 \t loss_train = 28785308.0 \t loss_valid = 25416558.0 \n",
      "Model_6_3140 \t loss_train = 28739370.0 \t loss_valid = 25381462.0 \n",
      "Model_6_3150 \t loss_train = 28611094.0 \t loss_valid = 25382328.0 \n",
      "Model_6_3160 \t loss_train = 28778650.0 \t loss_valid = 25381834.0 \n",
      "Model_6_3170 \t loss_train = 28477680.0 \t loss_valid = 25307472.0 \n",
      "Model_6_3180 \t loss_train = 28772778.0 \t loss_valid = 25399310.0 \n",
      "Model_6_3190 \t loss_train = 28659250.0 \t loss_valid = 25368344.0 \n",
      "Model_6_3200 \t loss_train = 28554298.0 \t loss_valid = 25343650.0 \n",
      "Model_6_3210 \t loss_train = 28556538.0 \t loss_valid = 25327850.0 \n",
      "Model_6_3220 \t loss_train = 28588384.0 \t loss_valid = 25355902.0 \n",
      "Model_6_3230 \t loss_train = 28649502.0 \t loss_valid = 25372578.0 \n",
      "Model_6_3240 \t loss_train = 28657708.0 \t loss_valid = 25388788.0 \n",
      "Model_6_3250 \t loss_train = 28465370.0 \t loss_valid = 25318476.0 \n",
      "Model_6_3260 \t loss_train = 28479270.0 \t loss_valid = 25309564.0 \n",
      "Model_6_3270 \t loss_train = 28539080.0 \t loss_valid = 25325274.0 \n",
      "Model_6_3280 \t loss_train = 28539684.0 \t loss_valid = 25307108.0 \n",
      "Model_6_3290 \t loss_train = 28587258.0 \t loss_valid = 25333462.0 \n",
      "Model_6_3300 \t loss_train = 28803260.0 \t loss_valid = 25468842.0 \n",
      "Model_6_3310 \t loss_train = 28567642.0 \t loss_valid = 25317954.0 \n",
      "Model_6_3320 \t loss_train = 28282390.0 \t loss_valid = 25299992.0 \n",
      "Model_6_3330 \t loss_train = 28549244.0 \t loss_valid = 25314634.0 \n",
      "Model_6_3340 \t loss_train = 28498508.0 \t loss_valid = 25314400.0 \n",
      "Model_6_3350 \t loss_train = 29021134.0 \t loss_valid = 25521892.0 \n",
      "Model_6_3360 \t loss_train = 29035454.0 \t loss_valid = 25530760.0 \n",
      "Model_6_3370 \t loss_train = 28553012.0 \t loss_valid = 25355734.0 \n",
      "Model_6_3380 \t loss_train = 28966364.0 \t loss_valid = 25475998.0 \n",
      "Model_6_3390 \t loss_train = 29305106.0 \t loss_valid = 25824154.0 \n",
      "Model_6_3400 \t loss_train = 28929730.0 \t loss_valid = 25563064.0 \n",
      "Model_6_3410 \t loss_train = 28845248.0 \t loss_valid = 25384520.0 \n",
      "Model_6_3420 \t loss_train = 28594726.0 \t loss_valid = 25370530.0 \n",
      "Model_6_3430 \t loss_train = 28544106.0 \t loss_valid = 25291064.0 \n",
      "Model_6_3440 \t loss_train = 28767486.0 \t loss_valid = 25362378.0 \n",
      "Model_6_3450 \t loss_train = 28553274.0 \t loss_valid = 25297664.0 \n",
      "Model_6_3460 \t loss_train = 28470704.0 \t loss_valid = 25302028.0 \n",
      "Model_6_3470 \t loss_train = 28596634.0 \t loss_valid = 25314616.0 \n",
      "Model_6_3480 \t loss_train = 28652172.0 \t loss_valid = 25332242.0 \n",
      "Model_6_3490 \t loss_train = 28480122.0 \t loss_valid = 25303204.0 \n",
      "Model_6_3500 \t loss_train = 28502306.0 \t loss_valid = 25314784.0 \n",
      "Model_6_3510 \t loss_train = 28580704.0 \t loss_valid = 25311226.0 \n",
      "Model_6_3520 \t loss_train = 28435666.0 \t loss_valid = 25303050.0 \n",
      "Model_6_3530 \t loss_train = 28363300.0 \t loss_valid = 25314146.0 \n",
      "Model_6_3540 \t loss_train = 28551446.0 \t loss_valid = 25307532.0 \n",
      "Model_6_3550 \t loss_train = 28551984.0 \t loss_valid = 25315528.0 \n",
      "Model_6_3560 \t loss_train = 28434250.0 \t loss_valid = 25338838.0 \n",
      "Model_6_3570 \t loss_train = 28836334.0 \t loss_valid = 25403030.0 \n",
      "Model_6_3580 \t loss_train = 28477550.0 \t loss_valid = 25310220.0 \n",
      "Model_6_3590 \t loss_train = 28797164.0 \t loss_valid = 25400662.0 \n",
      "Model_6_3600 \t loss_train = 29356564.0 \t loss_valid = 25699782.0 \n",
      "Model_6_3610 \t loss_train = 28854290.0 \t loss_valid = 25464114.0 \n",
      "Model_6_3620 \t loss_train = 28948190.0 \t loss_valid = 25459126.0 \n",
      "Model_6_3630 \t loss_train = 29167860.0 \t loss_valid = 25517768.0 \n",
      "Model_6_3640 \t loss_train = 29166116.0 \t loss_valid = 25652536.0 \n",
      "Model_6_3650 \t loss_train = 29097466.0 \t loss_valid = 25510780.0 \n",
      "Model_6_3660 \t loss_train = 28969474.0 \t loss_valid = 25449058.0 \n",
      "Model_6_3670 \t loss_train = 28728770.0 \t loss_valid = 25386084.0 \n",
      "Model_6_3680 \t loss_train = 28974524.0 \t loss_valid = 25431920.0 \n",
      "Model_6_3690 \t loss_train = 28821760.0 \t loss_valid = 25462066.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_6_3700 \t loss_train = 28737784.0 \t loss_valid = 25359258.0 \n",
      "Model_6_3710 \t loss_train = 28687178.0 \t loss_valid = 25316944.0 \n",
      "Model_6_3720 \t loss_train = 28627814.0 \t loss_valid = 25324528.0 \n",
      "Model_6_3730 \t loss_train = 28978218.0 \t loss_valid = 25431894.0 \n",
      "Model_6_3740 \t loss_train = 29166964.0 \t loss_valid = 25587370.0 \n",
      "Model_6_3750 \t loss_train = 28869638.0 \t loss_valid = 25410680.0 \n",
      "Model_6_3760 \t loss_train = 28891426.0 \t loss_valid = 25380374.0 \n",
      "Model_6_3770 \t loss_train = 28920168.0 \t loss_valid = 25404820.0 \n",
      "Model_6_3780 \t loss_train = 28658836.0 \t loss_valid = 25303398.0 \n",
      "Model_6_3790 \t loss_train = 28708672.0 \t loss_valid = 25308286.0 \n",
      "Model_6_3800 \t loss_train = 28506132.0 \t loss_valid = 25281928.0 \n",
      "Model_6_3810 \t loss_train = 28709358.0 \t loss_valid = 25350432.0 \n",
      "Model_6_3820 \t loss_train = 28848546.0 \t loss_valid = 25361376.0 \n",
      "Model_6_3830 \t loss_train = 28625816.0 \t loss_valid = 25309386.0 \n",
      "Model_6_3840 \t loss_train = 28764200.0 \t loss_valid = 25367634.0 \n",
      "Model_6_3850 \t loss_train = 28761034.0 \t loss_valid = 25356614.0 \n",
      "Model_6_3860 \t loss_train = 28940870.0 \t loss_valid = 25420450.0 \n",
      "Model_6_3870 \t loss_train = 29317468.0 \t loss_valid = 25706766.0 \n",
      "Model_6_3880 \t loss_train = 29080864.0 \t loss_valid = 25524280.0 \n",
      "Model_6_3890 \t loss_train = 28780316.0 \t loss_valid = 25393950.0 \n",
      "Model_6_3900 \t loss_train = 28975428.0 \t loss_valid = 25500382.0 \n",
      "Model_6_3910 \t loss_train = 29213126.0 \t loss_valid = 25602250.0 \n",
      "Model_6_3920 \t loss_train = 28862374.0 \t loss_valid = 25466200.0 \n",
      "Model_6_3930 \t loss_train = 28826286.0 \t loss_valid = 25375658.0 \n",
      "Model_6_3940 \t loss_train = 28521150.0 \t loss_valid = 25317614.0 \n",
      "Model_6_3950 \t loss_train = 28694044.0 \t loss_valid = 25379702.0 \n",
      "Model_6_3960 \t loss_train = 28733202.0 \t loss_valid = 25385810.0 \n",
      "Model_6_3970 \t loss_train = 28610458.0 \t loss_valid = 25324502.0 \n",
      "Model_6_3980 \t loss_train = 28537562.0 \t loss_valid = 25300626.0 \n",
      "Model_6_3990 \t loss_train = 28588952.0 \t loss_valid = 25290206.0 \n",
      "Model_6_4000 \t loss_train = 29071320.0 \t loss_valid = 25468460.0 \n",
      "Model_6_4010 \t loss_train = 28626136.0 \t loss_valid = 25356214.0 \n",
      "Model_6_4020 \t loss_train = 29177786.0 \t loss_valid = 25471222.0 \n",
      "Model_6_4030 \t loss_train = 29194942.0 \t loss_valid = 25632938.0 \n",
      "Model_6_4040 \t loss_train = 28991738.0 \t loss_valid = 25517366.0 \n",
      "Model_6_4050 \t loss_train = 28783134.0 \t loss_valid = 25344756.0 \n",
      "Model_6_4060 \t loss_train = 28649146.0 \t loss_valid = 25297096.0 \n",
      "Model_6_4070 \t loss_train = 28550928.0 \t loss_valid = 25298518.0 \n",
      "Model_6_4080 \t loss_train = 28653442.0 \t loss_valid = 25318614.0 \n",
      "Model_6_4090 \t loss_train = 28502090.0 \t loss_valid = 25298480.0 \n",
      "Model_6_4100 \t loss_train = 28573242.0 \t loss_valid = 25294292.0 \n",
      "Model_6_4110 \t loss_train = 28717096.0 \t loss_valid = 25355566.0 \n",
      "Model_6_4120 \t loss_train = 28794106.0 \t loss_valid = 25381212.0 \n",
      "Model_6_4130 \t loss_train = 28715622.0 \t loss_valid = 25350390.0 \n",
      "Model_6_4140 \t loss_train = 28862816.0 \t loss_valid = 25416812.0 \n",
      "Model_6_4150 \t loss_train = 28907858.0 \t loss_valid = 25389280.0 \n",
      "Model_6_4160 \t loss_train = 29078468.0 \t loss_valid = 25574572.0 \n",
      "Model_6_4170 \t loss_train = 29216728.0 \t loss_valid = 25616376.0 \n",
      "Model_6_4180 \t loss_train = 29010454.0 \t loss_valid = 25464464.0 \n",
      "Model_6_4190 \t loss_train = 28851790.0 \t loss_valid = 25416428.0 \n",
      "Model_6_4200 \t loss_train = 28972470.0 \t loss_valid = 25475376.0 \n",
      "Model_6_4210 \t loss_train = 28904472.0 \t loss_valid = 25434508.0 \n",
      "Model_6_4220 \t loss_train = 29090532.0 \t loss_valid = 25537134.0 \n",
      "Model_6_4230 \t loss_train = 29178924.0 \t loss_valid = 25540434.0 \n",
      "Model_6_4240 \t loss_train = 29155586.0 \t loss_valid = 25607866.0 \n",
      "Model_6_4250 \t loss_train = 29287864.0 \t loss_valid = 25642372.0 \n",
      "Model_6_4260 \t loss_train = 29278970.0 \t loss_valid = 25707556.0 \n",
      "Model_6_4270 \t loss_train = 29284720.0 \t loss_valid = 25637676.0 \n",
      "Model_6_4280 \t loss_train = 28947354.0 \t loss_valid = 25395046.0 \n",
      "Model_6_4290 \t loss_train = 29075230.0 \t loss_valid = 25588664.0 \n",
      "Model_6_4300 \t loss_train = 28888106.0 \t loss_valid = 25374166.0 \n",
      "Model_6_4310 \t loss_train = 28406794.0 \t loss_valid = 25298682.0 \n",
      "Model_6_4320 \t loss_train = 28595190.0 \t loss_valid = 25302508.0 \n",
      "Model_6_4330 \t loss_train = 28840340.0 \t loss_valid = 25365378.0 \n",
      "Model_6_4340 \t loss_train = 28804548.0 \t loss_valid = 25387832.0 \n",
      "Model_6_4350 \t loss_train = 28852396.0 \t loss_valid = 25426332.0 \n",
      "Model_6_4360 \t loss_train = 28886946.0 \t loss_valid = 25443860.0 \n",
      "Model_6_4370 \t loss_train = 28800814.0 \t loss_valid = 25386906.0 \n",
      "Model_6_4380 \t loss_train = 28677402.0 \t loss_valid = 25329134.0 \n",
      "Model_6_4390 \t loss_train = 29167100.0 \t loss_valid = 25607028.0 \n",
      "Model_6_4400 \t loss_train = 29679032.0 \t loss_valid = 25868850.0 \n",
      "Model_6_4410 \t loss_train = 29241414.0 \t loss_valid = 25615618.0 \n",
      "Model_6_4420 \t loss_train = 28929478.0 \t loss_valid = 25447412.0 \n",
      "Model_6_4430 \t loss_train = 28914258.0 \t loss_valid = 25432076.0 \n",
      "Model_6_4440 \t loss_train = 29351842.0 \t loss_valid = 25806888.0 \n",
      "Model_6_4450 \t loss_train = 29127640.0 \t loss_valid = 25599628.0 \n",
      "Model_6_4460 \t loss_train = 29317442.0 \t loss_valid = 25634162.0 \n",
      "Model_6_4470 \t loss_train = 28766904.0 \t loss_valid = 25374264.0 \n",
      "Model_6_4480 \t loss_train = 29154884.0 \t loss_valid = 25529462.0 \n",
      "Model_6_4490 \t loss_train = 29056532.0 \t loss_valid = 25505102.0 \n",
      "Model_6_4500 \t loss_train = 29210342.0 \t loss_valid = 25591068.0 \n",
      "Model_6_4510 \t loss_train = 29187544.0 \t loss_valid = 25642002.0 \n",
      "Model_6_4520 \t loss_train = 29165484.0 \t loss_valid = 25439860.0 \n",
      "Model_6_4530 \t loss_train = 29147752.0 \t loss_valid = 25622768.0 \n",
      "Model_6_4540 \t loss_train = 28901448.0 \t loss_valid = 25425718.0 \n",
      "Model_6_4550 \t loss_train = 28720528.0 \t loss_valid = 25338640.0 \n",
      "Model_6_4560 \t loss_train = 28724514.0 \t loss_valid = 25350856.0 \n",
      "Model_6_4570 \t loss_train = 29166366.0 \t loss_valid = 25536162.0 \n",
      "Model_6_4580 \t loss_train = 29262378.0 \t loss_valid = 25603806.0 \n",
      "Model_6_4590 \t loss_train = 29028734.0 \t loss_valid = 25449504.0 \n",
      "Model_6_4600 \t loss_train = 29004176.0 \t loss_valid = 25466318.0 \n",
      "Model_6_4610 \t loss_train = 29147318.0 \t loss_valid = 25493756.0 \n",
      "Model_6_4620 \t loss_train = 28850492.0 \t loss_valid = 25409344.0 \n",
      "Model_6_4630 \t loss_train = 29122444.0 \t loss_valid = 25473946.0 \n",
      "Model_6_4640 \t loss_train = 29164942.0 \t loss_valid = 25543614.0 \n",
      "Model_6_4650 \t loss_train = 29031940.0 \t loss_valid = 25475278.0 \n",
      "Model_6_4660 \t loss_train = 29479160.0 \t loss_valid = 25785430.0 \n",
      "Model_6_4670 \t loss_train = 29083126.0 \t loss_valid = 25419280.0 \n",
      "Model_6_4680 \t loss_train = 29036464.0 \t loss_valid = 25424290.0 \n",
      "Model_6_4690 \t loss_train = 28934818.0 \t loss_valid = 25437626.0 \n",
      "Model_6_4700 \t loss_train = 28669780.0 \t loss_valid = 25314308.0 \n",
      "Model_6_4710 \t loss_train = 28814718.0 \t loss_valid = 25320372.0 \n",
      "Model_6_4720 \t loss_train = 28686340.0 \t loss_valid = 25318990.0 \n",
      "Model_6_4730 \t loss_train = 29051472.0 \t loss_valid = 25437336.0 \n",
      "Model_6_4740 \t loss_train = 28745538.0 \t loss_valid = 25345880.0 \n",
      "Model_6_4750 \t loss_train = 28723142.0 \t loss_valid = 25341504.0 \n",
      "Model_6_4760 \t loss_train = 28962438.0 \t loss_valid = 25418604.0 \n",
      "Model_6_4770 \t loss_train = 28951478.0 \t loss_valid = 25443344.0 \n",
      "Model_6_4780 \t loss_train = 28899866.0 \t loss_valid = 25439440.0 \n",
      "Model_6_4790 \t loss_train = 29205316.0 \t loss_valid = 25526366.0 \n",
      "Model_6_4800 \t loss_train = 29189646.0 \t loss_valid = 25595634.0 \n",
      "Model_6_4810 \t loss_train = 28911208.0 \t loss_valid = 25427996.0 \n",
      "Model_6_4820 \t loss_train = 28902892.0 \t loss_valid = 25419998.0 \n",
      "Model_6_4830 \t loss_train = 29780728.0 \t loss_valid = 25924406.0 \n",
      "Model_6_4840 \t loss_train = 29216154.0 \t loss_valid = 25629850.0 \n",
      "Model_6_4850 \t loss_train = 29802576.0 \t loss_valid = 26043906.0 \n",
      "Model_6_4860 \t loss_train = 29383364.0 \t loss_valid = 25631678.0 \n",
      "Model_6_4870 \t loss_train = 29081928.0 \t loss_valid = 25528830.0 \n",
      "Model_6_4880 \t loss_train = 28882036.0 \t loss_valid = 25418812.0 \n",
      "Model_6_4890 \t loss_train = 28834232.0 \t loss_valid = 25395226.0 \n",
      "Model_6_4900 \t loss_train = 28679070.0 \t loss_valid = 25331974.0 \n",
      "Model_6_4910 \t loss_train = 28937018.0 \t loss_valid = 25408628.0 \n",
      "Model_6_4920 \t loss_train = 28728898.0 \t loss_valid = 25389316.0 \n",
      "Model_6_4930 \t loss_train = 28879726.0 \t loss_valid = 25421934.0 \n",
      "Model_6_4940 \t loss_train = 29110052.0 \t loss_valid = 25462062.0 \n",
      "Model_6_4950 \t loss_train = 28780478.0 \t loss_valid = 25384444.0 \n",
      "Model_6_4960 \t loss_train = 29112812.0 \t loss_valid = 25522962.0 \n",
      "Model_6_4970 \t loss_train = 29081750.0 \t loss_valid = 25453734.0 \n",
      "Model_6_4980 \t loss_train = 29117712.0 \t loss_valid = 25557486.0 \n",
      "Model_6_4990 \t loss_train = 28622292.0 \t loss_valid = 25324364.0 \n",
      "Model_6_5000 \t loss_train = 28769472.0 \t loss_valid = 25362120.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_6_5010 \t loss_train = 29144940.0 \t loss_valid = 25549308.0 \n",
      "Model_6_5020 \t loss_train = 28630018.0 \t loss_valid = 25308616.0 \n",
      "Model_6_5030 \t loss_train = 28749726.0 \t loss_valid = 25339028.0 \n",
      "Model_6_5040 \t loss_train = 28645216.0 \t loss_valid = 25315150.0 \n",
      "Model_6_5050 \t loss_train = 28699924.0 \t loss_valid = 25327694.0 \n",
      "Model_6_5060 \t loss_train = 28656246.0 \t loss_valid = 25305970.0 \n",
      "Model_6_5070 \t loss_train = 28609160.0 \t loss_valid = 25288436.0 \n",
      "Model_6_5080 \t loss_train = 28721876.0 \t loss_valid = 25311358.0 \n",
      "Model_6_5090 \t loss_train = 28949914.0 \t loss_valid = 25411030.0 \n",
      "Model_6_5100 \t loss_train = 29263776.0 \t loss_valid = 25567214.0 \n",
      "Model_6_5110 \t loss_train = 29295136.0 \t loss_valid = 25621940.0 \n",
      "Model_6_5120 \t loss_train = 28849662.0 \t loss_valid = 25394596.0 \n",
      "Model_6_5130 \t loss_train = 28944318.0 \t loss_valid = 25383178.0 \n",
      "Model_6_5140 \t loss_train = 28945964.0 \t loss_valid = 25397382.0 \n",
      "Model_6_5150 \t loss_train = 29035822.0 \t loss_valid = 25478336.0 \n",
      "Model_6_5160 \t loss_train = 28732668.0 \t loss_valid = 25325156.0 \n",
      "Model_6_5170 \t loss_train = 28917552.0 \t loss_valid = 25386544.0 \n",
      "Model_6_5180 \t loss_train = 28675618.0 \t loss_valid = 25311718.0 \n",
      "Model_6_5190 \t loss_train = 28860636.0 \t loss_valid = 25380436.0 \n",
      "Model_6_5200 \t loss_train = 28846438.0 \t loss_valid = 25365552.0 \n",
      "Model_6_5210 \t loss_train = 28724166.0 \t loss_valid = 25334412.0 \n",
      "Model_6_5220 \t loss_train = 28790080.0 \t loss_valid = 25323110.0 \n",
      "Model_6_5230 \t loss_train = 28984264.0 \t loss_valid = 25412252.0 \n",
      "Model_6_5240 \t loss_train = 29299416.0 \t loss_valid = 25607740.0 \n",
      "Model_6_5250 \t loss_train = 29255364.0 \t loss_valid = 25529834.0 \n",
      "Model_6_5260 \t loss_train = 28870658.0 \t loss_valid = 25369122.0 \n",
      "Model_6_5270 \t loss_train = 29230066.0 \t loss_valid = 25549682.0 \n",
      "Model_6_5280 \t loss_train = 28980788.0 \t loss_valid = 25460894.0 \n",
      "Model_6_5290 \t loss_train = 28922022.0 \t loss_valid = 25390510.0 \n",
      "Model_6_5300 \t loss_train = 29163986.0 \t loss_valid = 25467260.0 \n",
      "Model_6_5310 \t loss_train = 29077004.0 \t loss_valid = 25442734.0 \n",
      "Model_6_5320 \t loss_train = 29196094.0 \t loss_valid = 25535038.0 \n",
      "Model_6_5330 \t loss_train = 29005132.0 \t loss_valid = 25389312.0 \n",
      "Model_6_5340 \t loss_train = 29095274.0 \t loss_valid = 25485086.0 \n",
      "Model_6_5350 \t loss_train = 29513856.0 \t loss_valid = 25705884.0 \n",
      "Model_6_5360 \t loss_train = 29404122.0 \t loss_valid = 25672612.0 \n",
      "Model_6_5370 \t loss_train = 29044716.0 \t loss_valid = 25432632.0 \n",
      "Model_6_5380 \t loss_train = 28903142.0 \t loss_valid = 25379238.0 \n",
      "Model_6_5390 \t loss_train = 28996982.0 \t loss_valid = 25424736.0 \n",
      "Model_6_5400 \t loss_train = 29249138.0 \t loss_valid = 25527666.0 \n",
      "Model_6_5410 \t loss_train = 29013146.0 \t loss_valid = 25433452.0 \n",
      "Model_6_5420 \t loss_train = 29064776.0 \t loss_valid = 25446434.0 \n",
      "Model_6_5430 \t loss_train = 29318124.0 \t loss_valid = 25532870.0 \n",
      "Model_6_5440 \t loss_train = 28697832.0 \t loss_valid = 25309272.0 \n",
      "Model_6_5450 \t loss_train = 29055642.0 \t loss_valid = 25466634.0 \n",
      "Model_6_5460 \t loss_train = 28864130.0 \t loss_valid = 25367254.0 \n",
      "Model_6_5470 \t loss_train = 29131236.0 \t loss_valid = 25575878.0 \n",
      "Model_6_5480 \t loss_train = 29323824.0 \t loss_valid = 25580112.0 \n",
      "Model_6_5490 \t loss_train = 28997858.0 \t loss_valid = 25413142.0 \n",
      "Model_6_5500 \t loss_train = 28621290.0 \t loss_valid = 25306944.0 \n",
      "Model_6_5510 \t loss_train = 28621022.0 \t loss_valid = 25303514.0 \n",
      "Model_6_5520 \t loss_train = 28878262.0 \t loss_valid = 25369670.0 \n",
      "Model_6_5530 \t loss_train = 28860560.0 \t loss_valid = 25359932.0 \n",
      "Model_6_5540 \t loss_train = 29364620.0 \t loss_valid = 25626848.0 \n",
      "Model_6_5550 \t loss_train = 29095688.0 \t loss_valid = 25460218.0 \n",
      "Model_6_5560 \t loss_train = 29018316.0 \t loss_valid = 25417454.0 \n",
      "Model_6_5570 \t loss_train = 29569878.0 \t loss_valid = 25772584.0 \n",
      "Model_6_5580 \t loss_train = 29357910.0 \t loss_valid = 25631200.0 \n",
      "Model_6_5590 \t loss_train = 29271508.0 \t loss_valid = 25597306.0 \n",
      "Model_6_5600 \t loss_train = 29300288.0 \t loss_valid = 25555588.0 \n",
      "Model_6_5610 \t loss_train = 29374336.0 \t loss_valid = 25604260.0 \n",
      "Model_6_5620 \t loss_train = 29070270.0 \t loss_valid = 25482800.0 \n",
      "Model_6_5630 \t loss_train = 29366152.0 \t loss_valid = 25640628.0 \n",
      "Model_6_5640 \t loss_train = 29567332.0 \t loss_valid = 25734984.0 \n",
      "Model_6_5650 \t loss_train = 29089406.0 \t loss_valid = 25459334.0 \n",
      "Model_6_5660 \t loss_train = 28824320.0 \t loss_valid = 25350988.0 \n",
      "Model_6_5670 \t loss_train = 28714956.0 \t loss_valid = 25312942.0 \n",
      "Model_6_5680 \t loss_train = 28944176.0 \t loss_valid = 25381128.0 \n",
      "Model_6_5690 \t loss_train = 29003184.0 \t loss_valid = 25400196.0 \n",
      "Model_6_5700 \t loss_train = 28910738.0 \t loss_valid = 25362008.0 \n",
      "Model_6_5710 \t loss_train = 28847486.0 \t loss_valid = 25352582.0 \n",
      "Model_6_5720 \t loss_train = 29061164.0 \t loss_valid = 25422998.0 \n",
      "Model_6_5730 \t loss_train = 28955936.0 \t loss_valid = 25386550.0 \n",
      "Model_6_5740 \t loss_train = 29140074.0 \t loss_valid = 25468100.0 \n",
      "Model_6_5750 \t loss_train = 29649160.0 \t loss_valid = 25885980.0 \n",
      "Model_6_5760 \t loss_train = 29859398.0 \t loss_valid = 26008678.0 \n",
      "Model_6_5770 \t loss_train = 29295762.0 \t loss_valid = 25507742.0 \n",
      "Model_6_5780 \t loss_train = 29279964.0 \t loss_valid = 25584200.0 \n",
      "Model_6_5790 \t loss_train = 29113762.0 \t loss_valid = 25428544.0 \n",
      "Model_6_5800 \t loss_train = 28913898.0 \t loss_valid = 25359312.0 \n",
      "Model_6_5810 \t loss_train = 28846416.0 \t loss_valid = 25396126.0 \n",
      "Model_6_5820 \t loss_train = 29097596.0 \t loss_valid = 25463510.0 \n",
      "Model_6_5830 \t loss_train = 29025500.0 \t loss_valid = 25437048.0 \n",
      "Model_6_5840 \t loss_train = 29109690.0 \t loss_valid = 25455612.0 \n",
      "Model_6_5850 \t loss_train = 29029778.0 \t loss_valid = 25433516.0 \n",
      "Model_6_5860 \t loss_train = 29138838.0 \t loss_valid = 25498546.0 \n",
      "Model_6_5870 \t loss_train = 29062418.0 \t loss_valid = 25440706.0 \n",
      "Model_6_5880 \t loss_train = 29079752.0 \t loss_valid = 25486766.0 \n",
      "Model_6_5890 \t loss_train = 28889248.0 \t loss_valid = 25345366.0 \n",
      "Model_6_5900 \t loss_train = 28692366.0 \t loss_valid = 25300936.0 \n",
      "Model_6_5910 \t loss_train = 28507964.0 \t loss_valid = 25310740.0 \n",
      "Model_6_5920 \t loss_train = 28814048.0 \t loss_valid = 25346216.0 \n",
      "Model_6_5930 \t loss_train = 29073866.0 \t loss_valid = 25488538.0 \n",
      "Model_6_5940 \t loss_train = 29062428.0 \t loss_valid = 25421264.0 \n",
      "Model_6_5950 \t loss_train = 29225938.0 \t loss_valid = 25505554.0 \n",
      "Model_6_5960 \t loss_train = 29378846.0 \t loss_valid = 25608016.0 \n",
      "Model_6_5970 \t loss_train = 29421006.0 \t loss_valid = 25653146.0 \n",
      "Model_6_5980 \t loss_train = 29101524.0 \t loss_valid = 25462076.0 \n",
      "Model_6_5990 \t loss_train = 29445198.0 \t loss_valid = 25575468.0 \n",
      "Model_6_6000 \t loss_train = 29331416.0 \t loss_valid = 25587754.0 \n",
      "Model_6_6010 \t loss_train = 29407020.0 \t loss_valid = 25615962.0 \n",
      "Model_6_6020 \t loss_train = 29220358.0 \t loss_valid = 25554342.0 \n",
      "Model_6_6030 \t loss_train = 29367692.0 \t loss_valid = 25542860.0 \n",
      "Model_6_6040 \t loss_train = 29468912.0 \t loss_valid = 25655960.0 \n",
      "Model_6_6050 \t loss_train = 29140236.0 \t loss_valid = 25490214.0 \n",
      "Model_6_6060 \t loss_train = 28853488.0 \t loss_valid = 25376866.0 \n",
      "Model_6_6070 \t loss_train = 28813466.0 \t loss_valid = 25333860.0 \n",
      "Model_6_6080 \t loss_train = 29021714.0 \t loss_valid = 25429246.0 \n",
      "Model_6_6090 \t loss_train = 29397534.0 \t loss_valid = 25589994.0 \n",
      "Model_6_6100 \t loss_train = 29132084.0 \t loss_valid = 25478934.0 \n",
      "Model_6_6110 \t loss_train = 29181252.0 \t loss_valid = 25504536.0 \n",
      "Model_6_6120 \t loss_train = 29067568.0 \t loss_valid = 25427940.0 \n",
      "Model_6_6130 \t loss_train = 29204132.0 \t loss_valid = 25522616.0 \n",
      "Model_6_6140 \t loss_train = 29063856.0 \t loss_valid = 25412654.0 \n",
      "Model_6_6150 \t loss_train = 29246152.0 \t loss_valid = 25530274.0 \n",
      "Model_6_6160 \t loss_train = 28802940.0 \t loss_valid = 25346250.0 \n",
      "Model_6_6170 \t loss_train = 28969358.0 \t loss_valid = 25381404.0 \n",
      "Model_6_6180 \t loss_train = 29215208.0 \t loss_valid = 25543052.0 \n",
      "Model_6_6190 \t loss_train = 29233424.0 \t loss_valid = 25530984.0 \n",
      "Model_6_6200 \t loss_train = 29194122.0 \t loss_valid = 25530816.0 \n",
      "Model_6_6210 \t loss_train = 29289566.0 \t loss_valid = 25539938.0 \n",
      "Model_6_6220 \t loss_train = 29195990.0 \t loss_valid = 25506718.0 \n",
      "Model_6_6230 \t loss_train = 29047916.0 \t loss_valid = 25423580.0 \n",
      "Model_6_6240 \t loss_train = 29257078.0 \t loss_valid = 25532956.0 \n",
      "Model_6_6250 \t loss_train = 29031004.0 \t loss_valid = 25398806.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_6_6260 \t loss_train = 28982944.0 \t loss_valid = 25401370.0 \n",
      "Model_6_6270 \t loss_train = 29424886.0 \t loss_valid = 25629418.0 \n",
      "Model_6_6280 \t loss_train = 29357786.0 \t loss_valid = 25515922.0 \n",
      "Model_6_6290 \t loss_train = 29234700.0 \t loss_valid = 25548990.0 \n",
      "Model_6_6300 \t loss_train = 29194440.0 \t loss_valid = 25522102.0 \n",
      "Model_6_6310 \t loss_train = 29230666.0 \t loss_valid = 25514414.0 \n",
      "Model_6_6320 \t loss_train = 29156432.0 \t loss_valid = 25482916.0 \n",
      "Model_6_6330 \t loss_train = 29044808.0 \t loss_valid = 25439706.0 \n",
      "Model_6_6340 \t loss_train = 28801118.0 \t loss_valid = 25326472.0 \n",
      "Model_6_6350 \t loss_train = 29271140.0 \t loss_valid = 25513064.0 \n",
      "Model_6_6360 \t loss_train = 29088462.0 \t loss_valid = 25432836.0 \n",
      "Model_6_6370 \t loss_train = 29386988.0 \t loss_valid = 25630390.0 \n",
      "Model_6_6380 \t loss_train = 29267988.0 \t loss_valid = 25556570.0 \n",
      "Model_6_6390 \t loss_train = 29142706.0 \t loss_valid = 25455688.0 \n",
      "Model_6_6400 \t loss_train = 29203392.0 \t loss_valid = 25514432.0 \n",
      "Model_6_6410 \t loss_train = 29425610.0 \t loss_valid = 25592412.0 \n",
      "Model_6_6420 \t loss_train = 28957960.0 \t loss_valid = 25409910.0 \n",
      "Model_6_6430 \t loss_train = 28865202.0 \t loss_valid = 25382630.0 \n",
      "Model_6_6440 \t loss_train = 29026794.0 \t loss_valid = 25423998.0 \n",
      "Model_6_6450 \t loss_train = 29467920.0 \t loss_valid = 25671054.0 \n",
      "Model_6_6460 \t loss_train = 29578194.0 \t loss_valid = 25771106.0 \n",
      "Model_6_6470 \t loss_train = 29604354.0 \t loss_valid = 25688032.0 \n",
      "Model_6_6480 \t loss_train = 29334676.0 \t loss_valid = 25617078.0 \n",
      "Model_6_6490 \t loss_train = 29417012.0 \t loss_valid = 25580460.0 \n",
      "Model_6_6500 \t loss_train = 29442170.0 \t loss_valid = 25576146.0 \n",
      "Model_6_6510 \t loss_train = 29366660.0 \t loss_valid = 25541876.0 \n",
      "Model_6_6520 \t loss_train = 29266860.0 \t loss_valid = 25494770.0 \n",
      "Model_6_6530 \t loss_train = 29328108.0 \t loss_valid = 25517506.0 \n",
      "Model_6_6540 \t loss_train = 29109900.0 \t loss_valid = 25462878.0 \n",
      "Model_6_6550 \t loss_train = 28776768.0 \t loss_valid = 25363454.0 \n",
      "Model_6_6560 \t loss_train = 28878250.0 \t loss_valid = 25363488.0 \n",
      "Model_6_6570 \t loss_train = 29429158.0 \t loss_valid = 25680408.0 \n",
      "Model_6_6580 \t loss_train = 29266216.0 \t loss_valid = 25577590.0 \n",
      "Model_6_6590 \t loss_train = 29255524.0 \t loss_valid = 25500780.0 \n",
      "Model_6_6600 \t loss_train = 29260998.0 \t loss_valid = 25563996.0 \n",
      "Model_6_6610 \t loss_train = 29069800.0 \t loss_valid = 25420446.0 \n",
      "Model_6_6620 \t loss_train = 29058896.0 \t loss_valid = 25414966.0 \n",
      "Model_6_6630 \t loss_train = 29167262.0 \t loss_valid = 25481898.0 \n",
      "Model_6_6640 \t loss_train = 29514750.0 \t loss_valid = 25626952.0 \n",
      "Model_6_6650 \t loss_train = 29462844.0 \t loss_valid = 25597174.0 \n",
      "Model_6_6660 \t loss_train = 29269646.0 \t loss_valid = 25503896.0 \n",
      "Model_6_6670 \t loss_train = 29116614.0 \t loss_valid = 25426020.0 \n",
      "Model_6_6680 \t loss_train = 29609576.0 \t loss_valid = 25714868.0 \n",
      "Model_6_6690 \t loss_train = 29513176.0 \t loss_valid = 25666602.0 \n",
      "Model_6_6700 \t loss_train = 29048722.0 \t loss_valid = 25423564.0 \n",
      "Model_6_6710 \t loss_train = 29228880.0 \t loss_valid = 25453150.0 \n",
      "Model_6_6720 \t loss_train = 29477808.0 \t loss_valid = 25645068.0 \n",
      "Model_6_6730 \t loss_train = 29179088.0 \t loss_valid = 25461520.0 \n",
      "Model_6_6740 \t loss_train = 29806256.0 \t loss_valid = 25821196.0 \n",
      "Model_6_6750 \t loss_train = 29503968.0 \t loss_valid = 25708518.0 \n",
      "Model_6_6760 \t loss_train = 29335176.0 \t loss_valid = 25561234.0 \n",
      "Model_6_6770 \t loss_train = 29235902.0 \t loss_valid = 25442202.0 \n",
      "Model_6_6780 \t loss_train = 29061850.0 \t loss_valid = 25447772.0 \n",
      "Model_6_6790 \t loss_train = 29088248.0 \t loss_valid = 25433634.0 \n",
      "Model_6_6800 \t loss_train = 28944908.0 \t loss_valid = 25383782.0 \n",
      "Model_6_6810 \t loss_train = 29157328.0 \t loss_valid = 25453142.0 \n",
      "Model_6_6820 \t loss_train = 29237834.0 \t loss_valid = 25498150.0 \n",
      "Model_6_6830 \t loss_train = 29456190.0 \t loss_valid = 25634408.0 \n",
      "Model_6_6840 \t loss_train = 29598494.0 \t loss_valid = 25665584.0 \n",
      "Model_6_6850 \t loss_train = 29675036.0 \t loss_valid = 25705744.0 \n",
      "Model_6_6860 \t loss_train = 29281194.0 \t loss_valid = 25500530.0 \n",
      "Model_6_6870 \t loss_train = 29323278.0 \t loss_valid = 25517816.0 \n",
      "Model_6_6880 \t loss_train = 29537588.0 \t loss_valid = 25639832.0 \n",
      "Model_6_6890 \t loss_train = 29318764.0 \t loss_valid = 25539638.0 \n",
      "Model_6_6900 \t loss_train = 29396808.0 \t loss_valid = 25559284.0 \n",
      "Model_6_6910 \t loss_train = 29536384.0 \t loss_valid = 25651354.0 \n",
      "Model_6_6920 \t loss_train = 29186036.0 \t loss_valid = 25486372.0 \n",
      "Model_6_6930 \t loss_train = 28991326.0 \t loss_valid = 25387070.0 \n",
      "Model_6_6940 \t loss_train = 29002252.0 \t loss_valid = 25377494.0 \n",
      "Model_6_6950 \t loss_train = 29128002.0 \t loss_valid = 25444368.0 \n",
      "Model_6_6960 \t loss_train = 29328720.0 \t loss_valid = 25513276.0 \n",
      "Model_6_6970 \t loss_train = 29449424.0 \t loss_valid = 25631406.0 \n",
      "Model_6_6980 \t loss_train = 29438890.0 \t loss_valid = 25571678.0 \n",
      "Model_6_6990 \t loss_train = 29776412.0 \t loss_valid = 25770720.0 \n",
      "Model_6_7000 \t loss_train = 29175450.0 \t loss_valid = 25456596.0 \n",
      "Model_6_7010 \t loss_train = 29537128.0 \t loss_valid = 25629880.0 \n",
      "Model_6_7020 \t loss_train = 29208720.0 \t loss_valid = 25536080.0 \n",
      "Model_6_7030 \t loss_train = 29115084.0 \t loss_valid = 25451108.0 \n",
      "Model_6_7040 \t loss_train = 28991566.0 \t loss_valid = 25403876.0 \n",
      "Model_6_7050 \t loss_train = 29216564.0 \t loss_valid = 25449062.0 \n",
      "Model_6_7060 \t loss_train = 29392682.0 \t loss_valid = 25527984.0 \n",
      "Model_6_7070 \t loss_train = 29606170.0 \t loss_valid = 25728892.0 \n",
      "Model_6_7080 \t loss_train = 29414884.0 \t loss_valid = 25585394.0 \n",
      "Model_6_7090 \t loss_train = 29110490.0 \t loss_valid = 25427760.0 \n",
      "Model_6_7100 \t loss_train = 29019556.0 \t loss_valid = 25397462.0 \n",
      "Model_6_7110 \t loss_train = 29098282.0 \t loss_valid = 25423648.0 \n",
      "Model_6_7120 \t loss_train = 29362102.0 \t loss_valid = 25563292.0 \n",
      "Model_6_7130 \t loss_train = 29137434.0 \t loss_valid = 25490226.0 \n",
      "Model_6_7140 \t loss_train = 29223026.0 \t loss_valid = 25468052.0 \n",
      "Model_6_7150 \t loss_train = 29218350.0 \t loss_valid = 25473264.0 \n",
      "Model_6_7160 \t loss_train = 29223496.0 \t loss_valid = 25485648.0 \n",
      "Model_6_7170 \t loss_train = 29234204.0 \t loss_valid = 25458296.0 \n",
      "Model_6_7180 \t loss_train = 29086310.0 \t loss_valid = 25421438.0 \n",
      "Model_6_7190 \t loss_train = 29281392.0 \t loss_valid = 25518942.0 \n",
      "Model_6_7200 \t loss_train = 29438890.0 \t loss_valid = 25596520.0 \n",
      "Model_6_7210 \t loss_train = 29185722.0 \t loss_valid = 25455000.0 \n",
      "Model_6_7220 \t loss_train = 29621662.0 \t loss_valid = 25709558.0 \n",
      "Model_6_7230 \t loss_train = 29610776.0 \t loss_valid = 25631274.0 \n",
      "Model_6_7240 \t loss_train = 29128186.0 \t loss_valid = 25436586.0 \n",
      "Model_6_7250 \t loss_train = 29151310.0 \t loss_valid = 25432108.0 \n",
      "Model_6_7260 \t loss_train = 29523370.0 \t loss_valid = 25629018.0 \n",
      "Model_6_7270 \t loss_train = 29494298.0 \t loss_valid = 25590568.0 \n",
      "Model_6_7280 \t loss_train = 29228364.0 \t loss_valid = 25472014.0 \n",
      "Model_6_7290 \t loss_train = 29071834.0 \t loss_valid = 25408660.0 \n",
      "Model_6_7300 \t loss_train = 29593222.0 \t loss_valid = 25589054.0 \n",
      "Model_6_7310 \t loss_train = 29233128.0 \t loss_valid = 25540436.0 \n",
      "Model_6_7320 \t loss_train = 29703948.0 \t loss_valid = 25683932.0 \n",
      "Model_6_7330 \t loss_train = 29766030.0 \t loss_valid = 25768312.0 \n",
      "Model_6_7340 \t loss_train = 29464542.0 \t loss_valid = 25586422.0 \n",
      "Model_6_7350 \t loss_train = 29436280.0 \t loss_valid = 25572966.0 \n",
      "Model_6_7360 \t loss_train = 29232240.0 \t loss_valid = 25479564.0 \n",
      "Model_6_7370 \t loss_train = 29007186.0 \t loss_valid = 25400248.0 \n",
      "Model_6_7380 \t loss_train = 29594368.0 \t loss_valid = 25684256.0 \n",
      "Model_6_7390 \t loss_train = 29691782.0 \t loss_valid = 25716446.0 \n",
      "Model_6_7400 \t loss_train = 29829958.0 \t loss_valid = 25711722.0 \n",
      "Model_6_7410 \t loss_train = 29647448.0 \t loss_valid = 25653744.0 \n",
      "Model_6_7420 \t loss_train = 29273928.0 \t loss_valid = 25508626.0 \n",
      "Model_6_7430 \t loss_train = 29250550.0 \t loss_valid = 25497668.0 \n",
      "Model_6_7440 \t loss_train = 29191384.0 \t loss_valid = 25436100.0 \n",
      "Model_6_7450 \t loss_train = 29572910.0 \t loss_valid = 25647578.0 \n",
      "Model_6_7460 \t loss_train = 29432532.0 \t loss_valid = 25608214.0 \n",
      "Model_6_7470 \t loss_train = 29316294.0 \t loss_valid = 25489248.0 \n",
      "Model_6_7480 \t loss_train = 29131944.0 \t loss_valid = 25418130.0 \n",
      "Model_6_7490 \t loss_train = 28934420.0 \t loss_valid = 25353158.0 \n",
      "Model_6_7500 \t loss_train = 29086404.0 \t loss_valid = 25396468.0 \n",
      "Model_6_7510 \t loss_train = 29575228.0 \t loss_valid = 25657656.0 \n",
      "Model_6_7520 \t loss_train = 29690558.0 \t loss_valid = 25712620.0 \n",
      "Model_6_7530 \t loss_train = 29361556.0 \t loss_valid = 25515788.0 \n",
      "Model_6_7540 \t loss_train = 28866130.0 \t loss_valid = 25352620.0 \n",
      "Model_6_7550 \t loss_train = 29184006.0 \t loss_valid = 25456798.0 \n",
      "Model_6_7560 \t loss_train = 29263360.0 \t loss_valid = 25468502.0 \n",
      "Model_6_7570 \t loss_train = 29132910.0 \t loss_valid = 25425380.0 \n",
      "Model_6_7580 \t loss_train = 29632282.0 \t loss_valid = 25639718.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_6_7590 \t loss_train = 29523970.0 \t loss_valid = 25649518.0 \n",
      "Model_6_7600 \t loss_train = 29447292.0 \t loss_valid = 25579366.0 \n",
      "Model_6_7610 \t loss_train = 29527236.0 \t loss_valid = 25628688.0 \n",
      "Model_6_7620 \t loss_train = 29520184.0 \t loss_valid = 25579556.0 \n",
      "Model_6_7630 \t loss_train = 29095902.0 \t loss_valid = 25421322.0 \n",
      "Model_6_7640 \t loss_train = 29259530.0 \t loss_valid = 25477816.0 \n",
      "Model_6_7650 \t loss_train = 29626814.0 \t loss_valid = 25649320.0 \n",
      "Model_6_7660 \t loss_train = 29620822.0 \t loss_valid = 25668968.0 \n",
      "Model_6_7670 \t loss_train = 29596196.0 \t loss_valid = 25655604.0 \n",
      "Model_6_7680 \t loss_train = 29396900.0 \t loss_valid = 25547840.0 \n",
      "Model_6_7690 \t loss_train = 29664580.0 \t loss_valid = 25683446.0 \n",
      "Model_6_7700 \t loss_train = 29652170.0 \t loss_valid = 25673388.0 \n",
      "Model_6_7710 \t loss_train = 29291306.0 \t loss_valid = 25510750.0 \n",
      "Model_6_7720 \t loss_train = 29458910.0 \t loss_valid = 25584794.0 \n",
      "Model_6_7730 \t loss_train = 29762718.0 \t loss_valid = 25771952.0 \n",
      "Model_6_7740 \t loss_train = 29647900.0 \t loss_valid = 25708912.0 \n",
      "Model_6_7750 \t loss_train = 29194242.0 \t loss_valid = 25480740.0 \n",
      "Model_6_7760 \t loss_train = 29687308.0 \t loss_valid = 25713524.0 \n",
      "Model_6_7770 \t loss_train = 29399170.0 \t loss_valid = 25567572.0 \n",
      "Model_6_7780 \t loss_train = 29284048.0 \t loss_valid = 25507438.0 \n",
      "Model_6_7790 \t loss_train = 29530536.0 \t loss_valid = 25587832.0 \n",
      "Model_6_7800 \t loss_train = 29058828.0 \t loss_valid = 25388434.0 \n",
      "Model_6_7810 \t loss_train = 29256288.0 \t loss_valid = 25472038.0 \n",
      "Model_6_7820 \t loss_train = 28892744.0 \t loss_valid = 25349288.0 \n",
      "Model_6_7830 \t loss_train = 29453886.0 \t loss_valid = 25571312.0 \n",
      "Model_6_7840 \t loss_train = 29366372.0 \t loss_valid = 25633762.0 \n",
      "Model_6_7850 \t loss_train = 29402308.0 \t loss_valid = 25563382.0 \n",
      "Model_6_7860 \t loss_train = 29464080.0 \t loss_valid = 25588232.0 \n",
      "Model_6_7870 \t loss_train = 29278038.0 \t loss_valid = 25513168.0 \n",
      "Model_6_7880 \t loss_train = 29161728.0 \t loss_valid = 25450276.0 \n",
      "Model_6_7890 \t loss_train = 29426360.0 \t loss_valid = 25551334.0 \n",
      "Model_6_7900 \t loss_train = 29416908.0 \t loss_valid = 25534078.0 \n",
      "Model_6_7910 \t loss_train = 29469448.0 \t loss_valid = 25573092.0 \n",
      "Model_6_7920 \t loss_train = 29217998.0 \t loss_valid = 25475316.0 \n",
      "Model_6_7930 \t loss_train = 29527006.0 \t loss_valid = 25576384.0 \n",
      "Model_6_7940 \t loss_train = 29131080.0 \t loss_valid = 25424710.0 \n",
      "Model_6_7950 \t loss_train = 29339712.0 \t loss_valid = 25507486.0 \n",
      "Model_6_7960 \t loss_train = 29679656.0 \t loss_valid = 25669832.0 \n",
      "Model_6_7970 \t loss_train = 29238310.0 \t loss_valid = 25473712.0 \n",
      "Model_6_7980 \t loss_train = 29553890.0 \t loss_valid = 25633802.0 \n",
      "Model_6_7990 \t loss_train = 29351054.0 \t loss_valid = 25570436.0 \n",
      "Model_6_8000 \t loss_train = 29212112.0 \t loss_valid = 25466750.0 \n",
      "Model_6_8010 \t loss_train = 29514592.0 \t loss_valid = 25604732.0 \n",
      "Model_6_8020 \t loss_train = 29304854.0 \t loss_valid = 25514478.0 \n",
      "Model_6_8030 \t loss_train = 29249254.0 \t loss_valid = 25518874.0 \n",
      "Model_6_8040 \t loss_train = 29474978.0 \t loss_valid = 25595032.0 \n",
      "Model_6_8050 \t loss_train = 29379380.0 \t loss_valid = 25534754.0 \n",
      "Model_6_8060 \t loss_train = 29246228.0 \t loss_valid = 25451724.0 \n",
      "Model_6_8070 \t loss_train = 29114518.0 \t loss_valid = 25407346.0 \n",
      "Model_6_8080 \t loss_train = 29581346.0 \t loss_valid = 25656310.0 \n",
      "Model_6_8090 \t loss_train = 29497720.0 \t loss_valid = 25583720.0 \n",
      "Model_6_8100 \t loss_train = 29548158.0 \t loss_valid = 25636084.0 \n",
      "Model_6_8110 \t loss_train = 29509150.0 \t loss_valid = 25598404.0 \n",
      "Model_6_8120 \t loss_train = 29269690.0 \t loss_valid = 25473648.0 \n",
      "Model_6_8130 \t loss_train = 29087494.0 \t loss_valid = 25399432.0 \n",
      "Model_6_8140 \t loss_train = 29578592.0 \t loss_valid = 25626990.0 \n",
      "Model_6_8150 \t loss_train = 29915492.0 \t loss_valid = 25877484.0 \n",
      "Model_6_8160 \t loss_train = 29671912.0 \t loss_valid = 25682064.0 \n",
      "Model_6_8170 \t loss_train = 29316930.0 \t loss_valid = 25490520.0 \n",
      "Model_6_8180 \t loss_train = 29266760.0 \t loss_valid = 25483162.0 \n",
      "Model_6_8190 \t loss_train = 29333588.0 \t loss_valid = 25543006.0 \n",
      "Model_6_8200 \t loss_train = 29539810.0 \t loss_valid = 25621860.0 \n",
      "Model_6_8210 \t loss_train = 29457642.0 \t loss_valid = 25547230.0 \n",
      "Model_6_8220 \t loss_train = 29146094.0 \t loss_valid = 25425810.0 \n",
      "Model_6_8230 \t loss_train = 29365882.0 \t loss_valid = 25509584.0 \n",
      "Model_6_8240 \t loss_train = 29336750.0 \t loss_valid = 25477018.0 \n",
      "Model_6_8250 \t loss_train = 29352894.0 \t loss_valid = 25541374.0 \n",
      "Model_6_8260 \t loss_train = 29516932.0 \t loss_valid = 25614782.0 \n",
      "Model_6_8270 \t loss_train = 29250976.0 \t loss_valid = 25485150.0 \n",
      "Model_6_8280 \t loss_train = 29170056.0 \t loss_valid = 25442432.0 \n",
      "Model_6_8290 \t loss_train = 29230676.0 \t loss_valid = 25456394.0 \n",
      "Model_6_8300 \t loss_train = 29434168.0 \t loss_valid = 25573558.0 \n",
      "Model_6_8310 \t loss_train = 29256738.0 \t loss_valid = 25476220.0 \n",
      "Model_6_8320 \t loss_train = 29043984.0 \t loss_valid = 25412408.0 \n",
      "Model_6_8330 \t loss_train = 29278430.0 \t loss_valid = 25474342.0 \n",
      "Model_6_8340 \t loss_train = 29126384.0 \t loss_valid = 25411198.0 \n",
      "Model_6_8350 \t loss_train = 29308244.0 \t loss_valid = 25491248.0 \n",
      "Model_6_8360 \t loss_train = 29509720.0 \t loss_valid = 25629698.0 \n",
      "Model_6_8370 \t loss_train = 29235856.0 \t loss_valid = 25469826.0 \n",
      "Model_6_8380 \t loss_train = 29389082.0 \t loss_valid = 25542208.0 \n",
      "Model_6_8390 \t loss_train = 29408860.0 \t loss_valid = 25549232.0 \n",
      "Model_6_8400 \t loss_train = 29305752.0 \t loss_valid = 25497770.0 \n",
      "Model_6_8410 \t loss_train = 29356682.0 \t loss_valid = 25520608.0 \n",
      "Model_6_8420 \t loss_train = 29274544.0 \t loss_valid = 25494106.0 \n",
      "Model_6_8430 \t loss_train = 29094488.0 \t loss_valid = 25396104.0 \n",
      "Model_6_8440 \t loss_train = 29462312.0 \t loss_valid = 25547064.0 \n",
      "Model_6_8450 \t loss_train = 29311708.0 \t loss_valid = 25481530.0 \n",
      "Model_6_8460 \t loss_train = 29402230.0 \t loss_valid = 25511998.0 \n",
      "Model_6_8470 \t loss_train = 29135346.0 \t loss_valid = 25418064.0 \n",
      "Model_6_8480 \t loss_train = 29096994.0 \t loss_valid = 25399814.0 \n",
      "Model_6_8490 \t loss_train = 29300704.0 \t loss_valid = 25468416.0 \n",
      "Model_6_8500 \t loss_train = 29201844.0 \t loss_valid = 25465656.0 \n",
      "Model_6_8510 \t loss_train = 29028206.0 \t loss_valid = 25388910.0 \n",
      "Model_6_8520 \t loss_train = 29037196.0 \t loss_valid = 25382372.0 \n",
      "Model_6_8530 \t loss_train = 29130750.0 \t loss_valid = 25412258.0 \n",
      "Model_6_8540 \t loss_train = 29407036.0 \t loss_valid = 25603294.0 \n",
      "Model_6_8550 \t loss_train = 29762676.0 \t loss_valid = 25763812.0 \n",
      "Model_6_8560 \t loss_train = 29672346.0 \t loss_valid = 25681602.0 \n",
      "Model_6_8570 \t loss_train = 29597868.0 \t loss_valid = 25652584.0 \n",
      "Model_6_8580 \t loss_train = 29267984.0 \t loss_valid = 25464168.0 \n",
      "Model_6_8590 \t loss_train = 29082286.0 \t loss_valid = 25406270.0 \n",
      "Model_6_8600 \t loss_train = 29168050.0 \t loss_valid = 25416974.0 \n",
      "Model_6_8610 \t loss_train = 29401646.0 \t loss_valid = 25533784.0 \n",
      "Model_6_8620 \t loss_train = 29630068.0 \t loss_valid = 25655654.0 \n",
      "Model_6_8630 \t loss_train = 29394550.0 \t loss_valid = 25539824.0 \n",
      "Model_6_8640 \t loss_train = 29183288.0 \t loss_valid = 25447790.0 \n",
      "Model_6_8650 \t loss_train = 29242834.0 \t loss_valid = 25461874.0 \n",
      "Model_6_8660 \t loss_train = 29369378.0 \t loss_valid = 25517912.0 \n",
      "Model_6_8670 \t loss_train = 29537978.0 \t loss_valid = 25593980.0 \n",
      "Model_6_8680 \t loss_train = 29094600.0 \t loss_valid = 25411028.0 \n",
      "Model_6_8690 \t loss_train = 29071310.0 \t loss_valid = 25405316.0 \n",
      "Model_6_8700 \t loss_train = 29532066.0 \t loss_valid = 25605736.0 \n",
      "Model_6_8710 \t loss_train = 29336176.0 \t loss_valid = 25504016.0 \n",
      "Model_6_8720 \t loss_train = 28984594.0 \t loss_valid = 25373556.0 \n",
      "Model_6_8730 \t loss_train = 28934894.0 \t loss_valid = 25347204.0 \n",
      "Model_6_8740 \t loss_train = 29172530.0 \t loss_valid = 25425058.0 \n",
      "Model_6_8750 \t loss_train = 29288546.0 \t loss_valid = 25470578.0 \n",
      "Model_6_8760 \t loss_train = 29470586.0 \t loss_valid = 25582346.0 \n",
      "Model_6_8770 \t loss_train = 29475266.0 \t loss_valid = 25531584.0 \n",
      "Model_6_8780 \t loss_train = 29305326.0 \t loss_valid = 25501570.0 \n",
      "Model_6_8790 \t loss_train = 29255254.0 \t loss_valid = 25448136.0 \n",
      "Model_6_8800 \t loss_train = 29135008.0 \t loss_valid = 25410372.0 \n",
      "Model_6_8810 \t loss_train = 28904142.0 \t loss_valid = 25333808.0 \n",
      "Model_6_8820 \t loss_train = 29178782.0 \t loss_valid = 25428568.0 \n",
      "Model_6_8830 \t loss_train = 29549596.0 \t loss_valid = 25610906.0 \n",
      "Model_6_8840 \t loss_train = 29405446.0 \t loss_valid = 25601646.0 \n",
      "Model_6_8850 \t loss_train = 29255588.0 \t loss_valid = 25475748.0 \n",
      "Model_6_8860 \t loss_train = 29218782.0 \t loss_valid = 25459098.0 \n",
      "Model_6_8870 \t loss_train = 29107782.0 \t loss_valid = 25405790.0 \n",
      "Model_6_8880 \t loss_train = 29411160.0 \t loss_valid = 25542994.0 \n",
      "Model_6_8890 \t loss_train = 29314126.0 \t loss_valid = 25507992.0 \n",
      "Model_6_8900 \t loss_train = 29545352.0 \t loss_valid = 25594506.0 \n",
      "Model_6_8910 \t loss_train = 29238728.0 \t loss_valid = 25448196.0 \n",
      "Model_6_8920 \t loss_train = 29112822.0 \t loss_valid = 25431876.0 \n",
      "Model_6_8930 \t loss_train = 29313876.0 \t loss_valid = 25508424.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_6_8940 \t loss_train = 29361090.0 \t loss_valid = 25518092.0 \n",
      "Model_6_8950 \t loss_train = 29257276.0 \t loss_valid = 25495316.0 \n",
      "Model_6_8960 \t loss_train = 29402916.0 \t loss_valid = 25544240.0 \n",
      "Model_6_8970 \t loss_train = 29033602.0 \t loss_valid = 25379450.0 \n",
      "Model_6_8980 \t loss_train = 29094152.0 \t loss_valid = 25388300.0 \n",
      "Model_6_8990 \t loss_train = 29148412.0 \t loss_valid = 25405330.0 \n",
      "Model_6_9000 \t loss_train = 29102004.0 \t loss_valid = 25398614.0 \n",
      "Model_6_9010 \t loss_train = 29471428.0 \t loss_valid = 25557224.0 \n",
      "Model_6_9020 \t loss_train = 29216290.0 \t loss_valid = 25465444.0 \n",
      "Model_6_9030 \t loss_train = 29158630.0 \t loss_valid = 25415788.0 \n",
      "Model_6_9040 \t loss_train = 29213674.0 \t loss_valid = 25444144.0 \n",
      "Model_6_9050 \t loss_train = 29324726.0 \t loss_valid = 25515802.0 \n",
      "Model_6_9060 \t loss_train = 29370538.0 \t loss_valid = 25502508.0 \n",
      "Model_6_9070 \t loss_train = 29359828.0 \t loss_valid = 25515636.0 \n",
      "Model_6_9080 \t loss_train = 29064670.0 \t loss_valid = 25380326.0 \n",
      "Model_6_9090 \t loss_train = 29066152.0 \t loss_valid = 25389922.0 \n",
      "Model_6_9100 \t loss_train = 29303028.0 \t loss_valid = 25500378.0 \n",
      "Model_6_9110 \t loss_train = 29539988.0 \t loss_valid = 25562974.0 \n",
      "Model_6_9120 \t loss_train = 29297060.0 \t loss_valid = 25500840.0 \n",
      "Model_6_9130 \t loss_train = 29255782.0 \t loss_valid = 25469486.0 \n",
      "Model_6_9140 \t loss_train = 29232086.0 \t loss_valid = 25447200.0 \n",
      "Model_6_9150 \t loss_train = 29244684.0 \t loss_valid = 25461318.0 \n",
      "Model_6_9160 \t loss_train = 29171224.0 \t loss_valid = 25420256.0 \n",
      "Model_6_9170 \t loss_train = 29469054.0 \t loss_valid = 25575970.0 \n",
      "Model_6_9180 \t loss_train = 29229104.0 \t loss_valid = 25452350.0 \n",
      "Model_6_9190 \t loss_train = 29297802.0 \t loss_valid = 25486852.0 \n",
      "Model_6_9200 \t loss_train = 29259176.0 \t loss_valid = 25485240.0 \n",
      "Model_6_9210 \t loss_train = 29414492.0 \t loss_valid = 25584602.0 \n",
      "Model_6_9220 \t loss_train = 29695626.0 \t loss_valid = 25700634.0 \n",
      "Model_6_9230 \t loss_train = 29287246.0 \t loss_valid = 25481190.0 \n",
      "Model_6_9240 \t loss_train = 29009002.0 \t loss_valid = 25375750.0 \n",
      "Model_6_9250 \t loss_train = 29319340.0 \t loss_valid = 25506350.0 \n",
      "Model_6_9260 \t loss_train = 29115546.0 \t loss_valid = 25405820.0 \n",
      "Model_6_9270 \t loss_train = 29148428.0 \t loss_valid = 25434156.0 \n",
      "Model_6_9280 \t loss_train = 29248510.0 \t loss_valid = 25463646.0 \n",
      "Model_6_9290 \t loss_train = 29290282.0 \t loss_valid = 25514704.0 \n",
      "Model_6_9300 \t loss_train = 29252748.0 \t loss_valid = 25463678.0 \n",
      "Model_6_9310 \t loss_train = 28997074.0 \t loss_valid = 25356398.0 \n",
      "Model_6_9320 \t loss_train = 28953802.0 \t loss_valid = 25362486.0 \n",
      "Model_6_9330 \t loss_train = 28987912.0 \t loss_valid = 25351412.0 \n",
      "Model_6_9340 \t loss_train = 29038750.0 \t loss_valid = 25371996.0 \n",
      "Model_6_9350 \t loss_train = 29267340.0 \t loss_valid = 25442948.0 \n",
      "Model_6_9360 \t loss_train = 29195236.0 \t loss_valid = 25453236.0 \n",
      "Model_6_9370 \t loss_train = 29265110.0 \t loss_valid = 25461738.0 \n",
      "Model_6_9380 \t loss_train = 29076822.0 \t loss_valid = 25376698.0 \n",
      "Model_6_9390 \t loss_train = 29179268.0 \t loss_valid = 25435562.0 \n",
      "Model_6_9400 \t loss_train = 29278738.0 \t loss_valid = 25491684.0 \n",
      "Model_6_9410 \t loss_train = 29292112.0 \t loss_valid = 25487926.0 \n",
      "Model_6_9420 \t loss_train = 29094286.0 \t loss_valid = 25395446.0 \n",
      "Model_6_9430 \t loss_train = 29050858.0 \t loss_valid = 25388758.0 \n",
      "Model_6_9440 \t loss_train = 29232722.0 \t loss_valid = 25448896.0 \n",
      "Model_6_9450 \t loss_train = 29010174.0 \t loss_valid = 25367526.0 \n",
      "Model_6_9460 \t loss_train = 29243656.0 \t loss_valid = 25453224.0 \n",
      "Model_6_9470 \t loss_train = 29509896.0 \t loss_valid = 25577860.0 \n",
      "Model_6_9480 \t loss_train = 29227992.0 \t loss_valid = 25483670.0 \n",
      "Model_6_9490 \t loss_train = 28815502.0 \t loss_valid = 25319718.0 \n",
      "Model_6_9500 \t loss_train = 28748306.0 \t loss_valid = 25295408.0 \n",
      "Model_6_9510 \t loss_train = 28980364.0 \t loss_valid = 25354352.0 \n",
      "Model_6_9520 \t loss_train = 29191072.0 \t loss_valid = 25441370.0 \n",
      "Model_6_9530 \t loss_train = 29146934.0 \t loss_valid = 25429260.0 \n",
      "Model_6_9540 \t loss_train = 29014636.0 \t loss_valid = 25361746.0 \n",
      "Model_6_9550 \t loss_train = 29127754.0 \t loss_valid = 25456960.0 \n",
      "Model_6_9560 \t loss_train = 29399494.0 \t loss_valid = 25553268.0 \n",
      "Model_6_9570 \t loss_train = 28909816.0 \t loss_valid = 25333036.0 \n",
      "Model_6_9580 \t loss_train = 28955042.0 \t loss_valid = 25352442.0 \n",
      "Model_6_9590 \t loss_train = 28976136.0 \t loss_valid = 25355630.0 \n",
      "Model_6_9600 \t loss_train = 28991104.0 \t loss_valid = 25361624.0 \n",
      "Model_6_9610 \t loss_train = 28928264.0 \t loss_valid = 25351088.0 \n",
      "Model_6_9620 \t loss_train = 29134398.0 \t loss_valid = 25428898.0 \n",
      "Model_6_9630 \t loss_train = 29311024.0 \t loss_valid = 25491464.0 \n",
      "Model_6_9640 \t loss_train = 28992356.0 \t loss_valid = 25369976.0 \n",
      "Model_6_9650 \t loss_train = 29066408.0 \t loss_valid = 25410116.0 \n",
      "Model_6_9660 \t loss_train = 28963222.0 \t loss_valid = 25355392.0 \n",
      "Model_6_9670 \t loss_train = 29207396.0 \t loss_valid = 25444188.0 \n",
      "Model_6_9680 \t loss_train = 28954762.0 \t loss_valid = 25358204.0 \n",
      "Model_6_9690 \t loss_train = 29086290.0 \t loss_valid = 25405192.0 \n",
      "Model_6_9700 \t loss_train = 29040786.0 \t loss_valid = 25377876.0 \n",
      "Model_6_9710 \t loss_train = 29251758.0 \t loss_valid = 25468262.0 \n",
      "Model_6_9720 \t loss_train = 29202806.0 \t loss_valid = 25456042.0 \n",
      "Model_6_9730 \t loss_train = 29061620.0 \t loss_valid = 25391022.0 \n",
      "Model_6_9740 \t loss_train = 29018100.0 \t loss_valid = 25374764.0 \n",
      "Model_6_9750 \t loss_train = 29314798.0 \t loss_valid = 25499572.0 \n",
      "Model_6_9760 \t loss_train = 29047032.0 \t loss_valid = 25380880.0 \n",
      "Model_6_9770 \t loss_train = 29051234.0 \t loss_valid = 25381748.0 \n",
      "Model_6_9780 \t loss_train = 29106786.0 \t loss_valid = 25402054.0 \n",
      "Model_6_9790 \t loss_train = 29025028.0 \t loss_valid = 25372324.0 \n",
      "Model_6_9800 \t loss_train = 29301626.0 \t loss_valid = 25516404.0 \n",
      "Model_6_9810 \t loss_train = 29347142.0 \t loss_valid = 25502540.0 \n",
      "Model_6_9820 \t loss_train = 29193662.0 \t loss_valid = 25423300.0 \n",
      "Model_6_9830 \t loss_train = 29011904.0 \t loss_valid = 25368806.0 \n",
      "Model_6_9840 \t loss_train = 29239032.0 \t loss_valid = 25460664.0 \n",
      "Model_6_9850 \t loss_train = 29286650.0 \t loss_valid = 25472284.0 \n",
      "Model_6_9860 \t loss_train = 29048556.0 \t loss_valid = 25392270.0 \n",
      "Model_6_9870 \t loss_train = 29110356.0 \t loss_valid = 25416308.0 \n",
      "Model_6_9880 \t loss_train = 29014104.0 \t loss_valid = 25378368.0 \n",
      "Model_6_9890 \t loss_train = 29108144.0 \t loss_valid = 25393970.0 \n",
      "Model_6_9900 \t loss_train = 29171094.0 \t loss_valid = 25414050.0 \n",
      "Model_6_9910 \t loss_train = 28974658.0 \t loss_valid = 25365678.0 \n",
      "Model_6_9920 \t loss_train = 28900714.0 \t loss_valid = 25338524.0 \n",
      "Model_6_9930 \t loss_train = 28871980.0 \t loss_valid = 25321050.0 \n",
      "Model_6_9940 \t loss_train = 28910692.0 \t loss_valid = 25332120.0 \n",
      "Model_6_9950 \t loss_train = 29201272.0 \t loss_valid = 25445500.0 \n",
      "Model_6_9960 \t loss_train = 29161930.0 \t loss_valid = 25420880.0 \n",
      "Model_6_9970 \t loss_train = 28777930.0 \t loss_valid = 25293210.0 \n",
      "Model_6_9980 \t loss_train = 28736290.0 \t loss_valid = 25285516.0 \n",
      "Model_6_9990 \t loss_train = 28905986.0 \t loss_valid = 25330890.0 \n",
      "Model_6_10000 \t loss_train = 28997380.0 \t loss_valid = 25372090.0 \n",
      "Model_6_10010 \t loss_train = 28911784.0 \t loss_valid = 25326952.0 \n",
      "Model_6_10020 \t loss_train = 28951430.0 \t loss_valid = 25361400.0 \n",
      "Model_6_10030 \t loss_train = 28892110.0 \t loss_valid = 25328334.0 \n",
      "Model_6_10040 \t loss_train = 29148654.0 \t loss_valid = 25400658.0 \n",
      "Model_6_10050 \t loss_train = 29044756.0 \t loss_valid = 25400606.0 \n",
      "Model_6_10060 \t loss_train = 29073604.0 \t loss_valid = 25387520.0 \n",
      "Model_6_10070 \t loss_train = 28809234.0 \t loss_valid = 25300190.0 \n",
      "Model_6_10080 \t loss_train = 28855908.0 \t loss_valid = 25322124.0 \n",
      "Model_6_10090 \t loss_train = 29089804.0 \t loss_valid = 25406512.0 \n",
      "Model_6_10100 \t loss_train = 28884950.0 \t loss_valid = 25334608.0 \n",
      "Model_6_10110 \t loss_train = 28802114.0 \t loss_valid = 25304444.0 \n",
      "Model_6_10120 \t loss_train = 29040666.0 \t loss_valid = 25374028.0 \n",
      "Model_6_10130 \t loss_train = 29243582.0 \t loss_valid = 25457696.0 \n",
      "Model_6_10140 \t loss_train = 29052542.0 \t loss_valid = 25398954.0 \n",
      "Model_6_10150 \t loss_train = 28807896.0 \t loss_valid = 25301854.0 \n",
      "Model_6_10160 \t loss_train = 28842350.0 \t loss_valid = 25315958.0 \n",
      "Model_6_10170 \t loss_train = 29039648.0 \t loss_valid = 25381564.0 \n",
      "Model_6_10180 \t loss_train = 28821526.0 \t loss_valid = 25305088.0 \n",
      "Model_6_10190 \t loss_train = 28852748.0 \t loss_valid = 25314648.0 \n",
      "Model_6_10200 \t loss_train = 29188590.0 \t loss_valid = 25429830.0 \n",
      "Model_6_10210 \t loss_train = 29232518.0 \t loss_valid = 25455766.0 \n",
      "Model_6_10220 \t loss_train = 28791198.0 \t loss_valid = 25304166.0 \n",
      "Model_6_10230 \t loss_train = 28859698.0 \t loss_valid = 25316340.0 \n",
      "Model_6_10240 \t loss_train = 28943244.0 \t loss_valid = 25343050.0 \n",
      "Model_6_10250 \t loss_train = 28988844.0 \t loss_valid = 25373586.0 \n",
      "Model_6_10260 \t loss_train = 28937632.0 \t loss_valid = 25339550.0 \n",
      "Model_6_10270 \t loss_train = 28951740.0 \t loss_valid = 25352182.0 \n",
      "Model_6_10280 \t loss_train = 28924976.0 \t loss_valid = 25327364.0 \n",
      "Model_6_10290 \t loss_train = 28936280.0 \t loss_valid = 25341332.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_6_10300 \t loss_train = 28941326.0 \t loss_valid = 25340322.0 \n",
      "Model_6_10310 \t loss_train = 28827206.0 \t loss_valid = 25305624.0 \n",
      "Model_6_10320 \t loss_train = 28886954.0 \t loss_valid = 25319414.0 \n",
      "Model_6_10330 \t loss_train = 29199654.0 \t loss_valid = 25451856.0 \n",
      "Model_6_10340 \t loss_train = 28856726.0 \t loss_valid = 25314850.0 \n",
      "Model_6_10350 \t loss_train = 28929488.0 \t loss_valid = 25353732.0 \n",
      "Model_6_10360 \t loss_train = 29007930.0 \t loss_valid = 25359850.0 \n",
      "Model_6_10370 \t loss_train = 28825738.0 \t loss_valid = 25308100.0 \n",
      "Model_6_10380 \t loss_train = 29050046.0 \t loss_valid = 25393522.0 \n",
      "Model_6_10390 \t loss_train = 29111546.0 \t loss_valid = 25427746.0 \n",
      "Model_6_10400 \t loss_train = 28801546.0 \t loss_valid = 25301740.0 \n",
      "Model_6_10410 \t loss_train = 28653012.0 \t loss_valid = 25272470.0 \n",
      "Model_6_10420 \t loss_train = 28899858.0 \t loss_valid = 25338800.0 \n",
      "Model_6_10430 \t loss_train = 28938530.0 \t loss_valid = 25352490.0 \n",
      "Model_6_10440 \t loss_train = 28861002.0 \t loss_valid = 25317648.0 \n",
      "Model_6_10450 \t loss_train = 28999062.0 \t loss_valid = 25371360.0 \n",
      "Model_6_10460 \t loss_train = 28718228.0 \t loss_valid = 25283082.0 \n",
      "Model_6_10470 \t loss_train = 28875436.0 \t loss_valid = 25322138.0 \n",
      "Model_6_10480 \t loss_train = 28839014.0 \t loss_valid = 25321738.0 \n",
      "Model_6_10490 \t loss_train = 28806438.0 \t loss_valid = 25306396.0 \n",
      "Model_6_10500 \t loss_train = 28850526.0 \t loss_valid = 25314058.0 \n",
      "Model_6_10510 \t loss_train = 28812834.0 \t loss_valid = 25307140.0 \n",
      "Model_6_10520 \t loss_train = 28784930.0 \t loss_valid = 25296866.0 \n",
      "Model_6_10530 \t loss_train = 28930918.0 \t loss_valid = 25353220.0 \n",
      "Model_6_10540 \t loss_train = 28706512.0 \t loss_valid = 25287530.0 \n",
      "Model_6_10550 \t loss_train = 28882168.0 \t loss_valid = 25332564.0 \n",
      "Model_6_10560 \t loss_train = 28912996.0 \t loss_valid = 25331258.0 \n",
      "Model_6_10570 \t loss_train = 28739854.0 \t loss_valid = 25286126.0 \n",
      "Model_6_10580 \t loss_train = 28771092.0 \t loss_valid = 25293252.0 \n",
      "Model_6_10590 \t loss_train = 28627164.0 \t loss_valid = 25267222.0 \n",
      "Model_6_10600 \t loss_train = 28809768.0 \t loss_valid = 25302486.0 \n",
      "Model_6_10610 \t loss_train = 28947512.0 \t loss_valid = 25362268.0 \n",
      "Model_6_10620 \t loss_train = 28717450.0 \t loss_valid = 25284088.0 \n",
      "Model_6_10630 \t loss_train = 28618058.0 \t loss_valid = 25265292.0 \n",
      "Model_6_10640 \t loss_train = 28764636.0 \t loss_valid = 25290398.0 \n",
      "Model_6_10650 \t loss_train = 29011158.0 \t loss_valid = 25370926.0 \n",
      "Model_6_10660 \t loss_train = 28990348.0 \t loss_valid = 25382210.0 \n",
      "Model_6_10670 \t loss_train = 28718820.0 \t loss_valid = 25282970.0 \n",
      "Model_6_10680 \t loss_train = 28565664.0 \t loss_valid = 25260890.0 \n",
      "Model_6_10690 \t loss_train = 28796918.0 \t loss_valid = 25297728.0 \n",
      "Model_6_10700 \t loss_train = 28938136.0 \t loss_valid = 25336292.0 \n",
      "Model_6_10710 \t loss_train = 28800818.0 \t loss_valid = 25326916.0 \n",
      "Model_6_10720 \t loss_train = 28790666.0 \t loss_valid = 25307012.0 \n",
      "Model_6_10730 \t loss_train = 28601470.0 \t loss_valid = 25265142.0 \n",
      "Model_6_10740 \t loss_train = 28761708.0 \t loss_valid = 25292186.0 \n",
      "Model_6_10750 \t loss_train = 28714014.0 \t loss_valid = 25283556.0 \n",
      "Model_6_10760 \t loss_train = 28666342.0 \t loss_valid = 25277562.0 \n",
      "Model_6_10770 \t loss_train = 28896038.0 \t loss_valid = 25332192.0 \n",
      "Model_6_10780 \t loss_train = 28798736.0 \t loss_valid = 25299286.0 \n",
      "Model_6_10790 \t loss_train = 28731752.0 \t loss_valid = 25290784.0 \n",
      "Model_6_10800 \t loss_train = 28736168.0 \t loss_valid = 25294200.0 \n",
      "Model_6_10810 \t loss_train = 28691390.0 \t loss_valid = 25275646.0 \n",
      "Model_6_10820 \t loss_train = 28748690.0 \t loss_valid = 25288204.0 \n",
      "Model_6_10830 \t loss_train = 28959162.0 \t loss_valid = 25360208.0 \n",
      "Model_6_10840 \t loss_train = 28780190.0 \t loss_valid = 25300484.0 \n",
      "Model_6_10850 \t loss_train = 28721418.0 \t loss_valid = 25284528.0 \n",
      "Model_6_10860 \t loss_train = 28774800.0 \t loss_valid = 25294800.0 \n",
      "Model_6_10870 \t loss_train = 29046434.0 \t loss_valid = 25384374.0 \n",
      "Model_6_10880 \t loss_train = 28633828.0 \t loss_valid = 25268162.0 \n",
      "Model_6_10890 \t loss_train = 28776954.0 \t loss_valid = 25292302.0 \n",
      "Model_6_10900 \t loss_train = 28815490.0 \t loss_valid = 25311620.0 \n",
      "Model_6_10910 \t loss_train = 28743128.0 \t loss_valid = 25286056.0 \n",
      "Model_6_10920 \t loss_train = 28716896.0 \t loss_valid = 25287598.0 \n",
      "Model_6_10930 \t loss_train = 28961246.0 \t loss_valid = 25355780.0 \n",
      "Model_6_10940 \t loss_train = 28768652.0 \t loss_valid = 25291962.0 \n",
      "Model_6_10950 \t loss_train = 28577768.0 \t loss_valid = 25262468.0 \n",
      "Model_6_10960 \t loss_train = 28718888.0 \t loss_valid = 25285364.0 \n",
      "Model_6_10970 \t loss_train = 28934406.0 \t loss_valid = 25346336.0 \n",
      "Model_6_10980 \t loss_train = 28930630.0 \t loss_valid = 25346638.0 \n",
      "Model_6_10990 \t loss_train = 28636926.0 \t loss_valid = 25267718.0 \n",
      "Model_6_11000 \t loss_train = 28788046.0 \t loss_valid = 25310312.0 \n",
      "Model_6_11010 \t loss_train = 28709918.0 \t loss_valid = 25292822.0 \n",
      "Model_6_11020 \t loss_train = 28597574.0 \t loss_valid = 25263344.0 \n",
      "Model_6_11030 \t loss_train = 28643718.0 \t loss_valid = 25271112.0 \n",
      "Model_6_11040 \t loss_train = 28879670.0 \t loss_valid = 25336958.0 \n",
      "Model_6_11050 \t loss_train = 28781778.0 \t loss_valid = 25315708.0 \n",
      "Model_6_11060 \t loss_train = 28512788.0 \t loss_valid = 25255094.0 \n",
      "Model_6_11070 \t loss_train = 28519690.0 \t loss_valid = 25258268.0 \n",
      "Model_6_11080 \t loss_train = 28748150.0 \t loss_valid = 25292422.0 \n",
      "Model_6_11090 \t loss_train = 28705970.0 \t loss_valid = 25279770.0 \n",
      "Model_6_11100 \t loss_train = 28655236.0 \t loss_valid = 25277228.0 \n",
      "Model_6_11110 \t loss_train = 28636016.0 \t loss_valid = 25268084.0 \n",
      "Model_6_11120 \t loss_train = 28740158.0 \t loss_valid = 25291370.0 \n",
      "Model_6_11130 \t loss_train = 28626146.0 \t loss_valid = 25266722.0 \n",
      "Model_6_11140 \t loss_train = 28635392.0 \t loss_valid = 25266036.0 \n",
      "Model_6_11150 \t loss_train = 28661858.0 \t loss_valid = 25275502.0 \n",
      "Model_6_11160 \t loss_train = 28602910.0 \t loss_valid = 25262746.0 \n",
      "Model_6_11170 \t loss_train = 28785456.0 \t loss_valid = 25306396.0 \n",
      "Model_6_11180 \t loss_train = 28822058.0 \t loss_valid = 25325126.0 \n",
      "Model_6_11190 \t loss_train = 28873546.0 \t loss_valid = 25314474.0 \n",
      "Model_6_11200 \t loss_train = 28688066.0 \t loss_valid = 25276322.0 \n",
      "Model_6_11210 \t loss_train = 28617870.0 \t loss_valid = 25264044.0 \n",
      "Model_6_11220 \t loss_train = 28726994.0 \t loss_valid = 25282982.0 \n",
      "Model_6_11230 \t loss_train = 28603164.0 \t loss_valid = 25261600.0 \n",
      "Model_6_11240 \t loss_train = 28657374.0 \t loss_valid = 25270324.0 \n",
      "Model_6_11250 \t loss_train = 28927242.0 \t loss_valid = 25348288.0 \n",
      "Model_6_11260 \t loss_train = 28678956.0 \t loss_valid = 25279824.0 \n",
      "Model_6_11270 \t loss_train = 28500666.0 \t loss_valid = 25258622.0 \n",
      "Model_6_11280 \t loss_train = 28627782.0 \t loss_valid = 25267092.0 \n",
      "Model_6_11290 \t loss_train = 28739040.0 \t loss_valid = 25287068.0 \n",
      "Model_6_11300 \t loss_train = 28793640.0 \t loss_valid = 25329968.0 \n",
      "Model_6_11310 \t loss_train = 28480718.0 \t loss_valid = 25260852.0 \n",
      "Model_6_11320 \t loss_train = 28554954.0 \t loss_valid = 25257136.0 \n",
      "Model_6_11330 \t loss_train = 28666348.0 \t loss_valid = 25275718.0 \n",
      "Model_6_11340 \t loss_train = 28573192.0 \t loss_valid = 25274908.0 \n",
      "Model_6_11350 \t loss_train = 28585674.0 \t loss_valid = 25260630.0 \n",
      "Model_6_11360 \t loss_train = 28695392.0 \t loss_valid = 25279530.0 \n",
      "Model_6_11370 \t loss_train = 28590698.0 \t loss_valid = 25265650.0 \n",
      "Model_6_11380 \t loss_train = 28584044.0 \t loss_valid = 25262112.0 \n",
      "Model_6_11390 \t loss_train = 28609546.0 \t loss_valid = 25265468.0 \n",
      "Model_6_11400 \t loss_train = 28564222.0 \t loss_valid = 25261112.0 \n",
      "Model_6_11410 \t loss_train = 28538372.0 \t loss_valid = 25256430.0 \n",
      "Model_6_11420 \t loss_train = 28666930.0 \t loss_valid = 25276850.0 \n",
      "Model_6_11430 \t loss_train = 28558416.0 \t loss_valid = 25263508.0 \n",
      "Model_6_11440 \t loss_train = 28555678.0 \t loss_valid = 25258752.0 \n",
      "Model_6_11450 \t loss_train = 28705430.0 \t loss_valid = 25283760.0 \n",
      "Model_6_11460 \t loss_train = 28658366.0 \t loss_valid = 25269080.0 \n",
      "Model_6_11470 \t loss_train = 28579688.0 \t loss_valid = 25259448.0 \n",
      "Model_6_11480 \t loss_train = 28712882.0 \t loss_valid = 25287192.0 \n",
      "Model_6_11490 \t loss_train = 28615968.0 \t loss_valid = 25272076.0 \n",
      "Model_6_11500 \t loss_train = 28529106.0 \t loss_valid = 25254540.0 \n",
      "Model_6_11510 \t loss_train = 28558798.0 \t loss_valid = 25257150.0 \n",
      "Model_6_11520 \t loss_train = 28681248.0 \t loss_valid = 25283206.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_6_11530 \t loss_train = 28672114.0 \t loss_valid = 25276612.0 \n",
      "Model_6_11540 \t loss_train = 28493180.0 \t loss_valid = 25252494.0 \n",
      "Model_6_11550 \t loss_train = 28709526.0 \t loss_valid = 25280198.0 \n",
      "Model_6_11560 \t loss_train = 28586364.0 \t loss_valid = 25259944.0 \n",
      "Model_6_11570 \t loss_train = 28519108.0 \t loss_valid = 25255186.0 \n",
      "Model_6_11580 \t loss_train = 28704778.0 \t loss_valid = 25278612.0 \n",
      "Model_6_11590 \t loss_train = 28457646.0 \t loss_valid = 25252710.0 \n",
      "Model_6_11600 \t loss_train = 28445980.0 \t loss_valid = 25249886.0 \n",
      "Model_6_11610 \t loss_train = 28594844.0 \t loss_valid = 25260736.0 \n",
      "Model_6_11620 \t loss_train = 28602988.0 \t loss_valid = 25261662.0 \n",
      "Model_6_11630 \t loss_train = 28508044.0 \t loss_valid = 25255232.0 \n",
      "Model_6_11640 \t loss_train = 28625570.0 \t loss_valid = 25281260.0 \n",
      "Model_6_11650 \t loss_train = 28514316.0 \t loss_valid = 25255082.0 \n",
      "Model_6_11660 \t loss_train = 28619352.0 \t loss_valid = 25273370.0 \n",
      "Model_6_11670 \t loss_train = 28673142.0 \t loss_valid = 25285360.0 \n",
      "Model_6_11680 \t loss_train = 28392590.0 \t loss_valid = 25267952.0 \n",
      "Model_6_11690 \t loss_train = 28423430.0 \t loss_valid = 25252300.0 \n",
      "Model_6_11700 \t loss_train = 28638078.0 \t loss_valid = 25272032.0 \n",
      "Model_6_11710 \t loss_train = 28708954.0 \t loss_valid = 25293406.0 \n",
      "Model_6_11720 \t loss_train = 28674848.0 \t loss_valid = 25284124.0 \n",
      "Model_6_11730 \t loss_train = 28601400.0 \t loss_valid = 25261790.0 \n",
      "Model_6_11740 \t loss_train = 28491208.0 \t loss_valid = 25251760.0 \n",
      "Model_6_11750 \t loss_train = 28472876.0 \t loss_valid = 25250280.0 \n",
      "Model_6_11760 \t loss_train = 28371494.0 \t loss_valid = 25253976.0 \n",
      "Model_6_11770 \t loss_train = 28587672.0 \t loss_valid = 25260848.0 \n",
      "Model_6_11780 \t loss_train = 28575072.0 \t loss_valid = 25259570.0 \n",
      "Model_6_11790 \t loss_train = 28530232.0 \t loss_valid = 25254408.0 \n",
      "Model_6_11800 \t loss_train = 28716804.0 \t loss_valid = 25286728.0 \n",
      "Model_6_11810 \t loss_train = 28538408.0 \t loss_valid = 25254848.0 \n",
      "Model_6_11820 \t loss_train = 28450808.0 \t loss_valid = 25251742.0 \n",
      "Model_6_11830 \t loss_train = 28586784.0 \t loss_valid = 25265648.0 \n",
      "Model_6_11840 \t loss_train = 28640140.0 \t loss_valid = 25267074.0 \n",
      "Model_6_11850 \t loss_train = 28418330.0 \t loss_valid = 25261186.0 \n",
      "Model_6_11860 \t loss_train = 28507708.0 \t loss_valid = 25253724.0 \n",
      "Model_6_11870 \t loss_train = 28877180.0 \t loss_valid = 25344884.0 \n",
      "Model_6_11880 \t loss_train = 28482884.0 \t loss_valid = 25252214.0 \n",
      "Model_6_11890 \t loss_train = 28411970.0 \t loss_valid = 25259614.0 \n",
      "Model_6_11900 \t loss_train = 28508790.0 \t loss_valid = 25254004.0 \n",
      "Model_6_11910 \t loss_train = 28539398.0 \t loss_valid = 25262408.0 \n",
      "Model_6_11920 \t loss_train = 28453698.0 \t loss_valid = 25250050.0 \n",
      "Model_6_11930 \t loss_train = 28445542.0 \t loss_valid = 25262696.0 \n",
      "Model_6_11940 \t loss_train = 28600162.0 \t loss_valid = 25266290.0 \n",
      "Model_6_11950 \t loss_train = 28508370.0 \t loss_valid = 25256274.0 \n",
      "Model_6_11960 \t loss_train = 28485518.0 \t loss_valid = 25251144.0 \n",
      "Model_6_11970 \t loss_train = 28654106.0 \t loss_valid = 25270236.0 \n",
      "Model_6_11980 \t loss_train = 28589862.0 \t loss_valid = 25267596.0 \n",
      "Model_6_11990 \t loss_train = 28437140.0 \t loss_valid = 25250150.0 \n",
      "Model_6_12000 \t loss_train = 28469432.0 \t loss_valid = 25250030.0 \n",
      "Model_6_12010 \t loss_train = 28580480.0 \t loss_valid = 25259778.0 \n",
      "Model_6_12020 \t loss_train = 28603926.0 \t loss_valid = 25272842.0 \n",
      "Model_6_12030 \t loss_train = 28594798.0 \t loss_valid = 25260962.0 \n",
      "Model_6_12040 \t loss_train = 28514230.0 \t loss_valid = 25253040.0 \n",
      "Model_6_12050 \t loss_train = 28422280.0 \t loss_valid = 25249994.0 \n",
      "Model_6_12060 \t loss_train = 28590174.0 \t loss_valid = 25259542.0 \n",
      "Model_6_12070 \t loss_train = 28438312.0 \t loss_valid = 25249146.0 \n",
      "Model_6_12080 \t loss_train = 28439150.0 \t loss_valid = 25249704.0 \n",
      "Model_6_12090 \t loss_train = 28571032.0 \t loss_valid = 25257562.0 \n",
      "Model_6_12100 \t loss_train = 28535150.0 \t loss_valid = 25253542.0 \n",
      "Model_6_12110 \t loss_train = 28393422.0 \t loss_valid = 25249962.0 \n",
      "Model_6_12120 \t loss_train = 28419812.0 \t loss_valid = 25249754.0 \n",
      "Model_6_12130 \t loss_train = 28476152.0 \t loss_valid = 25250972.0 \n",
      "Model_6_12140 \t loss_train = 28540228.0 \t loss_valid = 25255834.0 \n",
      "Model_6_12150 \t loss_train = 28348788.0 \t loss_valid = 25257618.0 \n",
      "Model_6_12160 \t loss_train = 28569424.0 \t loss_valid = 25259440.0 \n",
      "Model_6_12170 \t loss_train = 28686114.0 \t loss_valid = 25281072.0 \n",
      "Model_6_12180 \t loss_train = 28252704.0 \t loss_valid = 25276106.0 \n",
      "Model_6_12190 \t loss_train = 28611608.0 \t loss_valid = 25263304.0 \n",
      "Model_6_12200 \t loss_train = 28549364.0 \t loss_valid = 25255992.0 \n",
      "Model_6_12210 \t loss_train = 28461212.0 \t loss_valid = 25249540.0 \n",
      "Model_6_12220 \t loss_train = 28466734.0 \t loss_valid = 25249872.0 \n",
      "Model_6_12230 \t loss_train = 28488004.0 \t loss_valid = 25251584.0 \n",
      "Model_6_12240 \t loss_train = 28529800.0 \t loss_valid = 25256046.0 \n",
      "Model_6_12250 \t loss_train = 28540862.0 \t loss_valid = 25254426.0 \n",
      "Model_6_12260 \t loss_train = 28568980.0 \t loss_valid = 25266052.0 \n",
      "Model_6_12270 \t loss_train = 28392254.0 \t loss_valid = 25249856.0 \n",
      "Model_6_12280 \t loss_train = 28450450.0 \t loss_valid = 25249592.0 \n",
      "Model_6_12290 \t loss_train = 28677058.0 \t loss_valid = 25278122.0 \n",
      "Model_6_12300 \t loss_train = 28365736.0 \t loss_valid = 25253124.0 \n",
      "Model_6_12310 \t loss_train = 28452690.0 \t loss_valid = 25249406.0 \n",
      "Model_6_12320 \t loss_train = 28544736.0 \t loss_valid = 25255540.0 \n",
      "Model_6_12330 \t loss_train = 28382792.0 \t loss_valid = 25251572.0 \n",
      "Model_6_12340 \t loss_train = 28535066.0 \t loss_valid = 25253772.0 \n",
      "Model_6_12350 \t loss_train = 28506182.0 \t loss_valid = 25251512.0 \n",
      "Model_6_12360 \t loss_train = 28535722.0 \t loss_valid = 25257446.0 \n",
      "Model_6_12370 \t loss_train = 28355790.0 \t loss_valid = 25261192.0 \n",
      "Model_6_12380 \t loss_train = 28463416.0 \t loss_valid = 25249232.0 \n",
      "Model_6_12390 \t loss_train = 28415068.0 \t loss_valid = 25248840.0 \n",
      "Model_6_12400 \t loss_train = 28591388.0 \t loss_valid = 25265080.0 \n",
      "Model_6_12410 \t loss_train = 28680170.0 \t loss_valid = 25279864.0 \n",
      "Model_6_12420 \t loss_train = 28389052.0 \t loss_valid = 25258702.0 \n",
      "Model_6_12430 \t loss_train = 28388792.0 \t loss_valid = 25251372.0 \n",
      "Model_6_12440 \t loss_train = 28417158.0 \t loss_valid = 25250390.0 \n",
      "Model_6_12450 \t loss_train = 28528110.0 \t loss_valid = 25253522.0 \n",
      "Model_6_12460 \t loss_train = 28320960.0 \t loss_valid = 25261974.0 \n",
      "Model_6_12470 \t loss_train = 28556776.0 \t loss_valid = 25259620.0 \n",
      "Model_6_12480 \t loss_train = 28510218.0 \t loss_valid = 25251660.0 \n",
      "Model_6_12490 \t loss_train = 28469956.0 \t loss_valid = 25255164.0 \n",
      "Model_6_12500 \t loss_train = 28418342.0 \t loss_valid = 25249924.0 \n",
      "Model_6_12510 \t loss_train = 28545898.0 \t loss_valid = 25254978.0 \n",
      "Model_6_12520 \t loss_train = 28418400.0 \t loss_valid = 25248494.0 \n",
      "Model_6_12530 \t loss_train = 28445606.0 \t loss_valid = 25252438.0 \n",
      "Model_6_12540 \t loss_train = 28437990.0 \t loss_valid = 25250130.0 \n",
      "Model_6_12550 \t loss_train = 28385232.0 \t loss_valid = 25254860.0 \n",
      "Model_6_12560 \t loss_train = 28545156.0 \t loss_valid = 25257288.0 \n",
      "Model_6_12570 \t loss_train = 28376126.0 \t loss_valid = 25250436.0 \n",
      "Model_6_12580 \t loss_train = 28377130.0 \t loss_valid = 25251264.0 \n",
      "Model_6_12590 \t loss_train = 28548162.0 \t loss_valid = 25257668.0 \n",
      "Model_6_12600 \t loss_train = 28413698.0 \t loss_valid = 25255564.0 \n",
      "Model_6_12610 \t loss_train = 28402584.0 \t loss_valid = 25249358.0 \n",
      "Model_6_12620 \t loss_train = 28440656.0 \t loss_valid = 25249240.0 \n",
      "Model_6_12630 \t loss_train = 28450686.0 \t loss_valid = 25249988.0 \n",
      "Model_6_12640 \t loss_train = 28356772.0 \t loss_valid = 25263974.0 \n",
      "Model_6_12650 \t loss_train = 28601726.0 \t loss_valid = 25274520.0 \n",
      "Model_6_12660 \t loss_train = 28299356.0 \t loss_valid = 25258198.0 \n",
      "Model_6_12670 \t loss_train = 28521332.0 \t loss_valid = 25253476.0 \n",
      "Model_6_12680 \t loss_train = 28455904.0 \t loss_valid = 25251784.0 \n",
      "Model_6_12690 \t loss_train = 28423114.0 \t loss_valid = 25250768.0 \n",
      "Model_6_12700 \t loss_train = 28437308.0 \t loss_valid = 25250950.0 \n",
      "Model_6_12710 \t loss_train = 28368344.0 \t loss_valid = 25252870.0 \n",
      "Model_6_12720 \t loss_train = 28379042.0 \t loss_valid = 25254134.0 \n",
      "Model_6_12730 \t loss_train = 28479702.0 \t loss_valid = 25252846.0 \n",
      "Model_6_12740 \t loss_train = 28454318.0 \t loss_valid = 25251128.0 \n",
      "Model_6_12750 \t loss_train = 28535936.0 \t loss_valid = 25254350.0 \n",
      "Model_6_12760 \t loss_train = 28469846.0 \t loss_valid = 25250074.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_6_12770 \t loss_train = 28375018.0 \t loss_valid = 25252072.0 \n",
      "Model_6_12780 \t loss_train = 28481684.0 \t loss_valid = 25250536.0 \n",
      "Model_6_12790 \t loss_train = 28436502.0 \t loss_valid = 25249360.0 \n",
      "Model_6_12800 \t loss_train = 28389616.0 \t loss_valid = 25250064.0 \n",
      "Model_6_12810 \t loss_train = 28469432.0 \t loss_valid = 25250174.0 \n",
      "Model_6_12820 \t loss_train = 28474770.0 \t loss_valid = 25250232.0 \n",
      "Model_6_12830 \t loss_train = 28505292.0 \t loss_valid = 25256770.0 \n",
      "Model_6_12840 \t loss_train = 28462002.0 \t loss_valid = 25249654.0 \n",
      "Model_6_12850 \t loss_train = 28437858.0 \t loss_valid = 25248376.0 \n",
      "Model_6_12860 \t loss_train = 28361298.0 \t loss_valid = 25254304.0 \n",
      "Model_6_12870 \t loss_train = 28477212.0 \t loss_valid = 25250138.0 \n",
      "Model_6_12880 \t loss_train = 28418596.0 \t loss_valid = 25250064.0 \n",
      "Model_6_12890 \t loss_train = 28553760.0 \t loss_valid = 25255286.0 \n",
      "Model_6_12900 \t loss_train = 28466764.0 \t loss_valid = 25251966.0 \n",
      "Model_6_12910 \t loss_train = 28259370.0 \t loss_valid = 25271536.0 \n",
      "Model_6_12920 \t loss_train = 28644736.0 \t loss_valid = 25278256.0 \n",
      "Model_6_12930 \t loss_train = 28360166.0 \t loss_valid = 25251074.0 \n",
      "Model_6_12940 \t loss_train = 28345248.0 \t loss_valid = 25253432.0 \n",
      "Model_6_12950 \t loss_train = 28386330.0 \t loss_valid = 25250180.0 \n",
      "Model_6_12960 \t loss_train = 28377344.0 \t loss_valid = 25261228.0 \n",
      "Model_6_12970 \t loss_train = 28556424.0 \t loss_valid = 25268446.0 \n",
      "Model_6_12980 \t loss_train = 28386612.0 \t loss_valid = 25252212.0 \n",
      "Model_6_12990 \t loss_train = 28425392.0 \t loss_valid = 25250488.0 \n",
      "Model_6_13000 \t loss_train = 28440150.0 \t loss_valid = 25248620.0 \n",
      "Model_6_13010 \t loss_train = 28465256.0 \t loss_valid = 25249402.0 \n",
      "Model_6_13020 \t loss_train = 28464528.0 \t loss_valid = 25251642.0 \n",
      "Model_6_13030 \t loss_train = 28313030.0 \t loss_valid = 25261060.0 \n",
      "Model_6_13040 \t loss_train = 28547278.0 \t loss_valid = 25269054.0 \n",
      "Model_6_13050 \t loss_train = 28363860.0 \t loss_valid = 25252040.0 \n",
      "Model_6_13060 \t loss_train = 28343804.0 \t loss_valid = 25254450.0 \n",
      "Model_6_13070 \t loss_train = 28478028.0 \t loss_valid = 25251628.0 \n",
      "Model_6_13080 \t loss_train = 28367824.0 \t loss_valid = 25253492.0 \n",
      "Model_6_13090 \t loss_train = 28397914.0 \t loss_valid = 25249972.0 \n",
      "Model_6_13100 \t loss_train = 28453000.0 \t loss_valid = 25249052.0 \n",
      "Model_6_13110 \t loss_train = 28240146.0 \t loss_valid = 25278294.0 \n",
      "Model_6_13120 \t loss_train = 28539686.0 \t loss_valid = 25258176.0 \n",
      "Model_6_13130 \t loss_train = 28299090.0 \t loss_valid = 25266742.0 \n",
      "Model_6_13140 \t loss_train = 28403542.0 \t loss_valid = 25249698.0 \n",
      "Model_6_13150 \t loss_train = 28330988.0 \t loss_valid = 25253840.0 \n",
      "Model_6_13160 \t loss_train = 28396670.0 \t loss_valid = 25249726.0 \n",
      "Model_6_13170 \t loss_train = 28377780.0 \t loss_valid = 25253588.0 \n",
      "Model_6_13180 \t loss_train = 28252526.0 \t loss_valid = 25271540.0 \n",
      "Model_6_13190 \t loss_train = 28472712.0 \t loss_valid = 25251680.0 \n",
      "Model_6_13200 \t loss_train = 28311102.0 \t loss_valid = 25264290.0 \n",
      "Model_6_13210 \t loss_train = 28463664.0 \t loss_valid = 25249274.0 \n",
      "Model_6_13220 \t loss_train = 28363172.0 \t loss_valid = 25253172.0 \n",
      "Model_6_13230 \t loss_train = 28421772.0 \t loss_valid = 25249090.0 \n",
      "Model_6_13240 \t loss_train = 28432030.0 \t loss_valid = 25249298.0 \n",
      "Model_6_13250 \t loss_train = 28262896.0 \t loss_valid = 25272656.0 \n",
      "Model_6_13260 \t loss_train = 28393030.0 \t loss_valid = 25250918.0 \n",
      "Model_6_13270 \t loss_train = 28393322.0 \t loss_valid = 25249498.0 \n",
      "Model_6_13280 \t loss_train = 28429128.0 \t loss_valid = 25249472.0 \n",
      "Model_6_13290 \t loss_train = 28372676.0 \t loss_valid = 25250226.0 \n",
      "Model_6_13300 \t loss_train = 28317988.0 \t loss_valid = 25261202.0 \n",
      "Model_6_13310 \t loss_train = 28352142.0 \t loss_valid = 25261328.0 \n",
      "Model_6_13320 \t loss_train = 28382302.0 \t loss_valid = 25270382.0 \n",
      "Model_6_13330 \t loss_train = 28408658.0 \t loss_valid = 25248984.0 \n",
      "Model_6_13340 \t loss_train = 28358924.0 \t loss_valid = 25253766.0 \n",
      "Model_6_13350 \t loss_train = 28397846.0 \t loss_valid = 25253158.0 \n",
      "Model_6_13360 \t loss_train = 28437846.0 \t loss_valid = 25251378.0 \n",
      "Model_6_13370 \t loss_train = 28341208.0 \t loss_valid = 25253320.0 \n",
      "Model_6_13380 \t loss_train = 28343742.0 \t loss_valid = 25254580.0 \n",
      "Model_6_13390 \t loss_train = 28385580.0 \t loss_valid = 25252552.0 \n",
      "Model_6_13400 \t loss_train = 28446774.0 \t loss_valid = 25248976.0 \n",
      "Model_6_13410 \t loss_train = 28331356.0 \t loss_valid = 25261216.0 \n",
      "Model_6_13420 \t loss_train = 28431482.0 \t loss_valid = 25250826.0 \n",
      "Model_6_13430 \t loss_train = 28311014.0 \t loss_valid = 25270258.0 \n",
      "Model_6_13440 \t loss_train = 28357294.0 \t loss_valid = 25257690.0 \n",
      "Model_6_13450 \t loss_train = 28340012.0 \t loss_valid = 25255816.0 \n",
      "Model_6_13460 \t loss_train = 28304664.0 \t loss_valid = 25257080.0 \n",
      "Model_6_13470 \t loss_train = 28394388.0 \t loss_valid = 25250686.0 \n",
      "Model_6_13480 \t loss_train = 28361654.0 \t loss_valid = 25251196.0 \n",
      "Model_6_13490 \t loss_train = 28344128.0 \t loss_valid = 25252916.0 \n",
      "Model_6_13500 \t loss_train = 28381614.0 \t loss_valid = 25252218.0 \n",
      "Model_6_13510 \t loss_train = 28434574.0 \t loss_valid = 25248568.0 \n",
      "Model_6_13520 \t loss_train = 28315884.0 \t loss_valid = 25255480.0 \n",
      "Model_6_13530 \t loss_train = 28278990.0 \t loss_valid = 25266808.0 \n",
      "Model_6_13540 \t loss_train = 28348202.0 \t loss_valid = 25252852.0 \n",
      "Model_6_13550 \t loss_train = 28317128.0 \t loss_valid = 25257936.0 \n",
      "Model_6_13560 \t loss_train = 28458740.0 \t loss_valid = 25249886.0 \n",
      "Model_6_13570 \t loss_train = 28367202.0 \t loss_valid = 25252232.0 \n",
      "Model_6_13580 \t loss_train = 28251188.0 \t loss_valid = 25294042.0 \n",
      "Model_6_13590 \t loss_train = 28520622.0 \t loss_valid = 25253948.0 \n",
      "Model_6_13600 \t loss_train = 28297242.0 \t loss_valid = 25269714.0 \n",
      "Model_6_13610 \t loss_train = 28358474.0 \t loss_valid = 25251850.0 \n",
      "Model_6_13620 \t loss_train = 28381636.0 \t loss_valid = 25251120.0 \n",
      "Model_6_13630 \t loss_train = 28191292.0 \t loss_valid = 25294390.0 \n",
      "Model_6_13640 \t loss_train = 28351738.0 \t loss_valid = 25252800.0 \n",
      "Model_6_13650 \t loss_train = 28453766.0 \t loss_valid = 25248932.0 \n",
      "Model_6_13660 \t loss_train = 28211706.0 \t loss_valid = 25294374.0 \n",
      "Model_6_13670 \t loss_train = 28436538.0 \t loss_valid = 25248534.0 \n",
      "Model_6_13680 \t loss_train = 28287782.0 \t loss_valid = 25262750.0 \n",
      "Model_6_13690 \t loss_train = 28427656.0 \t loss_valid = 25248432.0 \n",
      "Model_6_13700 \t loss_train = 28305032.0 \t loss_valid = 25267304.0 \n",
      "Model_6_13710 \t loss_train = 28299158.0 \t loss_valid = 25258366.0 \n",
      "Model_6_13720 \t loss_train = 28411908.0 \t loss_valid = 25249634.0 \n",
      "Model_6_13730 \t loss_train = 28339012.0 \t loss_valid = 25253900.0 \n",
      "Model_6_13740 \t loss_train = 28349744.0 \t loss_valid = 25252810.0 \n",
      "Model_6_13750 \t loss_train = 28443416.0 \t loss_valid = 25248300.0 \n",
      "Model_6_13760 \t loss_train = 28295066.0 \t loss_valid = 25260872.0 \n",
      "Model_6_13770 \t loss_train = 28322428.0 \t loss_valid = 25254628.0 \n",
      "Model_6_13780 \t loss_train = 28321368.0 \t loss_valid = 25253792.0 \n",
      "Model_6_13790 \t loss_train = 28348880.0 \t loss_valid = 25259160.0 \n",
      "Model_6_13800 \t loss_train = 28428820.0 \t loss_valid = 25248756.0 \n",
      "Model_6_13810 \t loss_train = 28308176.0 \t loss_valid = 25258500.0 \n",
      "Model_6_13820 \t loss_train = 28299758.0 \t loss_valid = 25260938.0 \n",
      "Model_6_13830 \t loss_train = 28377630.0 \t loss_valid = 25250946.0 \n",
      "Model_6_13840 \t loss_train = 28441740.0 \t loss_valid = 25248844.0 \n",
      "Model_6_13850 \t loss_train = 28251412.0 \t loss_valid = 25272554.0 \n",
      "Model_6_13860 \t loss_train = 28388992.0 \t loss_valid = 25249472.0 \n",
      "Model_6_13870 \t loss_train = 28367868.0 \t loss_valid = 25250720.0 \n",
      "Model_6_13880 \t loss_train = 28403554.0 \t loss_valid = 25251948.0 \n",
      "Model_6_13890 \t loss_train = 28328182.0 \t loss_valid = 25255358.0 \n",
      "Model_6_13900 \t loss_train = 28310410.0 \t loss_valid = 25259972.0 \n",
      "Model_6_13910 \t loss_train = 28417550.0 \t loss_valid = 25248710.0 \n",
      "Model_6_13920 \t loss_train = 28307534.0 \t loss_valid = 25255888.0 \n",
      "Model_6_13930 \t loss_train = 28341082.0 \t loss_valid = 25252190.0 \n",
      "Model_6_13940 \t loss_train = 28397022.0 \t loss_valid = 25249184.0 \n",
      "Model_6_13950 \t loss_train = 28364148.0 \t loss_valid = 25252168.0 \n",
      "Model_6_13960 \t loss_train = 28394662.0 \t loss_valid = 25249280.0 \n",
      "Model_6_13970 \t loss_train = 28315760.0 \t loss_valid = 25266316.0 \n",
      "Model_6_13980 \t loss_train = 28335718.0 \t loss_valid = 25252438.0 \n",
      "Model_6_13990 \t loss_train = 28353408.0 \t loss_valid = 25251246.0 \n",
      "Model_6_14000 \t loss_train = 28547814.0 \t loss_valid = 25255358.0 \n",
      "Model_6_14010 \t loss_train = 28239694.0 \t loss_valid = 25290002.0 \n",
      "Model_6_14020 \t loss_train = 28280106.0 \t loss_valid = 25262622.0 \n",
      "Model_6_14030 \t loss_train = 28282824.0 \t loss_valid = 25262860.0 \n",
      "Model_6_14040 \t loss_train = 28369510.0 \t loss_valid = 25256738.0 \n",
      "Model_6_14050 \t loss_train = 28286054.0 \t loss_valid = 25265494.0 \n",
      "Model_6_14060 \t loss_train = 28310546.0 \t loss_valid = 25256422.0 \n",
      "Model_6_14070 \t loss_train = 28385604.0 \t loss_valid = 25249630.0 \n",
      "Model_6_14080 \t loss_train = 28435954.0 \t loss_valid = 25248598.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_6_14090 \t loss_train = 28309002.0 \t loss_valid = 25260152.0 \n",
      "Model_6_14100 \t loss_train = 28360300.0 \t loss_valid = 25261616.0 \n",
      "Model_6_14110 \t loss_train = 28286410.0 \t loss_valid = 25267234.0 \n",
      "Model_6_14120 \t loss_train = 28316072.0 \t loss_valid = 25255184.0 \n",
      "Model_6_14130 \t loss_train = 28276484.0 \t loss_valid = 25266818.0 \n",
      "Model_6_14140 \t loss_train = 28265964.0 \t loss_valid = 25271194.0 \n",
      "Model_6_14150 \t loss_train = 28397590.0 \t loss_valid = 25248870.0 \n",
      "Model_6_14160 \t loss_train = 28254902.0 \t loss_valid = 25273408.0 \n",
      "Model_6_14170 \t loss_train = 28382292.0 \t loss_valid = 25250162.0 \n",
      "Model_6_14180 \t loss_train = 28357882.0 \t loss_valid = 25250864.0 \n",
      "Model_6_14190 \t loss_train = 28243822.0 \t loss_valid = 25275380.0 \n",
      "Model_6_14200 \t loss_train = 28418736.0 \t loss_valid = 25248722.0 \n",
      "Model_6_14210 \t loss_train = 28242860.0 \t loss_valid = 25278680.0 \n",
      "Model_6_14220 \t loss_train = 28281652.0 \t loss_valid = 25260254.0 \n",
      "Model_6_14230 \t loss_train = 28379064.0 \t loss_valid = 25249558.0 \n",
      "Model_6_14240 \t loss_train = 28262350.0 \t loss_valid = 25267654.0 \n",
      "Model_6_14250 \t loss_train = 28418932.0 \t loss_valid = 25248794.0 \n",
      "Model_6_14260 \t loss_train = 28295718.0 \t loss_valid = 25265790.0 \n",
      "Model_6_14270 \t loss_train = 28278000.0 \t loss_valid = 25270598.0 \n",
      "Model_6_14280 \t loss_train = 28414246.0 \t loss_valid = 25250392.0 \n",
      "Model_6_14290 \t loss_train = 28244828.0 \t loss_valid = 25273970.0 \n",
      "Model_6_14300 \t loss_train = 28348194.0 \t loss_valid = 25251934.0 \n",
      "Model_6_14310 \t loss_train = 28386168.0 \t loss_valid = 25249536.0 \n",
      "Model_6_14320 \t loss_train = 28276594.0 \t loss_valid = 25266082.0 \n",
      "Model_6_14330 \t loss_train = 28303334.0 \t loss_valid = 25257424.0 \n",
      "Model_6_14340 \t loss_train = 28387464.0 \t loss_valid = 25249394.0 \n",
      "Model_6_14350 \t loss_train = 28259156.0 \t loss_valid = 25276646.0 \n",
      "Model_6_14360 \t loss_train = 28358502.0 \t loss_valid = 25252512.0 \n",
      "Model_6_14370 \t loss_train = 28279258.0 \t loss_valid = 25261644.0 \n",
      "Model_6_14380 \t loss_train = 28356022.0 \t loss_valid = 25251800.0 \n",
      "Model_6_14390 \t loss_train = 28324542.0 \t loss_valid = 25261896.0 \n",
      "Model_6_14400 \t loss_train = 28375580.0 \t loss_valid = 25251066.0 \n",
      "Model_6_14410 \t loss_train = 28368288.0 \t loss_valid = 25254244.0 \n",
      "Model_6_14420 \t loss_train = 28275006.0 \t loss_valid = 25274298.0 \n",
      "Model_6_14430 \t loss_train = 28341348.0 \t loss_valid = 25256090.0 \n",
      "Model_6_14440 \t loss_train = 28270612.0 \t loss_valid = 25266726.0 \n",
      "Model_6_14450 \t loss_train = 28446202.0 \t loss_valid = 25249036.0 \n",
      "Model_6_14460 \t loss_train = 28331290.0 \t loss_valid = 25253246.0 \n",
      "Model_6_14470 \t loss_train = 28262716.0 \t loss_valid = 25271120.0 \n",
      "Model_6_14480 \t loss_train = 28351606.0 \t loss_valid = 25252198.0 \n",
      "Model_6_14490 \t loss_train = 28310342.0 \t loss_valid = 25255826.0 \n",
      "Model_6_14500 \t loss_train = 28237994.0 \t loss_valid = 25270712.0 \n",
      "Model_6_14510 \t loss_train = 28412054.0 \t loss_valid = 25248530.0 \n",
      "Model_6_14520 \t loss_train = 28278428.0 \t loss_valid = 25278914.0 \n",
      "Model_6_14530 \t loss_train = 28308720.0 \t loss_valid = 25262106.0 \n",
      "Model_6_14540 \t loss_train = 28316088.0 \t loss_valid = 25255912.0 \n",
      "Model_6_14550 \t loss_train = 28344150.0 \t loss_valid = 25253922.0 \n",
      "Model_6_14560 \t loss_train = 28273196.0 \t loss_valid = 25264816.0 \n",
      "Model_6_14570 \t loss_train = 28418972.0 \t loss_valid = 25249900.0 \n",
      "Model_6_14580 \t loss_train = 28277298.0 \t loss_valid = 25269020.0 \n",
      "Model_6_14590 \t loss_train = 28220484.0 \t loss_valid = 25277966.0 \n",
      "Model_6_14600 \t loss_train = 28301036.0 \t loss_valid = 25258198.0 \n",
      "Model_6_14610 \t loss_train = 28310238.0 \t loss_valid = 25258500.0 \n",
      "Model_6_14620 \t loss_train = 28315602.0 \t loss_valid = 25256702.0 \n",
      "Model_6_14630 \t loss_train = 28219382.0 \t loss_valid = 25292216.0 \n",
      "Model_6_14640 \t loss_train = 28391258.0 \t loss_valid = 25248666.0 \n",
      "Model_6_14650 \t loss_train = 28224188.0 \t loss_valid = 25273908.0 \n",
      "Model_6_14660 \t loss_train = 28291300.0 \t loss_valid = 25257828.0 \n",
      "Model_6_14670 \t loss_train = 28377432.0 \t loss_valid = 25249770.0 \n",
      "Model_6_14680 \t loss_train = 28202576.0 \t loss_valid = 25308854.0 \n",
      "Model_6_14690 \t loss_train = 28346762.0 \t loss_valid = 25253900.0 \n",
      "Model_6_14700 \t loss_train = 28354136.0 \t loss_valid = 25251274.0 \n",
      "Model_6_14710 \t loss_train = 28207988.0 \t loss_valid = 25288532.0 \n",
      "Model_6_14720 \t loss_train = 28394464.0 \t loss_valid = 25249344.0 \n",
      "Model_6_14730 \t loss_train = 28218964.0 \t loss_valid = 25286866.0 \n",
      "Model_6_14740 \t loss_train = 28334842.0 \t loss_valid = 25257906.0 \n",
      "Model_6_14750 \t loss_train = 28263712.0 \t loss_valid = 25266544.0 \n",
      "Model_6_14760 \t loss_train = 28353566.0 \t loss_valid = 25251900.0 \n",
      "Model_6_14770 \t loss_train = 28249412.0 \t loss_valid = 25271368.0 \n",
      "Model_6_14780 \t loss_train = 28328846.0 \t loss_valid = 25255070.0 \n",
      "Model_6_14790 \t loss_train = 28463722.0 \t loss_valid = 25250948.0 \n",
      "Model_6_14800 \t loss_train = 28172522.0 \t loss_valid = 25305272.0 \n",
      "Model_6_14810 \t loss_train = 28427876.0 \t loss_valid = 25248658.0 \n",
      "Model_6_14820 \t loss_train = 28338008.0 \t loss_valid = 25254400.0 \n",
      "Model_6_14830 \t loss_train = 28229924.0 \t loss_valid = 25290276.0 \n",
      "Model_6_14840 \t loss_train = 28399770.0 \t loss_valid = 25249442.0 \n",
      "Model_6_14850 \t loss_train = 28307498.0 \t loss_valid = 25259962.0 \n",
      "Model_6_14860 \t loss_train = 28319296.0 \t loss_valid = 25255156.0 \n",
      "Model_6_14870 \t loss_train = 28258616.0 \t loss_valid = 25268360.0 \n",
      "Model_6_14880 \t loss_train = 28263138.0 \t loss_valid = 25269840.0 \n",
      "Model_6_14890 \t loss_train = 28238294.0 \t loss_valid = 25276628.0 \n",
      "Model_6_14900 \t loss_train = 28304290.0 \t loss_valid = 25260550.0 \n",
      "Model_6_14910 \t loss_train = 28387862.0 \t loss_valid = 25249644.0 \n",
      "Model_6_14920 \t loss_train = 28228046.0 \t loss_valid = 25280560.0 \n",
      "Model_6_14930 \t loss_train = 28304310.0 \t loss_valid = 25256912.0 \n",
      "Model_6_14940 \t loss_train = 28327760.0 \t loss_valid = 25253816.0 \n",
      "Model_6_14950 \t loss_train = 28334422.0 \t loss_valid = 25254150.0 \n",
      "Model_6_14960 \t loss_train = 28223742.0 \t loss_valid = 25287380.0 \n",
      "Model_6_14970 \t loss_train = 28408094.0 \t loss_valid = 25248998.0 \n",
      "Model_6_14980 \t loss_train = 28223964.0 \t loss_valid = 25276470.0 \n",
      "Model_6_14990 \t loss_train = 28249342.0 \t loss_valid = 25275828.0 \n",
      "Model_6_15000 \t loss_train = 28398030.0 \t loss_valid = 25248560.0 \n",
      "Model_6_15010 \t loss_train = 28222778.0 \t loss_valid = 25280818.0 \n",
      "Model_6_15020 \t loss_train = 28320376.0 \t loss_valid = 25254222.0 \n",
      "Model_6_15030 \t loss_train = 28204154.0 \t loss_valid = 25295048.0 \n",
      "Model_6_15040 \t loss_train = 28282188.0 \t loss_valid = 25259814.0 \n",
      "Model_6_15050 \t loss_train = 28346712.0 \t loss_valid = 25250834.0 \n",
      "Model_6_15060 \t loss_train = 28293636.0 \t loss_valid = 25270952.0 \n",
      "Model_6_15070 \t loss_train = 28277758.0 \t loss_valid = 25271496.0 \n",
      "Model_6_15080 \t loss_train = 28296772.0 \t loss_valid = 25258416.0 \n",
      "Model_6_15090 \t loss_train = 28321108.0 \t loss_valid = 25255092.0 \n",
      "Model_6_15100 \t loss_train = 28260232.0 \t loss_valid = 25269760.0 \n",
      "Model_6_15110 \t loss_train = 28236680.0 \t loss_valid = 25277378.0 \n",
      "Model_6_15120 \t loss_train = 28287152.0 \t loss_valid = 25261760.0 \n",
      "Model_6_15130 \t loss_train = 28266694.0 \t loss_valid = 25268340.0 \n",
      "Model_6_15140 \t loss_train = 28279846.0 \t loss_valid = 25260248.0 \n",
      "Model_6_15150 \t loss_train = 28271160.0 \t loss_valid = 25261738.0 \n",
      "Model_6_15160 \t loss_train = 28333872.0 \t loss_valid = 25252704.0 \n",
      "Model_6_15170 \t loss_train = 28259056.0 \t loss_valid = 25263240.0 \n",
      "Model_6_15180 \t loss_train = 28352014.0 \t loss_valid = 25250598.0 \n",
      "Model_6_15190 \t loss_train = 28233284.0 \t loss_valid = 25278398.0 \n",
      "Model_6_15200 \t loss_train = 28253662.0 \t loss_valid = 25271624.0 \n",
      "Model_6_15210 \t loss_train = 28308164.0 \t loss_valid = 25256524.0 \n",
      "Model_6_15220 \t loss_train = 28335266.0 \t loss_valid = 25252576.0 \n",
      "Model_6_15230 \t loss_train = 28297282.0 \t loss_valid = 25260898.0 \n",
      "Model_6_15240 \t loss_train = 28359564.0 \t loss_valid = 25251602.0 \n",
      "Model_6_15250 \t loss_train = 28263112.0 \t loss_valid = 25264966.0 \n",
      "Model_6_15260 \t loss_train = 28249760.0 \t loss_valid = 25276390.0 \n",
      "Model_6_15270 \t loss_train = 28301682.0 \t loss_valid = 25262156.0 \n",
      "Model_6_15280 \t loss_train = 28246614.0 \t loss_valid = 25272324.0 \n",
      "Model_6_15290 \t loss_train = 28287148.0 \t loss_valid = 25262744.0 \n",
      "Model_6_15300 \t loss_train = 28236950.0 \t loss_valid = 25281826.0 \n",
      "Model_6_15310 \t loss_train = 28293682.0 \t loss_valid = 25259048.0 \n",
      "Model_6_15320 \t loss_train = 28254006.0 \t loss_valid = 25267548.0 \n",
      "Model_6_15330 \t loss_train = 28230764.0 \t loss_valid = 25283770.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_6_15340 \t loss_train = 28323334.0 \t loss_valid = 25254462.0 \n",
      "Model_6_15350 \t loss_train = 28248322.0 \t loss_valid = 25276326.0 \n",
      "Model_6_15360 \t loss_train = 28370722.0 \t loss_valid = 25250234.0 \n",
      "Model_6_15370 \t loss_train = 28261606.0 \t loss_valid = 25270186.0 \n",
      "Model_6_15380 \t loss_train = 28256362.0 \t loss_valid = 25266338.0 \n",
      "Model_6_15390 \t loss_train = 28314626.0 \t loss_valid = 25255810.0 \n",
      "Model_6_15400 \t loss_train = 28253778.0 \t loss_valid = 25267776.0 \n",
      "Model_6_15410 \t loss_train = 28254660.0 \t loss_valid = 25266246.0 \n",
      "Model_6_15420 \t loss_train = 28251680.0 \t loss_valid = 25267618.0 \n",
      "Model_6_15430 \t loss_train = 28354568.0 \t loss_valid = 25251426.0 \n",
      "Model_6_15440 \t loss_train = 28282042.0 \t loss_valid = 25263634.0 \n",
      "Model_6_15450 \t loss_train = 28292772.0 \t loss_valid = 25257770.0 \n",
      "Model_6_15460 \t loss_train = 28275736.0 \t loss_valid = 25261912.0 \n",
      "Model_6_15470 \t loss_train = 28237908.0 \t loss_valid = 25284062.0 \n",
      "Model_6_15480 \t loss_train = 28312028.0 \t loss_valid = 25255766.0 \n",
      "Model_6_15490 \t loss_train = 28202148.0 \t loss_valid = 25294088.0 \n",
      "Model_6_15500 \t loss_train = 28295756.0 \t loss_valid = 25258538.0 \n",
      "Model_6_15510 \t loss_train = 28320040.0 \t loss_valid = 25255564.0 \n",
      "Model_6_15520 \t loss_train = 28169816.0 \t loss_valid = 25311100.0 \n",
      "Model_6_15530 \t loss_train = 28271842.0 \t loss_valid = 25268846.0 \n",
      "Model_6_15540 \t loss_train = 28256596.0 \t loss_valid = 25267532.0 \n",
      "Model_6_15550 \t loss_train = 28268592.0 \t loss_valid = 25267242.0 \n",
      "Model_6_15560 \t loss_train = 28255746.0 \t loss_valid = 25266670.0 \n",
      "Model_6_15570 \t loss_train = 28305322.0 \t loss_valid = 25260182.0 \n",
      "Model_6_15580 \t loss_train = 28340606.0 \t loss_valid = 25252814.0 \n",
      "Model_6_15590 \t loss_train = 28264552.0 \t loss_valid = 25265136.0 \n",
      "Model_6_15600 \t loss_train = 28242040.0 \t loss_valid = 25270802.0 \n",
      "Model_6_15610 \t loss_train = 28276992.0 \t loss_valid = 25262124.0 \n",
      "Model_6_15620 \t loss_train = 28287448.0 \t loss_valid = 25259946.0 \n",
      "Model_6_15630 \t loss_train = 28270702.0 \t loss_valid = 25263220.0 \n",
      "Model_6_15640 \t loss_train = 28352482.0 \t loss_valid = 25251542.0 \n",
      "Model_6_15650 \t loss_train = 28191480.0 \t loss_valid = 25304528.0 \n",
      "Model_6_15660 \t loss_train = 28246814.0 \t loss_valid = 25266578.0 \n",
      "Model_6_15670 \t loss_train = 28271980.0 \t loss_valid = 25260826.0 \n",
      "Model_6_15680 \t loss_train = 28270176.0 \t loss_valid = 25270102.0 \n",
      "Model_6_15690 \t loss_train = 28268772.0 \t loss_valid = 25263318.0 \n",
      "Model_6_15700 \t loss_train = 28196330.0 \t loss_valid = 25284374.0 \n",
      "Model_6_15710 \t loss_train = 28292394.0 \t loss_valid = 25257002.0 \n",
      "Model_6_15720 \t loss_train = 28249048.0 \t loss_valid = 25271770.0 \n",
      "Model_6_15730 \t loss_train = 28256448.0 \t loss_valid = 25271120.0 \n",
      "Model_6_15740 \t loss_train = 28238190.0 \t loss_valid = 25271406.0 \n",
      "Model_6_15750 \t loss_train = 28260142.0 \t loss_valid = 25264936.0 \n",
      "Model_6_15760 \t loss_train = 28251958.0 \t loss_valid = 25271014.0 \n",
      "Model_6_15770 \t loss_train = 28314172.0 \t loss_valid = 25256640.0 \n",
      "Model_6_15780 \t loss_train = 28185336.0 \t loss_valid = 25297056.0 \n",
      "Model_6_15790 \t loss_train = 28278678.0 \t loss_valid = 25263420.0 \n",
      "Model_6_15800 \t loss_train = 28272936.0 \t loss_valid = 25263122.0 \n",
      "Model_6_15810 \t loss_train = 28224688.0 \t loss_valid = 25275312.0 \n",
      "Model_6_15820 \t loss_train = 28249142.0 \t loss_valid = 25268670.0 \n",
      "Model_6_15830 \t loss_train = 28309140.0 \t loss_valid = 25255948.0 \n",
      "Model_6_15840 \t loss_train = 28238342.0 \t loss_valid = 25277218.0 \n",
      "Model_6_15850 \t loss_train = 28259914.0 \t loss_valid = 25274020.0 \n",
      "Model_6_15860 \t loss_train = 28277134.0 \t loss_valid = 25264644.0 \n",
      "Model_6_15870 \t loss_train = 28224930.0 \t loss_valid = 25279168.0 \n",
      "Model_6_15880 \t loss_train = 28240860.0 \t loss_valid = 25273746.0 \n",
      "Model_6_15890 \t loss_train = 28298992.0 \t loss_valid = 25256568.0 \n",
      "Model_6_15900 \t loss_train = 28217648.0 \t loss_valid = 25280652.0 \n",
      "Model_6_15910 \t loss_train = 28243888.0 \t loss_valid = 25268296.0 \n",
      "Model_6_15920 \t loss_train = 28266438.0 \t loss_valid = 25263012.0 \n",
      "Model_6_15930 \t loss_train = 28330368.0 \t loss_valid = 25255586.0 \n",
      "Model_6_15940 \t loss_train = 28291338.0 \t loss_valid = 25257956.0 \n",
      "Model_6_15950 \t loss_train = 28230824.0 \t loss_valid = 25274356.0 \n",
      "Model_6_15960 \t loss_train = 28341498.0 \t loss_valid = 25251460.0 \n",
      "Model_6_15970 \t loss_train = 28177340.0 \t loss_valid = 25298278.0 \n",
      "Model_6_15980 \t loss_train = 28248164.0 \t loss_valid = 25272482.0 \n",
      "Model_6_15990 \t loss_train = 28287122.0 \t loss_valid = 25258098.0 \n",
      "Model_6_16000 \t loss_train = 28140018.0 \t loss_valid = 25321124.0 \n",
      "Model_6_16010 \t loss_train = 28334954.0 \t loss_valid = 25256302.0 \n",
      "Model_6_16020 \t loss_train = 28131832.0 \t loss_valid = 25341746.0 \n",
      "Model_6_16030 \t loss_train = 28322942.0 \t loss_valid = 25253688.0 \n",
      "Model_6_16040 \t loss_train = 28210260.0 \t loss_valid = 25289160.0 \n",
      "Model_6_16050 \t loss_train = 28345566.0 \t loss_valid = 25251132.0 \n",
      "Model_6_16060 \t loss_train = 28157092.0 \t loss_valid = 25312892.0 \n",
      "Model_6_16070 \t loss_train = 28315444.0 \t loss_valid = 25255728.0 \n",
      "Model_6_16080 \t loss_train = 28267352.0 \t loss_valid = 25267158.0 \n",
      "Model_6_16090 \t loss_train = 28285640.0 \t loss_valid = 25260632.0 \n",
      "Model_6_16100 \t loss_train = 28175838.0 \t loss_valid = 25298294.0 \n",
      "Model_6_16110 \t loss_train = 28323210.0 \t loss_valid = 25255834.0 \n",
      "Model_6_16120 \t loss_train = 28222524.0 \t loss_valid = 25292828.0 \n",
      "Model_6_16130 \t loss_train = 28187268.0 \t loss_valid = 25293014.0 \n",
      "Model_6_16140 \t loss_train = 28361988.0 \t loss_valid = 25251152.0 \n",
      "Model_6_16150 \t loss_train = 28138074.0 \t loss_valid = 25322730.0 \n",
      "Model_6_16160 \t loss_train = 28245360.0 \t loss_valid = 25271534.0 \n",
      "Model_6_16170 \t loss_train = 28313824.0 \t loss_valid = 25257746.0 \n",
      "Model_6_16180 \t loss_train = 28184270.0 \t loss_valid = 25300758.0 \n",
      "Model_6_16190 \t loss_train = 28295570.0 \t loss_valid = 25257672.0 \n",
      "Model_6_16200 \t loss_train = 28235926.0 \t loss_valid = 25272652.0 \n",
      "Model_6_16210 \t loss_train = 28238922.0 \t loss_valid = 25282560.0 \n",
      "Model_6_16220 \t loss_train = 28301220.0 \t loss_valid = 25258404.0 \n",
      "Model_6_16230 \t loss_train = 28212808.0 \t loss_valid = 25280138.0 \n",
      "Model_6_16240 \t loss_train = 28207604.0 \t loss_valid = 25282262.0 \n",
      "Model_6_16250 \t loss_train = 28273170.0 \t loss_valid = 25262302.0 \n",
      "Model_6_16260 \t loss_train = 28192904.0 \t loss_valid = 25291418.0 \n",
      "Model_6_16270 \t loss_train = 28337620.0 \t loss_valid = 25253632.0 \n",
      "Model_6_16280 \t loss_train = 28273502.0 \t loss_valid = 25266336.0 \n",
      "Model_6_16290 \t loss_train = 28148534.0 \t loss_valid = 25317080.0 \n",
      "Model_6_16300 \t loss_train = 28280736.0 \t loss_valid = 25262642.0 \n",
      "Model_6_16310 \t loss_train = 28266904.0 \t loss_valid = 25264244.0 \n",
      "Model_6_16320 \t loss_train = 28232996.0 \t loss_valid = 25272212.0 \n",
      "Model_6_16330 \t loss_train = 28302686.0 \t loss_valid = 25256642.0 \n",
      "Model_6_16340 \t loss_train = 28286580.0 \t loss_valid = 25264646.0 \n",
      "Model_6_16350 \t loss_train = 28214802.0 \t loss_valid = 25283506.0 \n",
      "Model_6_16360 \t loss_train = 28258824.0 \t loss_valid = 25265502.0 \n",
      "Model_6_16370 \t loss_train = 28274900.0 \t loss_valid = 25263070.0 \n",
      "Model_6_16380 \t loss_train = 28256288.0 \t loss_valid = 25269788.0 \n",
      "Model_6_16390 \t loss_train = 28198988.0 \t loss_valid = 25302912.0 \n",
      "Model_6_16400 \t loss_train = 28186938.0 \t loss_valid = 25295442.0 \n",
      "Model_6_16410 \t loss_train = 28241678.0 \t loss_valid = 25270216.0 \n",
      "Model_6_16420 \t loss_train = 28303316.0 \t loss_valid = 25256836.0 \n",
      "Model_6_16430 \t loss_train = 28198490.0 \t loss_valid = 25294738.0 \n",
      "Model_6_16440 \t loss_train = 28243506.0 \t loss_valid = 25273458.0 \n",
      "Model_6_16450 \t loss_train = 28251958.0 \t loss_valid = 25270262.0 \n",
      "Model_6_16460 \t loss_train = 28162746.0 \t loss_valid = 25312986.0 \n",
      "Model_6_16470 \t loss_train = 28332092.0 \t loss_valid = 25255036.0 \n",
      "Model_6_16480 \t loss_train = 28148502.0 \t loss_valid = 25343160.0 \n",
      "Model_6_16490 \t loss_train = 28318012.0 \t loss_valid = 25256616.0 \n",
      "Model_6_16500 \t loss_train = 28193440.0 \t loss_valid = 25295628.0 \n",
      "Model_6_16510 \t loss_train = 28237644.0 \t loss_valid = 25278844.0 \n",
      "Model_6_16520 \t loss_train = 28213052.0 \t loss_valid = 25283780.0 \n",
      "Model_6_16530 \t loss_train = 28231006.0 \t loss_valid = 25273770.0 \n",
      "Model_6_16540 \t loss_train = 28244118.0 \t loss_valid = 25269488.0 \n",
      "Model_6_16550 \t loss_train = 28227092.0 \t loss_valid = 25275080.0 \n",
      "Model_6_16560 \t loss_train = 28213120.0 \t loss_valid = 25284242.0 \n",
      "Model_6_16570 \t loss_train = 28264588.0 \t loss_valid = 25268442.0 \n",
      "Model_6_16580 \t loss_train = 28278660.0 \t loss_valid = 25266874.0 \n",
      "Model_6_16590 \t loss_train = 28195132.0 \t loss_valid = 25291976.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_6_16600 \t loss_train = 28265612.0 \t loss_valid = 25266394.0 \n",
      "Model_6_16610 \t loss_train = 28238014.0 \t loss_valid = 25276752.0 \n",
      "Model_6_16620 \t loss_train = 28251546.0 \t loss_valid = 25274426.0 \n",
      "Model_6_16630 \t loss_train = 28255360.0 \t loss_valid = 25272048.0 \n",
      "Model_6_16640 \t loss_train = 28198470.0 \t loss_valid = 25285508.0 \n",
      "Model_6_16650 \t loss_train = 28247240.0 \t loss_valid = 25267926.0 \n",
      "Model_6_16660 \t loss_train = 28164354.0 \t loss_valid = 25308590.0 \n",
      "Model_6_16670 \t loss_train = 28317652.0 \t loss_valid = 25255412.0 \n",
      "Model_6_16680 \t loss_train = 28219616.0 \t loss_valid = 25282648.0 \n",
      "Model_6_16690 \t loss_train = 28189306.0 \t loss_valid = 25297938.0 \n",
      "Model_6_16700 \t loss_train = 28251562.0 \t loss_valid = 25272150.0 \n",
      "Model_6_16710 \t loss_train = 28194118.0 \t loss_valid = 25293730.0 \n",
      "Model_6_16720 \t loss_train = 28237010.0 \t loss_valid = 25277194.0 \n",
      "Model_6_16730 \t loss_train = 28158960.0 \t loss_valid = 25312688.0 \n",
      "Model_6_16740 \t loss_train = 28337630.0 \t loss_valid = 25253670.0 \n",
      "Model_6_16750 \t loss_train = 28148502.0 \t loss_valid = 25324300.0 \n",
      "Model_6_16760 \t loss_train = 28291126.0 \t loss_valid = 25265596.0 \n",
      "Model_6_16770 \t loss_train = 28253312.0 \t loss_valid = 25276698.0 \n",
      "Model_6_16780 \t loss_train = 28191038.0 \t loss_valid = 25296532.0 \n",
      "Model_6_16790 \t loss_train = 28325282.0 \t loss_valid = 25254704.0 \n",
      "Model_6_16800 \t loss_train = 28171946.0 \t loss_valid = 25313268.0 \n",
      "Model_6_16810 \t loss_train = 28250754.0 \t loss_valid = 25269516.0 \n",
      "Model_6_16820 \t loss_train = 28200510.0 \t loss_valid = 25285840.0 \n",
      "Model_6_16830 \t loss_train = 28148562.0 \t loss_valid = 25324288.0 \n",
      "Model_6_16840 \t loss_train = 28309268.0 \t loss_valid = 25258386.0 \n",
      "Model_6_16850 \t loss_train = 28138580.0 \t loss_valid = 25330274.0 \n",
      "Model_6_16860 \t loss_train = 28242066.0 \t loss_valid = 25271944.0 \n",
      "Model_6_16870 \t loss_train = 28238426.0 \t loss_valid = 25279586.0 \n",
      "Model_6_16880 \t loss_train = 28256960.0 \t loss_valid = 25266356.0 \n",
      "Model_6_16890 \t loss_train = 28181740.0 \t loss_valid = 25294574.0 \n",
      "Model_6_16900 \t loss_train = 28238298.0 \t loss_valid = 25277260.0 \n",
      "Model_6_16910 \t loss_train = 28226254.0 \t loss_valid = 25282448.0 \n",
      "Model_6_16920 \t loss_train = 28191298.0 \t loss_valid = 25291018.0 \n",
      "Model_6_16930 \t loss_train = 28177720.0 \t loss_valid = 25295662.0 \n",
      "Model_6_16940 \t loss_train = 28230162.0 \t loss_valid = 25279372.0 \n",
      "Model_6_16950 \t loss_train = 28177424.0 \t loss_valid = 25313250.0 \n",
      "Model_6_16960 \t loss_train = 28358960.0 \t loss_valid = 25251208.0 \n",
      "Model_6_16970 \t loss_train = 28134650.0 \t loss_valid = 25323234.0 \n",
      "Model_6_16980 \t loss_train = 28309434.0 \t loss_valid = 25256776.0 \n",
      "Model_6_16990 \t loss_train = 28137672.0 \t loss_valid = 25330096.0 \n",
      "Model_6_17000 \t loss_train = 28197964.0 \t loss_valid = 25287624.0 \n",
      "Model_6_17010 \t loss_train = 28188512.0 \t loss_valid = 25293606.0 \n",
      "Model_6_17020 \t loss_train = 28255618.0 \t loss_valid = 25267890.0 \n",
      "Model_6_17030 \t loss_train = 28153562.0 \t loss_valid = 25309398.0 \n",
      "Model_6_17040 \t loss_train = 28249052.0 \t loss_valid = 25271056.0 \n",
      "Model_6_17050 \t loss_train = 28254756.0 \t loss_valid = 25270146.0 \n",
      "Model_6_17060 \t loss_train = 28175780.0 \t loss_valid = 25300724.0 \n",
      "Model_6_17070 \t loss_train = 28219434.0 \t loss_valid = 25278256.0 \n",
      "Model_6_17080 \t loss_train = 28181338.0 \t loss_valid = 25300214.0 \n",
      "Model_6_17090 \t loss_train = 28288982.0 \t loss_valid = 25266406.0 \n",
      "Model_6_17100 \t loss_train = 28178778.0 \t loss_valid = 25307354.0 \n",
      "Model_6_17110 \t loss_train = 28225418.0 \t loss_valid = 25279782.0 \n",
      "Model_6_17120 \t loss_train = 28188226.0 \t loss_valid = 25297848.0 \n",
      "Model_6_17130 \t loss_train = 28284080.0 \t loss_valid = 25262740.0 \n",
      "Model_6_17140 \t loss_train = 28137248.0 \t loss_valid = 25331932.0 \n",
      "Model_6_17150 \t loss_train = 28263864.0 \t loss_valid = 25269646.0 \n",
      "Model_6_17160 \t loss_train = 28234060.0 \t loss_valid = 25273652.0 \n",
      "Model_6_17170 \t loss_train = 28183646.0 \t loss_valid = 25295024.0 \n",
      "Model_6_17180 \t loss_train = 28304472.0 \t loss_valid = 25258600.0 \n",
      "Model_6_17190 \t loss_train = 28136810.0 \t loss_valid = 25327536.0 \n",
      "Model_6_17200 \t loss_train = 28244806.0 \t loss_valid = 25275696.0 \n",
      "Model_6_17210 \t loss_train = 28199076.0 \t loss_valid = 25309548.0 \n",
      "Model_6_17220 \t loss_train = 28221926.0 \t loss_valid = 25293100.0 \n",
      "Model_6_17230 \t loss_train = 28175652.0 \t loss_valid = 25301302.0 \n",
      "Model_6_17240 \t loss_train = 28214490.0 \t loss_valid = 25281922.0 \n",
      "Model_6_17250 \t loss_train = 28231434.0 \t loss_valid = 25280458.0 \n",
      "Model_6_17260 \t loss_train = 28192982.0 \t loss_valid = 25303006.0 \n",
      "Model_6_17270 \t loss_train = 28296918.0 \t loss_valid = 25260368.0 \n",
      "Model_6_17280 \t loss_train = 28157356.0 \t loss_valid = 25312950.0 \n",
      "Model_6_17290 \t loss_train = 28235618.0 \t loss_valid = 25276486.0 \n",
      "Model_6_17300 \t loss_train = 28222796.0 \t loss_valid = 25287774.0 \n",
      "Model_6_17310 \t loss_train = 28201106.0 \t loss_valid = 25293954.0 \n",
      "Model_6_17320 \t loss_train = 28170768.0 \t loss_valid = 25304050.0 \n",
      "Model_6_17330 \t loss_train = 28184996.0 \t loss_valid = 25300590.0 \n",
      "Model_6_17340 \t loss_train = 28274456.0 \t loss_valid = 25268724.0 \n",
      "Model_6_17350 \t loss_train = 28193366.0 \t loss_valid = 25292752.0 \n",
      "Model_6_17360 \t loss_train = 28227606.0 \t loss_valid = 25277232.0 \n",
      "Model_6_17370 \t loss_train = 28254630.0 \t loss_valid = 25271134.0 \n",
      "Model_6_17380 \t loss_train = 28208780.0 \t loss_valid = 25295196.0 \n",
      "Model_6_17390 \t loss_train = 28242352.0 \t loss_valid = 25275702.0 \n",
      "Model_6_17400 \t loss_train = 28174232.0 \t loss_valid = 25297260.0 \n",
      "Model_6_17410 \t loss_train = 28233694.0 \t loss_valid = 25273072.0 \n",
      "Model_6_17420 \t loss_train = 28217372.0 \t loss_valid = 25284320.0 \n",
      "Model_6_17430 \t loss_train = 28141306.0 \t loss_valid = 25327702.0 \n",
      "Model_6_17440 \t loss_train = 28191046.0 \t loss_valid = 25290884.0 \n",
      "Model_6_17450 \t loss_train = 28222472.0 \t loss_valid = 25278930.0 \n",
      "Model_6_17460 \t loss_train = 28216764.0 \t loss_valid = 25284590.0 \n",
      "Model_6_17470 \t loss_train = 28209534.0 \t loss_valid = 25285288.0 \n",
      "Model_6_17480 \t loss_train = 28161634.0 \t loss_valid = 25326256.0 \n",
      "Model_6_17490 \t loss_train = 28254618.0 \t loss_valid = 25282962.0 \n",
      "Model_6_17500 \t loss_train = 28209586.0 \t loss_valid = 25289678.0 \n",
      "Model_6_17510 \t loss_train = 28159386.0 \t loss_valid = 25312438.0 \n",
      "Model_6_17520 \t loss_train = 28200842.0 \t loss_valid = 25291228.0 \n",
      "Model_6_17530 \t loss_train = 28212344.0 \t loss_valid = 25286624.0 \n",
      "Model_6_17540 \t loss_train = 28205082.0 \t loss_valid = 25286916.0 \n",
      "Model_6_17550 \t loss_train = 28141040.0 \t loss_valid = 25326620.0 \n",
      "Model_6_17560 \t loss_train = 28269906.0 \t loss_valid = 25266648.0 \n",
      "Model_6_17570 \t loss_train = 28191266.0 \t loss_valid = 25293476.0 \n",
      "Model_6_17580 \t loss_train = 28233634.0 \t loss_valid = 25275316.0 \n",
      "Model_6_17590 \t loss_train = 28139956.0 \t loss_valid = 25328926.0 \n",
      "Model_6_17600 \t loss_train = 28330736.0 \t loss_valid = 25255890.0 \n",
      "Model_6_17610 \t loss_train = 28152608.0 \t loss_valid = 25322742.0 \n",
      "Model_6_17620 \t loss_train = 28276782.0 \t loss_valid = 25265488.0 \n",
      "Model_6_17630 \t loss_train = 28226104.0 \t loss_valid = 25278088.0 \n",
      "Model_6_17640 \t loss_train = 28221738.0 \t loss_valid = 25278482.0 \n",
      "Model_6_17650 \t loss_train = 28242076.0 \t loss_valid = 25270964.0 \n",
      "Model_6_17660 \t loss_train = 28151446.0 \t loss_valid = 25315928.0 \n",
      "Model_6_17670 \t loss_train = 28198558.0 \t loss_valid = 25289236.0 \n",
      "Model_6_17680 \t loss_train = 28234036.0 \t loss_valid = 25271526.0 \n",
      "Model_6_17690 \t loss_train = 28188648.0 \t loss_valid = 25292496.0 \n",
      "Model_6_17700 \t loss_train = 28214132.0 \t loss_valid = 25277300.0 \n",
      "Model_6_17710 \t loss_train = 28154952.0 \t loss_valid = 25311800.0 \n",
      "Model_6_17720 \t loss_train = 28159748.0 \t loss_valid = 25311730.0 \n",
      "Model_6_17730 \t loss_train = 28229738.0 \t loss_valid = 25276470.0 \n",
      "Model_6_17740 \t loss_train = 28113696.0 \t loss_valid = 25362046.0 \n",
      "Model_6_17750 \t loss_train = 28313916.0 \t loss_valid = 25255856.0 \n",
      "Model_6_17760 \t loss_train = 28122376.0 \t loss_valid = 25336956.0 \n",
      "Model_6_17770 \t loss_train = 28219746.0 \t loss_valid = 25281006.0 \n",
      "Model_6_17780 \t loss_train = 28191078.0 \t loss_valid = 25300288.0 \n",
      "Model_6_17790 \t loss_train = 28227088.0 \t loss_valid = 25279702.0 \n",
      "Model_6_17800 \t loss_train = 28195106.0 \t loss_valid = 25288894.0 \n",
      "Model_6_17810 \t loss_train = 28199298.0 \t loss_valid = 25291630.0 \n",
      "Model_6_17820 \t loss_train = 28190666.0 \t loss_valid = 25291272.0 \n",
      "Model_6_17830 \t loss_train = 28204460.0 \t loss_valid = 25282964.0 \n",
      "Model_6_17840 \t loss_train = 28251382.0 \t loss_valid = 25270548.0 \n",
      "Model_6_17850 \t loss_train = 28194758.0 \t loss_valid = 25296584.0 \n",
      "Model_6_17860 \t loss_train = 28223550.0 \t loss_valid = 25279888.0 \n",
      "Model_6_17870 \t loss_train = 28207884.0 \t loss_valid = 25284990.0 \n",
      "Model_6_17880 \t loss_train = 28261258.0 \t loss_valid = 25266170.0 \n",
      "Model_6_17890 \t loss_train = 28155260.0 \t loss_valid = 25313226.0 \n",
      "Model_6_17900 \t loss_train = 28241490.0 \t loss_valid = 25272958.0 \n",
      "Model_6_17910 \t loss_train = 28171900.0 \t loss_valid = 25299706.0 \n",
      "Model_6_17920 \t loss_train = 28226634.0 \t loss_valid = 25274478.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_6_17930 \t loss_train = 28183806.0 \t loss_valid = 25299404.0 \n",
      "Model_6_17940 \t loss_train = 28231028.0 \t loss_valid = 25281972.0 \n",
      "Model_6_17950 \t loss_train = 28161774.0 \t loss_valid = 25307666.0 \n",
      "Model_6_17960 \t loss_train = 28283884.0 \t loss_valid = 25260132.0 \n",
      "Model_6_17970 \t loss_train = 28140498.0 \t loss_valid = 25330752.0 \n",
      "Model_6_17980 \t loss_train = 28217064.0 \t loss_valid = 25291690.0 \n",
      "Model_6_17990 \t loss_train = 28186952.0 \t loss_valid = 25294760.0 \n",
      "Model_6_18000 \t loss_train = 28227806.0 \t loss_valid = 25274342.0 \n",
      "Model_6_18010 \t loss_train = 28151822.0 \t loss_valid = 25309754.0 \n",
      "Model_6_18020 \t loss_train = 28242634.0 \t loss_valid = 25271150.0 \n",
      "Model_6_18030 \t loss_train = 28189978.0 \t loss_valid = 25297412.0 \n",
      "Model_6_18040 \t loss_train = 28181056.0 \t loss_valid = 25305308.0 \n",
      "Model_6_18050 \t loss_train = 28264480.0 \t loss_valid = 25268492.0 \n",
      "Model_6_18060 \t loss_train = 28128104.0 \t loss_valid = 25338008.0 \n",
      "Model_6_18070 \t loss_train = 28154064.0 \t loss_valid = 25313906.0 \n",
      "Model_6_18080 \t loss_train = 28237876.0 \t loss_valid = 25270238.0 \n",
      "Model_6_18090 \t loss_train = 28188594.0 \t loss_valid = 25291128.0 \n",
      "Model_6_18100 \t loss_train = 28179592.0 \t loss_valid = 25308138.0 \n",
      "Model_6_18110 \t loss_train = 28143750.0 \t loss_valid = 25324142.0 \n",
      "Model_6_18120 \t loss_train = 28225074.0 \t loss_valid = 25274888.0 \n",
      "Model_6_18130 \t loss_train = 28153630.0 \t loss_valid = 25311440.0 \n",
      "Model_6_18140 \t loss_train = 28141196.0 \t loss_valid = 25319604.0 \n",
      "Model_6_18150 \t loss_train = 28212256.0 \t loss_valid = 25280804.0 \n",
      "Model_6_18160 \t loss_train = 28186450.0 \t loss_valid = 25294286.0 \n",
      "Model_6_18170 \t loss_train = 28127196.0 \t loss_valid = 25344842.0 \n",
      "Model_6_18180 \t loss_train = 28273296.0 \t loss_valid = 25265600.0 \n",
      "Model_6_18190 \t loss_train = 28167564.0 \t loss_valid = 25300668.0 \n",
      "Model_6_18200 \t loss_train = 28229610.0 \t loss_valid = 25272990.0 \n",
      "Model_6_18210 \t loss_train = 28222488.0 \t loss_valid = 25276938.0 \n",
      "Model_6_18220 \t loss_train = 28203344.0 \t loss_valid = 25289348.0 \n",
      "Model_6_18230 \t loss_train = 28141082.0 \t loss_valid = 25322076.0 \n",
      "Model_6_18240 \t loss_train = 28218116.0 \t loss_valid = 25275760.0 \n",
      "Model_6_18250 \t loss_train = 28133128.0 \t loss_valid = 25319028.0 \n",
      "Model_6_18260 \t loss_train = 28244744.0 \t loss_valid = 25268722.0 \n",
      "Model_6_18270 \t loss_train = 28230542.0 \t loss_valid = 25273600.0 \n",
      "Model_6_18280 \t loss_train = 28197802.0 \t loss_valid = 25289628.0 \n",
      "Model_6_18290 \t loss_train = 28195066.0 \t loss_valid = 25290160.0 \n",
      "Model_6_18300 \t loss_train = 28181558.0 \t loss_valid = 25302438.0 \n",
      "Model_6_18310 \t loss_train = 28228694.0 \t loss_valid = 25277388.0 \n",
      "Model_6_18320 \t loss_train = 28133664.0 \t loss_valid = 25322528.0 \n",
      "Model_6_18330 \t loss_train = 28222460.0 \t loss_valid = 25277684.0 \n",
      "Model_6_18340 \t loss_train = 28116204.0 \t loss_valid = 25348654.0 \n",
      "Model_6_18350 \t loss_train = 28263448.0 \t loss_valid = 25268062.0 \n",
      "Model_6_18360 \t loss_train = 28153076.0 \t loss_valid = 25328718.0 \n",
      "Model_6_18370 \t loss_train = 28184600.0 \t loss_valid = 25301722.0 \n",
      "Model_6_18380 \t loss_train = 28215514.0 \t loss_valid = 25280958.0 \n",
      "Model_6_18390 \t loss_train = 28177534.0 \t loss_valid = 25303714.0 \n",
      "Model_6_18400 \t loss_train = 28153118.0 \t loss_valid = 25314376.0 \n",
      "Model_6_18410 \t loss_train = 28177828.0 \t loss_valid = 25293358.0 \n",
      "Model_6_18420 \t loss_train = 28215868.0 \t loss_valid = 25281342.0 \n",
      "Model_6_18430 \t loss_train = 28175428.0 \t loss_valid = 25310354.0 \n",
      "Model_6_18440 \t loss_train = 28237994.0 \t loss_valid = 25280410.0 \n",
      "Model_6_18450 \t loss_train = 28140988.0 \t loss_valid = 25324532.0 \n",
      "Model_6_18460 \t loss_train = 28233600.0 \t loss_valid = 25275874.0 \n",
      "Model_6_18470 \t loss_train = 28184024.0 \t loss_valid = 25301068.0 \n",
      "Model_6_18480 \t loss_train = 28163710.0 \t loss_valid = 25314812.0 \n",
      "Model_6_18490 \t loss_train = 28203750.0 \t loss_valid = 25285596.0 \n",
      "Model_6_18500 \t loss_train = 28180176.0 \t loss_valid = 25291634.0 \n",
      "Model_6_18510 \t loss_train = 28186654.0 \t loss_valid = 25292360.0 \n",
      "Model_6_18520 \t loss_train = 28223744.0 \t loss_valid = 25277342.0 \n",
      "Model_6_18530 \t loss_train = 28126692.0 \t loss_valid = 25324614.0 \n",
      "Model_6_18540 \t loss_train = 28222902.0 \t loss_valid = 25276048.0 \n",
      "Model_6_18550 \t loss_train = 28092346.0 \t loss_valid = 25380498.0 \n",
      "Model_6_18560 \t loss_train = 28327612.0 \t loss_valid = 25255044.0 \n",
      "Model_6_18570 \t loss_train = 28097804.0 \t loss_valid = 25358494.0 \n",
      "Model_6_18580 \t loss_train = 28193682.0 \t loss_valid = 25286116.0 \n",
      "Model_6_18590 \t loss_train = 28172408.0 \t loss_valid = 25297748.0 \n",
      "Model_6_18600 \t loss_train = 28193290.0 \t loss_valid = 25293316.0 \n",
      "Model_6_18610 \t loss_train = 28166606.0 \t loss_valid = 25310274.0 \n",
      "Model_6_18620 \t loss_train = 28181424.0 \t loss_valid = 25292706.0 \n",
      "Model_6_18630 \t loss_train = 28132838.0 \t loss_valid = 25316476.0 \n",
      "Model_6_18640 \t loss_train = 28128546.0 \t loss_valid = 25323734.0 \n",
      "Model_6_18650 \t loss_train = 28188610.0 \t loss_valid = 25292842.0 \n",
      "Model_6_18660 \t loss_train = 28210080.0 \t loss_valid = 25288324.0 \n",
      "Model_6_18670 \t loss_train = 28155296.0 \t loss_valid = 25313824.0 \n",
      "Model_6_18680 \t loss_train = 28199488.0 \t loss_valid = 25286122.0 \n",
      "Model_6_18690 \t loss_train = 28204904.0 \t loss_valid = 25283878.0 \n",
      "Model_6_18700 \t loss_train = 28143060.0 \t loss_valid = 25320420.0 \n",
      "Model_6_18710 \t loss_train = 28275702.0 \t loss_valid = 25262826.0 \n",
      "Model_6_18720 \t loss_train = 28064578.0 \t loss_valid = 25411122.0 \n",
      "Model_6_18730 \t loss_train = 28217926.0 \t loss_valid = 25280072.0 \n",
      "Model_6_18740 \t loss_train = 28136728.0 \t loss_valid = 25326292.0 \n",
      "Model_6_18750 \t loss_train = 28206184.0 \t loss_valid = 25289634.0 \n",
      "Model_6_18760 \t loss_train = 28167300.0 \t loss_valid = 25310446.0 \n",
      "Model_6_18770 \t loss_train = 28166532.0 \t loss_valid = 25306792.0 \n",
      "Model_6_18780 \t loss_train = 28182174.0 \t loss_valid = 25299570.0 \n",
      "Model_6_18790 \t loss_train = 28197802.0 \t loss_valid = 25293688.0 \n",
      "Model_6_18800 \t loss_train = 28141964.0 \t loss_valid = 25322116.0 \n",
      "Model_6_18810 \t loss_train = 28242844.0 \t loss_valid = 25273354.0 \n",
      "Model_6_18820 \t loss_train = 28170884.0 \t loss_valid = 25305012.0 \n",
      "Model_6_18830 \t loss_train = 28177622.0 \t loss_valid = 25297908.0 \n",
      "Model_6_18840 \t loss_train = 28158644.0 \t loss_valid = 25307910.0 \n",
      "Model_6_18850 \t loss_train = 28173186.0 \t loss_valid = 25297926.0 \n",
      "Model_6_18860 \t loss_train = 28161050.0 \t loss_valid = 25307564.0 \n",
      "Model_6_18870 \t loss_train = 28166124.0 \t loss_valid = 25311342.0 \n",
      "Model_6_18880 \t loss_train = 28149698.0 \t loss_valid = 25320896.0 \n",
      "Model_6_18890 \t loss_train = 28144650.0 \t loss_valid = 25318498.0 \n",
      "Model_6_18900 \t loss_train = 28193070.0 \t loss_valid = 25293192.0 \n",
      "Model_6_18910 \t loss_train = 28182682.0 \t loss_valid = 25302452.0 \n",
      "Model_6_18920 \t loss_train = 28167998.0 \t loss_valid = 25309934.0 \n",
      "Model_6_18930 \t loss_train = 28160622.0 \t loss_valid = 25310302.0 \n",
      "Model_6_18940 \t loss_train = 28226236.0 \t loss_valid = 25281464.0 \n",
      "Model_6_18950 \t loss_train = 28179060.0 \t loss_valid = 25299192.0 \n",
      "Model_6_18960 \t loss_train = 28205448.0 \t loss_valid = 25284282.0 \n",
      "Model_6_18970 \t loss_train = 28142484.0 \t loss_valid = 25322932.0 \n",
      "Model_6_18980 \t loss_train = 28173854.0 \t loss_valid = 25301408.0 \n",
      "Model_6_18990 \t loss_train = 28143428.0 \t loss_valid = 25320226.0 \n",
      "Model_6_19000 \t loss_train = 28198312.0 \t loss_valid = 25286966.0 \n",
      "Model_6_19010 \t loss_train = 28174540.0 \t loss_valid = 25294760.0 \n",
      "Model_6_19020 \t loss_train = 28136282.0 \t loss_valid = 25322116.0 \n",
      "Model_6_19030 \t loss_train = 28196554.0 \t loss_valid = 25294190.0 \n",
      "Model_6_19040 \t loss_train = 28154248.0 \t loss_valid = 25318540.0 \n",
      "Model_6_19050 \t loss_train = 28186972.0 \t loss_valid = 25295040.0 \n",
      "Model_6_19060 \t loss_train = 28198614.0 \t loss_valid = 25288752.0 \n",
      "Model_6_19070 \t loss_train = 28105266.0 \t loss_valid = 25349006.0 \n",
      "Model_6_19080 \t loss_train = 28174518.0 \t loss_valid = 25301248.0 \n",
      "Model_6_19090 \t loss_train = 28177170.0 \t loss_valid = 25296378.0 \n",
      "Model_6_19100 \t loss_train = 28157766.0 \t loss_valid = 25306058.0 \n",
      "Model_6_19110 \t loss_train = 28210304.0 \t loss_valid = 25279722.0 \n",
      "Model_6_19120 \t loss_train = 28135990.0 \t loss_valid = 25319310.0 \n",
      "Model_6_19130 \t loss_train = 28173730.0 \t loss_valid = 25293806.0 \n",
      "Model_6_19140 \t loss_train = 28123106.0 \t loss_valid = 25329512.0 \n",
      "Model_6_19150 \t loss_train = 28277082.0 \t loss_valid = 25260282.0 \n",
      "Model_6_19160 \t loss_train = 28120888.0 \t loss_valid = 25343402.0 \n",
      "Model_6_19170 \t loss_train = 28285816.0 \t loss_valid = 25264342.0 \n",
      "Model_6_19180 \t loss_train = 28171698.0 \t loss_valid = 25311246.0 \n",
      "Model_6_19190 \t loss_train = 28195228.0 \t loss_valid = 25295770.0 \n",
      "Model_6_19200 \t loss_train = 28175564.0 \t loss_valid = 25302196.0 \n",
      "Model_6_19210 \t loss_train = 28133068.0 \t loss_valid = 25324732.0 \n",
      "Model_6_19220 \t loss_train = 28174240.0 \t loss_valid = 25299472.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_6_19230 \t loss_train = 28197344.0 \t loss_valid = 25294712.0 \n",
      "Model_6_19240 \t loss_train = 28170364.0 \t loss_valid = 25310026.0 \n",
      "Model_6_19250 \t loss_train = 28103098.0 \t loss_valid = 25356128.0 \n",
      "Model_6_19260 \t loss_train = 28221974.0 \t loss_valid = 25278128.0 \n",
      "Model_6_19270 \t loss_train = 28126954.0 \t loss_valid = 25332056.0 \n",
      "Model_6_19280 \t loss_train = 28169072.0 \t loss_valid = 25300344.0 \n",
      "Model_6_19290 \t loss_train = 28148310.0 \t loss_valid = 25316152.0 \n",
      "Model_6_19300 \t loss_train = 28140584.0 \t loss_valid = 25330400.0 \n",
      "Model_6_19310 \t loss_train = 28226412.0 \t loss_valid = 25279788.0 \n",
      "Model_6_19320 \t loss_train = 28110422.0 \t loss_valid = 25344752.0 \n",
      "Model_6_19330 \t loss_train = 28153290.0 \t loss_valid = 25312800.0 \n",
      "Model_6_19340 \t loss_train = 28147218.0 \t loss_valid = 25318788.0 \n",
      "Model_6_19350 \t loss_train = 28147540.0 \t loss_valid = 25318658.0 \n",
      "Model_6_19360 \t loss_train = 28194200.0 \t loss_valid = 25297162.0 \n",
      "Model_6_19370 \t loss_train = 28161576.0 \t loss_valid = 25318594.0 \n",
      "Model_6_19380 \t loss_train = 28158592.0 \t loss_valid = 25314090.0 \n",
      "Model_6_19390 \t loss_train = 28170020.0 \t loss_valid = 25300626.0 \n",
      "Model_6_19400 \t loss_train = 28154980.0 \t loss_valid = 25310260.0 \n",
      "Model_6_19410 \t loss_train = 28133098.0 \t loss_valid = 25329404.0 \n",
      "Model_6_19420 \t loss_train = 28208964.0 \t loss_valid = 25287248.0 \n",
      "Model_6_19430 \t loss_train = 28173376.0 \t loss_valid = 25302036.0 \n",
      "Model_6_19440 \t loss_train = 28173706.0 \t loss_valid = 25299776.0 \n",
      "Model_6_19450 \t loss_train = 28176290.0 \t loss_valid = 25301040.0 \n",
      "Model_6_19460 \t loss_train = 28162576.0 \t loss_valid = 25311100.0 \n",
      "Model_6_19470 \t loss_train = 28199838.0 \t loss_valid = 25288188.0 \n",
      "Model_6_19480 \t loss_train = 28153454.0 \t loss_valid = 25312784.0 \n",
      "Model_6_19490 \t loss_train = 28117898.0 \t loss_valid = 25346308.0 \n",
      "Model_6_19500 \t loss_train = 28238280.0 \t loss_valid = 25274768.0 \n",
      "Model_6_19510 \t loss_train = 28138152.0 \t loss_valid = 25330990.0 \n",
      "Model_6_19520 \t loss_train = 28158942.0 \t loss_valid = 25312832.0 \n",
      "Model_6_19530 \t loss_train = 28184950.0 \t loss_valid = 25295132.0 \n",
      "Model_6_19540 \t loss_train = 28096332.0 \t loss_valid = 25365436.0 \n",
      "Model_6_19550 \t loss_train = 28210936.0 \t loss_valid = 25288204.0 \n",
      "Model_6_19560 \t loss_train = 28158350.0 \t loss_valid = 25319142.0 \n",
      "Model_6_19570 \t loss_train = 28223150.0 \t loss_valid = 25279586.0 \n",
      "Model_6_19580 \t loss_train = 28147268.0 \t loss_valid = 25317316.0 \n",
      "Model_6_19590 \t loss_train = 28172284.0 \t loss_valid = 25303292.0 \n",
      "Model_6_19600 \t loss_train = 28209702.0 \t loss_valid = 25286546.0 \n",
      "Model_6_19610 \t loss_train = 28131772.0 \t loss_valid = 25327824.0 \n",
      "Model_6_19620 \t loss_train = 28174874.0 \t loss_valid = 25295492.0 \n",
      "Model_6_19630 \t loss_train = 28221858.0 \t loss_valid = 25276008.0 \n",
      "Model_6_19640 \t loss_train = 28121784.0 \t loss_valid = 25332444.0 \n",
      "Model_6_19650 \t loss_train = 28167274.0 \t loss_valid = 25305392.0 \n",
      "Model_6_19660 \t loss_train = 28151082.0 \t loss_valid = 25317002.0 \n",
      "Model_6_19670 \t loss_train = 28162386.0 \t loss_valid = 25307318.0 \n",
      "Model_6_19680 \t loss_train = 28110926.0 \t loss_valid = 25343936.0 \n",
      "Model_6_19690 \t loss_train = 28138996.0 \t loss_valid = 25326310.0 \n",
      "Model_6_19700 \t loss_train = 28218100.0 \t loss_valid = 25287608.0 \n",
      "Model_6_19710 \t loss_train = 28166158.0 \t loss_valid = 25306462.0 \n",
      "Model_6_19720 \t loss_train = 28205158.0 \t loss_valid = 25284458.0 \n",
      "Model_6_19730 \t loss_train = 28109270.0 \t loss_valid = 25345108.0 \n",
      "Model_6_19740 \t loss_train = 28161264.0 \t loss_valid = 25307760.0 \n",
      "Model_6_19750 \t loss_train = 28189768.0 \t loss_valid = 25298190.0 \n",
      "Model_6_19760 \t loss_train = 28111280.0 \t loss_valid = 25344698.0 \n",
      "Model_6_19770 \t loss_train = 28159928.0 \t loss_valid = 25307284.0 \n",
      "Model_6_19780 \t loss_train = 28158340.0 \t loss_valid = 25310682.0 \n",
      "Model_6_19790 \t loss_train = 28160314.0 \t loss_valid = 25310536.0 \n",
      "Model_6_19800 \t loss_train = 28139172.0 \t loss_valid = 25321626.0 \n",
      "Model_6_19810 \t loss_train = 28166244.0 \t loss_valid = 25302900.0 \n",
      "Model_6_19820 \t loss_train = 28130338.0 \t loss_valid = 25325448.0 \n",
      "Model_6_19830 \t loss_train = 28214546.0 \t loss_valid = 25281348.0 \n",
      "Model_6_19840 \t loss_train = 28063056.0 \t loss_valid = 25405238.0 \n",
      "Model_6_19850 \t loss_train = 28244180.0 \t loss_valid = 25273104.0 \n",
      "Model_6_19860 \t loss_train = 28122190.0 \t loss_valid = 25332336.0 \n",
      "Model_6_19870 \t loss_train = 28153680.0 \t loss_valid = 25307644.0 \n",
      "Model_6_19880 \t loss_train = 28207286.0 \t loss_valid = 25281816.0 \n",
      "Model_6_19890 \t loss_train = 28075174.0 \t loss_valid = 25376860.0 \n",
      "Model_6_19900 \t loss_train = 28235596.0 \t loss_valid = 25272052.0 \n",
      "Model_6_19910 \t loss_train = 28120748.0 \t loss_valid = 25335044.0 \n",
      "Model_6_19920 \t loss_train = 28160606.0 \t loss_valid = 25303644.0 \n",
      "Model_6_19930 \t loss_train = 28135490.0 \t loss_valid = 25320650.0 \n",
      "Model_6_19940 \t loss_train = 28160712.0 \t loss_valid = 25308944.0 \n",
      "Model_6_19950 \t loss_train = 28193048.0 \t loss_valid = 25289492.0 \n",
      "Model_6_19960 \t loss_train = 28177938.0 \t loss_valid = 25300326.0 \n",
      "Model_6_19970 \t loss_train = 28149186.0 \t loss_valid = 25317752.0 \n",
      "Model_6_19980 \t loss_train = 28150792.0 \t loss_valid = 25312426.0 \n",
      "Model_6_19990 \t loss_train = 28137214.0 \t loss_valid = 25325066.0 \n",
      "Model_6_20000 \t loss_train = 28155698.0 \t loss_valid = 25318240.0 \n",
      "Model_6_20010 \t loss_train = 28149064.0 \t loss_valid = 25322332.0 \n",
      "Model_6_20020 \t loss_train = 28179248.0 \t loss_valid = 25297836.0 \n",
      "Model_6_20030 \t loss_train = 28080734.0 \t loss_valid = 25374920.0 \n",
      "Model_6_20040 \t loss_train = 28271556.0 \t loss_valid = 25263114.0 \n",
      "Model_6_20050 \t loss_train = 28117152.0 \t loss_valid = 25336912.0 \n",
      "Model_6_20060 \t loss_train = 28106154.0 \t loss_valid = 25351082.0 \n",
      "Model_6_20070 \t loss_train = 28164994.0 \t loss_valid = 25308540.0 \n",
      "Model_6_20080 \t loss_train = 28139494.0 \t loss_valid = 25324206.0 \n",
      "Model_6_20090 \t loss_train = 28140250.0 \t loss_valid = 25322408.0 \n",
      "Model_6_20100 \t loss_train = 28175316.0 \t loss_valid = 25308454.0 \n",
      "Model_6_20110 \t loss_train = 28135928.0 \t loss_valid = 25342872.0 \n",
      "Model_6_20120 \t loss_train = 28151512.0 \t loss_valid = 25318476.0 \n",
      "Model_6_20130 \t loss_train = 28144652.0 \t loss_valid = 25317022.0 \n",
      "Model_6_20140 \t loss_train = 28124784.0 \t loss_valid = 25327614.0 \n",
      "Model_6_20150 \t loss_train = 28136056.0 \t loss_valid = 25320784.0 \n",
      "Model_6_20160 \t loss_train = 28194920.0 \t loss_valid = 25291380.0 \n",
      "Model_6_20170 \t loss_train = 28133134.0 \t loss_valid = 25336060.0 \n",
      "Model_6_20180 \t loss_train = 28177412.0 \t loss_valid = 25299978.0 \n",
      "Model_6_20190 \t loss_train = 28117614.0 \t loss_valid = 25336734.0 \n",
      "Model_6_20200 \t loss_train = 28138412.0 \t loss_valid = 25323354.0 \n",
      "Model_6_20210 \t loss_train = 28160944.0 \t loss_valid = 25310796.0 \n",
      "Model_6_20220 \t loss_train = 28141930.0 \t loss_valid = 25320646.0 \n",
      "Model_6_20230 \t loss_train = 28155806.0 \t loss_valid = 25309940.0 \n",
      "Model_6_20240 \t loss_train = 28222450.0 \t loss_valid = 25281462.0 \n",
      "Model_6_20250 \t loss_train = 28095788.0 \t loss_valid = 25363060.0 \n",
      "Model_6_20260 \t loss_train = 28153584.0 \t loss_valid = 25308270.0 \n",
      "Model_6_20270 \t loss_train = 28139890.0 \t loss_valid = 25317276.0 \n",
      "Model_6_20280 \t loss_train = 28141494.0 \t loss_valid = 25317890.0 \n",
      "Model_6_20290 \t loss_train = 28168348.0 \t loss_valid = 25302114.0 \n",
      "Model_6_20300 \t loss_train = 28140304.0 \t loss_valid = 25318802.0 \n",
      "Model_6_20310 \t loss_train = 28161294.0 \t loss_valid = 25306192.0 \n",
      "Model_6_20320 \t loss_train = 28109636.0 \t loss_valid = 25349468.0 \n",
      "Model_6_20330 \t loss_train = 28188120.0 \t loss_valid = 25295604.0 \n",
      "Model_6_20340 \t loss_train = 28151342.0 \t loss_valid = 25319782.0 \n",
      "Model_6_20350 \t loss_train = 28177794.0 \t loss_valid = 25301054.0 \n",
      "Model_6_20360 \t loss_train = 28146530.0 \t loss_valid = 25316566.0 \n",
      "Model_6_20370 \t loss_train = 28154332.0 \t loss_valid = 25313698.0 \n",
      "Model_6_20380 \t loss_train = 28173762.0 \t loss_valid = 25302532.0 \n",
      "Model_6_20390 \t loss_train = 28161092.0 \t loss_valid = 25310730.0 \n",
      "Model_6_20400 \t loss_train = 28149986.0 \t loss_valid = 25321232.0 \n",
      "Model_6_20410 \t loss_train = 28188996.0 \t loss_valid = 25294584.0 \n",
      "Model_6_20420 \t loss_train = 28156172.0 \t loss_valid = 25310784.0 \n",
      "Model_6_20430 \t loss_train = 28090044.0 \t loss_valid = 25365974.0 \n",
      "Model_6_20440 \t loss_train = 28143906.0 \t loss_valid = 25316178.0 \n",
      "Model_6_20450 \t loss_train = 28156578.0 \t loss_valid = 25306916.0 \n",
      "Model_6_20460 \t loss_train = 28172226.0 \t loss_valid = 25297728.0 \n",
      "Model_6_20470 \t loss_train = 28120546.0 \t loss_valid = 25336816.0 \n",
      "Model_6_20480 \t loss_train = 28203586.0 \t loss_valid = 25286310.0 \n",
      "Model_6_20490 \t loss_train = 28091462.0 \t loss_valid = 25366980.0 \n",
      "Model_6_20500 \t loss_train = 28180092.0 \t loss_valid = 25295966.0 \n",
      "Model_6_20510 \t loss_train = 28192494.0 \t loss_valid = 25289502.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_6_20520 \t loss_train = 28119782.0 \t loss_valid = 25334300.0 \n",
      "Model_6_20530 \t loss_train = 28114380.0 \t loss_valid = 25339478.0 \n",
      "Model_6_20540 \t loss_train = 28165356.0 \t loss_valid = 25307326.0 \n",
      "Model_6_20550 \t loss_train = 28154872.0 \t loss_valid = 25317896.0 \n",
      "Model_6_20560 \t loss_train = 28175478.0 \t loss_valid = 25302614.0 \n",
      "Model_6_20570 \t loss_train = 28118274.0 \t loss_valid = 25340356.0 \n",
      "Model_6_20580 \t loss_train = 28169914.0 \t loss_valid = 25301030.0 \n",
      "Model_6_20590 \t loss_train = 28137554.0 \t loss_valid = 25322420.0 \n",
      "Model_6_20600 \t loss_train = 28146958.0 \t loss_valid = 25319470.0 \n",
      "Model_6_20610 \t loss_train = 28117426.0 \t loss_valid = 25341226.0 \n",
      "Model_6_20620 \t loss_train = 28129928.0 \t loss_valid = 25327034.0 \n",
      "Model_6_20630 \t loss_train = 28161472.0 \t loss_valid = 25308086.0 \n",
      "Model_6_20640 \t loss_train = 28152504.0 \t loss_valid = 25312660.0 \n",
      "Model_6_20650 \t loss_train = 28188096.0 \t loss_valid = 25293792.0 \n",
      "Model_6_20660 \t loss_train = 28122754.0 \t loss_valid = 25338950.0 \n",
      "Model_6_20670 \t loss_train = 28110620.0 \t loss_valid = 25352656.0 \n",
      "Model_6_20680 \t loss_train = 28202282.0 \t loss_valid = 25290652.0 \n",
      "Model_6_20690 \t loss_train = 28129194.0 \t loss_valid = 25330618.0 \n",
      "Model_6_20700 \t loss_train = 28128302.0 \t loss_valid = 25324176.0 \n",
      "Model_6_20710 \t loss_train = 28157452.0 \t loss_valid = 25304594.0 \n",
      "Model_6_20720 \t loss_train = 28121170.0 \t loss_valid = 25331828.0 \n",
      "Model_6_20730 \t loss_train = 28194090.0 \t loss_valid = 25289430.0 \n",
      "Model_6_20740 \t loss_train = 28123698.0 \t loss_valid = 25338082.0 \n",
      "Model_6_20750 \t loss_train = 28207626.0 \t loss_valid = 25284144.0 \n",
      "Model_6_20760 \t loss_train = 28120146.0 \t loss_valid = 25339758.0 \n",
      "Model_6_20770 \t loss_train = 28136994.0 \t loss_valid = 25327914.0 \n",
      "Model_6_20780 \t loss_train = 28193712.0 \t loss_valid = 25292408.0 \n",
      "Model_6_20790 \t loss_train = 28083626.0 \t loss_valid = 25388438.0 \n",
      "Model_6_20800 \t loss_train = 28148682.0 \t loss_valid = 25323458.0 \n",
      "Model_6_20810 \t loss_train = 28091146.0 \t loss_valid = 25371736.0 \n",
      "Model_6_20820 \t loss_train = 28235884.0 \t loss_valid = 25274454.0 \n",
      "Model_6_20830 \t loss_train = 28128848.0 \t loss_valid = 25330104.0 \n",
      "Model_6_20840 \t loss_train = 28128842.0 \t loss_valid = 25326880.0 \n",
      "Model_6_20850 \t loss_train = 28089766.0 \t loss_valid = 25362468.0 \n",
      "Model_6_20860 \t loss_train = 28225072.0 \t loss_valid = 25276720.0 \n",
      "Model_6_20870 \t loss_train = 28107404.0 \t loss_valid = 25352792.0 \n",
      "Model_6_20880 \t loss_train = 28206928.0 \t loss_valid = 25292140.0 \n",
      "Model_6_20890 \t loss_train = 28107174.0 \t loss_valid = 25361694.0 \n",
      "Model_6_20900 \t loss_train = 28158574.0 \t loss_valid = 25313340.0 \n",
      "Model_6_20910 \t loss_train = 28157558.0 \t loss_valid = 25311050.0 \n",
      "Model_6_20920 \t loss_train = 28175326.0 \t loss_valid = 25302066.0 \n",
      "Model_6_20930 \t loss_train = 28104738.0 \t loss_valid = 25363106.0 \n",
      "Model_6_20940 \t loss_train = 28205986.0 \t loss_valid = 25287914.0 \n",
      "Model_6_20950 \t loss_train = 28111594.0 \t loss_valid = 25348268.0 \n",
      "Model_6_20960 \t loss_train = 28173034.0 \t loss_valid = 25297066.0 \n",
      "Model_6_20970 \t loss_train = 28111474.0 \t loss_valid = 25336566.0 \n",
      "Model_6_20980 \t loss_train = 28151540.0 \t loss_valid = 25309542.0 \n",
      "Model_6_20990 \t loss_train = 28104184.0 \t loss_valid = 25354040.0 \n",
      "Model_6_21000 \t loss_train = 28121124.0 \t loss_valid = 25337672.0 \n",
      "Model_6_21010 \t loss_train = 28153216.0 \t loss_valid = 25310152.0 \n",
      "Model_6_21020 \t loss_train = 28103014.0 \t loss_valid = 25348536.0 \n",
      "Model_6_21030 \t loss_train = 28169934.0 \t loss_valid = 25301298.0 \n",
      "Model_6_21040 \t loss_train = 28086922.0 \t loss_valid = 25373366.0 \n",
      "Model_6_21050 \t loss_train = 28167532.0 \t loss_valid = 25305926.0 \n",
      "Model_6_21060 \t loss_train = 28107510.0 \t loss_valid = 25351030.0 \n",
      "Model_6_21070 \t loss_train = 28132354.0 \t loss_valid = 25325180.0 \n",
      "Model_6_21080 \t loss_train = 28137560.0 \t loss_valid = 25323652.0 \n",
      "Model_6_21090 \t loss_train = 28134840.0 \t loss_valid = 25325894.0 \n",
      "Model_6_21100 \t loss_train = 28137344.0 \t loss_valid = 25324096.0 \n",
      "Model_6_21110 \t loss_train = 28125540.0 \t loss_valid = 25333238.0 \n",
      "Model_6_21120 \t loss_train = 28222754.0 \t loss_valid = 25279778.0 \n",
      "Model_6_21130 \t loss_train = 28090100.0 \t loss_valid = 25366064.0 \n",
      "Model_6_21140 \t loss_train = 28249958.0 \t loss_valid = 25268620.0 \n",
      "Model_6_21150 \t loss_train = 28117338.0 \t loss_valid = 25338130.0 \n",
      "Model_6_21160 \t loss_train = 28157782.0 \t loss_valid = 25311048.0 \n",
      "Model_6_21170 \t loss_train = 28161312.0 \t loss_valid = 25312214.0 \n",
      "Model_6_21180 \t loss_train = 28096090.0 \t loss_valid = 25365220.0 \n",
      "Model_6_21190 \t loss_train = 28119882.0 \t loss_valid = 25345240.0 \n",
      "Model_6_21200 \t loss_train = 28135744.0 \t loss_valid = 25328794.0 \n",
      "Model_6_21210 \t loss_train = 28164082.0 \t loss_valid = 25303962.0 \n",
      "Model_6_21220 \t loss_train = 28115872.0 \t loss_valid = 25334992.0 \n",
      "Model_6_21230 \t loss_train = 28164786.0 \t loss_valid = 25303424.0 \n",
      "Model_6_21240 \t loss_train = 28128912.0 \t loss_valid = 25328720.0 \n",
      "Model_6_21250 \t loss_train = 28146470.0 \t loss_valid = 25314146.0 \n",
      "Model_6_21260 \t loss_train = 28138948.0 \t loss_valid = 25318018.0 \n",
      "Model_6_21270 \t loss_train = 28126538.0 \t loss_valid = 25328228.0 \n",
      "Model_6_21280 \t loss_train = 28115126.0 \t loss_valid = 25342852.0 \n",
      "Model_6_21290 \t loss_train = 28119088.0 \t loss_valid = 25341060.0 \n",
      "Model_6_21300 \t loss_train = 28090354.0 \t loss_valid = 25368118.0 \n",
      "Model_6_21310 \t loss_train = 28145254.0 \t loss_valid = 25321018.0 \n",
      "Model_6_21320 \t loss_train = 28140602.0 \t loss_valid = 25325294.0 \n",
      "Model_6_21330 \t loss_train = 28145122.0 \t loss_valid = 25319022.0 \n",
      "Model_6_21340 \t loss_train = 28139742.0 \t loss_valid = 25321448.0 \n",
      "Model_6_21350 \t loss_train = 28118798.0 \t loss_valid = 25337708.0 \n",
      "Model_6_21360 \t loss_train = 28151380.0 \t loss_valid = 25313396.0 \n",
      "Model_6_21370 \t loss_train = 28148782.0 \t loss_valid = 25318716.0 \n",
      "Model_6_21380 \t loss_train = 28117342.0 \t loss_valid = 25336862.0 \n",
      "Model_6_21390 \t loss_train = 28175662.0 \t loss_valid = 25296168.0 \n",
      "Model_6_21400 \t loss_train = 28126008.0 \t loss_valid = 25330962.0 \n",
      "Model_6_21410 \t loss_train = 28203410.0 \t loss_valid = 25289470.0 \n",
      "Model_6_21420 \t loss_train = 28081820.0 \t loss_valid = 25384816.0 \n",
      "Model_6_21430 \t loss_train = 28135798.0 \t loss_valid = 25328154.0 \n",
      "Model_6_21440 \t loss_train = 28130996.0 \t loss_valid = 25328428.0 \n",
      "Model_6_21450 \t loss_train = 28143314.0 \t loss_valid = 25319142.0 \n",
      "Model_6_21460 \t loss_train = 28109146.0 \t loss_valid = 25344406.0 \n",
      "Model_6_21470 \t loss_train = 28179926.0 \t loss_valid = 25295100.0 \n",
      "Model_6_21480 \t loss_train = 28120490.0 \t loss_valid = 25334882.0 \n",
      "Model_6_21490 \t loss_train = 28165426.0 \t loss_valid = 25303906.0 \n",
      "Model_6_21500 \t loss_train = 28077972.0 \t loss_valid = 25376204.0 \n",
      "Model_6_21510 \t loss_train = 28153128.0 \t loss_valid = 25314142.0 \n",
      "Model_6_21520 \t loss_train = 28083324.0 \t loss_valid = 25387264.0 \n",
      "Model_6_21530 \t loss_train = 28164258.0 \t loss_valid = 25308904.0 \n",
      "Model_6_21540 \t loss_train = 28063690.0 \t loss_valid = 25394444.0 \n",
      "Model_6_21550 \t loss_train = 28216972.0 \t loss_valid = 25277610.0 \n",
      "Model_6_21560 \t loss_train = 28073652.0 \t loss_valid = 25378762.0 \n",
      "Model_6_21570 \t loss_train = 28143350.0 \t loss_valid = 25317626.0 \n",
      "Model_6_21580 \t loss_train = 28116674.0 \t loss_valid = 25338566.0 \n",
      "Model_6_21590 \t loss_train = 28085092.0 \t loss_valid = 25370286.0 \n",
      "Model_6_21600 \t loss_train = 28147194.0 \t loss_valid = 25316592.0 \n",
      "Model_6_21610 \t loss_train = 28106150.0 \t loss_valid = 25349576.0 \n",
      "Model_6_21620 \t loss_train = 28157620.0 \t loss_valid = 25310742.0 \n",
      "Model_6_21630 \t loss_train = 28135190.0 \t loss_valid = 25327022.0 \n",
      "Model_6_21640 \t loss_train = 28130826.0 \t loss_valid = 25333888.0 \n",
      "Model_6_21650 \t loss_train = 28114626.0 \t loss_valid = 25345318.0 \n",
      "Model_6_21660 \t loss_train = 28088034.0 \t loss_valid = 25375462.0 \n",
      "Model_6_21670 \t loss_train = 28157830.0 \t loss_valid = 25320202.0 \n",
      "Model_6_21680 \t loss_train = 28138334.0 \t loss_valid = 25331698.0 \n",
      "Model_6_21690 \t loss_train = 28102800.0 \t loss_valid = 25361974.0 \n",
      "Model_6_21700 \t loss_train = 28122916.0 \t loss_valid = 25335006.0 \n",
      "Model_6_21710 \t loss_train = 28113240.0 \t loss_valid = 25337424.0 \n",
      "Model_6_21720 \t loss_train = 28136108.0 \t loss_valid = 25322338.0 \n",
      "Model_6_21730 \t loss_train = 28129828.0 \t loss_valid = 25328704.0 \n",
      "Model_6_21740 \t loss_train = 28127674.0 \t loss_valid = 25333804.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_6_21750 \t loss_train = 28133572.0 \t loss_valid = 25332906.0 \n",
      "Model_6_21760 \t loss_train = 28179280.0 \t loss_valid = 25302464.0 \n",
      "Model_6_21770 \t loss_train = 28074264.0 \t loss_valid = 25387608.0 \n",
      "Model_6_21780 \t loss_train = 28181192.0 \t loss_valid = 25295894.0 \n",
      "Model_6_21790 \t loss_train = 28081890.0 \t loss_valid = 25374180.0 \n",
      "Model_6_21800 \t loss_train = 28146282.0 \t loss_valid = 25317524.0 \n",
      "Model_6_21810 \t loss_train = 28107416.0 \t loss_valid = 25343920.0 \n",
      "Model_6_21820 \t loss_train = 28150296.0 \t loss_valid = 25310842.0 \n",
      "Model_6_21830 \t loss_train = 28057236.0 \t loss_valid = 25406284.0 \n",
      "Model_6_21840 \t loss_train = 28193690.0 \t loss_valid = 25286492.0 \n",
      "Model_6_21850 \t loss_train = 28095612.0 \t loss_valid = 25354864.0 \n",
      "Model_6_21860 \t loss_train = 28120384.0 \t loss_valid = 25335616.0 \n",
      "Model_6_21870 \t loss_train = 28122518.0 \t loss_valid = 25335546.0 \n",
      "Model_6_21880 \t loss_train = 28102276.0 \t loss_valid = 25352578.0 \n",
      "Model_6_21890 \t loss_train = 28161032.0 \t loss_valid = 25307494.0 \n",
      "Model_6_21900 \t loss_train = 28162412.0 \t loss_valid = 25306422.0 \n",
      "Model_6_21910 \t loss_train = 28141064.0 \t loss_valid = 25319254.0 \n",
      "Model_6_21920 \t loss_train = 28109918.0 \t loss_valid = 25344028.0 \n",
      "Model_6_21930 \t loss_train = 28161494.0 \t loss_valid = 25306138.0 \n",
      "Model_6_21940 \t loss_train = 28094062.0 \t loss_valid = 25360536.0 \n",
      "Model_6_21950 \t loss_train = 28125726.0 \t loss_valid = 25333718.0 \n",
      "Model_6_21960 \t loss_train = 28116332.0 \t loss_valid = 25344426.0 \n",
      "Model_6_21970 \t loss_train = 28167864.0 \t loss_valid = 25307702.0 \n",
      "Model_6_21980 \t loss_train = 28113684.0 \t loss_valid = 25347824.0 \n",
      "Model_6_21990 \t loss_train = 28124144.0 \t loss_valid = 25333776.0 \n",
      "Model_6_22000 \t loss_train = 28079606.0 \t loss_valid = 25378216.0 \n",
      "Model_6_22010 \t loss_train = 28172412.0 \t loss_valid = 25302154.0 \n",
      "Model_6_22020 \t loss_train = 28096070.0 \t loss_valid = 25360982.0 \n",
      "Model_6_22030 \t loss_train = 28106664.0 \t loss_valid = 25349918.0 \n",
      "Model_6_22040 \t loss_train = 28165134.0 \t loss_valid = 25306784.0 \n",
      "Model_6_22050 \t loss_train = 28112064.0 \t loss_valid = 25345972.0 \n",
      "Model_6_22060 \t loss_train = 28132936.0 \t loss_valid = 25328124.0 \n",
      "Model_6_22070 \t loss_train = 28150614.0 \t loss_valid = 25315434.0 \n",
      "Model_6_22080 \t loss_train = 28117852.0 \t loss_valid = 25338878.0 \n",
      "Model_6_22090 \t loss_train = 28142004.0 \t loss_valid = 25321242.0 \n",
      "Model_6_22100 \t loss_train = 28140958.0 \t loss_valid = 25322624.0 \n",
      "Model_6_22110 \t loss_train = 28131040.0 \t loss_valid = 25325976.0 \n",
      "Model_6_22120 \t loss_train = 28119726.0 \t loss_valid = 25336026.0 \n",
      "Model_6_22130 \t loss_train = 28115266.0 \t loss_valid = 25343960.0 \n",
      "Model_6_22140 \t loss_train = 28123972.0 \t loss_valid = 25339642.0 \n",
      "Model_6_22150 \t loss_train = 28101884.0 \t loss_valid = 25365908.0 \n",
      "Model_6_22160 \t loss_train = 28214556.0 \t loss_valid = 25287214.0 \n",
      "Model_6_22170 \t loss_train = 28046960.0 \t loss_valid = 25431660.0 \n",
      "Model_6_22180 \t loss_train = 28190398.0 \t loss_valid = 25291118.0 \n",
      "Model_6_22190 \t loss_train = 28083816.0 \t loss_valid = 25370432.0 \n",
      "Model_6_22200 \t loss_train = 28135486.0 \t loss_valid = 25322512.0 \n",
      "Model_6_22210 \t loss_train = 28078076.0 \t loss_valid = 25377066.0 \n",
      "Model_6_22220 \t loss_train = 28129694.0 \t loss_valid = 25325830.0 \n",
      "Model_6_22230 \t loss_train = 28049600.0 \t loss_valid = 25419020.0 \n",
      "Model_6_22240 \t loss_train = 28170004.0 \t loss_valid = 25302234.0 \n",
      "Model_6_22250 \t loss_train = 28070672.0 \t loss_valid = 25391354.0 \n",
      "Model_6_22260 \t loss_train = 28088220.0 \t loss_valid = 25369062.0 \n",
      "Model_6_22270 \t loss_train = 28123404.0 \t loss_valid = 25335728.0 \n",
      "Model_6_22280 \t loss_train = 28112722.0 \t loss_valid = 25349282.0 \n",
      "Model_6_22290 \t loss_train = 28127964.0 \t loss_valid = 25337116.0 \n",
      "Model_6_22300 \t loss_train = 28133480.0 \t loss_valid = 25332064.0 \n",
      "Model_6_22310 \t loss_train = 28094702.0 \t loss_valid = 25367436.0 \n",
      "Model_6_22320 \t loss_train = 28145316.0 \t loss_valid = 25318792.0 \n",
      "Model_6_22330 \t loss_train = 28112314.0 \t loss_valid = 25345200.0 \n",
      "Model_6_22340 \t loss_train = 28126718.0 \t loss_valid = 25333350.0 \n",
      "Model_6_22350 \t loss_train = 28124674.0 \t loss_valid = 25335616.0 \n",
      "Model_6_22360 \t loss_train = 28111874.0 \t loss_valid = 25346466.0 \n",
      "Model_6_22370 \t loss_train = 28132606.0 \t loss_valid = 25328966.0 \n",
      "Model_6_22380 \t loss_train = 28099992.0 \t loss_valid = 25360394.0 \n",
      "Model_6_22390 \t loss_train = 28131454.0 \t loss_valid = 25330128.0 \n",
      "Model_6_22400 \t loss_train = 28181216.0 \t loss_valid = 25298652.0 \n",
      "Model_6_22410 \t loss_train = 28064720.0 \t loss_valid = 25403696.0 \n",
      "Model_6_22420 \t loss_train = 28137816.0 \t loss_valid = 25330376.0 \n",
      "Model_6_22430 \t loss_train = 28101384.0 \t loss_valid = 25364730.0 \n",
      "Model_6_22440 \t loss_train = 28134790.0 \t loss_valid = 25330074.0 \n",
      "Model_6_22450 \t loss_train = 28067890.0 \t loss_valid = 25395020.0 \n",
      "Model_6_22460 \t loss_train = 28182678.0 \t loss_valid = 25294588.0 \n",
      "Model_6_22470 \t loss_train = 28066082.0 \t loss_valid = 25393138.0 \n",
      "Model_6_22480 \t loss_train = 28193268.0 \t loss_valid = 25288670.0 \n",
      "Model_6_22490 \t loss_train = 28073296.0 \t loss_valid = 25382444.0 \n",
      "Model_6_22500 \t loss_train = 28158230.0 \t loss_valid = 25310530.0 \n",
      "Model_6_22510 \t loss_train = 28116928.0 \t loss_valid = 25341360.0 \n",
      "Model_6_22520 \t loss_train = 28073626.0 \t loss_valid = 25383642.0 \n",
      "Model_6_22530 \t loss_train = 28166004.0 \t loss_valid = 25304940.0 \n",
      "Model_6_22540 \t loss_train = 28052692.0 \t loss_valid = 25420926.0 \n",
      "Model_6_22550 \t loss_train = 28198114.0 \t loss_valid = 25292212.0 \n",
      "Model_6_22560 \t loss_train = 28068030.0 \t loss_valid = 25407798.0 \n",
      "Model_6_22570 \t loss_train = 28202262.0 \t loss_valid = 25290920.0 \n",
      "Model_6_22580 \t loss_train = 28077182.0 \t loss_valid = 25382532.0 \n",
      "Model_6_22590 \t loss_train = 28086354.0 \t loss_valid = 25369288.0 \n",
      "Model_6_22600 \t loss_train = 28141192.0 \t loss_valid = 25317962.0 \n",
      "Model_6_22610 \t loss_train = 28105010.0 \t loss_valid = 25344132.0 \n",
      "Model_6_22620 \t loss_train = 28128782.0 \t loss_valid = 25326688.0 \n",
      "Model_6_22630 \t loss_train = 28091964.0 \t loss_valid = 25362088.0 \n",
      "Model_6_22640 \t loss_train = 28133802.0 \t loss_valid = 25326762.0 \n",
      "Model_6_22650 \t loss_train = 28095960.0 \t loss_valid = 25361252.0 \n",
      "Model_6_22660 \t loss_train = 28125996.0 \t loss_valid = 25336144.0 \n",
      "Model_6_22670 \t loss_train = 28103152.0 \t loss_valid = 25359862.0 \n",
      "Model_6_22680 \t loss_train = 28123608.0 \t loss_valid = 25339112.0 \n",
      "Model_6_22690 \t loss_train = 28140402.0 \t loss_valid = 25323742.0 \n",
      "Model_6_22700 \t loss_train = 28104746.0 \t loss_valid = 25352742.0 \n",
      "Model_6_22710 \t loss_train = 28131300.0 \t loss_valid = 25331174.0 \n",
      "Model_6_22720 \t loss_train = 28110126.0 \t loss_valid = 25350058.0 \n",
      "Model_6_22730 \t loss_train = 28113464.0 \t loss_valid = 25345480.0 \n",
      "Model_6_22740 \t loss_train = 28063748.0 \t loss_valid = 25403074.0 \n",
      "Model_6_22750 \t loss_train = 28148880.0 \t loss_valid = 25318034.0 \n",
      "Model_6_22760 \t loss_train = 28175594.0 \t loss_valid = 25300154.0 \n",
      "Model_6_22770 \t loss_train = 28098554.0 \t loss_valid = 25355542.0 \n",
      "Model_6_22780 \t loss_train = 28104208.0 \t loss_valid = 25350934.0 \n",
      "Model_6_22790 \t loss_train = 28163722.0 \t loss_valid = 25307424.0 \n",
      "Model_6_22800 \t loss_train = 28090530.0 \t loss_valid = 25367302.0 \n",
      "Model_6_22810 \t loss_train = 28133594.0 \t loss_valid = 25328040.0 \n",
      "Model_6_22820 \t loss_train = 28106470.0 \t loss_valid = 25354070.0 \n",
      "Model_6_22830 \t loss_train = 28115540.0 \t loss_valid = 25345338.0 \n",
      "Model_6_22840 \t loss_train = 28155008.0 \t loss_valid = 25313676.0 \n",
      "Model_6_22850 \t loss_train = 28096288.0 \t loss_valid = 25360846.0 \n",
      "Model_6_22860 \t loss_train = 28131186.0 \t loss_valid = 25328706.0 \n",
      "Model_6_22870 \t loss_train = 28117958.0 \t loss_valid = 25339396.0 \n",
      "Model_6_22880 \t loss_train = 28090196.0 \t loss_valid = 25361934.0 \n",
      "Model_6_22890 \t loss_train = 28126238.0 \t loss_valid = 25330552.0 \n",
      "Model_6_22900 \t loss_train = 28065696.0 \t loss_valid = 25396710.0 \n",
      "Model_6_22910 \t loss_train = 28120392.0 \t loss_valid = 25339540.0 \n",
      "Model_6_22920 \t loss_train = 28098312.0 \t loss_valid = 25360776.0 \n",
      "Model_6_22930 \t loss_train = 28126158.0 \t loss_valid = 25331236.0 \n",
      "Model_6_22940 \t loss_train = 28075506.0 \t loss_valid = 25380110.0 \n",
      "Model_6_22950 \t loss_train = 28154756.0 \t loss_valid = 25309942.0 \n",
      "Model_6_22960 \t loss_train = 28100514.0 \t loss_valid = 25351880.0 \n",
      "Model_6_22970 \t loss_train = 28103058.0 \t loss_valid = 25349152.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_6_22980 \t loss_train = 28140228.0 \t loss_valid = 25318276.0 \n",
      "Model_6_22990 \t loss_train = 28129734.0 \t loss_valid = 25329496.0 \n",
      "Model_6_23000 \t loss_train = 28084714.0 \t loss_valid = 25372902.0 \n",
      "Model_6_23010 \t loss_train = 28134464.0 \t loss_valid = 25326000.0 \n",
      "Model_6_23020 \t loss_train = 28097928.0 \t loss_valid = 25358152.0 \n",
      "Model_6_23030 \t loss_train = 28099184.0 \t loss_valid = 25359228.0 \n",
      "Model_6_23040 \t loss_train = 28137952.0 \t loss_valid = 25325738.0 \n",
      "Model_6_23050 \t loss_train = 28053312.0 \t loss_valid = 25417704.0 \n",
      "Model_6_23060 \t loss_train = 28164162.0 \t loss_valid = 25305616.0 \n",
      "Model_6_23070 \t loss_train = 28086012.0 \t loss_valid = 25375896.0 \n",
      "Model_6_23080 \t loss_train = 28113716.0 \t loss_valid = 25346724.0 \n",
      "Model_6_23090 \t loss_train = 28066372.0 \t loss_valid = 25399504.0 \n",
      "Model_6_23100 \t loss_train = 28091688.0 \t loss_valid = 25364294.0 \n",
      "Model_6_23110 \t loss_train = 28092324.0 \t loss_valid = 25363374.0 \n",
      "Model_6_23120 \t loss_train = 28097036.0 \t loss_valid = 25359184.0 \n",
      "Model_6_23130 \t loss_train = 28090872.0 \t loss_valid = 25365192.0 \n",
      "Model_6_23140 \t loss_train = 28092274.0 \t loss_valid = 25362352.0 \n",
      "Model_6_23150 \t loss_train = 28101362.0 \t loss_valid = 25356756.0 \n",
      "Model_6_23160 \t loss_train = 28080700.0 \t loss_valid = 25382104.0 \n",
      "Model_6_23170 \t loss_train = 28158248.0 \t loss_valid = 25312470.0 \n",
      "Model_6_23180 \t loss_train = 28058526.0 \t loss_valid = 25416182.0 \n",
      "Model_6_23190 \t loss_train = 28161338.0 \t loss_valid = 25312456.0 \n",
      "Model_6_23200 \t loss_train = 28083408.0 \t loss_valid = 25380572.0 \n",
      "Model_6_23210 \t loss_train = 28114134.0 \t loss_valid = 25346578.0 \n",
      "Model_6_23220 \t loss_train = 28117754.0 \t loss_valid = 25339124.0 \n",
      "Model_6_23230 \t loss_train = 28095288.0 \t loss_valid = 25357632.0 \n",
      "Model_6_23240 \t loss_train = 28114024.0 \t loss_valid = 25339094.0 \n",
      "Model_6_23250 \t loss_train = 28120374.0 \t loss_valid = 25332876.0 \n",
      "Model_6_23260 \t loss_train = 28098442.0 \t loss_valid = 25356402.0 \n",
      "Model_6_23270 \t loss_train = 28074834.0 \t loss_valid = 25386104.0 \n",
      "Model_6_23280 \t loss_train = 28102466.0 \t loss_valid = 25352874.0 \n",
      "Model_6_23290 \t loss_train = 28120420.0 \t loss_valid = 25334170.0 \n",
      "Model_6_23300 \t loss_train = 28105494.0 \t loss_valid = 25346362.0 \n",
      "Model_6_23310 \t loss_train = 28120146.0 \t loss_valid = 25335658.0 \n",
      "Model_6_23320 \t loss_train = 28089028.0 \t loss_valid = 25366940.0 \n",
      "Model_6_23330 \t loss_train = 28120658.0 \t loss_valid = 25339064.0 \n",
      "Model_6_23340 \t loss_train = 28064452.0 \t loss_valid = 25405488.0 \n",
      "Model_6_23350 \t loss_train = 28122098.0 \t loss_valid = 25337660.0 \n",
      "Model_6_23360 \t loss_train = 28084798.0 \t loss_valid = 25370666.0 \n",
      "Model_6_23370 \t loss_train = 28156940.0 \t loss_valid = 25309660.0 \n",
      "Model_6_23380 \t loss_train = 28094448.0 \t loss_valid = 25362088.0 \n",
      "Model_6_23390 \t loss_train = 28077434.0 \t loss_valid = 25381470.0 \n",
      "Model_6_23400 \t loss_train = 28108112.0 \t loss_valid = 25347376.0 \n",
      "Model_6_23410 \t loss_train = 28087294.0 \t loss_valid = 25369114.0 \n",
      "Model_6_23420 \t loss_train = 28109490.0 \t loss_valid = 25351422.0 \n",
      "Model_6_23430 \t loss_train = 28115548.0 \t loss_valid = 25348428.0 \n",
      "Model_6_23440 \t loss_train = 28143474.0 \t loss_valid = 25322672.0 \n",
      "Model_6_23450 \t loss_train = 28097156.0 \t loss_valid = 25363828.0 \n",
      "Model_6_23460 \t loss_train = 28082566.0 \t loss_valid = 25385814.0 \n",
      "Model_6_23470 \t loss_train = 28138984.0 \t loss_valid = 25329698.0 \n",
      "Model_6_23480 \t loss_train = 28074414.0 \t loss_valid = 25390318.0 \n",
      "Model_6_23490 \t loss_train = 28105806.0 \t loss_valid = 25351774.0 \n",
      "Model_6_23500 \t loss_train = 28060340.0 \t loss_valid = 25405388.0 \n",
      "Model_6_23510 \t loss_train = 28131938.0 \t loss_valid = 25327116.0 \n",
      "Model_6_23520 \t loss_train = 28120292.0 \t loss_valid = 25335390.0 \n",
      "Model_6_23530 \t loss_train = 28091066.0 \t loss_valid = 25362736.0 \n",
      "Model_6_23540 \t loss_train = 28120886.0 \t loss_valid = 25333416.0 \n",
      "Model_6_23550 \t loss_train = 28050182.0 \t loss_valid = 25415504.0 \n",
      "Model_6_23560 \t loss_train = 28131600.0 \t loss_valid = 25326110.0 \n",
      "Model_6_23570 \t loss_train = 28109992.0 \t loss_valid = 25346938.0 \n",
      "Model_6_23580 \t loss_train = 28090080.0 \t loss_valid = 25366500.0 \n",
      "Model_6_23590 \t loss_train = 28115720.0 \t loss_valid = 25342288.0 \n",
      "Model_6_23600 \t loss_train = 28090252.0 \t loss_valid = 25371206.0 \n",
      "Model_6_23610 \t loss_train = 28110418.0 \t loss_valid = 25353188.0 \n",
      "Model_6_23620 \t loss_train = 28102840.0 \t loss_valid = 25357768.0 \n",
      "Model_6_23630 \t loss_train = 28079860.0 \t loss_valid = 25378202.0 \n",
      "Model_6_23640 \t loss_train = 28133616.0 \t loss_valid = 25324788.0 \n",
      "Model_6_23650 \t loss_train = 28096070.0 \t loss_valid = 25357932.0 \n",
      "Model_6_23660 \t loss_train = 28121624.0 \t loss_valid = 25333666.0 \n",
      "Model_6_23670 \t loss_train = 28067982.0 \t loss_valid = 25395078.0 \n",
      "Model_6_23680 \t loss_train = 28113048.0 \t loss_valid = 25342246.0 \n",
      "Model_6_23690 \t loss_train = 28110316.0 \t loss_valid = 25342838.0 \n",
      "Model_6_23700 \t loss_train = 28102598.0 \t loss_valid = 25347610.0 \n",
      "Model_6_23710 \t loss_train = 28041654.0 \t loss_valid = 25426830.0 \n",
      "Model_6_23720 \t loss_train = 28148638.0 \t loss_valid = 25310218.0 \n",
      "Model_6_23730 \t loss_train = 28040192.0 \t loss_valid = 25431186.0 \n",
      "Model_6_23740 \t loss_train = 28110208.0 \t loss_valid = 25340656.0 \n",
      "Model_6_23750 \t loss_train = 28080336.0 \t loss_valid = 25370952.0 \n",
      "Model_6_23760 \t loss_train = 28122060.0 \t loss_valid = 25331150.0 \n",
      "Early stopping!\n",
      "Model_7_0 \t loss_train = 119156600.0 \t loss_valid = 104059104.0 \n",
      "Model_7_10 \t loss_train = 117151872.0 \t loss_valid = 101678016.0 \n",
      "Model_7_20 \t loss_train = 112168712.0 \t loss_valid = 95818680.0 \n",
      "Model_7_30 \t loss_train = 97424088.0 \t loss_valid = 78722240.0 \n",
      "Model_7_40 \t loss_train = 70507112.0 \t loss_valid = 54653224.0 \n",
      "Model_7_50 \t loss_train = 65718936.0 \t loss_valid = 66603236.0 \n",
      "Model_7_60 \t loss_train = 63065720.0 \t loss_valid = 52956320.0 \n",
      "Model_7_70 \t loss_train = 61600428.0 \t loss_valid = 50667664.0 \n",
      "Model_7_80 \t loss_train = 59693668.0 \t loss_valid = 50421964.0 \n",
      "Model_7_90 \t loss_train = 58704448.0 \t loss_valid = 47473696.0 \n",
      "Model_7_100 \t loss_train = 57380840.0 \t loss_valid = 45808192.0 \n",
      "Model_7_110 \t loss_train = 56181200.0 \t loss_valid = 44184824.0 \n",
      "Model_7_120 \t loss_train = 55401356.0 \t loss_valid = 42551680.0 \n",
      "Model_7_130 \t loss_train = 54788820.0 \t loss_valid = 41355136.0 \n",
      "Model_7_140 \t loss_train = 53671368.0 \t loss_valid = 40416548.0 \n",
      "Model_7_150 \t loss_train = 53309088.0 \t loss_valid = 39722800.0 \n",
      "Model_7_160 \t loss_train = 52702196.0 \t loss_valid = 39219816.0 \n",
      "Model_7_170 \t loss_train = 52380488.0 \t loss_valid = 38866564.0 \n",
      "Model_7_180 \t loss_train = 52007172.0 \t loss_valid = 38504396.0 \n",
      "Model_7_190 \t loss_train = 51187724.0 \t loss_valid = 38258668.0 \n",
      "Model_7_200 \t loss_train = 51115636.0 \t loss_valid = 37951376.0 \n",
      "Model_7_210 \t loss_train = 50229148.0 \t loss_valid = 37785540.0 \n",
      "Model_7_220 \t loss_train = 49681160.0 \t loss_valid = 37612008.0 \n",
      "Model_7_230 \t loss_train = 49143800.0 \t loss_valid = 37516220.0 \n",
      "Model_7_240 \t loss_train = 48200880.0 \t loss_valid = 37063068.0 \n",
      "Model_7_250 \t loss_train = 47370576.0 \t loss_valid = 36697828.0 \n",
      "Model_7_260 \t loss_train = 46597848.0 \t loss_valid = 36405196.0 \n",
      "Model_7_270 \t loss_train = 45476908.0 \t loss_valid = 36239916.0 \n",
      "Model_7_280 \t loss_train = 44473472.0 \t loss_valid = 35776160.0 \n",
      "Model_7_290 \t loss_train = 44035768.0 \t loss_valid = 35380812.0 \n",
      "Model_7_300 \t loss_train = 41860132.0 \t loss_valid = 34453104.0 \n",
      "Model_7_310 \t loss_train = 40522528.0 \t loss_valid = 33843412.0 \n",
      "Model_7_320 \t loss_train = 38449620.0 \t loss_valid = 33308672.0 \n",
      "Model_7_330 \t loss_train = 36761992.0 \t loss_valid = 32279856.0 \n",
      "Model_7_340 \t loss_train = 35260560.0 \t loss_valid = 31910634.0 \n",
      "Model_7_350 \t loss_train = 33404804.0 \t loss_valid = 31004220.0 \n",
      "Model_7_360 \t loss_train = 31754694.0 \t loss_valid = 30263918.0 \n",
      "Model_7_370 \t loss_train = 30425304.0 \t loss_valid = 30420186.0 \n",
      "Model_7_380 \t loss_train = 29758022.0 \t loss_valid = 28290642.0 \n",
      "Model_7_390 \t loss_train = 29326466.0 \t loss_valid = 27911924.0 \n",
      "Model_7_400 \t loss_train = 28727224.0 \t loss_valid = 27977468.0 \n",
      "Model_7_410 \t loss_train = 28585076.0 \t loss_valid = 27431850.0 \n",
      "Model_7_420 \t loss_train = 29051346.0 \t loss_valid = 26844170.0 \n",
      "Model_7_430 \t loss_train = 28496988.0 \t loss_valid = 27170146.0 \n",
      "Model_7_440 \t loss_train = 28543104.0 \t loss_valid = 26849770.0 \n",
      "Model_7_450 \t loss_train = 28426630.0 \t loss_valid = 28257400.0 \n",
      "Model_7_460 \t loss_train = 28521822.0 \t loss_valid = 26623892.0 \n",
      "Model_7_470 \t loss_train = 28285034.0 \t loss_valid = 27063796.0 \n",
      "Model_7_480 \t loss_train = 28478910.0 \t loss_valid = 26460804.0 \n",
      "Model_7_490 \t loss_train = 28260134.0 \t loss_valid = 26894778.0 \n",
      "Model_7_500 \t loss_train = 28278932.0 \t loss_valid = 26709666.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_7_510 \t loss_train = 28413662.0 \t loss_valid = 26391104.0 \n",
      "Model_7_520 \t loss_train = 28229502.0 \t loss_valid = 26550658.0 \n",
      "Model_7_530 \t loss_train = 28409456.0 \t loss_valid = 26312362.0 \n",
      "Model_7_540 \t loss_train = 28602696.0 \t loss_valid = 26209922.0 \n",
      "Model_7_550 \t loss_train = 28270970.0 \t loss_valid = 27884484.0 \n",
      "Model_7_560 \t loss_train = 28461256.0 \t loss_valid = 26209108.0 \n",
      "Model_7_570 \t loss_train = 28182088.0 \t loss_valid = 27028868.0 \n",
      "Model_7_580 \t loss_train = 28695064.0 \t loss_valid = 25998364.0 \n",
      "Model_7_590 \t loss_train = 28212230.0 \t loss_valid = 26695996.0 \n",
      "Model_7_600 \t loss_train = 28808874.0 \t loss_valid = 26130120.0 \n",
      "Model_7_610 \t loss_train = 28186758.0 \t loss_valid = 26983440.0 \n",
      "Model_7_620 \t loss_train = 28716334.0 \t loss_valid = 25997096.0 \n",
      "Model_7_630 \t loss_train = 28264092.0 \t loss_valid = 26447270.0 \n",
      "Model_7_640 \t loss_train = 28229902.0 \t loss_valid = 26184628.0 \n",
      "Model_7_650 \t loss_train = 29040052.0 \t loss_valid = 26083744.0 \n",
      "Model_7_660 \t loss_train = 28175696.0 \t loss_valid = 26647856.0 \n",
      "Model_7_670 \t loss_train = 28187106.0 \t loss_valid = 27218306.0 \n",
      "Model_7_680 \t loss_train = 28205350.0 \t loss_valid = 26145612.0 \n",
      "Model_7_690 \t loss_train = 29082882.0 \t loss_valid = 25945098.0 \n",
      "Model_7_700 \t loss_train = 28185654.0 \t loss_valid = 27359484.0 \n",
      "Model_7_710 \t loss_train = 28314286.0 \t loss_valid = 25882530.0 \n",
      "Model_7_720 \t loss_train = 28390282.0 \t loss_valid = 25871188.0 \n",
      "Model_7_730 \t loss_train = 28097234.0 \t loss_valid = 26384678.0 \n",
      "Model_7_740 \t loss_train = 28182846.0 \t loss_valid = 25866706.0 \n",
      "Model_7_750 \t loss_train = 28345718.0 \t loss_valid = 25806178.0 \n",
      "Model_7_760 \t loss_train = 28336400.0 \t loss_valid = 25661080.0 \n",
      "Model_7_770 \t loss_train = 28289060.0 \t loss_valid = 25616678.0 \n",
      "Model_7_780 \t loss_train = 28357370.0 \t loss_valid = 25697014.0 \n",
      "Model_7_790 \t loss_train = 28322538.0 \t loss_valid = 25528210.0 \n",
      "Model_7_800 \t loss_train = 28302980.0 \t loss_valid = 25688136.0 \n",
      "Model_7_810 \t loss_train = 28285900.0 \t loss_valid = 25533342.0 \n",
      "Model_7_820 \t loss_train = 28161806.0 \t loss_valid = 26036288.0 \n",
      "Model_7_830 \t loss_train = 28562120.0 \t loss_valid = 25544558.0 \n",
      "Model_7_840 \t loss_train = 28267754.0 \t loss_valid = 25642252.0 \n",
      "Model_7_850 \t loss_train = 28102076.0 \t loss_valid = 26336250.0 \n",
      "Model_7_860 \t loss_train = 28415268.0 \t loss_valid = 25547586.0 \n",
      "Model_7_870 \t loss_train = 28698750.0 \t loss_valid = 25534422.0 \n",
      "Model_7_880 \t loss_train = 28272612.0 \t loss_valid = 25592348.0 \n",
      "Model_7_890 \t loss_train = 28328350.0 \t loss_valid = 25548872.0 \n",
      "Model_7_900 \t loss_train = 28070268.0 \t loss_valid = 26019870.0 \n",
      "Model_7_910 \t loss_train = 28172546.0 \t loss_valid = 25711582.0 \n",
      "Model_7_920 \t loss_train = 28249900.0 \t loss_valid = 25531012.0 \n",
      "Model_7_930 \t loss_train = 28184428.0 \t loss_valid = 25542836.0 \n",
      "Model_7_940 \t loss_train = 28357360.0 \t loss_valid = 25491452.0 \n",
      "Model_7_950 \t loss_train = 28382376.0 \t loss_valid = 25695146.0 \n",
      "Model_7_960 \t loss_train = 28130534.0 \t loss_valid = 25854762.0 \n",
      "Model_7_970 \t loss_train = 28420846.0 \t loss_valid = 25520364.0 \n",
      "Model_7_980 \t loss_train = 28194518.0 \t loss_valid = 25564954.0 \n",
      "Model_7_990 \t loss_train = 28148510.0 \t loss_valid = 25931026.0 \n",
      "Model_7_1000 \t loss_train = 28212768.0 \t loss_valid = 25555452.0 \n",
      "Model_7_1010 \t loss_train = 28360714.0 \t loss_valid = 25545588.0 \n",
      "Model_7_1020 \t loss_train = 28126680.0 \t loss_valid = 25915344.0 \n",
      "Model_7_1030 \t loss_train = 28508472.0 \t loss_valid = 25447420.0 \n",
      "Model_7_1040 \t loss_train = 28149488.0 \t loss_valid = 25949896.0 \n",
      "Model_7_1050 \t loss_train = 28687518.0 \t loss_valid = 25464568.0 \n",
      "Model_7_1060 \t loss_train = 28592828.0 \t loss_valid = 25480444.0 \n",
      "Model_7_1070 \t loss_train = 28385310.0 \t loss_valid = 25431464.0 \n",
      "Model_7_1080 \t loss_train = 28050880.0 \t loss_valid = 25916552.0 \n",
      "Model_7_1090 \t loss_train = 28218862.0 \t loss_valid = 25497034.0 \n",
      "Model_7_1100 \t loss_train = 28436044.0 \t loss_valid = 25426922.0 \n",
      "Model_7_1110 \t loss_train = 28663150.0 \t loss_valid = 25461188.0 \n",
      "Model_7_1120 \t loss_train = 28387442.0 \t loss_valid = 25424356.0 \n",
      "Model_7_1130 \t loss_train = 28231774.0 \t loss_valid = 25621154.0 \n",
      "Model_7_1140 \t loss_train = 28689250.0 \t loss_valid = 25479172.0 \n",
      "Model_7_1150 \t loss_train = 28204264.0 \t loss_valid = 25497868.0 \n",
      "Model_7_1160 \t loss_train = 28125052.0 \t loss_valid = 25777540.0 \n",
      "Model_7_1170 \t loss_train = 28300984.0 \t loss_valid = 25456832.0 \n",
      "Model_7_1180 \t loss_train = 28384484.0 \t loss_valid = 25450404.0 \n",
      "Model_7_1190 \t loss_train = 28362096.0 \t loss_valid = 25462728.0 \n",
      "Model_7_1200 \t loss_train = 28229002.0 \t loss_valid = 25529300.0 \n",
      "Model_7_1210 \t loss_train = 28303028.0 \t loss_valid = 25499796.0 \n",
      "Model_7_1220 \t loss_train = 28570048.0 \t loss_valid = 25408816.0 \n",
      "Model_7_1230 \t loss_train = 28568604.0 \t loss_valid = 25430994.0 \n",
      "Model_7_1240 \t loss_train = 28306816.0 \t loss_valid = 25525588.0 \n",
      "Model_7_1250 \t loss_train = 28604838.0 \t loss_valid = 25457382.0 \n",
      "Model_7_1260 \t loss_train = 28173772.0 \t loss_valid = 25915908.0 \n",
      "Model_7_1270 \t loss_train = 28380446.0 \t loss_valid = 25499252.0 \n",
      "Model_7_1280 \t loss_train = 28124304.0 \t loss_valid = 25654502.0 \n",
      "Model_7_1290 \t loss_train = 28462302.0 \t loss_valid = 25429750.0 \n",
      "Model_7_1300 \t loss_train = 28182822.0 \t loss_valid = 25548004.0 \n",
      "Model_7_1310 \t loss_train = 28393432.0 \t loss_valid = 25421706.0 \n",
      "Model_7_1320 \t loss_train = 28196242.0 \t loss_valid = 25514840.0 \n",
      "Model_7_1330 \t loss_train = 28669666.0 \t loss_valid = 25399166.0 \n",
      "Model_7_1340 \t loss_train = 28386560.0 \t loss_valid = 25425992.0 \n",
      "Model_7_1350 \t loss_train = 28429300.0 \t loss_valid = 25385632.0 \n",
      "Model_7_1360 \t loss_train = 28300904.0 \t loss_valid = 25484944.0 \n",
      "Model_7_1370 \t loss_train = 28407674.0 \t loss_valid = 25407280.0 \n",
      "Model_7_1380 \t loss_train = 28636358.0 \t loss_valid = 25391492.0 \n",
      "Model_7_1390 \t loss_train = 28550944.0 \t loss_valid = 25407982.0 \n",
      "Model_7_1400 \t loss_train = 28318134.0 \t loss_valid = 25415482.0 \n",
      "Model_7_1410 \t loss_train = 28487128.0 \t loss_valid = 25431792.0 \n",
      "Model_7_1420 \t loss_train = 28615300.0 \t loss_valid = 25404884.0 \n",
      "Model_7_1430 \t loss_train = 28604602.0 \t loss_valid = 25437316.0 \n",
      "Model_7_1440 \t loss_train = 28702402.0 \t loss_valid = 25409664.0 \n",
      "Model_7_1450 \t loss_train = 28101616.0 \t loss_valid = 25687560.0 \n",
      "Model_7_1460 \t loss_train = 29547428.0 \t loss_valid = 25826642.0 \n",
      "Model_7_1470 \t loss_train = 28285582.0 \t loss_valid = 25452518.0 \n",
      "Model_7_1480 \t loss_train = 28536834.0 \t loss_valid = 25375840.0 \n",
      "Model_7_1490 \t loss_train = 29242050.0 \t loss_valid = 25545644.0 \n",
      "Model_7_1500 \t loss_train = 28305908.0 \t loss_valid = 25407344.0 \n",
      "Model_7_1510 \t loss_train = 29114736.0 \t loss_valid = 25499268.0 \n",
      "Model_7_1520 \t loss_train = 28774694.0 \t loss_valid = 25394844.0 \n",
      "Model_7_1530 \t loss_train = 28426186.0 \t loss_valid = 25393590.0 \n",
      "Model_7_1540 \t loss_train = 28591752.0 \t loss_valid = 25348324.0 \n",
      "Model_7_1550 \t loss_train = 28474760.0 \t loss_valid = 25425332.0 \n",
      "Model_7_1560 \t loss_train = 29120072.0 \t loss_valid = 25483938.0 \n",
      "Model_7_1570 \t loss_train = 28685736.0 \t loss_valid = 25349196.0 \n",
      "Model_7_1580 \t loss_train = 28576258.0 \t loss_valid = 25339326.0 \n",
      "Model_7_1590 \t loss_train = 28523308.0 \t loss_valid = 25421038.0 \n",
      "Model_7_1600 \t loss_train = 28843986.0 \t loss_valid = 25456410.0 \n",
      "Model_7_1610 \t loss_train = 29092028.0 \t loss_valid = 25478516.0 \n",
      "Model_7_1620 \t loss_train = 28538930.0 \t loss_valid = 25352932.0 \n",
      "Model_7_1630 \t loss_train = 28690178.0 \t loss_valid = 25360814.0 \n",
      "Model_7_1640 \t loss_train = 29181124.0 \t loss_valid = 25484254.0 \n",
      "Model_7_1650 \t loss_train = 28614238.0 \t loss_valid = 25330594.0 \n",
      "Model_7_1660 \t loss_train = 28843244.0 \t loss_valid = 25369328.0 \n",
      "Model_7_1670 \t loss_train = 29295396.0 \t loss_valid = 25579614.0 \n",
      "Model_7_1680 \t loss_train = 28722176.0 \t loss_valid = 25357678.0 \n",
      "Model_7_1690 \t loss_train = 28544166.0 \t loss_valid = 25369262.0 \n",
      "Model_7_1700 \t loss_train = 28795288.0 \t loss_valid = 25381200.0 \n",
      "Model_7_1710 \t loss_train = 29065106.0 \t loss_valid = 25477966.0 \n",
      "Model_7_1720 \t loss_train = 28928036.0 \t loss_valid = 25424810.0 \n",
      "Model_7_1730 \t loss_train = 28993452.0 \t loss_valid = 25405826.0 \n",
      "Model_7_1740 \t loss_train = 28935326.0 \t loss_valid = 25453830.0 \n",
      "Model_7_1750 \t loss_train = 28851898.0 \t loss_valid = 25357678.0 \n",
      "Model_7_1760 \t loss_train = 29009808.0 \t loss_valid = 25425166.0 \n",
      "Model_7_1770 \t loss_train = 28777854.0 \t loss_valid = 25375484.0 \n",
      "Model_7_1780 \t loss_train = 29155844.0 \t loss_valid = 25531670.0 \n",
      "Model_7_1790 \t loss_train = 29166520.0 \t loss_valid = 25469350.0 \n",
      "Model_7_1800 \t loss_train = 29173624.0 \t loss_valid = 25505006.0 \n",
      "Model_7_1810 \t loss_train = 29095138.0 \t loss_valid = 25412446.0 \n",
      "Model_7_1820 \t loss_train = 29248806.0 \t loss_valid = 25508364.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_7_1830 \t loss_train = 29209906.0 \t loss_valid = 25510980.0 \n",
      "Model_7_1840 \t loss_train = 29188144.0 \t loss_valid = 25452388.0 \n",
      "Model_7_1850 \t loss_train = 29316954.0 \t loss_valid = 25578726.0 \n",
      "Model_7_1860 \t loss_train = 30268778.0 \t loss_valid = 26071620.0 \n",
      "Model_7_1870 \t loss_train = 28647292.0 \t loss_valid = 25335106.0 \n",
      "Model_7_1880 \t loss_train = 29583238.0 \t loss_valid = 25701078.0 \n",
      "Model_7_1890 \t loss_train = 29424238.0 \t loss_valid = 25622930.0 \n",
      "Model_7_1900 \t loss_train = 29089328.0 \t loss_valid = 25462904.0 \n",
      "Model_7_1910 \t loss_train = 29717938.0 \t loss_valid = 25802522.0 \n",
      "Model_7_1920 \t loss_train = 29339412.0 \t loss_valid = 25516624.0 \n",
      "Model_7_1930 \t loss_train = 29730340.0 \t loss_valid = 25681156.0 \n",
      "Model_7_1940 \t loss_train = 30513910.0 \t loss_valid = 26290440.0 \n",
      "Model_7_1950 \t loss_train = 28861720.0 \t loss_valid = 25374082.0 \n",
      "Model_7_1960 \t loss_train = 29900050.0 \t loss_valid = 25926238.0 \n",
      "Model_7_1970 \t loss_train = 29819378.0 \t loss_valid = 25837180.0 \n",
      "Model_7_1980 \t loss_train = 29618530.0 \t loss_valid = 25716630.0 \n",
      "Model_7_1990 \t loss_train = 30310594.0 \t loss_valid = 26061556.0 \n",
      "Model_7_2000 \t loss_train = 29774020.0 \t loss_valid = 25760332.0 \n",
      "Model_7_2010 \t loss_train = 29957132.0 \t loss_valid = 25862164.0 \n",
      "Model_7_2020 \t loss_train = 30047312.0 \t loss_valid = 25962720.0 \n",
      "Model_7_2030 \t loss_train = 29587506.0 \t loss_valid = 25625942.0 \n",
      "Model_7_2040 \t loss_train = 30265948.0 \t loss_valid = 26108904.0 \n",
      "Model_7_2050 \t loss_train = 29710012.0 \t loss_valid = 25674890.0 \n",
      "Model_7_2060 \t loss_train = 30254302.0 \t loss_valid = 26141648.0 \n",
      "Model_7_2070 \t loss_train = 30038390.0 \t loss_valid = 25907438.0 \n",
      "Model_7_2080 \t loss_train = 30659946.0 \t loss_valid = 26268962.0 \n",
      "Model_7_2090 \t loss_train = 30188626.0 \t loss_valid = 26027614.0 \n",
      "Model_7_2100 \t loss_train = 30355940.0 \t loss_valid = 25997786.0 \n",
      "Model_7_2110 \t loss_train = 29942410.0 \t loss_valid = 25861672.0 \n",
      "Model_7_2120 \t loss_train = 29519428.0 \t loss_valid = 25607870.0 \n",
      "Model_7_2130 \t loss_train = 31032468.0 \t loss_valid = 26618726.0 \n",
      "Model_7_2140 \t loss_train = 30665706.0 \t loss_valid = 26211968.0 \n",
      "Model_7_2150 \t loss_train = 30652450.0 \t loss_valid = 26178090.0 \n",
      "Model_7_2160 \t loss_train = 30612012.0 \t loss_valid = 26133314.0 \n",
      "Model_7_2170 \t loss_train = 30940448.0 \t loss_valid = 26458204.0 \n",
      "Model_7_2180 \t loss_train = 30935762.0 \t loss_valid = 26516168.0 \n",
      "Model_7_2190 \t loss_train = 31249468.0 \t loss_valid = 26647420.0 \n",
      "Model_7_2200 \t loss_train = 30658312.0 \t loss_valid = 26167502.0 \n",
      "Model_7_2210 \t loss_train = 30974370.0 \t loss_valid = 26503082.0 \n",
      "Model_7_2220 \t loss_train = 31467352.0 \t loss_valid = 26827448.0 \n",
      "Model_7_2230 \t loss_train = 31945778.0 \t loss_valid = 27172800.0 \n",
      "Model_7_2240 \t loss_train = 30605510.0 \t loss_valid = 26172886.0 \n",
      "Model_7_2250 \t loss_train = 31772424.0 \t loss_valid = 26940960.0 \n",
      "Model_7_2260 \t loss_train = 31596906.0 \t loss_valid = 26859154.0 \n",
      "Model_7_2270 \t loss_train = 31297128.0 \t loss_valid = 26749714.0 \n",
      "Model_7_2280 \t loss_train = 32103562.0 \t loss_valid = 27103362.0 \n",
      "Model_7_2290 \t loss_train = 31192630.0 \t loss_valid = 26757300.0 \n",
      "Model_7_2300 \t loss_train = 31711594.0 \t loss_valid = 26819792.0 \n",
      "Model_7_2310 \t loss_train = 31578048.0 \t loss_valid = 26935938.0 \n",
      "Model_7_2320 \t loss_train = 31749714.0 \t loss_valid = 26885660.0 \n",
      "Model_7_2330 \t loss_train = 31731008.0 \t loss_valid = 26930786.0 \n",
      "Model_7_2340 \t loss_train = 32652296.0 \t loss_valid = 27704156.0 \n",
      "Model_7_2350 \t loss_train = 31606852.0 \t loss_valid = 26826938.0 \n",
      "Model_7_2360 \t loss_train = 32137904.0 \t loss_valid = 27473126.0 \n",
      "Model_7_2370 \t loss_train = 32159208.0 \t loss_valid = 27174814.0 \n",
      "Model_7_2380 \t loss_train = 32669472.0 \t loss_valid = 27739882.0 \n",
      "Model_7_2390 \t loss_train = 32873008.0 \t loss_valid = 27707114.0 \n",
      "Model_7_2400 \t loss_train = 31552940.0 \t loss_valid = 26724014.0 \n",
      "Model_7_2410 \t loss_train = 32750314.0 \t loss_valid = 27735072.0 \n",
      "Model_7_2420 \t loss_train = 32828126.0 \t loss_valid = 27656730.0 \n",
      "Model_7_2430 \t loss_train = 32162830.0 \t loss_valid = 27260024.0 \n",
      "Model_7_2440 \t loss_train = 32620644.0 \t loss_valid = 27522450.0 \n",
      "Model_7_2450 \t loss_train = 32252614.0 \t loss_valid = 27321414.0 \n",
      "Model_7_2460 \t loss_train = 32892354.0 \t loss_valid = 27697244.0 \n",
      "Model_7_2470 \t loss_train = 32052268.0 \t loss_valid = 27065242.0 \n",
      "Model_7_2480 \t loss_train = 33586720.0 \t loss_valid = 28342468.0 \n",
      "Model_7_2490 \t loss_train = 32694698.0 \t loss_valid = 27583182.0 \n",
      "Model_7_2500 \t loss_train = 32596870.0 \t loss_valid = 27537932.0 \n",
      "Model_7_2510 \t loss_train = 33232816.0 \t loss_valid = 28079092.0 \n",
      "Model_7_2520 \t loss_train = 31982944.0 \t loss_valid = 27015332.0 \n",
      "Model_7_2530 \t loss_train = 33200224.0 \t loss_valid = 28091344.0 \n",
      "Model_7_2540 \t loss_train = 33129660.0 \t loss_valid = 27950242.0 \n",
      "Model_7_2550 \t loss_train = 32305738.0 \t loss_valid = 27408874.0 \n",
      "Model_7_2560 \t loss_train = 32516912.0 \t loss_valid = 27490480.0 \n",
      "Model_7_2570 \t loss_train = 32765924.0 \t loss_valid = 27665532.0 \n",
      "Model_7_2580 \t loss_train = 32876406.0 \t loss_valid = 27718166.0 \n",
      "Model_7_2590 \t loss_train = 33137192.0 \t loss_valid = 28068690.0 \n",
      "Model_7_2600 \t loss_train = 33073490.0 \t loss_valid = 27836438.0 \n",
      "Model_7_2610 \t loss_train = 32872414.0 \t loss_valid = 27766854.0 \n",
      "Model_7_2620 \t loss_train = 32398766.0 \t loss_valid = 27371810.0 \n",
      "Model_7_2630 \t loss_train = 33305968.0 \t loss_valid = 28104406.0 \n",
      "Model_7_2640 \t loss_train = 32806558.0 \t loss_valid = 27639448.0 \n",
      "Model_7_2650 \t loss_train = 33534966.0 \t loss_valid = 28328240.0 \n",
      "Model_7_2660 \t loss_train = 33125146.0 \t loss_valid = 27771032.0 \n",
      "Model_7_2670 \t loss_train = 32716012.0 \t loss_valid = 27708078.0 \n",
      "Model_7_2680 \t loss_train = 33299840.0 \t loss_valid = 27911828.0 \n",
      "Model_7_2690 \t loss_train = 33878368.0 \t loss_valid = 28567078.0 \n",
      "Model_7_2700 \t loss_train = 32971930.0 \t loss_valid = 27770522.0 \n",
      "Model_7_2710 \t loss_train = 33379626.0 \t loss_valid = 28137974.0 \n",
      "Model_7_2720 \t loss_train = 33209412.0 \t loss_valid = 28011280.0 \n",
      "Model_7_2730 \t loss_train = 33177794.0 \t loss_valid = 27959764.0 \n",
      "Model_7_2740 \t loss_train = 33716360.0 \t loss_valid = 28356848.0 \n",
      "Model_7_2750 \t loss_train = 32696730.0 \t loss_valid = 27495200.0 \n",
      "Model_7_2760 \t loss_train = 33377100.0 \t loss_valid = 28009074.0 \n",
      "Model_7_2770 \t loss_train = 33909524.0 \t loss_valid = 28614030.0 \n",
      "Model_7_2780 \t loss_train = 32744792.0 \t loss_valid = 27527398.0 \n",
      "Model_7_2790 \t loss_train = 33248374.0 \t loss_valid = 28091174.0 \n",
      "Model_7_2800 \t loss_train = 33704396.0 \t loss_valid = 28426026.0 \n",
      "Model_7_2810 \t loss_train = 33500280.0 \t loss_valid = 28303850.0 \n",
      "Model_7_2820 \t loss_train = 33529320.0 \t loss_valid = 28357550.0 \n",
      "Model_7_2830 \t loss_train = 33723956.0 \t loss_valid = 28407100.0 \n",
      "Model_7_2840 \t loss_train = 33921568.0 \t loss_valid = 28636398.0 \n",
      "Model_7_2850 \t loss_train = 33375186.0 \t loss_valid = 28139154.0 \n",
      "Model_7_2860 \t loss_train = 33318330.0 \t loss_valid = 28005892.0 \n",
      "Model_7_2870 \t loss_train = 33301402.0 \t loss_valid = 28231658.0 \n",
      "Model_7_2880 \t loss_train = 33076172.0 \t loss_valid = 27702910.0 \n",
      "Model_7_2890 \t loss_train = 33355194.0 \t loss_valid = 28103838.0 \n",
      "Model_7_2900 \t loss_train = 33441354.0 \t loss_valid = 28246540.0 \n",
      "Model_7_2910 \t loss_train = 33367370.0 \t loss_valid = 28087808.0 \n",
      "Model_7_2920 \t loss_train = 33659972.0 \t loss_valid = 28429154.0 \n",
      "Model_7_2930 \t loss_train = 33524438.0 \t loss_valid = 28233732.0 \n",
      "Model_7_2940 \t loss_train = 33372602.0 \t loss_valid = 28080922.0 \n",
      "Model_7_2950 \t loss_train = 34408884.0 \t loss_valid = 28967648.0 \n",
      "Model_7_2960 \t loss_train = 32703860.0 \t loss_valid = 27662866.0 \n",
      "Model_7_2970 \t loss_train = 33071662.0 \t loss_valid = 27852560.0 \n",
      "Model_7_2980 \t loss_train = 33668196.0 \t loss_valid = 28349956.0 \n",
      "Model_7_2990 \t loss_train = 34256396.0 \t loss_valid = 28769766.0 \n",
      "Model_7_3000 \t loss_train = 32920630.0 \t loss_valid = 27858918.0 \n",
      "Model_7_3010 \t loss_train = 33534038.0 \t loss_valid = 28208380.0 \n",
      "Model_7_3020 \t loss_train = 34086568.0 \t loss_valid = 28708108.0 \n",
      "Model_7_3030 \t loss_train = 32810160.0 \t loss_valid = 27625586.0 \n",
      "Model_7_3040 \t loss_train = 34123436.0 \t loss_valid = 28837790.0 \n",
      "Model_7_3050 \t loss_train = 34227540.0 \t loss_valid = 28867558.0 \n",
      "Model_7_3060 \t loss_train = 33598832.0 \t loss_valid = 28274518.0 \n",
      "Model_7_3070 \t loss_train = 33681108.0 \t loss_valid = 28380532.0 \n",
      "Model_7_3080 \t loss_train = 33964472.0 \t loss_valid = 28626752.0 \n",
      "Model_7_3090 \t loss_train = 33147622.0 \t loss_valid = 27982876.0 \n",
      "Model_7_3100 \t loss_train = 34063296.0 \t loss_valid = 28689970.0 \n",
      "Model_7_3110 \t loss_train = 33553690.0 \t loss_valid = 28233228.0 \n",
      "Model_7_3120 \t loss_train = 33242950.0 \t loss_valid = 28002664.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_7_3130 \t loss_train = 33793012.0 \t loss_valid = 28470642.0 \n",
      "Model_7_3140 \t loss_train = 33442988.0 \t loss_valid = 28243068.0 \n",
      "Model_7_3150 \t loss_train = 33740380.0 \t loss_valid = 28345144.0 \n",
      "Model_7_3160 \t loss_train = 33516910.0 \t loss_valid = 28276944.0 \n",
      "Model_7_3170 \t loss_train = 33929128.0 \t loss_valid = 28515394.0 \n",
      "Model_7_3180 \t loss_train = 33331942.0 \t loss_valid = 28102576.0 \n",
      "Model_7_3190 \t loss_train = 32923316.0 \t loss_valid = 27672260.0 \n",
      "Model_7_3200 \t loss_train = 33725320.0 \t loss_valid = 28423172.0 \n",
      "Model_7_3210 \t loss_train = 34115304.0 \t loss_valid = 28603196.0 \n",
      "Model_7_3220 \t loss_train = 33649908.0 \t loss_valid = 28194168.0 \n",
      "Model_7_3230 \t loss_train = 33844920.0 \t loss_valid = 28490620.0 \n",
      "Model_7_3240 \t loss_train = 33565148.0 \t loss_valid = 28322114.0 \n",
      "Model_7_3250 \t loss_train = 33512070.0 \t loss_valid = 28218350.0 \n",
      "Model_7_3260 \t loss_train = 34108632.0 \t loss_valid = 28672750.0 \n",
      "Model_7_3270 \t loss_train = 33158270.0 \t loss_valid = 27941774.0 \n",
      "Model_7_3280 \t loss_train = 34048096.0 \t loss_valid = 28627456.0 \n",
      "Model_7_3290 \t loss_train = 33835756.0 \t loss_valid = 28458562.0 \n",
      "Model_7_3300 \t loss_train = 33949800.0 \t loss_valid = 28338138.0 \n",
      "Model_7_3310 \t loss_train = 33654672.0 \t loss_valid = 28428954.0 \n",
      "Model_7_3320 \t loss_train = 33828456.0 \t loss_valid = 28353570.0 \n",
      "Model_7_3330 \t loss_train = 34482344.0 \t loss_valid = 29071300.0 \n",
      "Model_7_3340 \t loss_train = 33427686.0 \t loss_valid = 27905932.0 \n",
      "Model_7_3350 \t loss_train = 34928008.0 \t loss_valid = 29316206.0 \n",
      "Model_7_3360 \t loss_train = 32812506.0 \t loss_valid = 27637172.0 \n",
      "Model_7_3370 \t loss_train = 34188712.0 \t loss_valid = 28687898.0 \n",
      "Model_7_3380 \t loss_train = 33762304.0 \t loss_valid = 28318566.0 \n",
      "Model_7_3390 \t loss_train = 33825092.0 \t loss_valid = 28552414.0 \n",
      "Model_7_3400 \t loss_train = 33626364.0 \t loss_valid = 28141088.0 \n",
      "Model_7_3410 \t loss_train = 32949598.0 \t loss_valid = 27785652.0 \n",
      "Model_7_3420 \t loss_train = 33491040.0 \t loss_valid = 28205916.0 \n",
      "Model_7_3430 \t loss_train = 34250624.0 \t loss_valid = 28955102.0 \n",
      "Model_7_3440 \t loss_train = 33320014.0 \t loss_valid = 28021596.0 \n",
      "Model_7_3450 \t loss_train = 33733576.0 \t loss_valid = 28414546.0 \n",
      "Model_7_3460 \t loss_train = 34440288.0 \t loss_valid = 29046066.0 \n",
      "Model_7_3470 \t loss_train = 32898856.0 \t loss_valid = 27706848.0 \n",
      "Model_7_3480 \t loss_train = 34556948.0 \t loss_valid = 29088942.0 \n",
      "Model_7_3490 \t loss_train = 33324080.0 \t loss_valid = 28099534.0 \n",
      "Model_7_3500 \t loss_train = 33873920.0 \t loss_valid = 28325854.0 \n",
      "Model_7_3510 \t loss_train = 33216950.0 \t loss_valid = 28073092.0 \n",
      "Model_7_3520 \t loss_train = 34297484.0 \t loss_valid = 28785488.0 \n",
      "Model_7_3530 \t loss_train = 33360262.0 \t loss_valid = 28109938.0 \n",
      "Model_7_3540 \t loss_train = 34331008.0 \t loss_valid = 28784636.0 \n",
      "Model_7_3550 \t loss_train = 34832760.0 \t loss_valid = 29401100.0 \n",
      "Model_7_3560 \t loss_train = 32994970.0 \t loss_valid = 27777580.0 \n",
      "Model_7_3570 \t loss_train = 35059464.0 \t loss_valid = 29632312.0 \n",
      "Model_7_3580 \t loss_train = 33646384.0 \t loss_valid = 28344294.0 \n",
      "Model_7_3590 \t loss_train = 33731472.0 \t loss_valid = 28296214.0 \n",
      "Model_7_3600 \t loss_train = 34283064.0 \t loss_valid = 28904426.0 \n",
      "Model_7_3610 \t loss_train = 33169882.0 \t loss_valid = 27903538.0 \n",
      "Model_7_3620 \t loss_train = 34085168.0 \t loss_valid = 28847044.0 \n",
      "Model_7_3630 \t loss_train = 33473046.0 \t loss_valid = 28061146.0 \n",
      "Model_7_3640 \t loss_train = 33596992.0 \t loss_valid = 28419410.0 \n",
      "Model_7_3650 \t loss_train = 34124288.0 \t loss_valid = 28635954.0 \n",
      "Model_7_3660 \t loss_train = 33106928.0 \t loss_valid = 27915900.0 \n",
      "Model_7_3670 \t loss_train = 33706460.0 \t loss_valid = 28400184.0 \n",
      "Model_7_3680 \t loss_train = 33773880.0 \t loss_valid = 28473106.0 \n",
      "Model_7_3690 \t loss_train = 34192892.0 \t loss_valid = 28672176.0 \n",
      "Model_7_3700 \t loss_train = 33646140.0 \t loss_valid = 28339646.0 \n",
      "Model_7_3710 \t loss_train = 33289918.0 \t loss_valid = 27932982.0 \n",
      "Model_7_3720 \t loss_train = 34262064.0 \t loss_valid = 28818564.0 \n",
      "Model_7_3730 \t loss_train = 33258366.0 \t loss_valid = 27948832.0 \n",
      "Model_7_3740 \t loss_train = 33283900.0 \t loss_valid = 27914480.0 \n",
      "Model_7_3750 \t loss_train = 33573828.0 \t loss_valid = 28208286.0 \n",
      "Model_7_3760 \t loss_train = 33754256.0 \t loss_valid = 28488294.0 \n",
      "Model_7_3770 \t loss_train = 33403696.0 \t loss_valid = 28075602.0 \n",
      "Model_7_3780 \t loss_train = 33845316.0 \t loss_valid = 28429748.0 \n",
      "Model_7_3790 \t loss_train = 33849756.0 \t loss_valid = 28412486.0 \n",
      "Model_7_3800 \t loss_train = 33888708.0 \t loss_valid = 28452590.0 \n",
      "Model_7_3810 \t loss_train = 33123610.0 \t loss_valid = 27914478.0 \n",
      "Model_7_3820 \t loss_train = 33621724.0 \t loss_valid = 28337816.0 \n",
      "Model_7_3830 \t loss_train = 33762144.0 \t loss_valid = 28409182.0 \n",
      "Model_7_3840 \t loss_train = 33661328.0 \t loss_valid = 28308752.0 \n",
      "Model_7_3850 \t loss_train = 32881650.0 \t loss_valid = 27601838.0 \n",
      "Model_7_3860 \t loss_train = 33535136.0 \t loss_valid = 28191868.0 \n",
      "Model_7_3870 \t loss_train = 34166496.0 \t loss_valid = 28626262.0 \n",
      "Model_7_3880 \t loss_train = 33737236.0 \t loss_valid = 28380362.0 \n",
      "Model_7_3890 \t loss_train = 33425720.0 \t loss_valid = 28084062.0 \n",
      "Model_7_3900 \t loss_train = 33679628.0 \t loss_valid = 28469470.0 \n",
      "Model_7_3910 \t loss_train = 34128568.0 \t loss_valid = 28609542.0 \n",
      "Model_7_3920 \t loss_train = 33279148.0 \t loss_valid = 27826060.0 \n",
      "Model_7_3930 \t loss_train = 34213100.0 \t loss_valid = 28860556.0 \n",
      "Model_7_3940 \t loss_train = 33607564.0 \t loss_valid = 28152254.0 \n",
      "Model_7_3950 \t loss_train = 33151452.0 \t loss_valid = 27919092.0 \n",
      "Model_7_3960 \t loss_train = 33611044.0 \t loss_valid = 28292506.0 \n",
      "Model_7_3970 \t loss_train = 33741416.0 \t loss_valid = 28298698.0 \n",
      "Model_7_3980 \t loss_train = 33125554.0 \t loss_valid = 27901970.0 \n",
      "Model_7_3990 \t loss_train = 33300974.0 \t loss_valid = 27982686.0 \n",
      "Model_7_4000 \t loss_train = 33326776.0 \t loss_valid = 28199528.0 \n",
      "Model_7_4010 \t loss_train = 32908510.0 \t loss_valid = 27657860.0 \n",
      "Model_7_4020 \t loss_train = 34447236.0 \t loss_valid = 29061064.0 \n",
      "Model_7_4030 \t loss_train = 33077078.0 \t loss_valid = 27838666.0 \n",
      "Model_7_4040 \t loss_train = 33802404.0 \t loss_valid = 28529184.0 \n",
      "Model_7_4050 \t loss_train = 33905280.0 \t loss_valid = 28461542.0 \n",
      "Model_7_4060 \t loss_train = 32954930.0 \t loss_valid = 27766942.0 \n",
      "Model_7_4070 \t loss_train = 33793708.0 \t loss_valid = 28502960.0 \n",
      "Model_7_4080 \t loss_train = 33528424.0 \t loss_valid = 28226190.0 \n",
      "Model_7_4090 \t loss_train = 33045222.0 \t loss_valid = 27834238.0 \n",
      "Model_7_4100 \t loss_train = 34313764.0 \t loss_valid = 28937542.0 \n",
      "Model_7_4110 \t loss_train = 33223826.0 \t loss_valid = 27904218.0 \n",
      "Model_7_4120 \t loss_train = 34081892.0 \t loss_valid = 28672032.0 \n",
      "Model_7_4130 \t loss_train = 33295124.0 \t loss_valid = 27929692.0 \n",
      "Model_7_4140 \t loss_train = 33971288.0 \t loss_valid = 28658864.0 \n",
      "Model_7_4150 \t loss_train = 33586716.0 \t loss_valid = 28231276.0 \n",
      "Model_7_4160 \t loss_train = 33819752.0 \t loss_valid = 28390068.0 \n",
      "Model_7_4170 \t loss_train = 34059536.0 \t loss_valid = 28628340.0 \n",
      "Model_7_4180 \t loss_train = 33671596.0 \t loss_valid = 28329854.0 \n",
      "Model_7_4190 \t loss_train = 33767196.0 \t loss_valid = 28458386.0 \n",
      "Model_7_4200 \t loss_train = 33912204.0 \t loss_valid = 28630082.0 \n",
      "Model_7_4210 \t loss_train = 33809868.0 \t loss_valid = 28551540.0 \n",
      "Model_7_4220 \t loss_train = 33924672.0 \t loss_valid = 28499434.0 \n",
      "Model_7_4230 \t loss_train = 32929194.0 \t loss_valid = 27680568.0 \n",
      "Model_7_4240 \t loss_train = 34054548.0 \t loss_valid = 28769160.0 \n",
      "Model_7_4250 \t loss_train = 33181496.0 \t loss_valid = 27925090.0 \n",
      "Model_7_4260 \t loss_train = 34192388.0 \t loss_valid = 28776660.0 \n",
      "Model_7_4270 \t loss_train = 33265824.0 \t loss_valid = 28049968.0 \n",
      "Model_7_4280 \t loss_train = 33692120.0 \t loss_valid = 28323812.0 \n",
      "Model_7_4290 \t loss_train = 33240874.0 \t loss_valid = 27976594.0 \n",
      "Model_7_4300 \t loss_train = 34210920.0 \t loss_valid = 28787152.0 \n",
      "Model_7_4310 \t loss_train = 33603912.0 \t loss_valid = 28392448.0 \n",
      "Model_7_4320 \t loss_train = 33743712.0 \t loss_valid = 28441566.0 \n",
      "Model_7_4330 \t loss_train = 33028372.0 \t loss_valid = 27854318.0 \n",
      "Model_7_4340 \t loss_train = 34192752.0 \t loss_valid = 28816584.0 \n",
      "Model_7_4350 \t loss_train = 33643980.0 \t loss_valid = 28451088.0 \n",
      "Model_7_4360 \t loss_train = 33448212.0 \t loss_valid = 28171252.0 \n",
      "Model_7_4370 \t loss_train = 33869404.0 \t loss_valid = 28528804.0 \n",
      "Model_7_4380 \t loss_train = 33218850.0 \t loss_valid = 28161322.0 \n",
      "Model_7_4390 \t loss_train = 33602956.0 \t loss_valid = 28234044.0 \n",
      "Model_7_4400 \t loss_train = 33308616.0 \t loss_valid = 28118148.0 \n",
      "Model_7_4410 \t loss_train = 33365226.0 \t loss_valid = 28049566.0 \n",
      "Model_7_4420 \t loss_train = 33600472.0 \t loss_valid = 28336516.0 \n",
      "Model_7_4430 \t loss_train = 33561236.0 \t loss_valid = 28178158.0 \n",
      "Model_7_4440 \t loss_train = 34129044.0 \t loss_valid = 28642286.0 \n",
      "Model_7_4450 \t loss_train = 33302862.0 \t loss_valid = 28046678.0 \n",
      "Model_7_4460 \t loss_train = 33363672.0 \t loss_valid = 28120200.0 \n",
      "Model_7_4470 \t loss_train = 33639540.0 \t loss_valid = 28252654.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_7_4480 \t loss_train = 33668616.0 \t loss_valid = 28442536.0 \n",
      "Model_7_4490 \t loss_train = 33206110.0 \t loss_valid = 27952742.0 \n",
      "Model_7_4500 \t loss_train = 33196826.0 \t loss_valid = 27995658.0 \n",
      "Model_7_4510 \t loss_train = 33766924.0 \t loss_valid = 28348264.0 \n",
      "Model_7_4520 \t loss_train = 34310704.0 \t loss_valid = 29028002.0 \n",
      "Model_7_4530 \t loss_train = 32736202.0 \t loss_valid = 27522462.0 \n",
      "Model_7_4540 \t loss_train = 34083656.0 \t loss_valid = 28671210.0 \n",
      "Model_7_4550 \t loss_train = 33630256.0 \t loss_valid = 28322522.0 \n",
      "Model_7_4560 \t loss_train = 33832448.0 \t loss_valid = 28405504.0 \n",
      "Model_7_4570 \t loss_train = 33660336.0 \t loss_valid = 28339120.0 \n",
      "Model_7_4580 \t loss_train = 34399948.0 \t loss_valid = 28993638.0 \n",
      "Model_7_4590 \t loss_train = 33941692.0 \t loss_valid = 28473666.0 \n",
      "Model_7_4600 \t loss_train = 33318322.0 \t loss_valid = 28049806.0 \n",
      "Model_7_4610 \t loss_train = 34063712.0 \t loss_valid = 28636998.0 \n",
      "Model_7_4620 \t loss_train = 33888416.0 \t loss_valid = 28412458.0 \n",
      "Model_7_4630 \t loss_train = 33458200.0 \t loss_valid = 28124570.0 \n",
      "Model_7_4640 \t loss_train = 33438312.0 \t loss_valid = 28050864.0 \n",
      "Model_7_4650 \t loss_train = 33566452.0 \t loss_valid = 28231860.0 \n",
      "Model_7_4660 \t loss_train = 33749280.0 \t loss_valid = 28363298.0 \n",
      "Model_7_4670 \t loss_train = 33733024.0 \t loss_valid = 28453518.0 \n",
      "Model_7_4680 \t loss_train = 33871316.0 \t loss_valid = 28523404.0 \n",
      "Model_7_4690 \t loss_train = 33243486.0 \t loss_valid = 27946856.0 \n",
      "Model_7_4700 \t loss_train = 34203968.0 \t loss_valid = 28764128.0 \n",
      "Model_7_4710 \t loss_train = 33565296.0 \t loss_valid = 28384926.0 \n",
      "Model_7_4720 \t loss_train = 34734340.0 \t loss_valid = 29242248.0 \n",
      "Model_7_4730 \t loss_train = 33255000.0 \t loss_valid = 28063870.0 \n",
      "Model_7_4740 \t loss_train = 33948220.0 \t loss_valid = 28569764.0 \n",
      "Model_7_4750 \t loss_train = 33428830.0 \t loss_valid = 28184842.0 \n",
      "Model_7_4760 \t loss_train = 33801304.0 \t loss_valid = 28537938.0 \n",
      "Model_7_4770 \t loss_train = 32960092.0 \t loss_valid = 27727796.0 \n",
      "Model_7_4780 \t loss_train = 33939732.0 \t loss_valid = 28660050.0 \n",
      "Model_7_4790 \t loss_train = 33472188.0 \t loss_valid = 28127264.0 \n",
      "Model_7_4800 \t loss_train = 33660624.0 \t loss_valid = 28375166.0 \n",
      "Model_7_4810 \t loss_train = 33985992.0 \t loss_valid = 28606372.0 \n",
      "Model_7_4820 \t loss_train = 33382510.0 \t loss_valid = 28155392.0 \n",
      "Model_7_4830 \t loss_train = 34571884.0 \t loss_valid = 29080092.0 \n",
      "Model_7_4840 \t loss_train = 34129964.0 \t loss_valid = 28720710.0 \n",
      "Model_7_4850 \t loss_train = 33612956.0 \t loss_valid = 28278718.0 \n",
      "Model_7_4860 \t loss_train = 33021092.0 \t loss_valid = 27811362.0 \n",
      "Model_7_4870 \t loss_train = 33775384.0 \t loss_valid = 28426604.0 \n",
      "Model_7_4880 \t loss_train = 33391748.0 \t loss_valid = 28110140.0 \n",
      "Model_7_4890 \t loss_train = 33149632.0 \t loss_valid = 27978452.0 \n",
      "Model_7_4900 \t loss_train = 33604592.0 \t loss_valid = 28298938.0 \n",
      "Model_7_4910 \t loss_train = 33521100.0 \t loss_valid = 28257078.0 \n",
      "Model_7_4920 \t loss_train = 33407314.0 \t loss_valid = 28223462.0 \n",
      "Model_7_4930 \t loss_train = 34478332.0 \t loss_valid = 29098274.0 \n",
      "Model_7_4940 \t loss_train = 32937456.0 \t loss_valid = 27907906.0 \n",
      "Model_7_4950 \t loss_train = 33865588.0 \t loss_valid = 28427034.0 \n",
      "Model_7_4960 \t loss_train = 33292766.0 \t loss_valid = 28135848.0 \n",
      "Model_7_4970 \t loss_train = 33486634.0 \t loss_valid = 28117962.0 \n",
      "Model_7_4980 \t loss_train = 33462490.0 \t loss_valid = 28171200.0 \n",
      "Model_7_4990 \t loss_train = 33989568.0 \t loss_valid = 28557142.0 \n",
      "Model_7_5000 \t loss_train = 33757016.0 \t loss_valid = 28501908.0 \n",
      "Model_7_5010 \t loss_train = 33969952.0 \t loss_valid = 28543394.0 \n",
      "Model_7_5020 \t loss_train = 33426548.0 \t loss_valid = 28137506.0 \n",
      "Model_7_5030 \t loss_train = 33881428.0 \t loss_valid = 28591430.0 \n",
      "Model_7_5040 \t loss_train = 33336746.0 \t loss_valid = 27989352.0 \n",
      "Model_7_5050 \t loss_train = 33854208.0 \t loss_valid = 28550856.0 \n",
      "Model_7_5060 \t loss_train = 33500306.0 \t loss_valid = 28172984.0 \n",
      "Model_7_5070 \t loss_train = 33506594.0 \t loss_valid = 28272538.0 \n",
      "Model_7_5080 \t loss_train = 33669848.0 \t loss_valid = 28354566.0 \n",
      "Model_7_5090 \t loss_train = 33874968.0 \t loss_valid = 28505972.0 \n",
      "Model_7_5100 \t loss_train = 33406294.0 \t loss_valid = 28110830.0 \n",
      "Model_7_5110 \t loss_train = 33752148.0 \t loss_valid = 28388150.0 \n",
      "Model_7_5120 \t loss_train = 33666360.0 \t loss_valid = 28387464.0 \n",
      "Model_7_5130 \t loss_train = 32808388.0 \t loss_valid = 27603184.0 \n",
      "Model_7_5140 \t loss_train = 34229092.0 \t loss_valid = 28703734.0 \n",
      "Model_7_5150 \t loss_train = 33129436.0 \t loss_valid = 27846928.0 \n",
      "Model_7_5160 \t loss_train = 34117404.0 \t loss_valid = 28687682.0 \n",
      "Model_7_5170 \t loss_train = 33110246.0 \t loss_valid = 27885182.0 \n",
      "Model_7_5180 \t loss_train = 34192900.0 \t loss_valid = 28722476.0 \n",
      "Model_7_5190 \t loss_train = 34189772.0 \t loss_valid = 28837512.0 \n",
      "Model_7_5200 \t loss_train = 33950264.0 \t loss_valid = 28595118.0 \n",
      "Model_7_5210 \t loss_train = 33888132.0 \t loss_valid = 28539954.0 \n",
      "Model_7_5220 \t loss_train = 32968698.0 \t loss_valid = 27788224.0 \n",
      "Model_7_5230 \t loss_train = 34276040.0 \t loss_valid = 28772858.0 \n",
      "Model_7_5240 \t loss_train = 33383846.0 \t loss_valid = 28007914.0 \n",
      "Model_7_5250 \t loss_train = 33930128.0 \t loss_valid = 28580258.0 \n",
      "Model_7_5260 \t loss_train = 33480018.0 \t loss_valid = 28146232.0 \n",
      "Model_7_5270 \t loss_train = 34584428.0 \t loss_valid = 29053844.0 \n",
      "Model_7_5280 \t loss_train = 33277764.0 \t loss_valid = 27962558.0 \n",
      "Model_7_5290 \t loss_train = 33830436.0 \t loss_valid = 28527818.0 \n",
      "Model_7_5300 \t loss_train = 33330338.0 \t loss_valid = 28100880.0 \n",
      "Model_7_5310 \t loss_train = 33208088.0 \t loss_valid = 27959858.0 \n",
      "Model_7_5320 \t loss_train = 33528966.0 \t loss_valid = 28278974.0 \n",
      "Model_7_5330 \t loss_train = 33579564.0 \t loss_valid = 28248114.0 \n",
      "Model_7_5340 \t loss_train = 33679668.0 \t loss_valid = 28347654.0 \n",
      "Model_7_5350 \t loss_train = 33581688.0 \t loss_valid = 28128534.0 \n",
      "Model_7_5360 \t loss_train = 33639940.0 \t loss_valid = 28377724.0 \n",
      "Model_7_5370 \t loss_train = 34005460.0 \t loss_valid = 28443000.0 \n",
      "Model_7_5380 \t loss_train = 34082200.0 \t loss_valid = 28812180.0 \n",
      "Model_7_5390 \t loss_train = 34205596.0 \t loss_valid = 28733712.0 \n",
      "Model_7_5400 \t loss_train = 33755240.0 \t loss_valid = 28425890.0 \n",
      "Model_7_5410 \t loss_train = 33966136.0 \t loss_valid = 28514092.0 \n",
      "Model_7_5420 \t loss_train = 33395070.0 \t loss_valid = 28131504.0 \n",
      "Model_7_5430 \t loss_train = 33627692.0 \t loss_valid = 28319836.0 \n",
      "Model_7_5440 \t loss_train = 34233272.0 \t loss_valid = 28832054.0 \n",
      "Model_7_5450 \t loss_train = 33262882.0 \t loss_valid = 27918620.0 \n",
      "Model_7_5460 \t loss_train = 34173688.0 \t loss_valid = 28826326.0 \n",
      "Model_7_5470 \t loss_train = 33864260.0 \t loss_valid = 28385568.0 \n",
      "Model_7_5480 \t loss_train = 33527390.0 \t loss_valid = 28317762.0 \n",
      "Model_7_5490 \t loss_train = 34068880.0 \t loss_valid = 28610898.0 \n",
      "Model_7_5500 \t loss_train = 33340026.0 \t loss_valid = 28111506.0 \n",
      "Model_7_5510 \t loss_train = 34257084.0 \t loss_valid = 28817556.0 \n",
      "Model_7_5520 \t loss_train = 34033872.0 \t loss_valid = 28681396.0 \n",
      "Model_7_5530 \t loss_train = 34103812.0 \t loss_valid = 28704920.0 \n",
      "Model_7_5540 \t loss_train = 34145004.0 \t loss_valid = 28733212.0 \n",
      "Model_7_5550 \t loss_train = 33964640.0 \t loss_valid = 28574328.0 \n",
      "Model_7_5560 \t loss_train = 33507550.0 \t loss_valid = 28173722.0 \n",
      "Model_7_5570 \t loss_train = 34247720.0 \t loss_valid = 28924214.0 \n",
      "Model_7_5580 \t loss_train = 34144464.0 \t loss_valid = 28611242.0 \n",
      "Model_7_5590 \t loss_train = 32930492.0 \t loss_valid = 27773152.0 \n",
      "Model_7_5600 \t loss_train = 34422444.0 \t loss_valid = 28894208.0 \n",
      "Model_7_5610 \t loss_train = 34021056.0 \t loss_valid = 28748886.0 \n",
      "Model_7_5620 \t loss_train = 33863128.0 \t loss_valid = 28484974.0 \n",
      "Model_7_5630 \t loss_train = 34240148.0 \t loss_valid = 28772402.0 \n",
      "Model_7_5640 \t loss_train = 33715700.0 \t loss_valid = 28333960.0 \n",
      "Model_7_5650 \t loss_train = 33971040.0 \t loss_valid = 28638824.0 \n",
      "Model_7_5660 \t loss_train = 33591132.0 \t loss_valid = 28290528.0 \n",
      "Model_7_5670 \t loss_train = 34029624.0 \t loss_valid = 28622440.0 \n",
      "Model_7_5680 \t loss_train = 33634880.0 \t loss_valid = 28238326.0 \n",
      "Model_7_5690 \t loss_train = 34105580.0 \t loss_valid = 28679736.0 \n",
      "Model_7_5700 \t loss_train = 34184596.0 \t loss_valid = 28829700.0 \n",
      "Model_7_5710 \t loss_train = 33776824.0 \t loss_valid = 28523924.0 \n",
      "Model_7_5720 \t loss_train = 34129252.0 \t loss_valid = 28697632.0 \n",
      "Model_7_5730 \t loss_train = 34049668.0 \t loss_valid = 28622778.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_7_5740 \t loss_train = 33799480.0 \t loss_valid = 28500152.0 \n",
      "Model_7_5750 \t loss_train = 34325072.0 \t loss_valid = 28917492.0 \n",
      "Model_7_5760 \t loss_train = 33704080.0 \t loss_valid = 28422848.0 \n",
      "Model_7_5770 \t loss_train = 34037316.0 \t loss_valid = 28567864.0 \n",
      "Model_7_5780 \t loss_train = 33589752.0 \t loss_valid = 28339800.0 \n",
      "Model_7_5790 \t loss_train = 34668904.0 \t loss_valid = 29172518.0 \n",
      "Model_7_5800 \t loss_train = 33905708.0 \t loss_valid = 28545856.0 \n",
      "Model_7_5810 \t loss_train = 33429700.0 \t loss_valid = 28201868.0 \n",
      "Model_7_5820 \t loss_train = 34519788.0 \t loss_valid = 29048866.0 \n",
      "Model_7_5830 \t loss_train = 33604396.0 \t loss_valid = 28327406.0 \n",
      "Model_7_5840 \t loss_train = 33983912.0 \t loss_valid = 28556756.0 \n",
      "Model_7_5850 \t loss_train = 34439092.0 \t loss_valid = 28930472.0 \n",
      "Model_7_5860 \t loss_train = 33392208.0 \t loss_valid = 28102666.0 \n",
      "Model_7_5870 \t loss_train = 34428556.0 \t loss_valid = 28932040.0 \n",
      "Model_7_5880 \t loss_train = 34129504.0 \t loss_valid = 28740020.0 \n",
      "Model_7_5890 \t loss_train = 33892708.0 \t loss_valid = 28566818.0 \n",
      "Model_7_5900 \t loss_train = 33913220.0 \t loss_valid = 28562170.0 \n",
      "Model_7_5910 \t loss_train = 34852912.0 \t loss_valid = 29292562.0 \n",
      "Model_7_5920 \t loss_train = 34064716.0 \t loss_valid = 28694908.0 \n",
      "Model_7_5930 \t loss_train = 33806012.0 \t loss_valid = 28368252.0 \n",
      "Model_7_5940 \t loss_train = 34033728.0 \t loss_valid = 28671232.0 \n",
      "Model_7_5950 \t loss_train = 33451218.0 \t loss_valid = 28112154.0 \n",
      "Model_7_5960 \t loss_train = 34070364.0 \t loss_valid = 28764116.0 \n",
      "Model_7_5970 \t loss_train = 34399588.0 \t loss_valid = 28947308.0 \n",
      "Model_7_5980 \t loss_train = 33604140.0 \t loss_valid = 28339020.0 \n",
      "Model_7_5990 \t loss_train = 34067644.0 \t loss_valid = 28592564.0 \n",
      "Model_7_6000 \t loss_train = 33811508.0 \t loss_valid = 28450398.0 \n",
      "Model_7_6010 \t loss_train = 34244896.0 \t loss_valid = 28669190.0 \n",
      "Model_7_6020 \t loss_train = 33949520.0 \t loss_valid = 28566342.0 \n",
      "Model_7_6030 \t loss_train = 35157568.0 \t loss_valid = 29641514.0 \n",
      "Model_7_6040 \t loss_train = 33901568.0 \t loss_valid = 28462428.0 \n",
      "Model_7_6050 \t loss_train = 33595620.0 \t loss_valid = 28264562.0 \n",
      "Model_7_6060 \t loss_train = 34009604.0 \t loss_valid = 28633240.0 \n",
      "Model_7_6070 \t loss_train = 34272708.0 \t loss_valid = 28840644.0 \n",
      "Model_7_6080 \t loss_train = 34091216.0 \t loss_valid = 28663166.0 \n",
      "Model_7_6090 \t loss_train = 34243436.0 \t loss_valid = 28753162.0 \n",
      "Model_7_6100 \t loss_train = 34179368.0 \t loss_valid = 28812920.0 \n",
      "Model_7_6110 \t loss_train = 34337568.0 \t loss_valid = 28802080.0 \n",
      "Model_7_6120 \t loss_train = 34002620.0 \t loss_valid = 28587100.0 \n",
      "Model_7_6130 \t loss_train = 34452412.0 \t loss_valid = 29068272.0 \n",
      "Model_7_6140 \t loss_train = 34362980.0 \t loss_valid = 29039552.0 \n",
      "Model_7_6150 \t loss_train = 33703784.0 \t loss_valid = 28319860.0 \n",
      "Model_7_6160 \t loss_train = 34167380.0 \t loss_valid = 28791998.0 \n",
      "Model_7_6170 \t loss_train = 34246676.0 \t loss_valid = 28802434.0 \n",
      "Model_7_6180 \t loss_train = 33821012.0 \t loss_valid = 28388340.0 \n",
      "Model_7_6190 \t loss_train = 33942200.0 \t loss_valid = 28470004.0 \n",
      "Model_7_6200 \t loss_train = 34012724.0 \t loss_valid = 28585042.0 \n",
      "Model_7_6210 \t loss_train = 34265084.0 \t loss_valid = 28756682.0 \n",
      "Model_7_6220 \t loss_train = 34702444.0 \t loss_valid = 29010508.0 \n",
      "Model_7_6230 \t loss_train = 33974480.0 \t loss_valid = 28535906.0 \n",
      "Model_7_6240 \t loss_train = 33629044.0 \t loss_valid = 28209108.0 \n",
      "Model_7_6250 \t loss_train = 34010220.0 \t loss_valid = 28696576.0 \n",
      "Model_7_6260 \t loss_train = 33377806.0 \t loss_valid = 27925258.0 \n",
      "Model_7_6270 \t loss_train = 34238308.0 \t loss_valid = 28711784.0 \n",
      "Model_7_6280 \t loss_train = 34458516.0 \t loss_valid = 28913608.0 \n",
      "Model_7_6290 \t loss_train = 33983536.0 \t loss_valid = 28632484.0 \n",
      "Model_7_6300 \t loss_train = 34414224.0 \t loss_valid = 28840574.0 \n",
      "Model_7_6310 \t loss_train = 33580448.0 \t loss_valid = 28295794.0 \n",
      "Model_7_6320 \t loss_train = 34657740.0 \t loss_valid = 29077448.0 \n",
      "Model_7_6330 \t loss_train = 33631820.0 \t loss_valid = 28380148.0 \n",
      "Model_7_6340 \t loss_train = 34033828.0 \t loss_valid = 28675688.0 \n",
      "Model_7_6350 \t loss_train = 34831312.0 \t loss_valid = 29306242.0 \n",
      "Model_7_6360 \t loss_train = 33829080.0 \t loss_valid = 28469428.0 \n",
      "Model_7_6370 \t loss_train = 33748812.0 \t loss_valid = 28443942.0 \n",
      "Model_7_6380 \t loss_train = 35275580.0 \t loss_valid = 29465698.0 \n",
      "Model_7_6390 \t loss_train = 33290086.0 \t loss_valid = 28115422.0 \n",
      "Model_7_6400 \t loss_train = 33828980.0 \t loss_valid = 28380722.0 \n",
      "Model_7_6410 \t loss_train = 33837792.0 \t loss_valid = 28433996.0 \n",
      "Model_7_6420 \t loss_train = 34335828.0 \t loss_valid = 28724498.0 \n",
      "Model_7_6430 \t loss_train = 34032016.0 \t loss_valid = 28579912.0 \n",
      "Model_7_6440 \t loss_train = 33971400.0 \t loss_valid = 28473092.0 \n",
      "Model_7_6450 \t loss_train = 33949852.0 \t loss_valid = 28509750.0 \n",
      "Model_7_6460 \t loss_train = 34535092.0 \t loss_valid = 29052008.0 \n",
      "Model_7_6470 \t loss_train = 34066312.0 \t loss_valid = 28508470.0 \n",
      "Model_7_6480 \t loss_train = 34554968.0 \t loss_valid = 29037828.0 \n",
      "Model_7_6490 \t loss_train = 33576344.0 \t loss_valid = 28276578.0 \n",
      "Model_7_6500 \t loss_train = 34909992.0 \t loss_valid = 29387040.0 \n",
      "Model_7_6510 \t loss_train = 33976244.0 \t loss_valid = 28581388.0 \n",
      "Model_7_6520 \t loss_train = 34688424.0 \t loss_valid = 29182528.0 \n",
      "Model_7_6530 \t loss_train = 33830416.0 \t loss_valid = 28365590.0 \n",
      "Model_7_6540 \t loss_train = 33241424.0 \t loss_valid = 28025186.0 \n",
      "Model_7_6550 \t loss_train = 34592256.0 \t loss_valid = 29127692.0 \n",
      "Model_7_6560 \t loss_train = 33907676.0 \t loss_valid = 28554824.0 \n",
      "Model_7_6570 \t loss_train = 34150880.0 \t loss_valid = 28550656.0 \n",
      "Model_7_6580 \t loss_train = 34312368.0 \t loss_valid = 28863824.0 \n",
      "Model_7_6590 \t loss_train = 34703796.0 \t loss_valid = 29130872.0 \n",
      "Model_7_6600 \t loss_train = 33973000.0 \t loss_valid = 28460958.0 \n",
      "Model_7_6610 \t loss_train = 33939784.0 \t loss_valid = 28399764.0 \n",
      "Model_7_6620 \t loss_train = 34168536.0 \t loss_valid = 28664762.0 \n",
      "Model_7_6630 \t loss_train = 34440740.0 \t loss_valid = 29006444.0 \n",
      "Model_7_6640 \t loss_train = 34153772.0 \t loss_valid = 28626218.0 \n",
      "Model_7_6650 \t loss_train = 34339260.0 \t loss_valid = 28893520.0 \n",
      "Model_7_6660 \t loss_train = 34733080.0 \t loss_valid = 29186880.0 \n",
      "Model_7_6670 \t loss_train = 34402052.0 \t loss_valid = 28853416.0 \n",
      "Model_7_6680 \t loss_train = 34290060.0 \t loss_valid = 28747636.0 \n",
      "Model_7_6690 \t loss_train = 34890384.0 \t loss_valid = 29369274.0 \n",
      "Model_7_6700 \t loss_train = 34346896.0 \t loss_valid = 28819956.0 \n",
      "Model_7_6710 \t loss_train = 33945416.0 \t loss_valid = 28540988.0 \n",
      "Model_7_6720 \t loss_train = 34422112.0 \t loss_valid = 28789090.0 \n",
      "Model_7_6730 \t loss_train = 34061308.0 \t loss_valid = 28691340.0 \n",
      "Model_7_6740 \t loss_train = 34018964.0 \t loss_valid = 28461012.0 \n",
      "Model_7_6750 \t loss_train = 34679976.0 \t loss_valid = 29208630.0 \n",
      "Model_7_6760 \t loss_train = 33977116.0 \t loss_valid = 28470796.0 \n",
      "Model_7_6770 \t loss_train = 34940372.0 \t loss_valid = 29352580.0 \n",
      "Model_7_6780 \t loss_train = 34080960.0 \t loss_valid = 28738956.0 \n",
      "Model_7_6790 \t loss_train = 34250304.0 \t loss_valid = 28827926.0 \n",
      "Model_7_6800 \t loss_train = 34153576.0 \t loss_valid = 28719724.0 \n",
      "Model_7_6810 \t loss_train = 34046900.0 \t loss_valid = 28583370.0 \n",
      "Model_7_6820 \t loss_train = 34542492.0 \t loss_valid = 29043438.0 \n",
      "Model_7_6830 \t loss_train = 34634056.0 \t loss_valid = 29135868.0 \n",
      "Model_7_6840 \t loss_train = 34488860.0 \t loss_valid = 28965550.0 \n",
      "Model_7_6850 \t loss_train = 33965996.0 \t loss_valid = 28466308.0 \n",
      "Model_7_6860 \t loss_train = 34513460.0 \t loss_valid = 29043150.0 \n",
      "Model_7_6870 \t loss_train = 34631000.0 \t loss_valid = 29062770.0 \n",
      "Model_7_6880 \t loss_train = 34524380.0 \t loss_valid = 28968016.0 \n",
      "Model_7_6890 \t loss_train = 34241704.0 \t loss_valid = 28729420.0 \n",
      "Model_7_6900 \t loss_train = 35084276.0 \t loss_valid = 29379302.0 \n",
      "Model_7_6910 \t loss_train = 33879248.0 \t loss_valid = 28357418.0 \n",
      "Model_7_6920 \t loss_train = 34037784.0 \t loss_valid = 28573314.0 \n",
      "Model_7_6930 \t loss_train = 34623492.0 \t loss_valid = 29120786.0 \n",
      "Model_7_6940 \t loss_train = 34600256.0 \t loss_valid = 28914640.0 \n",
      "Model_7_6950 \t loss_train = 34794052.0 \t loss_valid = 29262400.0 \n",
      "Model_7_6960 \t loss_train = 35160712.0 \t loss_valid = 29439160.0 \n",
      "Model_7_6970 \t loss_train = 34694544.0 \t loss_valid = 29244714.0 \n",
      "Model_7_6980 \t loss_train = 34149004.0 \t loss_valid = 28628900.0 \n",
      "Model_7_6990 \t loss_train = 34480052.0 \t loss_valid = 29042202.0 \n",
      "Model_7_7000 \t loss_train = 34221312.0 \t loss_valid = 28697746.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_7_7010 \t loss_train = 34527244.0 \t loss_valid = 29078314.0 \n",
      "Model_7_7020 \t loss_train = 33719480.0 \t loss_valid = 28408996.0 \n",
      "Model_7_7030 \t loss_train = 35192772.0 \t loss_valid = 29597934.0 \n",
      "Model_7_7040 \t loss_train = 34015388.0 \t loss_valid = 28537970.0 \n",
      "Model_7_7050 \t loss_train = 34584132.0 \t loss_valid = 29064546.0 \n",
      "Model_7_7060 \t loss_train = 34262448.0 \t loss_valid = 28878490.0 \n",
      "Model_7_7070 \t loss_train = 34473860.0 \t loss_valid = 28974990.0 \n",
      "Model_7_7080 \t loss_train = 34643556.0 \t loss_valid = 29063930.0 \n",
      "Model_7_7090 \t loss_train = 34095204.0 \t loss_valid = 28597810.0 \n",
      "Model_7_7100 \t loss_train = 34002400.0 \t loss_valid = 28532234.0 \n",
      "Model_7_7110 \t loss_train = 35001696.0 \t loss_valid = 29329816.0 \n",
      "Model_7_7120 \t loss_train = 34210264.0 \t loss_valid = 28702872.0 \n",
      "Model_7_7130 \t loss_train = 34817356.0 \t loss_valid = 29229720.0 \n",
      "Model_7_7140 \t loss_train = 34769288.0 \t loss_valid = 29157146.0 \n",
      "Model_7_7150 \t loss_train = 34796556.0 \t loss_valid = 29340188.0 \n",
      "Model_7_7160 \t loss_train = 35417712.0 \t loss_valid = 29638856.0 \n",
      "Model_7_7170 \t loss_train = 33792320.0 \t loss_valid = 28408972.0 \n",
      "Model_7_7180 \t loss_train = 35627344.0 \t loss_valid = 29764280.0 \n",
      "Model_7_7190 \t loss_train = 35111372.0 \t loss_valid = 29463600.0 \n",
      "Model_7_7200 \t loss_train = 34607168.0 \t loss_valid = 29000954.0 \n",
      "Model_7_7210 \t loss_train = 34969352.0 \t loss_valid = 29452696.0 \n",
      "Model_7_7220 \t loss_train = 34268892.0 \t loss_valid = 28706924.0 \n",
      "Model_7_7230 \t loss_train = 35253380.0 \t loss_valid = 29650436.0 \n",
      "Model_7_7240 \t loss_train = 34379172.0 \t loss_valid = 28819962.0 \n",
      "Model_7_7250 \t loss_train = 34762776.0 \t loss_valid = 29227640.0 \n",
      "Model_7_7260 \t loss_train = 34655192.0 \t loss_valid = 29005192.0 \n",
      "Model_7_7270 \t loss_train = 34634464.0 \t loss_valid = 29097996.0 \n",
      "Model_7_7280 \t loss_train = 34333444.0 \t loss_valid = 28739006.0 \n",
      "Model_7_7290 \t loss_train = 34811464.0 \t loss_valid = 29177476.0 \n",
      "Model_7_7300 \t loss_train = 34814584.0 \t loss_valid = 29266308.0 \n",
      "Model_7_7310 \t loss_train = 34100096.0 \t loss_valid = 28538070.0 \n",
      "Model_7_7320 \t loss_train = 34540352.0 \t loss_valid = 28985092.0 \n",
      "Model_7_7330 \t loss_train = 34641660.0 \t loss_valid = 28871522.0 \n",
      "Model_7_7340 \t loss_train = 34304516.0 \t loss_valid = 28873040.0 \n",
      "Model_7_7350 \t loss_train = 34850984.0 \t loss_valid = 29192002.0 \n",
      "Model_7_7360 \t loss_train = 34312500.0 \t loss_valid = 28716962.0 \n",
      "Model_7_7370 \t loss_train = 34436692.0 \t loss_valid = 28834902.0 \n",
      "Model_7_7380 \t loss_train = 35651848.0 \t loss_valid = 29855402.0 \n",
      "Model_7_7390 \t loss_train = 34234508.0 \t loss_valid = 28619788.0 \n",
      "Model_7_7400 \t loss_train = 34521768.0 \t loss_valid = 28950822.0 \n",
      "Model_7_7410 \t loss_train = 35205260.0 \t loss_valid = 29600982.0 \n",
      "Model_7_7420 \t loss_train = 34291592.0 \t loss_valid = 28821428.0 \n",
      "Model_7_7430 \t loss_train = 35102748.0 \t loss_valid = 29546016.0 \n",
      "Model_7_7440 \t loss_train = 35177332.0 \t loss_valid = 29493666.0 \n",
      "Model_7_7450 \t loss_train = 35149288.0 \t loss_valid = 29566872.0 \n",
      "Model_7_7460 \t loss_train = 35317520.0 \t loss_valid = 29580418.0 \n",
      "Model_7_7470 \t loss_train = 34288820.0 \t loss_valid = 28730228.0 \n",
      "Model_7_7480 \t loss_train = 34946732.0 \t loss_valid = 29266204.0 \n",
      "Model_7_7490 \t loss_train = 35663560.0 \t loss_valid = 29906338.0 \n",
      "Model_7_7500 \t loss_train = 34364632.0 \t loss_valid = 28814354.0 \n",
      "Model_7_7510 \t loss_train = 34826292.0 \t loss_valid = 29220472.0 \n",
      "Model_7_7520 \t loss_train = 34993380.0 \t loss_valid = 29287892.0 \n",
      "Model_7_7530 \t loss_train = 34745464.0 \t loss_valid = 29039430.0 \n",
      "Model_7_7540 \t loss_train = 34610812.0 \t loss_valid = 29042926.0 \n",
      "Model_7_7550 \t loss_train = 34805200.0 \t loss_valid = 29147070.0 \n",
      "Model_7_7560 \t loss_train = 35066024.0 \t loss_valid = 29410248.0 \n",
      "Model_7_7570 \t loss_train = 34227432.0 \t loss_valid = 28625566.0 \n",
      "Model_7_7580 \t loss_train = 35499972.0 \t loss_valid = 29810388.0 \n",
      "Model_7_7590 \t loss_train = 34548512.0 \t loss_valid = 28921186.0 \n",
      "Model_7_7600 \t loss_train = 34498460.0 \t loss_valid = 28983972.0 \n",
      "Model_7_7610 \t loss_train = 34612312.0 \t loss_valid = 28994768.0 \n",
      "Model_7_7620 \t loss_train = 35113848.0 \t loss_valid = 29519536.0 \n",
      "Model_7_7630 \t loss_train = 35539892.0 \t loss_valid = 29726906.0 \n",
      "Model_7_7640 \t loss_train = 33851860.0 \t loss_valid = 28417856.0 \n",
      "Model_7_7650 \t loss_train = 34992052.0 \t loss_valid = 29312380.0 \n",
      "Model_7_7660 \t loss_train = 34814084.0 \t loss_valid = 29211976.0 \n",
      "Model_7_7670 \t loss_train = 34690904.0 \t loss_valid = 29073902.0 \n",
      "Model_7_7680 \t loss_train = 35508240.0 \t loss_valid = 29742668.0 \n",
      "Model_7_7690 \t loss_train = 35466336.0 \t loss_valid = 29802786.0 \n",
      "Model_7_7700 \t loss_train = 35422008.0 \t loss_valid = 29686894.0 \n",
      "Model_7_7710 \t loss_train = 34752308.0 \t loss_valid = 29175850.0 \n",
      "Model_7_7720 \t loss_train = 35076652.0 \t loss_valid = 29416040.0 \n",
      "Model_7_7730 \t loss_train = 34927480.0 \t loss_valid = 29264154.0 \n",
      "Model_7_7740 \t loss_train = 35132100.0 \t loss_valid = 29506538.0 \n",
      "Model_7_7750 \t loss_train = 35153808.0 \t loss_valid = 29436390.0 \n",
      "Model_7_7760 \t loss_train = 34885252.0 \t loss_valid = 29184948.0 \n",
      "Model_7_7770 \t loss_train = 35213392.0 \t loss_valid = 29444178.0 \n",
      "Model_7_7780 \t loss_train = 34849324.0 \t loss_valid = 29209410.0 \n",
      "Model_7_7790 \t loss_train = 34801700.0 \t loss_valid = 29120152.0 \n",
      "Model_7_7800 \t loss_train = 35165444.0 \t loss_valid = 29460808.0 \n",
      "Model_7_7810 \t loss_train = 35288584.0 \t loss_valid = 29647322.0 \n",
      "Model_7_7820 \t loss_train = 35087236.0 \t loss_valid = 29347262.0 \n",
      "Model_7_7830 \t loss_train = 34593632.0 \t loss_valid = 29061054.0 \n",
      "Model_7_7840 \t loss_train = 35267812.0 \t loss_valid = 29558680.0 \n",
      "Model_7_7850 \t loss_train = 34973940.0 \t loss_valid = 29324118.0 \n",
      "Model_7_7860 \t loss_train = 34960776.0 \t loss_valid = 29240380.0 \n",
      "Model_7_7870 \t loss_train = 35165260.0 \t loss_valid = 29395174.0 \n",
      "Model_7_7880 \t loss_train = 35110108.0 \t loss_valid = 29411664.0 \n",
      "Model_7_7890 \t loss_train = 34964232.0 \t loss_valid = 29245396.0 \n",
      "Model_7_7900 \t loss_train = 35162620.0 \t loss_valid = 29409728.0 \n",
      "Model_7_7910 \t loss_train = 35108216.0 \t loss_valid = 29354098.0 \n",
      "Model_7_7920 \t loss_train = 34918828.0 \t loss_valid = 29251588.0 \n",
      "Model_7_7930 \t loss_train = 35354484.0 \t loss_valid = 29626716.0 \n",
      "Model_7_7940 \t loss_train = 35422272.0 \t loss_valid = 29641514.0 \n",
      "Model_7_7950 \t loss_train = 35129456.0 \t loss_valid = 29397568.0 \n",
      "Model_7_7960 \t loss_train = 36122396.0 \t loss_valid = 30228404.0 \n",
      "Model_7_7970 \t loss_train = 34844488.0 \t loss_valid = 29191696.0 \n",
      "Model_7_7980 \t loss_train = 35228264.0 \t loss_valid = 29597358.0 \n",
      "Model_7_7990 \t loss_train = 35305080.0 \t loss_valid = 29504190.0 \n",
      "Model_7_8000 \t loss_train = 35734312.0 \t loss_valid = 29850450.0 \n",
      "Model_7_8010 \t loss_train = 35521636.0 \t loss_valid = 29630912.0 \n",
      "Model_7_8020 \t loss_train = 35326624.0 \t loss_valid = 29587456.0 \n",
      "Model_7_8030 \t loss_train = 35773660.0 \t loss_valid = 29902046.0 \n",
      "Model_7_8040 \t loss_train = 34680388.0 \t loss_valid = 28890640.0 \n",
      "Model_7_8050 \t loss_train = 35634808.0 \t loss_valid = 29832208.0 \n",
      "Model_7_8060 \t loss_train = 35476048.0 \t loss_valid = 29733952.0 \n",
      "Model_7_8070 \t loss_train = 35135632.0 \t loss_valid = 29417310.0 \n",
      "Model_7_8080 \t loss_train = 35964504.0 \t loss_valid = 30084554.0 \n",
      "Model_7_8090 \t loss_train = 35217048.0 \t loss_valid = 29463366.0 \n",
      "Model_7_8100 \t loss_train = 35631044.0 \t loss_valid = 29727830.0 \n",
      "Model_7_8110 \t loss_train = 35502160.0 \t loss_valid = 29718434.0 \n",
      "Model_7_8120 \t loss_train = 35574220.0 \t loss_valid = 29832236.0 \n",
      "Model_7_8130 \t loss_train = 35361996.0 \t loss_valid = 29490236.0 \n",
      "Model_7_8140 \t loss_train = 35480592.0 \t loss_valid = 29694754.0 \n",
      "Model_7_8150 \t loss_train = 35266716.0 \t loss_valid = 29417472.0 \n",
      "Model_7_8160 \t loss_train = 35397740.0 \t loss_valid = 29424558.0 \n",
      "Model_7_8170 \t loss_train = 35909836.0 \t loss_valid = 30063010.0 \n",
      "Model_7_8180 \t loss_train = 35266144.0 \t loss_valid = 29387298.0 \n",
      "Model_7_8190 \t loss_train = 35629304.0 \t loss_valid = 29791772.0 \n",
      "Model_7_8200 \t loss_train = 36107108.0 \t loss_valid = 30160840.0 \n",
      "Model_7_8210 \t loss_train = 35319888.0 \t loss_valid = 29371888.0 \n",
      "Model_7_8220 \t loss_train = 35369860.0 \t loss_valid = 29559210.0 \n",
      "Model_7_8230 \t loss_train = 35414804.0 \t loss_valid = 29659886.0 \n",
      "Model_7_8240 \t loss_train = 35072124.0 \t loss_valid = 29320368.0 \n",
      "Model_7_8250 \t loss_train = 35971612.0 \t loss_valid = 30211218.0 \n",
      "Model_7_8260 \t loss_train = 35201640.0 \t loss_valid = 29338574.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_7_8270 \t loss_train = 35234388.0 \t loss_valid = 29426210.0 \n",
      "Model_7_8280 \t loss_train = 35984756.0 \t loss_valid = 29988520.0 \n",
      "Model_7_8290 \t loss_train = 34290660.0 \t loss_valid = 28592378.0 \n",
      "Model_7_8300 \t loss_train = 36856164.0 \t loss_valid = 30739178.0 \n",
      "Model_7_8310 \t loss_train = 34259076.0 \t loss_valid = 28635434.0 \n",
      "Model_7_8320 \t loss_train = 35548764.0 \t loss_valid = 29678456.0 \n",
      "Model_7_8330 \t loss_train = 35307696.0 \t loss_valid = 29440670.0 \n",
      "Model_7_8340 \t loss_train = 35107752.0 \t loss_valid = 29419466.0 \n",
      "Model_7_8350 \t loss_train = 35711812.0 \t loss_valid = 29815688.0 \n",
      "Model_7_8360 \t loss_train = 35722216.0 \t loss_valid = 29966212.0 \n",
      "Model_7_8370 \t loss_train = 35555632.0 \t loss_valid = 29705370.0 \n",
      "Model_7_8380 \t loss_train = 35690512.0 \t loss_valid = 29914776.0 \n",
      "Model_7_8390 \t loss_train = 35430376.0 \t loss_valid = 29613894.0 \n",
      "Model_7_8400 \t loss_train = 36171380.0 \t loss_valid = 30270024.0 \n",
      "Model_7_8410 \t loss_train = 35612228.0 \t loss_valid = 29667022.0 \n",
      "Model_7_8420 \t loss_train = 35903152.0 \t loss_valid = 30090468.0 \n",
      "Model_7_8430 \t loss_train = 35429348.0 \t loss_valid = 29586414.0 \n",
      "Model_7_8440 \t loss_train = 36230932.0 \t loss_valid = 30258972.0 \n",
      "Model_7_8450 \t loss_train = 35712496.0 \t loss_valid = 29789038.0 \n",
      "Model_7_8460 \t loss_train = 36005216.0 \t loss_valid = 30009714.0 \n",
      "Model_7_8470 \t loss_train = 36051644.0 \t loss_valid = 30075648.0 \n",
      "Model_7_8480 \t loss_train = 35367836.0 \t loss_valid = 29410218.0 \n",
      "Model_7_8490 \t loss_train = 35725668.0 \t loss_valid = 29727776.0 \n",
      "Model_7_8500 \t loss_train = 36243932.0 \t loss_valid = 30233512.0 \n",
      "Model_7_8510 \t loss_train = 35977488.0 \t loss_valid = 30016584.0 \n",
      "Model_7_8520 \t loss_train = 35595376.0 \t loss_valid = 29815232.0 \n",
      "Model_7_8530 \t loss_train = 36341316.0 \t loss_valid = 30413270.0 \n",
      "Model_7_8540 \t loss_train = 35895344.0 \t loss_valid = 30051850.0 \n",
      "Model_7_8550 \t loss_train = 36428768.0 \t loss_valid = 30370722.0 \n",
      "Model_7_8560 \t loss_train = 35446504.0 \t loss_valid = 29610170.0 \n",
      "Model_7_8570 \t loss_train = 36340744.0 \t loss_valid = 30257588.0 \n",
      "Model_7_8580 \t loss_train = 36000596.0 \t loss_valid = 30078916.0 \n",
      "Model_7_8590 \t loss_train = 36038468.0 \t loss_valid = 30200528.0 \n",
      "Model_7_8600 \t loss_train = 35720208.0 \t loss_valid = 29866228.0 \n",
      "Model_7_8610 \t loss_train = 36167240.0 \t loss_valid = 30191306.0 \n",
      "Model_7_8620 \t loss_train = 35759048.0 \t loss_valid = 29770364.0 \n",
      "Model_7_8630 \t loss_train = 35469844.0 \t loss_valid = 29733620.0 \n",
      "Model_7_8640 \t loss_train = 36134708.0 \t loss_valid = 30269304.0 \n",
      "Model_7_8650 \t loss_train = 35281700.0 \t loss_valid = 29400270.0 \n",
      "Model_7_8660 \t loss_train = 35660956.0 \t loss_valid = 29679432.0 \n",
      "Model_7_8670 \t loss_train = 35949548.0 \t loss_valid = 29719248.0 \n",
      "Model_7_8680 \t loss_train = 36445708.0 \t loss_valid = 30471212.0 \n",
      "Model_7_8690 \t loss_train = 35882112.0 \t loss_valid = 29853244.0 \n",
      "Model_7_8700 \t loss_train = 36044396.0 \t loss_valid = 30007338.0 \n",
      "Model_7_8710 \t loss_train = 35399244.0 \t loss_valid = 29413234.0 \n",
      "Model_7_8720 \t loss_train = 36210660.0 \t loss_valid = 30230652.0 \n",
      "Model_7_8730 \t loss_train = 36227500.0 \t loss_valid = 30244972.0 \n",
      "Model_7_8740 \t loss_train = 35966744.0 \t loss_valid = 29974426.0 \n",
      "Model_7_8750 \t loss_train = 35895380.0 \t loss_valid = 29888430.0 \n",
      "Model_7_8760 \t loss_train = 36394664.0 \t loss_valid = 30490696.0 \n",
      "Model_7_8770 \t loss_train = 35244664.0 \t loss_valid = 29363566.0 \n",
      "Model_7_8780 \t loss_train = 36791968.0 \t loss_valid = 30765062.0 \n",
      "Model_7_8790 \t loss_train = 36271172.0 \t loss_valid = 30242254.0 \n",
      "Model_7_8800 \t loss_train = 36021956.0 \t loss_valid = 29944218.0 \n",
      "Model_7_8810 \t loss_train = 36104280.0 \t loss_valid = 30066262.0 \n",
      "Model_7_8820 \t loss_train = 36639404.0 \t loss_valid = 30479594.0 \n",
      "Model_7_8830 \t loss_train = 36434976.0 \t loss_valid = 30314996.0 \n",
      "Model_7_8840 \t loss_train = 35605780.0 \t loss_valid = 29642572.0 \n",
      "Model_7_8850 \t loss_train = 36845600.0 \t loss_valid = 30714542.0 \n",
      "Model_7_8860 \t loss_train = 35625540.0 \t loss_valid = 29790092.0 \n",
      "Model_7_8870 \t loss_train = 37131696.0 \t loss_valid = 30928960.0 \n",
      "Model_7_8880 \t loss_train = 36429444.0 \t loss_valid = 30452552.0 \n",
      "Model_7_8890 \t loss_train = 36370528.0 \t loss_valid = 30251134.0 \n",
      "Model_7_8900 \t loss_train = 36613204.0 \t loss_valid = 30663614.0 \n",
      "Model_7_8910 \t loss_train = 36002180.0 \t loss_valid = 30031100.0 \n",
      "Model_7_8920 \t loss_train = 36382156.0 \t loss_valid = 30122284.0 \n",
      "Model_7_8930 \t loss_train = 36144008.0 \t loss_valid = 30091562.0 \n",
      "Model_7_8940 \t loss_train = 36211896.0 \t loss_valid = 30254814.0 \n",
      "Model_7_8950 \t loss_train = 36027212.0 \t loss_valid = 30077194.0 \n",
      "Model_7_8960 \t loss_train = 36448820.0 \t loss_valid = 30378306.0 \n",
      "Model_7_8970 \t loss_train = 35951316.0 \t loss_valid = 29957718.0 \n",
      "Model_7_8980 \t loss_train = 35944372.0 \t loss_valid = 29998734.0 \n",
      "Model_7_8990 \t loss_train = 36385548.0 \t loss_valid = 30240756.0 \n",
      "Model_7_9000 \t loss_train = 36435976.0 \t loss_valid = 30307360.0 \n",
      "Model_7_9010 \t loss_train = 36430848.0 \t loss_valid = 30348134.0 \n",
      "Model_7_9020 \t loss_train = 36908700.0 \t loss_valid = 30721612.0 \n",
      "Model_7_9030 \t loss_train = 35916444.0 \t loss_valid = 30120426.0 \n",
      "Model_7_9040 \t loss_train = 36648800.0 \t loss_valid = 30572104.0 \n",
      "Model_7_9050 \t loss_train = 36647600.0 \t loss_valid = 30512842.0 \n",
      "Model_7_9060 \t loss_train = 36238380.0 \t loss_valid = 30278644.0 \n",
      "Model_7_9070 \t loss_train = 36985384.0 \t loss_valid = 30878046.0 \n",
      "Model_7_9080 \t loss_train = 36509700.0 \t loss_valid = 30367542.0 \n",
      "Model_7_9090 \t loss_train = 36239548.0 \t loss_valid = 30306844.0 \n",
      "Model_7_9100 \t loss_train = 35850432.0 \t loss_valid = 29886520.0 \n",
      "Model_7_9110 \t loss_train = 36181532.0 \t loss_valid = 30168058.0 \n",
      "Model_7_9120 \t loss_train = 37077532.0 \t loss_valid = 30885878.0 \n",
      "Model_7_9130 \t loss_train = 36936364.0 \t loss_valid = 30831452.0 \n",
      "Model_7_9140 \t loss_train = 36313128.0 \t loss_valid = 30323424.0 \n",
      "Model_7_9150 \t loss_train = 36193228.0 \t loss_valid = 30173444.0 \n",
      "Model_7_9160 \t loss_train = 37043816.0 \t loss_valid = 30816484.0 \n",
      "Model_7_9170 \t loss_train = 35751844.0 \t loss_valid = 29607156.0 \n",
      "Model_7_9180 \t loss_train = 37275628.0 \t loss_valid = 31161660.0 \n",
      "Model_7_9190 \t loss_train = 36481680.0 \t loss_valid = 30308108.0 \n",
      "Model_7_9200 \t loss_train = 36430552.0 \t loss_valid = 30300204.0 \n",
      "Model_7_9210 \t loss_train = 36532396.0 \t loss_valid = 30598890.0 \n",
      "Model_7_9220 \t loss_train = 35524744.0 \t loss_valid = 29500126.0 \n",
      "Model_7_9230 \t loss_train = 36884432.0 \t loss_valid = 30662312.0 \n",
      "Model_7_9240 \t loss_train = 36760552.0 \t loss_valid = 30604550.0 \n",
      "Model_7_9250 \t loss_train = 36638888.0 \t loss_valid = 30530136.0 \n",
      "Model_7_9260 \t loss_train = 35979360.0 \t loss_valid = 30006746.0 \n",
      "Model_7_9270 \t loss_train = 37078668.0 \t loss_valid = 30846618.0 \n",
      "Model_7_9280 \t loss_train = 35831744.0 \t loss_valid = 29764320.0 \n",
      "Model_7_9290 \t loss_train = 36661364.0 \t loss_valid = 30507374.0 \n",
      "Model_7_9300 \t loss_train = 37160448.0 \t loss_valid = 30961730.0 \n",
      "Model_7_9310 \t loss_train = 36651652.0 \t loss_valid = 30521426.0 \n",
      "Model_7_9320 \t loss_train = 36695736.0 \t loss_valid = 30637268.0 \n",
      "Model_7_9330 \t loss_train = 36594096.0 \t loss_valid = 30535124.0 \n",
      "Model_7_9340 \t loss_train = 37041432.0 \t loss_valid = 30750290.0 \n",
      "Model_7_9350 \t loss_train = 37017448.0 \t loss_valid = 30828360.0 \n",
      "Model_7_9360 \t loss_train = 36133684.0 \t loss_valid = 30058756.0 \n",
      "Model_7_9370 \t loss_train = 37044540.0 \t loss_valid = 30742108.0 \n",
      "Model_7_9380 \t loss_train = 36841580.0 \t loss_valid = 30790492.0 \n",
      "Model_7_9390 \t loss_train = 36690684.0 \t loss_valid = 30542064.0 \n",
      "Model_7_9400 \t loss_train = 37151608.0 \t loss_valid = 30928782.0 \n",
      "Model_7_9410 \t loss_train = 37199456.0 \t loss_valid = 30916096.0 \n",
      "Model_7_9420 \t loss_train = 37119408.0 \t loss_valid = 31088024.0 \n",
      "Model_7_9430 \t loss_train = 36500104.0 \t loss_valid = 30396306.0 \n",
      "Model_7_9440 \t loss_train = 37337756.0 \t loss_valid = 31057186.0 \n",
      "Model_7_9450 \t loss_train = 37272008.0 \t loss_valid = 30917512.0 \n",
      "Model_7_9460 \t loss_train = 36235816.0 \t loss_valid = 30094160.0 \n",
      "Model_7_9470 \t loss_train = 37108180.0 \t loss_valid = 30882624.0 \n",
      "Model_7_9480 \t loss_train = 36823164.0 \t loss_valid = 30737402.0 \n",
      "Model_7_9490 \t loss_train = 37482888.0 \t loss_valid = 31138594.0 \n",
      "Model_7_9500 \t loss_train = 37465956.0 \t loss_valid = 31151944.0 \n",
      "Model_7_9510 \t loss_train = 36247788.0 \t loss_valid = 30213102.0 \n",
      "Model_7_9520 \t loss_train = 36956024.0 \t loss_valid = 30698082.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_7_9530 \t loss_train = 36608124.0 \t loss_valid = 30389732.0 \n",
      "Model_7_9540 \t loss_train = 36904572.0 \t loss_valid = 30713996.0 \n",
      "Model_7_9550 \t loss_train = 36829760.0 \t loss_valid = 30400866.0 \n",
      "Model_7_9560 \t loss_train = 37295352.0 \t loss_valid = 31037858.0 \n",
      "Model_7_9570 \t loss_train = 36833268.0 \t loss_valid = 30723928.0 \n",
      "Model_7_9580 \t loss_train = 37040724.0 \t loss_valid = 30708230.0 \n",
      "Model_7_9590 \t loss_train = 36963184.0 \t loss_valid = 30671682.0 \n",
      "Model_7_9600 \t loss_train = 36574180.0 \t loss_valid = 30390316.0 \n",
      "Model_7_9610 \t loss_train = 36906436.0 \t loss_valid = 30699184.0 \n",
      "Model_7_9620 \t loss_train = 37095916.0 \t loss_valid = 30782568.0 \n",
      "Model_7_9630 \t loss_train = 36418880.0 \t loss_valid = 30118954.0 \n",
      "Model_7_9640 \t loss_train = 36367912.0 \t loss_valid = 30351620.0 \n",
      "Model_7_9650 \t loss_train = 37482924.0 \t loss_valid = 31091406.0 \n",
      "Model_7_9660 \t loss_train = 36892532.0 \t loss_valid = 30670146.0 \n",
      "Model_7_9670 \t loss_train = 36790020.0 \t loss_valid = 30644920.0 \n",
      "Model_7_9680 \t loss_train = 37590184.0 \t loss_valid = 31215388.0 \n",
      "Model_7_9690 \t loss_train = 36750512.0 \t loss_valid = 30485700.0 \n",
      "Model_7_9700 \t loss_train = 37169068.0 \t loss_valid = 30936874.0 \n",
      "Model_7_9710 \t loss_train = 37372284.0 \t loss_valid = 30995700.0 \n",
      "Model_7_9720 \t loss_train = 36964280.0 \t loss_valid = 30820770.0 \n",
      "Model_7_9730 \t loss_train = 37998228.0 \t loss_valid = 31586332.0 \n",
      "Model_7_9740 \t loss_train = 37417852.0 \t loss_valid = 31102306.0 \n",
      "Model_7_9750 \t loss_train = 36882468.0 \t loss_valid = 30713142.0 \n",
      "Model_7_9760 \t loss_train = 37265288.0 \t loss_valid = 30958634.0 \n",
      "Model_7_9770 \t loss_train = 37828184.0 \t loss_valid = 31352086.0 \n",
      "Model_7_9780 \t loss_train = 36689696.0 \t loss_valid = 30530354.0 \n",
      "Model_7_9790 \t loss_train = 37293600.0 \t loss_valid = 31136870.0 \n",
      "Model_7_9800 \t loss_train = 36844608.0 \t loss_valid = 30656670.0 \n",
      "Model_7_9810 \t loss_train = 36858684.0 \t loss_valid = 30689810.0 \n",
      "Model_7_9820 \t loss_train = 37223856.0 \t loss_valid = 30838510.0 \n",
      "Model_7_9830 \t loss_train = 37453688.0 \t loss_valid = 31127804.0 \n",
      "Model_7_9840 \t loss_train = 36612856.0 \t loss_valid = 30488924.0 \n",
      "Model_7_9850 \t loss_train = 37064928.0 \t loss_valid = 30646638.0 \n",
      "Model_7_9860 \t loss_train = 37513916.0 \t loss_valid = 31157394.0 \n",
      "Model_7_9870 \t loss_train = 37232372.0 \t loss_valid = 30901274.0 \n",
      "Model_7_9880 \t loss_train = 37601828.0 \t loss_valid = 31128352.0 \n",
      "Model_7_9890 \t loss_train = 37264868.0 \t loss_valid = 30625570.0 \n",
      "Model_7_9900 \t loss_train = 37417444.0 \t loss_valid = 31128870.0 \n",
      "Model_7_9910 \t loss_train = 36868472.0 \t loss_valid = 30728464.0 \n",
      "Model_7_9920 \t loss_train = 37606456.0 \t loss_valid = 31283898.0 \n",
      "Model_7_9930 \t loss_train = 37379888.0 \t loss_valid = 31115592.0 \n",
      "Model_7_9940 \t loss_train = 37259100.0 \t loss_valid = 31024938.0 \n",
      "Model_7_9950 \t loss_train = 37143724.0 \t loss_valid = 30889826.0 \n",
      "Model_7_9960 \t loss_train = 37608184.0 \t loss_valid = 31198376.0 \n",
      "Model_7_9970 \t loss_train = 37172680.0 \t loss_valid = 30805014.0 \n",
      "Model_7_9980 \t loss_train = 37116868.0 \t loss_valid = 30935204.0 \n",
      "Model_7_9990 \t loss_train = 37661896.0 \t loss_valid = 31391428.0 \n",
      "Model_7_10000 \t loss_train = 36687932.0 \t loss_valid = 30310018.0 \n",
      "Model_7_10010 \t loss_train = 37419496.0 \t loss_valid = 30812704.0 \n",
      "Model_7_10020 \t loss_train = 37195904.0 \t loss_valid = 30930922.0 \n",
      "Model_7_10030 \t loss_train = 38155004.0 \t loss_valid = 31791584.0 \n",
      "Model_7_10040 \t loss_train = 37405604.0 \t loss_valid = 31118000.0 \n",
      "Model_7_10050 \t loss_train = 37028596.0 \t loss_valid = 30834014.0 \n",
      "Model_7_10060 \t loss_train = 36793776.0 \t loss_valid = 30693342.0 \n",
      "Model_7_10070 \t loss_train = 37580744.0 \t loss_valid = 31358098.0 \n",
      "Model_7_10080 \t loss_train = 37236928.0 \t loss_valid = 30912686.0 \n",
      "Model_7_10090 \t loss_train = 37570104.0 \t loss_valid = 31146420.0 \n",
      "Model_7_10100 \t loss_train = 37296356.0 \t loss_valid = 31065038.0 \n",
      "Model_7_10110 \t loss_train = 36975640.0 \t loss_valid = 30620406.0 \n",
      "Model_7_10120 \t loss_train = 37187028.0 \t loss_valid = 30772844.0 \n",
      "Model_7_10130 \t loss_train = 37772728.0 \t loss_valid = 31369984.0 \n",
      "Model_7_10140 \t loss_train = 37443784.0 \t loss_valid = 31097666.0 \n",
      "Model_7_10150 \t loss_train = 37610680.0 \t loss_valid = 31325096.0 \n",
      "Model_7_10160 \t loss_train = 37099924.0 \t loss_valid = 30918738.0 \n",
      "Model_7_10170 \t loss_train = 37474384.0 \t loss_valid = 31112060.0 \n",
      "Model_7_10180 \t loss_train = 36734036.0 \t loss_valid = 30600174.0 \n",
      "Model_7_10190 \t loss_train = 37756548.0 \t loss_valid = 31424474.0 \n",
      "Model_7_10200 \t loss_train = 37617392.0 \t loss_valid = 31173808.0 \n",
      "Model_7_10210 \t loss_train = 36780108.0 \t loss_valid = 30220976.0 \n",
      "Model_7_10220 \t loss_train = 37938308.0 \t loss_valid = 31383938.0 \n",
      "Model_7_10230 \t loss_train = 37191064.0 \t loss_valid = 30755018.0 \n",
      "Model_7_10240 \t loss_train = 37802044.0 \t loss_valid = 31378116.0 \n",
      "Model_7_10250 \t loss_train = 37640908.0 \t loss_valid = 31254228.0 \n",
      "Model_7_10260 \t loss_train = 37429668.0 \t loss_valid = 31144034.0 \n",
      "Model_7_10270 \t loss_train = 37379704.0 \t loss_valid = 31059244.0 \n",
      "Model_7_10280 \t loss_train = 37413720.0 \t loss_valid = 31145842.0 \n",
      "Model_7_10290 \t loss_train = 37848360.0 \t loss_valid = 31406994.0 \n",
      "Model_7_10300 \t loss_train = 37050296.0 \t loss_valid = 30585626.0 \n",
      "Model_7_10310 \t loss_train = 37805588.0 \t loss_valid = 31350190.0 \n",
      "Model_7_10320 \t loss_train = 37287684.0 \t loss_valid = 30962758.0 \n",
      "Model_7_10330 \t loss_train = 37239784.0 \t loss_valid = 30996552.0 \n",
      "Model_7_10340 \t loss_train = 37806400.0 \t loss_valid = 31455232.0 \n",
      "Model_7_10350 \t loss_train = 36976084.0 \t loss_valid = 30738226.0 \n",
      "Model_7_10360 \t loss_train = 37323424.0 \t loss_valid = 30899068.0 \n",
      "Model_7_10370 \t loss_train = 37677572.0 \t loss_valid = 31215770.0 \n",
      "Model_7_10380 \t loss_train = 37729868.0 \t loss_valid = 31275820.0 \n",
      "Model_7_10390 \t loss_train = 37742124.0 \t loss_valid = 31347750.0 \n",
      "Model_7_10400 \t loss_train = 37153140.0 \t loss_valid = 30727352.0 \n",
      "Model_7_10410 \t loss_train = 37535824.0 \t loss_valid = 31218248.0 \n",
      "Model_7_10420 \t loss_train = 37982024.0 \t loss_valid = 31624846.0 \n",
      "Model_7_10430 \t loss_train = 37503788.0 \t loss_valid = 31022732.0 \n",
      "Model_7_10440 \t loss_train = 38121512.0 \t loss_valid = 31655070.0 \n",
      "Model_7_10450 \t loss_train = 37234640.0 \t loss_valid = 30835134.0 \n",
      "Model_7_10460 \t loss_train = 37909184.0 \t loss_valid = 31375348.0 \n",
      "Model_7_10470 \t loss_train = 37531116.0 \t loss_valid = 31196220.0 \n",
      "Model_7_10480 \t loss_train = 37318640.0 \t loss_valid = 30952934.0 \n",
      "Model_7_10490 \t loss_train = 38118676.0 \t loss_valid = 31583924.0 \n",
      "Model_7_10500 \t loss_train = 37892968.0 \t loss_valid = 31414440.0 \n",
      "Model_7_10510 \t loss_train = 37584124.0 \t loss_valid = 31243320.0 \n",
      "Model_7_10520 \t loss_train = 37891708.0 \t loss_valid = 31291154.0 \n",
      "Model_7_10530 \t loss_train = 36905748.0 \t loss_valid = 30709612.0 \n",
      "Model_7_10540 \t loss_train = 37755232.0 \t loss_valid = 31318174.0 \n",
      "Model_7_10550 \t loss_train = 36956116.0 \t loss_valid = 30701818.0 \n",
      "Model_7_10560 \t loss_train = 38039012.0 \t loss_valid = 31517942.0 \n",
      "Model_7_10570 \t loss_train = 37901932.0 \t loss_valid = 31444220.0 \n",
      "Model_7_10580 \t loss_train = 37471988.0 \t loss_valid = 31046220.0 \n",
      "Model_7_10590 \t loss_train = 37504588.0 \t loss_valid = 31138640.0 \n",
      "Model_7_10600 \t loss_train = 37238744.0 \t loss_valid = 30901854.0 \n",
      "Model_7_10610 \t loss_train = 37951584.0 \t loss_valid = 31572202.0 \n",
      "Model_7_10620 \t loss_train = 37263836.0 \t loss_valid = 30931680.0 \n",
      "Model_7_10630 \t loss_train = 38125120.0 \t loss_valid = 31597126.0 \n",
      "Model_7_10640 \t loss_train = 37773932.0 \t loss_valid = 31208606.0 \n",
      "Model_7_10650 \t loss_train = 37385652.0 \t loss_valid = 30942262.0 \n",
      "Model_7_10660 \t loss_train = 37124744.0 \t loss_valid = 30561384.0 \n",
      "Model_7_10670 \t loss_train = 37094932.0 \t loss_valid = 30754728.0 \n",
      "Model_7_10680 \t loss_train = 38354804.0 \t loss_valid = 31882764.0 \n",
      "Model_7_10690 \t loss_train = 37435544.0 \t loss_valid = 31088336.0 \n",
      "Model_7_10700 \t loss_train = 37919884.0 \t loss_valid = 31448178.0 \n",
      "Model_7_10710 \t loss_train = 37393116.0 \t loss_valid = 30976402.0 \n",
      "Model_7_10720 \t loss_train = 37547820.0 \t loss_valid = 31269862.0 \n",
      "Model_7_10730 \t loss_train = 37341816.0 \t loss_valid = 30979198.0 \n",
      "Model_7_10740 \t loss_train = 38265648.0 \t loss_valid = 31767308.0 \n",
      "Model_7_10750 \t loss_train = 37459300.0 \t loss_valid = 31060834.0 \n",
      "Model_7_10760 \t loss_train = 37492448.0 \t loss_valid = 30915338.0 \n",
      "Model_7_10770 \t loss_train = 37813704.0 \t loss_valid = 31288304.0 \n",
      "Model_7_10780 \t loss_train = 37730436.0 \t loss_valid = 31362004.0 \n",
      "Model_7_10790 \t loss_train = 36756292.0 \t loss_valid = 30688372.0 \n",
      "Model_7_10800 \t loss_train = 38140780.0 \t loss_valid = 31545850.0 \n",
      "Model_7_10810 \t loss_train = 37828344.0 \t loss_valid = 31378202.0 \n",
      "Model_7_10820 \t loss_train = 37752244.0 \t loss_valid = 31234398.0 \n",
      "Model_7_10830 \t loss_train = 37734528.0 \t loss_valid = 31323148.0 \n",
      "Model_7_10840 \t loss_train = 38057596.0 \t loss_valid = 31472770.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_7_10850 \t loss_train = 38065292.0 \t loss_valid = 31519580.0 \n",
      "Model_7_10860 \t loss_train = 38033384.0 \t loss_valid = 31600492.0 \n",
      "Model_7_10870 \t loss_train = 37549632.0 \t loss_valid = 31180948.0 \n",
      "Model_7_10880 \t loss_train = 37550772.0 \t loss_valid = 31162510.0 \n",
      "Model_7_10890 \t loss_train = 38304520.0 \t loss_valid = 31729898.0 \n",
      "Model_7_10900 \t loss_train = 37516352.0 \t loss_valid = 30980836.0 \n",
      "Model_7_10910 \t loss_train = 37673612.0 \t loss_valid = 31181486.0 \n",
      "Model_7_10920 \t loss_train = 37789756.0 \t loss_valid = 31379288.0 \n",
      "Model_7_10930 \t loss_train = 38246804.0 \t loss_valid = 31689816.0 \n",
      "Model_7_10940 \t loss_train = 38168640.0 \t loss_valid = 31603440.0 \n",
      "Model_7_10950 \t loss_train = 37367508.0 \t loss_valid = 30799846.0 \n",
      "Model_7_10960 \t loss_train = 38291924.0 \t loss_valid = 31784492.0 \n",
      "Model_7_10970 \t loss_train = 37724380.0 \t loss_valid = 31185730.0 \n",
      "Model_7_10980 \t loss_train = 38049252.0 \t loss_valid = 31640760.0 \n",
      "Model_7_10990 \t loss_train = 37901484.0 \t loss_valid = 31334938.0 \n",
      "Model_7_11000 \t loss_train = 38235816.0 \t loss_valid = 31827936.0 \n",
      "Model_7_11010 \t loss_train = 37977428.0 \t loss_valid = 31435868.0 \n",
      "Model_7_11020 \t loss_train = 37930200.0 \t loss_valid = 31560186.0 \n",
      "Model_7_11030 \t loss_train = 37442488.0 \t loss_valid = 30903346.0 \n",
      "Model_7_11040 \t loss_train = 38091864.0 \t loss_valid = 31578982.0 \n",
      "Model_7_11050 \t loss_train = 37880640.0 \t loss_valid = 31377314.0 \n",
      "Model_7_11060 \t loss_train = 38082564.0 \t loss_valid = 31583466.0 \n",
      "Model_7_11070 \t loss_train = 37724956.0 \t loss_valid = 31257942.0 \n",
      "Model_7_11080 \t loss_train = 37967052.0 \t loss_valid = 31525986.0 \n",
      "Model_7_11090 \t loss_train = 37994544.0 \t loss_valid = 31491204.0 \n",
      "Model_7_11100 \t loss_train = 37782688.0 \t loss_valid = 31317320.0 \n",
      "Model_7_11110 \t loss_train = 38421008.0 \t loss_valid = 31807226.0 \n",
      "Model_7_11120 \t loss_train = 37580716.0 \t loss_valid = 31223094.0 \n",
      "Model_7_11130 \t loss_train = 37927368.0 \t loss_valid = 31407192.0 \n",
      "Model_7_11140 \t loss_train = 38555192.0 \t loss_valid = 32015280.0 \n",
      "Model_7_11150 \t loss_train = 37363700.0 \t loss_valid = 31003768.0 \n",
      "Model_7_11160 \t loss_train = 37868660.0 \t loss_valid = 31418678.0 \n",
      "Model_7_11170 \t loss_train = 38071600.0 \t loss_valid = 31641686.0 \n",
      "Model_7_11180 \t loss_train = 37517876.0 \t loss_valid = 31171388.0 \n",
      "Model_7_11190 \t loss_train = 38368912.0 \t loss_valid = 31728956.0 \n",
      "Model_7_11200 \t loss_train = 37929268.0 \t loss_valid = 31190958.0 \n",
      "Model_7_11210 \t loss_train = 38489232.0 \t loss_valid = 31988938.0 \n",
      "Model_7_11220 \t loss_train = 37871028.0 \t loss_valid = 31428310.0 \n",
      "Model_7_11230 \t loss_train = 37989232.0 \t loss_valid = 31432110.0 \n",
      "Model_7_11240 \t loss_train = 38219296.0 \t loss_valid = 31571784.0 \n",
      "Model_7_11250 \t loss_train = 38052680.0 \t loss_valid = 31608414.0 \n",
      "Model_7_11260 \t loss_train = 38209232.0 \t loss_valid = 31694174.0 \n",
      "Model_7_11270 \t loss_train = 38359168.0 \t loss_valid = 31750460.0 \n",
      "Model_7_11280 \t loss_train = 38281528.0 \t loss_valid = 31680626.0 \n",
      "Model_7_11290 \t loss_train = 38221348.0 \t loss_valid = 31660532.0 \n",
      "Model_7_11300 \t loss_train = 37824432.0 \t loss_valid = 31375650.0 \n",
      "Model_7_11310 \t loss_train = 38803684.0 \t loss_valid = 32217366.0 \n",
      "Model_7_11320 \t loss_train = 37706144.0 \t loss_valid = 31203404.0 \n",
      "Model_7_11330 \t loss_train = 38373856.0 \t loss_valid = 31838388.0 \n",
      "Model_7_11340 \t loss_train = 37961144.0 \t loss_valid = 31427084.0 \n",
      "Model_7_11350 \t loss_train = 38199044.0 \t loss_valid = 31687806.0 \n",
      "Model_7_11360 \t loss_train = 38680468.0 \t loss_valid = 32131664.0 \n",
      "Model_7_11370 \t loss_train = 38337816.0 \t loss_valid = 31871308.0 \n",
      "Model_7_11380 \t loss_train = 37790792.0 \t loss_valid = 31291764.0 \n",
      "Model_7_11390 \t loss_train = 37936120.0 \t loss_valid = 31419578.0 \n",
      "Model_7_11400 \t loss_train = 37832916.0 \t loss_valid = 31372320.0 \n",
      "Model_7_11410 \t loss_train = 38458744.0 \t loss_valid = 31920394.0 \n",
      "Model_7_11420 \t loss_train = 37814568.0 \t loss_valid = 31318594.0 \n",
      "Model_7_11430 \t loss_train = 38290872.0 \t loss_valid = 31797324.0 \n",
      "Model_7_11440 \t loss_train = 38535740.0 \t loss_valid = 31974526.0 \n",
      "Model_7_11450 \t loss_train = 37819064.0 \t loss_valid = 31375290.0 \n",
      "Model_7_11460 \t loss_train = 38323292.0 \t loss_valid = 31789084.0 \n",
      "Model_7_11470 \t loss_train = 38009260.0 \t loss_valid = 31479482.0 \n",
      "Model_7_11480 \t loss_train = 38290212.0 \t loss_valid = 31737604.0 \n",
      "Model_7_11490 \t loss_train = 38485756.0 \t loss_valid = 31907022.0 \n",
      "Model_7_11500 \t loss_train = 37966576.0 \t loss_valid = 31476076.0 \n",
      "Model_7_11510 \t loss_train = 38512812.0 \t loss_valid = 31899752.0 \n",
      "Model_7_11520 \t loss_train = 37580764.0 \t loss_valid = 31208678.0 \n",
      "Model_7_11530 \t loss_train = 38280040.0 \t loss_valid = 31794344.0 \n",
      "Model_7_11540 \t loss_train = 38051856.0 \t loss_valid = 31541962.0 \n",
      "Model_7_11550 \t loss_train = 38518368.0 \t loss_valid = 31935740.0 \n",
      "Model_7_11560 \t loss_train = 37686868.0 \t loss_valid = 31192522.0 \n",
      "Model_7_11570 \t loss_train = 38176660.0 \t loss_valid = 31717484.0 \n",
      "Model_7_11580 \t loss_train = 38024804.0 \t loss_valid = 31613282.0 \n",
      "Model_7_11590 \t loss_train = 38533716.0 \t loss_valid = 31946676.0 \n",
      "Model_7_11600 \t loss_train = 38076920.0 \t loss_valid = 31573010.0 \n",
      "Model_7_11610 \t loss_train = 38393780.0 \t loss_valid = 31868682.0 \n",
      "Model_7_11620 \t loss_train = 38116036.0 \t loss_valid = 31607812.0 \n",
      "Model_7_11630 \t loss_train = 38586764.0 \t loss_valid = 31973688.0 \n",
      "Model_7_11640 \t loss_train = 37938116.0 \t loss_valid = 31410890.0 \n",
      "Model_7_11650 \t loss_train = 37960340.0 \t loss_valid = 31417250.0 \n",
      "Model_7_11660 \t loss_train = 39045496.0 \t loss_valid = 32327194.0 \n",
      "Early stopping!\n",
      "Model_8_0 \t loss_train = 119709280.0 \t loss_valid = 104771424.0 \n",
      "Model_8_10 \t loss_train = 118291040.0 \t loss_valid = 102993408.0 \n",
      "Model_8_20 \t loss_train = 114711208.0 \t loss_valid = 98531440.0 \n",
      "Model_8_30 \t loss_train = 105845264.0 \t loss_valid = 87916152.0 \n",
      "Model_8_40 \t loss_train = 85000056.0 \t loss_valid = 65045904.0 \n",
      "Model_8_50 \t loss_train = 63720432.0 \t loss_valid = 56536492.0 \n",
      "Model_8_60 \t loss_train = 62732400.0 \t loss_valid = 58548760.0 \n",
      "Model_8_70 \t loss_train = 62202592.0 \t loss_valid = 50064792.0 \n",
      "Model_8_80 \t loss_train = 60133956.0 \t loss_valid = 49033172.0 \n",
      "Model_8_90 \t loss_train = 58521392.0 \t loss_valid = 48419260.0 \n",
      "Model_8_100 \t loss_train = 57736864.0 \t loss_valid = 45964624.0 \n",
      "Model_8_110 \t loss_train = 56588500.0 \t loss_valid = 44656260.0 \n",
      "Model_8_120 \t loss_train = 55925160.0 \t loss_valid = 43311432.0 \n",
      "Model_8_130 \t loss_train = 55166292.0 \t loss_valid = 42266804.0 \n",
      "Model_8_140 \t loss_train = 54844800.0 \t loss_valid = 41508880.0 \n",
      "Model_8_150 \t loss_train = 54102692.0 \t loss_valid = 40831744.0 \n",
      "Model_8_160 \t loss_train = 53807828.0 \t loss_valid = 40331600.0 \n",
      "Model_8_170 \t loss_train = 53826228.0 \t loss_valid = 40091796.0 \n",
      "Model_8_180 \t loss_train = 53103852.0 \t loss_valid = 39613172.0 \n",
      "Model_8_190 \t loss_train = 52848392.0 \t loss_valid = 39402172.0 \n",
      "Model_8_200 \t loss_train = 52467448.0 \t loss_valid = 39137428.0 \n",
      "Model_8_210 \t loss_train = 52528500.0 \t loss_valid = 39071736.0 \n",
      "Model_8_220 \t loss_train = 51971420.0 \t loss_valid = 38942544.0 \n",
      "Model_8_230 \t loss_train = 52001048.0 \t loss_valid = 38881976.0 \n",
      "Model_8_240 \t loss_train = 51470108.0 \t loss_valid = 38593668.0 \n",
      "Model_8_250 \t loss_train = 51154152.0 \t loss_valid = 38304496.0 \n",
      "Model_8_260 \t loss_train = 50681128.0 \t loss_valid = 38045732.0 \n",
      "Model_8_270 \t loss_train = 50078632.0 \t loss_valid = 38040700.0 \n",
      "Model_8_280 \t loss_train = 49978240.0 \t loss_valid = 37780544.0 \n",
      "Model_8_290 \t loss_train = 49584308.0 \t loss_valid = 37569144.0 \n",
      "Model_8_300 \t loss_train = 48607608.0 \t loss_valid = 37947356.0 \n",
      "Model_8_310 \t loss_train = 48408732.0 \t loss_valid = 36989160.0 \n",
      "Model_8_320 \t loss_train = 47908552.0 \t loss_valid = 36689972.0 \n",
      "Model_8_330 \t loss_train = 46604288.0 \t loss_valid = 36236792.0 \n",
      "Model_8_340 \t loss_train = 45803728.0 \t loss_valid = 35717096.0 \n",
      "Model_8_350 \t loss_train = 45375348.0 \t loss_valid = 35202528.0 \n",
      "Model_8_360 \t loss_train = 44215360.0 \t loss_valid = 34622956.0 \n",
      "Model_8_370 \t loss_train = 42673000.0 \t loss_valid = 34314264.0 \n",
      "Model_8_380 \t loss_train = 41360308.0 \t loss_valid = 33384170.0 \n",
      "Model_8_390 \t loss_train = 40054896.0 \t loss_valid = 32355340.0 \n",
      "Model_8_400 \t loss_train = 38510356.0 \t loss_valid = 31373388.0 \n",
      "Model_8_410 \t loss_train = 37049408.0 \t loss_valid = 30676114.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_8_420 \t loss_train = 35453532.0 \t loss_valid = 29972498.0 \n",
      "Model_8_430 \t loss_train = 33334980.0 \t loss_valid = 28680944.0 \n",
      "Model_8_440 \t loss_train = 32089612.0 \t loss_valid = 27867796.0 \n",
      "Model_8_450 \t loss_train = 30583822.0 \t loss_valid = 26939114.0 \n",
      "Model_8_460 \t loss_train = 29616646.0 \t loss_valid = 26401020.0 \n",
      "Model_8_470 \t loss_train = 29070366.0 \t loss_valid = 25954798.0 \n",
      "Model_8_480 \t loss_train = 28754694.0 \t loss_valid = 25911346.0 \n",
      "Model_8_490 \t loss_train = 29221050.0 \t loss_valid = 25743712.0 \n",
      "Model_8_500 \t loss_train = 28316016.0 \t loss_valid = 26012936.0 \n",
      "Model_8_510 \t loss_train = 28796700.0 \t loss_valid = 25681984.0 \n",
      "Model_8_520 \t loss_train = 28247660.0 \t loss_valid = 25758144.0 \n",
      "Model_8_530 \t loss_train = 28503692.0 \t loss_valid = 25476362.0 \n",
      "Model_8_540 \t loss_train = 28316356.0 \t loss_valid = 25527248.0 \n",
      "Model_8_550 \t loss_train = 28250054.0 \t loss_valid = 25505796.0 \n",
      "Model_8_560 \t loss_train = 28413966.0 \t loss_valid = 25402282.0 \n",
      "Model_8_570 \t loss_train = 28401634.0 \t loss_valid = 25427364.0 \n",
      "Model_8_580 \t loss_train = 28943348.0 \t loss_valid = 25596140.0 \n",
      "Model_8_590 \t loss_train = 28354722.0 \t loss_valid = 25431022.0 \n",
      "Model_8_600 \t loss_train = 28284372.0 \t loss_valid = 25503596.0 \n",
      "Model_8_610 \t loss_train = 29011392.0 \t loss_valid = 25675002.0 \n",
      "Model_8_620 \t loss_train = 28303252.0 \t loss_valid = 25542404.0 \n",
      "Model_8_630 \t loss_train = 28289822.0 \t loss_valid = 25455446.0 \n",
      "Model_8_640 \t loss_train = 28629016.0 \t loss_valid = 25378838.0 \n",
      "Model_8_650 \t loss_train = 28179226.0 \t loss_valid = 25491216.0 \n",
      "Model_8_660 \t loss_train = 28143860.0 \t loss_valid = 25482514.0 \n",
      "Model_8_670 \t loss_train = 28829770.0 \t loss_valid = 25478008.0 \n",
      "Model_8_680 \t loss_train = 28377698.0 \t loss_valid = 25368700.0 \n",
      "Model_8_690 \t loss_train = 28797818.0 \t loss_valid = 25475540.0 \n",
      "Model_8_700 \t loss_train = 28207544.0 \t loss_valid = 25762894.0 \n",
      "Model_8_710 \t loss_train = 28609598.0 \t loss_valid = 25412696.0 \n",
      "Model_8_720 \t loss_train = 28492004.0 \t loss_valid = 25358948.0 \n",
      "Model_8_730 \t loss_train = 28697922.0 \t loss_valid = 25396720.0 \n",
      "Model_8_740 \t loss_train = 28316760.0 \t loss_valid = 25372884.0 \n",
      "Model_8_750 \t loss_train = 28505240.0 \t loss_valid = 25326978.0 \n",
      "Model_8_760 \t loss_train = 28272978.0 \t loss_valid = 25368632.0 \n",
      "Model_8_770 \t loss_train = 28460964.0 \t loss_valid = 25349124.0 \n",
      "Model_8_780 \t loss_train = 28183772.0 \t loss_valid = 25372090.0 \n",
      "Model_8_790 \t loss_train = 28462658.0 \t loss_valid = 25308880.0 \n",
      "Model_8_800 \t loss_train = 28255506.0 \t loss_valid = 25360244.0 \n",
      "Model_8_810 \t loss_train = 28385048.0 \t loss_valid = 25315240.0 \n",
      "Model_8_820 \t loss_train = 28730734.0 \t loss_valid = 25416112.0 \n",
      "Model_8_830 \t loss_train = 28156276.0 \t loss_valid = 25540260.0 \n",
      "Model_8_840 \t loss_train = 28513940.0 \t loss_valid = 25329376.0 \n",
      "Model_8_850 \t loss_train = 28256082.0 \t loss_valid = 25367694.0 \n",
      "Model_8_860 \t loss_train = 28322476.0 \t loss_valid = 25300880.0 \n",
      "Model_8_870 \t loss_train = 28601432.0 \t loss_valid = 25342682.0 \n",
      "Model_8_880 \t loss_train = 28119118.0 \t loss_valid = 25492656.0 \n",
      "Model_8_890 \t loss_train = 28214180.0 \t loss_valid = 25351794.0 \n",
      "Model_8_900 \t loss_train = 29035058.0 \t loss_valid = 25473798.0 \n",
      "Model_8_910 \t loss_train = 28318894.0 \t loss_valid = 25334290.0 \n",
      "Model_8_920 \t loss_train = 28532994.0 \t loss_valid = 25354982.0 \n",
      "Model_8_930 \t loss_train = 28461804.0 \t loss_valid = 25330274.0 \n",
      "Model_8_940 \t loss_train = 28252670.0 \t loss_valid = 25334028.0 \n",
      "Model_8_950 \t loss_train = 28463346.0 \t loss_valid = 25312498.0 \n",
      "Model_8_960 \t loss_train = 28833312.0 \t loss_valid = 25441530.0 \n",
      "Model_8_970 \t loss_train = 28213040.0 \t loss_valid = 25460360.0 \n",
      "Model_8_980 \t loss_train = 28461458.0 \t loss_valid = 25295204.0 \n",
      "Model_8_990 \t loss_train = 28424880.0 \t loss_valid = 25295710.0 \n",
      "Model_8_1000 \t loss_train = 28177582.0 \t loss_valid = 25419094.0 \n",
      "Model_8_1010 \t loss_train = 29149442.0 \t loss_valid = 25528222.0 \n",
      "Model_8_1020 \t loss_train = 28314714.0 \t loss_valid = 25293586.0 \n",
      "Model_8_1030 \t loss_train = 28389724.0 \t loss_valid = 25280540.0 \n",
      "Model_8_1040 \t loss_train = 28355944.0 \t loss_valid = 25299500.0 \n",
      "Model_8_1050 \t loss_train = 28856860.0 \t loss_valid = 25397842.0 \n",
      "Model_8_1060 \t loss_train = 28250072.0 \t loss_valid = 25357270.0 \n",
      "Model_8_1070 \t loss_train = 28492684.0 \t loss_valid = 25286690.0 \n",
      "Model_8_1080 \t loss_train = 28552124.0 \t loss_valid = 25311040.0 \n",
      "Model_8_1090 \t loss_train = 28862340.0 \t loss_valid = 25410964.0 \n",
      "Model_8_1100 \t loss_train = 28701932.0 \t loss_valid = 25363806.0 \n",
      "Model_8_1110 \t loss_train = 28256146.0 \t loss_valid = 25322658.0 \n",
      "Model_8_1120 \t loss_train = 28281076.0 \t loss_valid = 25347068.0 \n",
      "Model_8_1130 \t loss_train = 28560750.0 \t loss_valid = 25317998.0 \n",
      "Model_8_1140 \t loss_train = 28573440.0 \t loss_valid = 25298666.0 \n",
      "Model_8_1150 \t loss_train = 28375724.0 \t loss_valid = 25306636.0 \n",
      "Model_8_1160 \t loss_train = 28586158.0 \t loss_valid = 25298244.0 \n",
      "Model_8_1170 \t loss_train = 28568478.0 \t loss_valid = 25291638.0 \n",
      "Model_8_1180 \t loss_train = 28493280.0 \t loss_valid = 25283452.0 \n",
      "Model_8_1190 \t loss_train = 28318328.0 \t loss_valid = 25284348.0 \n",
      "Model_8_1200 \t loss_train = 29045782.0 \t loss_valid = 25425634.0 \n",
      "Model_8_1210 \t loss_train = 28354020.0 \t loss_valid = 25271814.0 \n",
      "Model_8_1220 \t loss_train = 28993816.0 \t loss_valid = 25427926.0 \n",
      "Model_8_1230 \t loss_train = 28804438.0 \t loss_valid = 25344494.0 \n",
      "Model_8_1240 \t loss_train = 28637110.0 \t loss_valid = 25331136.0 \n",
      "Model_8_1250 \t loss_train = 28669352.0 \t loss_valid = 25324604.0 \n",
      "Model_8_1260 \t loss_train = 28756634.0 \t loss_valid = 25320896.0 \n",
      "Model_8_1270 \t loss_train = 28796428.0 \t loss_valid = 25354578.0 \n",
      "Model_8_1280 \t loss_train = 28862014.0 \t loss_valid = 25366254.0 \n",
      "Model_8_1290 \t loss_train = 28525944.0 \t loss_valid = 25283528.0 \n",
      "Model_8_1300 \t loss_train = 29007110.0 \t loss_valid = 25509690.0 \n",
      "Model_8_1310 \t loss_train = 28398638.0 \t loss_valid = 25284846.0 \n",
      "Model_8_1320 \t loss_train = 28571424.0 \t loss_valid = 25286806.0 \n",
      "Model_8_1330 \t loss_train = 29179074.0 \t loss_valid = 25562400.0 \n",
      "Model_8_1340 \t loss_train = 28554322.0 \t loss_valid = 25323908.0 \n",
      "Model_8_1350 \t loss_train = 29213242.0 \t loss_valid = 25568256.0 \n",
      "Model_8_1360 \t loss_train = 29111918.0 \t loss_valid = 25518090.0 \n",
      "Model_8_1370 \t loss_train = 28491038.0 \t loss_valid = 25341946.0 \n",
      "Model_8_1380 \t loss_train = 28765486.0 \t loss_valid = 25343212.0 \n",
      "Model_8_1390 \t loss_train = 29248042.0 \t loss_valid = 25584204.0 \n",
      "Model_8_1400 \t loss_train = 28446632.0 \t loss_valid = 25411764.0 \n",
      "Model_8_1410 \t loss_train = 28590478.0 \t loss_valid = 25300468.0 \n",
      "Model_8_1420 \t loss_train = 29339298.0 \t loss_valid = 25604516.0 \n",
      "Model_8_1430 \t loss_train = 28758678.0 \t loss_valid = 25335626.0 \n",
      "Model_8_1440 \t loss_train = 28466204.0 \t loss_valid = 25308880.0 \n",
      "Model_8_1450 \t loss_train = 29521430.0 \t loss_valid = 25721882.0 \n",
      "Model_8_1460 \t loss_train = 28825146.0 \t loss_valid = 25362662.0 \n",
      "Model_8_1470 \t loss_train = 28633770.0 \t loss_valid = 25298798.0 \n",
      "Model_8_1480 \t loss_train = 28883962.0 \t loss_valid = 25368462.0 \n",
      "Model_8_1490 \t loss_train = 28668660.0 \t loss_valid = 25310378.0 \n",
      "Model_8_1500 \t loss_train = 29462592.0 \t loss_valid = 25622162.0 \n",
      "Model_8_1510 \t loss_train = 29828666.0 \t loss_valid = 25936884.0 \n",
      "Model_8_1520 \t loss_train = 28821562.0 \t loss_valid = 25345988.0 \n",
      "Model_8_1530 \t loss_train = 28689000.0 \t loss_valid = 25305742.0 \n",
      "Model_8_1540 \t loss_train = 29468298.0 \t loss_valid = 25640486.0 \n",
      "Model_8_1550 \t loss_train = 29207230.0 \t loss_valid = 25517052.0 \n",
      "Model_8_1560 \t loss_train = 28784432.0 \t loss_valid = 25342862.0 \n",
      "Model_8_1570 \t loss_train = 29405820.0 \t loss_valid = 25693626.0 \n",
      "Model_8_1580 \t loss_train = 29112164.0 \t loss_valid = 25456802.0 \n",
      "Model_8_1590 \t loss_train = 29252664.0 \t loss_valid = 25519340.0 \n",
      "Model_8_1600 \t loss_train = 28885438.0 \t loss_valid = 25360530.0 \n",
      "Model_8_1610 \t loss_train = 29633726.0 \t loss_valid = 25790564.0 \n",
      "Model_8_1620 \t loss_train = 29182026.0 \t loss_valid = 25502076.0 \n",
      "Model_8_1630 \t loss_train = 28834254.0 \t loss_valid = 25350818.0 \n",
      "Model_8_1640 \t loss_train = 29680516.0 \t loss_valid = 25761170.0 \n",
      "Model_8_1650 \t loss_train = 29636154.0 \t loss_valid = 25739388.0 \n",
      "Model_8_1660 \t loss_train = 28952990.0 \t loss_valid = 25366186.0 \n",
      "Model_8_1670 \t loss_train = 29314196.0 \t loss_valid = 25565364.0 \n",
      "Model_8_1680 \t loss_train = 29364400.0 \t loss_valid = 25546586.0 \n",
      "Model_8_1690 \t loss_train = 29304192.0 \t loss_valid = 25496938.0 \n",
      "Model_8_1700 \t loss_train = 29371724.0 \t loss_valid = 25550620.0 \n",
      "Model_8_1710 \t loss_train = 29533928.0 \t loss_valid = 25632298.0 \n",
      "Model_8_1720 \t loss_train = 29146958.0 \t loss_valid = 25442510.0 \n",
      "Model_8_1730 \t loss_train = 29182072.0 \t loss_valid = 25470432.0 \n",
      "Model_8_1740 \t loss_train = 29508256.0 \t loss_valid = 25639570.0 \n",
      "Model_8_1750 \t loss_train = 29414212.0 \t loss_valid = 25544282.0 \n",
      "Model_8_1760 \t loss_train = 29703488.0 \t loss_valid = 25774648.0 \n",
      "Model_8_1770 \t loss_train = 29198620.0 \t loss_valid = 25436344.0 \n",
      "Model_8_1780 \t loss_train = 28920730.0 \t loss_valid = 25376756.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_8_1790 \t loss_train = 29868138.0 \t loss_valid = 25876690.0 \n",
      "Model_8_1800 \t loss_train = 29941932.0 \t loss_valid = 25854926.0 \n",
      "Model_8_1810 \t loss_train = 29139576.0 \t loss_valid = 25431238.0 \n",
      "Model_8_1820 \t loss_train = 29453190.0 \t loss_valid = 25565504.0 \n",
      "Model_8_1830 \t loss_train = 29288546.0 \t loss_valid = 25482136.0 \n",
      "Model_8_1840 \t loss_train = 29285336.0 \t loss_valid = 25511270.0 \n",
      "Model_8_1850 \t loss_train = 29581296.0 \t loss_valid = 25610310.0 \n",
      "Model_8_1860 \t loss_train = 30088286.0 \t loss_valid = 26035278.0 \n",
      "Model_8_1870 \t loss_train = 28953416.0 \t loss_valid = 25355892.0 \n",
      "Model_8_1880 \t loss_train = 29481320.0 \t loss_valid = 25588258.0 \n",
      "Model_8_1890 \t loss_train = 29774728.0 \t loss_valid = 25804924.0 \n",
      "Model_8_1900 \t loss_train = 29564734.0 \t loss_valid = 25695580.0 \n",
      "Model_8_1910 \t loss_train = 29357204.0 \t loss_valid = 25495446.0 \n",
      "Model_8_1920 \t loss_train = 29684008.0 \t loss_valid = 25726242.0 \n",
      "Model_8_1930 \t loss_train = 29984362.0 \t loss_valid = 25941120.0 \n",
      "Model_8_1940 \t loss_train = 29522462.0 \t loss_valid = 25590472.0 \n",
      "Model_8_1950 \t loss_train = 29563726.0 \t loss_valid = 25593878.0 \n",
      "Model_8_1960 \t loss_train = 30052304.0 \t loss_valid = 25966048.0 \n",
      "Model_8_1970 \t loss_train = 29990754.0 \t loss_valid = 25896176.0 \n",
      "Model_8_1980 \t loss_train = 29359450.0 \t loss_valid = 25506546.0 \n",
      "Model_8_1990 \t loss_train = 29333226.0 \t loss_valid = 25517758.0 \n",
      "Model_8_2000 \t loss_train = 29535648.0 \t loss_valid = 25608332.0 \n",
      "Model_8_2010 \t loss_train = 29525712.0 \t loss_valid = 25560648.0 \n",
      "Model_8_2020 \t loss_train = 29874932.0 \t loss_valid = 25817050.0 \n",
      "Model_8_2030 \t loss_train = 30102234.0 \t loss_valid = 25924186.0 \n",
      "Model_8_2040 \t loss_train = 29782820.0 \t loss_valid = 25707686.0 \n",
      "Model_8_2050 \t loss_train = 29330814.0 \t loss_valid = 25491506.0 \n",
      "Model_8_2060 \t loss_train = 29892996.0 \t loss_valid = 25812376.0 \n",
      "Model_8_2070 \t loss_train = 29937314.0 \t loss_valid = 25819136.0 \n",
      "Model_8_2080 \t loss_train = 29701158.0 \t loss_valid = 25662856.0 \n",
      "Model_8_2090 \t loss_train = 29229900.0 \t loss_valid = 25440364.0 \n",
      "Model_8_2100 \t loss_train = 30086688.0 \t loss_valid = 25894100.0 \n",
      "Model_8_2110 \t loss_train = 29622492.0 \t loss_valid = 25639860.0 \n",
      "Model_8_2120 \t loss_train = 30338876.0 \t loss_valid = 26080632.0 \n",
      "Model_8_2130 \t loss_train = 29665320.0 \t loss_valid = 25596172.0 \n",
      "Model_8_2140 \t loss_train = 29527512.0 \t loss_valid = 25565480.0 \n",
      "Model_8_2150 \t loss_train = 30376604.0 \t loss_valid = 26167540.0 \n",
      "Model_8_2160 \t loss_train = 30349266.0 \t loss_valid = 26073506.0 \n",
      "Model_8_2170 \t loss_train = 29718684.0 \t loss_valid = 25671262.0 \n",
      "Model_8_2180 \t loss_train = 29576388.0 \t loss_valid = 25613992.0 \n",
      "Model_8_2190 \t loss_train = 30367916.0 \t loss_valid = 26201808.0 \n",
      "Model_8_2200 \t loss_train = 29620940.0 \t loss_valid = 25599454.0 \n",
      "Model_8_2210 \t loss_train = 29925018.0 \t loss_valid = 25781368.0 \n",
      "Model_8_2220 \t loss_train = 30614740.0 \t loss_valid = 26323396.0 \n",
      "Model_8_2230 \t loss_train = 30355956.0 \t loss_valid = 26054894.0 \n",
      "Model_8_2240 \t loss_train = 29720054.0 \t loss_valid = 25685636.0 \n",
      "Model_8_2250 \t loss_train = 30282208.0 \t loss_valid = 26041742.0 \n",
      "Model_8_2260 \t loss_train = 30453744.0 \t loss_valid = 26179672.0 \n",
      "Model_8_2270 \t loss_train = 29693538.0 \t loss_valid = 25690154.0 \n",
      "Model_8_2280 \t loss_train = 29226736.0 \t loss_valid = 25467766.0 \n",
      "Model_8_2290 \t loss_train = 30599258.0 \t loss_valid = 26247856.0 \n",
      "Model_8_2300 \t loss_train = 30288454.0 \t loss_valid = 26076532.0 \n",
      "Model_8_2310 \t loss_train = 30445712.0 \t loss_valid = 26124118.0 \n",
      "Model_8_2320 \t loss_train = 29804864.0 \t loss_valid = 25695250.0 \n",
      "Model_8_2330 \t loss_train = 30349676.0 \t loss_valid = 26093172.0 \n",
      "Model_8_2340 \t loss_train = 29852890.0 \t loss_valid = 25716274.0 \n",
      "Model_8_2350 \t loss_train = 30709456.0 \t loss_valid = 26329906.0 \n",
      "Model_8_2360 \t loss_train = 30449040.0 \t loss_valid = 26171434.0 \n",
      "Model_8_2370 \t loss_train = 30394568.0 \t loss_valid = 26070358.0 \n",
      "Model_8_2380 \t loss_train = 30282636.0 \t loss_valid = 25982710.0 \n",
      "Model_8_2390 \t loss_train = 30099776.0 \t loss_valid = 25899124.0 \n",
      "Model_8_2400 \t loss_train = 30264772.0 \t loss_valid = 25983586.0 \n",
      "Model_8_2410 \t loss_train = 30208574.0 \t loss_valid = 25952244.0 \n",
      "Model_8_2420 \t loss_train = 30413218.0 \t loss_valid = 26046986.0 \n",
      "Model_8_2430 \t loss_train = 30321128.0 \t loss_valid = 26026026.0 \n",
      "Model_8_2440 \t loss_train = 30855298.0 \t loss_valid = 26424956.0 \n",
      "Model_8_2450 \t loss_train = 30055672.0 \t loss_valid = 25837888.0 \n",
      "Model_8_2460 \t loss_train = 29968164.0 \t loss_valid = 25842450.0 \n",
      "Model_8_2470 \t loss_train = 30105792.0 \t loss_valid = 25835320.0 \n",
      "Model_8_2480 \t loss_train = 30050638.0 \t loss_valid = 25887628.0 \n",
      "Model_8_2490 \t loss_train = 30650042.0 \t loss_valid = 26269534.0 \n",
      "Model_8_2500 \t loss_train = 31344764.0 \t loss_valid = 26804356.0 \n",
      "Model_8_2510 \t loss_train = 30171208.0 \t loss_valid = 25934708.0 \n",
      "Model_8_2520 \t loss_train = 30032566.0 \t loss_valid = 25802462.0 \n",
      "Model_8_2530 \t loss_train = 30880528.0 \t loss_valid = 26434804.0 \n",
      "Model_8_2540 \t loss_train = 31275418.0 \t loss_valid = 26780170.0 \n",
      "Model_8_2550 \t loss_train = 30166322.0 \t loss_valid = 25924604.0 \n",
      "Model_8_2560 \t loss_train = 30298632.0 \t loss_valid = 25965506.0 \n",
      "Model_8_2570 \t loss_train = 30622426.0 \t loss_valid = 26251434.0 \n",
      "Model_8_2580 \t loss_train = 30504742.0 \t loss_valid = 26167958.0 \n",
      "Model_8_2590 \t loss_train = 30737538.0 \t loss_valid = 26316774.0 \n",
      "Model_8_2600 \t loss_train = 30678752.0 \t loss_valid = 26248598.0 \n",
      "Model_8_2610 \t loss_train = 30104782.0 \t loss_valid = 25919514.0 \n",
      "Model_8_2620 \t loss_train = 30714064.0 \t loss_valid = 26255990.0 \n",
      "Model_8_2630 \t loss_train = 31179710.0 \t loss_valid = 26616828.0 \n",
      "Model_8_2640 \t loss_train = 30623116.0 \t loss_valid = 26210156.0 \n",
      "Model_8_2650 \t loss_train = 30465684.0 \t loss_valid = 26102422.0 \n",
      "Model_8_2660 \t loss_train = 30649888.0 \t loss_valid = 26217200.0 \n",
      "Model_8_2670 \t loss_train = 30881226.0 \t loss_valid = 26353294.0 \n",
      "Model_8_2680 \t loss_train = 30377678.0 \t loss_valid = 26025776.0 \n",
      "Model_8_2690 \t loss_train = 29890148.0 \t loss_valid = 25752592.0 \n",
      "Model_8_2700 \t loss_train = 31026020.0 \t loss_valid = 26565862.0 \n",
      "Model_8_2710 \t loss_train = 31548932.0 \t loss_valid = 27002356.0 \n",
      "Model_8_2720 \t loss_train = 31218202.0 \t loss_valid = 26667396.0 \n",
      "Model_8_2730 \t loss_train = 29890736.0 \t loss_valid = 25723476.0 \n",
      "Model_8_2740 \t loss_train = 30622032.0 \t loss_valid = 26208670.0 \n",
      "Model_8_2750 \t loss_train = 30798592.0 \t loss_valid = 26359704.0 \n",
      "Model_8_2760 \t loss_train = 30530404.0 \t loss_valid = 26148438.0 \n",
      "Model_8_2770 \t loss_train = 30758028.0 \t loss_valid = 26313500.0 \n",
      "Model_8_2780 \t loss_train = 30897748.0 \t loss_valid = 26375852.0 \n",
      "Model_8_2790 \t loss_train = 30559628.0 \t loss_valid = 26155996.0 \n",
      "Model_8_2800 \t loss_train = 30634296.0 \t loss_valid = 26239684.0 \n",
      "Model_8_2810 \t loss_train = 31544104.0 \t loss_valid = 26963996.0 \n",
      "Model_8_2820 \t loss_train = 31232552.0 \t loss_valid = 26619758.0 \n",
      "Model_8_2830 \t loss_train = 30514770.0 \t loss_valid = 26175458.0 \n",
      "Model_8_2840 \t loss_train = 30992098.0 \t loss_valid = 26487984.0 \n",
      "Model_8_2850 \t loss_train = 31098464.0 \t loss_valid = 26587976.0 \n",
      "Model_8_2860 \t loss_train = 30711362.0 \t loss_valid = 26238706.0 \n",
      "Model_8_2870 \t loss_train = 30777260.0 \t loss_valid = 26317850.0 \n",
      "Model_8_2880 \t loss_train = 30760676.0 \t loss_valid = 26272874.0 \n",
      "Model_8_2890 \t loss_train = 30365482.0 \t loss_valid = 25994246.0 \n",
      "Model_8_2900 \t loss_train = 30800048.0 \t loss_valid = 26342916.0 \n",
      "Model_8_2910 \t loss_train = 31481530.0 \t loss_valid = 26882346.0 \n",
      "Model_8_2920 \t loss_train = 31336720.0 \t loss_valid = 26755354.0 \n",
      "Model_8_2930 \t loss_train = 30616058.0 \t loss_valid = 26157284.0 \n",
      "Model_8_2940 \t loss_train = 30780854.0 \t loss_valid = 26283602.0 \n",
      "Model_8_2950 \t loss_train = 30696972.0 \t loss_valid = 26266782.0 \n",
      "Model_8_2960 \t loss_train = 30813116.0 \t loss_valid = 26298348.0 \n",
      "Model_8_2970 \t loss_train = 30828420.0 \t loss_valid = 26281152.0 \n",
      "Model_8_2980 \t loss_train = 31214532.0 \t loss_valid = 26629040.0 \n",
      "Model_8_2990 \t loss_train = 31030178.0 \t loss_valid = 26545234.0 \n",
      "Model_8_3000 \t loss_train = 30970070.0 \t loss_valid = 26415758.0 \n",
      "Model_8_3010 \t loss_train = 31179736.0 \t loss_valid = 26629898.0 \n",
      "Model_8_3020 \t loss_train = 31186004.0 \t loss_valid = 26582332.0 \n",
      "Model_8_3030 \t loss_train = 30429234.0 \t loss_valid = 26036552.0 \n",
      "Model_8_3040 \t loss_train = 31340914.0 \t loss_valid = 26723518.0 \n",
      "Model_8_3050 \t loss_train = 31317008.0 \t loss_valid = 26615398.0 \n",
      "Model_8_3060 \t loss_train = 30713100.0 \t loss_valid = 26180892.0 \n",
      "Model_8_3070 \t loss_train = 30442054.0 \t loss_valid = 26050558.0 \n",
      "Model_8_3080 \t loss_train = 30626290.0 \t loss_valid = 26188502.0 \n",
      "Model_8_3090 \t loss_train = 31451434.0 \t loss_valid = 26801468.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_8_3100 \t loss_train = 31054524.0 \t loss_valid = 26471096.0 \n",
      "Model_8_3110 \t loss_train = 31378984.0 \t loss_valid = 26757158.0 \n",
      "Model_8_3120 \t loss_train = 31103110.0 \t loss_valid = 26523178.0 \n",
      "Model_8_3130 \t loss_train = 30675698.0 \t loss_valid = 26229312.0 \n",
      "Model_8_3140 \t loss_train = 30970926.0 \t loss_valid = 26403824.0 \n",
      "Model_8_3150 \t loss_train = 31155088.0 \t loss_valid = 26522614.0 \n",
      "Model_8_3160 \t loss_train = 31287456.0 \t loss_valid = 26734700.0 \n",
      "Model_8_3170 \t loss_train = 31146074.0 \t loss_valid = 26626528.0 \n",
      "Model_8_3180 \t loss_train = 30784120.0 \t loss_valid = 26252870.0 \n",
      "Model_8_3190 \t loss_train = 30555688.0 \t loss_valid = 26145368.0 \n",
      "Model_8_3200 \t loss_train = 31146466.0 \t loss_valid = 26583486.0 \n",
      "Model_8_3210 \t loss_train = 31425222.0 \t loss_valid = 26746838.0 \n",
      "Model_8_3220 \t loss_train = 30872038.0 \t loss_valid = 26367920.0 \n",
      "Model_8_3230 \t loss_train = 30670460.0 \t loss_valid = 26227896.0 \n",
      "Model_8_3240 \t loss_train = 31518638.0 \t loss_valid = 26825198.0 \n",
      "Model_8_3250 \t loss_train = 31192336.0 \t loss_valid = 26579554.0 \n",
      "Model_8_3260 \t loss_train = 31449456.0 \t loss_valid = 26817390.0 \n",
      "Model_8_3270 \t loss_train = 31258310.0 \t loss_valid = 26649170.0 \n",
      "Model_8_3280 \t loss_train = 31508958.0 \t loss_valid = 26844090.0 \n",
      "Model_8_3290 \t loss_train = 31748092.0 \t loss_valid = 27118756.0 \n",
      "Model_8_3300 \t loss_train = 31579134.0 \t loss_valid = 26861014.0 \n",
      "Model_8_3310 \t loss_train = 31023884.0 \t loss_valid = 26460846.0 \n",
      "Model_8_3320 \t loss_train = 31238002.0 \t loss_valid = 26624736.0 \n",
      "Model_8_3330 \t loss_train = 31787978.0 \t loss_valid = 27033852.0 \n",
      "Model_8_3340 \t loss_train = 31037178.0 \t loss_valid = 26477444.0 \n",
      "Model_8_3350 \t loss_train = 31309464.0 \t loss_valid = 26651426.0 \n",
      "Model_8_3360 \t loss_train = 31061360.0 \t loss_valid = 26478462.0 \n",
      "Model_8_3370 \t loss_train = 31153644.0 \t loss_valid = 26600432.0 \n",
      "Model_8_3380 \t loss_train = 31038544.0 \t loss_valid = 26508982.0 \n",
      "Model_8_3390 \t loss_train = 30599224.0 \t loss_valid = 26216368.0 \n",
      "Model_8_3400 \t loss_train = 30689906.0 \t loss_valid = 26200086.0 \n",
      "Model_8_3410 \t loss_train = 30983438.0 \t loss_valid = 26379514.0 \n",
      "Model_8_3420 \t loss_train = 30556094.0 \t loss_valid = 26125402.0 \n",
      "Model_8_3430 \t loss_train = 30936688.0 \t loss_valid = 26413270.0 \n",
      "Model_8_3440 \t loss_train = 31479818.0 \t loss_valid = 26844242.0 \n",
      "Model_8_3450 \t loss_train = 31665506.0 \t loss_valid = 26977132.0 \n",
      "Model_8_3460 \t loss_train = 30654360.0 \t loss_valid = 26180190.0 \n",
      "Model_8_3470 \t loss_train = 31029488.0 \t loss_valid = 26446384.0 \n",
      "Model_8_3480 \t loss_train = 31821168.0 \t loss_valid = 27086386.0 \n",
      "Model_8_3490 \t loss_train = 31681666.0 \t loss_valid = 27027070.0 \n",
      "Model_8_3500 \t loss_train = 31218268.0 \t loss_valid = 26650596.0 \n",
      "Model_8_3510 \t loss_train = 30800508.0 \t loss_valid = 26232038.0 \n",
      "Model_8_3520 \t loss_train = 30835458.0 \t loss_valid = 26351578.0 \n",
      "Model_8_3530 \t loss_train = 31438306.0 \t loss_valid = 26869226.0 \n",
      "Model_8_3540 \t loss_train = 31287556.0 \t loss_valid = 26614968.0 \n",
      "Model_8_3550 \t loss_train = 31151680.0 \t loss_valid = 26544482.0 \n",
      "Model_8_3560 \t loss_train = 31248638.0 \t loss_valid = 26602786.0 \n",
      "Model_8_3570 \t loss_train = 30922726.0 \t loss_valid = 26350736.0 \n",
      "Model_8_3580 \t loss_train = 30977648.0 \t loss_valid = 26470674.0 \n",
      "Model_8_3590 \t loss_train = 31430190.0 \t loss_valid = 26748644.0 \n",
      "Model_8_3600 \t loss_train = 31889490.0 \t loss_valid = 27096816.0 \n",
      "Model_8_3610 \t loss_train = 31213464.0 \t loss_valid = 26594506.0 \n",
      "Model_8_3620 \t loss_train = 30535300.0 \t loss_valid = 26113552.0 \n",
      "Model_8_3630 \t loss_train = 31612316.0 \t loss_valid = 26853088.0 \n",
      "Model_8_3640 \t loss_train = 31766230.0 \t loss_valid = 26968150.0 \n",
      "Model_8_3650 \t loss_train = 32116420.0 \t loss_valid = 27251690.0 \n",
      "Model_8_3660 \t loss_train = 31345414.0 \t loss_valid = 26741956.0 \n",
      "Model_8_3670 \t loss_train = 30664486.0 \t loss_valid = 26204696.0 \n",
      "Model_8_3680 \t loss_train = 30802672.0 \t loss_valid = 26291032.0 \n",
      "Model_8_3690 \t loss_train = 31396684.0 \t loss_valid = 26728076.0 \n",
      "Model_8_3700 \t loss_train = 31622964.0 \t loss_valid = 26877466.0 \n",
      "Model_8_3710 \t loss_train = 31334270.0 \t loss_valid = 26653278.0 \n",
      "Model_8_3720 \t loss_train = 31893794.0 \t loss_valid = 27124632.0 \n",
      "Model_8_3730 \t loss_train = 31615178.0 \t loss_valid = 26927436.0 \n",
      "Model_8_3740 \t loss_train = 31205058.0 \t loss_valid = 26626788.0 \n",
      "Model_8_3750 \t loss_train = 31570676.0 \t loss_valid = 26830090.0 \n",
      "Model_8_3760 \t loss_train = 31493408.0 \t loss_valid = 26847090.0 \n",
      "Model_8_3770 \t loss_train = 31516370.0 \t loss_valid = 26796382.0 \n",
      "Model_8_3780 \t loss_train = 31195484.0 \t loss_valid = 26548594.0 \n",
      "Model_8_3790 \t loss_train = 31316716.0 \t loss_valid = 26675670.0 \n",
      "Model_8_3800 \t loss_train = 31633716.0 \t loss_valid = 26992852.0 \n",
      "Model_8_3810 \t loss_train = 31438984.0 \t loss_valid = 26718170.0 \n",
      "Model_8_3820 \t loss_train = 31719482.0 \t loss_valid = 26916626.0 \n",
      "Model_8_3830 \t loss_train = 31494752.0 \t loss_valid = 26789082.0 \n",
      "Model_8_3840 \t loss_train = 31768234.0 \t loss_valid = 26959992.0 \n",
      "Model_8_3850 \t loss_train = 31742750.0 \t loss_valid = 27023546.0 \n",
      "Model_8_3860 \t loss_train = 31826766.0 \t loss_valid = 27099568.0 \n",
      "Model_8_3870 \t loss_train = 32141118.0 \t loss_valid = 27264916.0 \n",
      "Model_8_3880 \t loss_train = 31422252.0 \t loss_valid = 26717374.0 \n",
      "Model_8_3890 \t loss_train = 31221126.0 \t loss_valid = 26580022.0 \n",
      "Model_8_3900 \t loss_train = 31651284.0 \t loss_valid = 26988834.0 \n",
      "Model_8_3910 \t loss_train = 31835136.0 \t loss_valid = 27120592.0 \n",
      "Model_8_3920 \t loss_train = 31890544.0 \t loss_valid = 27049106.0 \n",
      "Model_8_3930 \t loss_train = 31604270.0 \t loss_valid = 26873082.0 \n",
      "Model_8_3940 \t loss_train = 31668516.0 \t loss_valid = 26918466.0 \n",
      "Model_8_3950 \t loss_train = 31981686.0 \t loss_valid = 27182062.0 \n",
      "Model_8_3960 \t loss_train = 32266616.0 \t loss_valid = 27463304.0 \n",
      "Model_8_3970 \t loss_train = 31783292.0 \t loss_valid = 26977504.0 \n",
      "Model_8_3980 \t loss_train = 31116590.0 \t loss_valid = 26462370.0 \n",
      "Model_8_3990 \t loss_train = 31272654.0 \t loss_valid = 26666764.0 \n",
      "Model_8_4000 \t loss_train = 32083616.0 \t loss_valid = 27263634.0 \n",
      "Model_8_4010 \t loss_train = 32196740.0 \t loss_valid = 27402470.0 \n",
      "Model_8_4020 \t loss_train = 32093454.0 \t loss_valid = 27275742.0 \n",
      "Model_8_4030 \t loss_train = 31670740.0 \t loss_valid = 26899844.0 \n",
      "Model_8_4040 \t loss_train = 31471488.0 \t loss_valid = 26759336.0 \n",
      "Model_8_4050 \t loss_train = 31716328.0 \t loss_valid = 26987416.0 \n",
      "Model_8_4060 \t loss_train = 31569700.0 \t loss_valid = 26889356.0 \n",
      "Model_8_4070 \t loss_train = 31305128.0 \t loss_valid = 26624674.0 \n",
      "Model_8_4080 \t loss_train = 31743488.0 \t loss_valid = 27004890.0 \n",
      "Model_8_4090 \t loss_train = 31568190.0 \t loss_valid = 26859938.0 \n",
      "Model_8_4100 \t loss_train = 32138706.0 \t loss_valid = 27302638.0 \n",
      "Model_8_4110 \t loss_train = 31819680.0 \t loss_valid = 27081080.0 \n",
      "Model_8_4120 \t loss_train = 32396084.0 \t loss_valid = 27461512.0 \n",
      "Model_8_4130 \t loss_train = 31394506.0 \t loss_valid = 26662930.0 \n",
      "Model_8_4140 \t loss_train = 31838494.0 \t loss_valid = 26964540.0 \n",
      "Model_8_4150 \t loss_train = 31770746.0 \t loss_valid = 27002102.0 \n",
      "Model_8_4160 \t loss_train = 32255252.0 \t loss_valid = 27479404.0 \n",
      "Model_8_4170 \t loss_train = 32020550.0 \t loss_valid = 27193552.0 \n",
      "Model_8_4180 \t loss_train = 31659912.0 \t loss_valid = 26886246.0 \n",
      "Model_8_4190 \t loss_train = 31688976.0 \t loss_valid = 26952654.0 \n",
      "Model_8_4200 \t loss_train = 31556862.0 \t loss_valid = 26814498.0 \n",
      "Model_8_4210 \t loss_train = 31312106.0 \t loss_valid = 26632648.0 \n",
      "Model_8_4220 \t loss_train = 31791518.0 \t loss_valid = 26950344.0 \n",
      "Model_8_4230 \t loss_train = 32222110.0 \t loss_valid = 27419550.0 \n",
      "Model_8_4240 \t loss_train = 31878930.0 \t loss_valid = 27173344.0 \n",
      "Model_8_4250 \t loss_train = 31522924.0 \t loss_valid = 26816350.0 \n",
      "Model_8_4260 \t loss_train = 31749840.0 \t loss_valid = 26972662.0 \n",
      "Model_8_4270 \t loss_train = 32077562.0 \t loss_valid = 27253470.0 \n",
      "Model_8_4280 \t loss_train = 32092286.0 \t loss_valid = 27267780.0 \n",
      "Model_8_4290 \t loss_train = 31750672.0 \t loss_valid = 27031428.0 \n",
      "Model_8_4300 \t loss_train = 32031200.0 \t loss_valid = 27187598.0 \n",
      "Model_8_4310 \t loss_train = 32397434.0 \t loss_valid = 27418296.0 \n",
      "Model_8_4320 \t loss_train = 31730234.0 \t loss_valid = 27008456.0 \n",
      "Model_8_4330 \t loss_train = 32183116.0 \t loss_valid = 27208828.0 \n",
      "Model_8_4340 \t loss_train = 32117222.0 \t loss_valid = 27224488.0 \n",
      "Model_8_4350 \t loss_train = 31780782.0 \t loss_valid = 27052510.0 \n",
      "Model_8_4360 \t loss_train = 32759648.0 \t loss_valid = 27745128.0 \n",
      "Model_8_4370 \t loss_train = 31936582.0 \t loss_valid = 27186400.0 \n",
      "Model_8_4380 \t loss_train = 31562230.0 \t loss_valid = 26801246.0 \n",
      "Model_8_4390 \t loss_train = 31505142.0 \t loss_valid = 26773672.0 \n",
      "Model_8_4400 \t loss_train = 32016048.0 \t loss_valid = 27163042.0 \n",
      "Model_8_4410 \t loss_train = 32165350.0 \t loss_valid = 27253146.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_8_4420 \t loss_train = 32301292.0 \t loss_valid = 27424238.0 \n",
      "Model_8_4430 \t loss_train = 31981868.0 \t loss_valid = 27240072.0 \n",
      "Model_8_4440 \t loss_train = 31620748.0 \t loss_valid = 26890380.0 \n",
      "Model_8_4450 \t loss_train = 31939224.0 \t loss_valid = 27132008.0 \n",
      "Model_8_4460 \t loss_train = 32369966.0 \t loss_valid = 27506782.0 \n",
      "Model_8_4470 \t loss_train = 32746054.0 \t loss_valid = 27859598.0 \n",
      "Model_8_4480 \t loss_train = 32495472.0 \t loss_valid = 27640358.0 \n",
      "Model_8_4490 \t loss_train = 32311822.0 \t loss_valid = 27398100.0 \n",
      "Model_8_4500 \t loss_train = 32812552.0 \t loss_valid = 27929552.0 \n",
      "Model_8_4510 \t loss_train = 31725178.0 \t loss_valid = 26970450.0 \n",
      "Model_8_4520 \t loss_train = 31527408.0 \t loss_valid = 26747598.0 \n",
      "Model_8_4530 \t loss_train = 32190966.0 \t loss_valid = 27245460.0 \n",
      "Model_8_4540 \t loss_train = 32034024.0 \t loss_valid = 27323240.0 \n",
      "Model_8_4550 \t loss_train = 32023002.0 \t loss_valid = 27174878.0 \n",
      "Model_8_4560 \t loss_train = 31895376.0 \t loss_valid = 27067076.0 \n",
      "Model_8_4570 \t loss_train = 31806750.0 \t loss_valid = 27010654.0 \n",
      "Model_8_4580 \t loss_train = 31919358.0 \t loss_valid = 27128804.0 \n",
      "Model_8_4590 \t loss_train = 31696872.0 \t loss_valid = 26980222.0 \n",
      "Model_8_4600 \t loss_train = 32412662.0 \t loss_valid = 27553780.0 \n",
      "Model_8_4610 \t loss_train = 32364190.0 \t loss_valid = 27447880.0 \n",
      "Model_8_4620 \t loss_train = 31449302.0 \t loss_valid = 26792034.0 \n",
      "Model_8_4630 \t loss_train = 31990522.0 \t loss_valid = 27152280.0 \n",
      "Model_8_4640 \t loss_train = 32032822.0 \t loss_valid = 27158006.0 \n",
      "Model_8_4650 \t loss_train = 32264562.0 \t loss_valid = 27398908.0 \n",
      "Model_8_4660 \t loss_train = 32199556.0 \t loss_valid = 27379674.0 \n",
      "Model_8_4670 \t loss_train = 32104912.0 \t loss_valid = 27233858.0 \n",
      "Model_8_4680 \t loss_train = 31430436.0 \t loss_valid = 26746804.0 \n",
      "Model_8_4690 \t loss_train = 32491886.0 \t loss_valid = 27564706.0 \n",
      "Model_8_4700 \t loss_train = 32181014.0 \t loss_valid = 27287156.0 \n",
      "Model_8_4710 \t loss_train = 31588250.0 \t loss_valid = 26913494.0 \n",
      "Model_8_4720 \t loss_train = 31933500.0 \t loss_valid = 27105154.0 \n",
      "Model_8_4730 \t loss_train = 31655930.0 \t loss_valid = 26844306.0 \n",
      "Model_8_4740 \t loss_train = 31923648.0 \t loss_valid = 27073668.0 \n",
      "Model_8_4750 \t loss_train = 32384600.0 \t loss_valid = 27486310.0 \n",
      "Model_8_4760 \t loss_train = 32312266.0 \t loss_valid = 27481142.0 \n",
      "Model_8_4770 \t loss_train = 32264318.0 \t loss_valid = 27433528.0 \n",
      "Model_8_4780 \t loss_train = 31646930.0 \t loss_valid = 26894942.0 \n",
      "Model_8_4790 \t loss_train = 31662770.0 \t loss_valid = 26978294.0 \n",
      "Model_8_4800 \t loss_train = 32262764.0 \t loss_valid = 27446170.0 \n",
      "Model_8_4810 \t loss_train = 32412568.0 \t loss_valid = 27532750.0 \n",
      "Model_8_4820 \t loss_train = 32359348.0 \t loss_valid = 27515448.0 \n",
      "Model_8_4830 \t loss_train = 32414894.0 \t loss_valid = 27577290.0 \n",
      "Model_8_4840 \t loss_train = 31888346.0 \t loss_valid = 27071558.0 \n",
      "Model_8_4850 \t loss_train = 31876318.0 \t loss_valid = 27097258.0 \n",
      "Model_8_4860 \t loss_train = 32358060.0 \t loss_valid = 27496076.0 \n",
      "Model_8_4870 \t loss_train = 32596690.0 \t loss_valid = 27766866.0 \n",
      "Model_8_4880 \t loss_train = 32349440.0 \t loss_valid = 27452394.0 \n",
      "Model_8_4890 \t loss_train = 32249348.0 \t loss_valid = 27329872.0 \n",
      "Model_8_4900 \t loss_train = 32288008.0 \t loss_valid = 27423206.0 \n",
      "Model_8_4910 \t loss_train = 32894332.0 \t loss_valid = 28012910.0 \n",
      "Model_8_4920 \t loss_train = 32621048.0 \t loss_valid = 27668828.0 \n",
      "Model_8_4930 \t loss_train = 32343462.0 \t loss_valid = 27488692.0 \n",
      "Model_8_4940 \t loss_train = 32187020.0 \t loss_valid = 27353340.0 \n",
      "Model_8_4950 \t loss_train = 31849270.0 \t loss_valid = 27060002.0 \n",
      "Model_8_4960 \t loss_train = 32017040.0 \t loss_valid = 27187204.0 \n",
      "Model_8_4970 \t loss_train = 32444414.0 \t loss_valid = 27524968.0 \n",
      "Model_8_4980 \t loss_train = 32326022.0 \t loss_valid = 27475512.0 \n",
      "Model_8_4990 \t loss_train = 32541420.0 \t loss_valid = 27561564.0 \n",
      "Model_8_5000 \t loss_train = 32216288.0 \t loss_valid = 27333692.0 \n",
      "Model_8_5010 \t loss_train = 32286936.0 \t loss_valid = 27388264.0 \n",
      "Model_8_5020 \t loss_train = 32571530.0 \t loss_valid = 27643524.0 \n",
      "Model_8_5030 \t loss_train = 32398474.0 \t loss_valid = 27554964.0 \n",
      "Model_8_5040 \t loss_train = 32610072.0 \t loss_valid = 27634824.0 \n",
      "Model_8_5050 \t loss_train = 32474164.0 \t loss_valid = 27590362.0 \n",
      "Model_8_5060 \t loss_train = 32386566.0 \t loss_valid = 27506684.0 \n",
      "Model_8_5070 \t loss_train = 32207304.0 \t loss_valid = 27348322.0 \n",
      "Model_8_5080 \t loss_train = 32346886.0 \t loss_valid = 27439850.0 \n",
      "Model_8_5090 \t loss_train = 32413348.0 \t loss_valid = 27524898.0 \n",
      "Model_8_5100 \t loss_train = 32942674.0 \t loss_valid = 27957026.0 \n",
      "Model_8_5110 \t loss_train = 32161542.0 \t loss_valid = 27295298.0 \n",
      "Model_8_5120 \t loss_train = 32044988.0 \t loss_valid = 27144888.0 \n",
      "Model_8_5130 \t loss_train = 32525946.0 \t loss_valid = 27645620.0 \n",
      "Model_8_5140 \t loss_train = 32879378.0 \t loss_valid = 27907362.0 \n",
      "Model_8_5150 \t loss_train = 32502436.0 \t loss_valid = 27578128.0 \n",
      "Model_8_5160 \t loss_train = 32411664.0 \t loss_valid = 27534266.0 \n",
      "Model_8_5170 \t loss_train = 32621088.0 \t loss_valid = 27684724.0 \n",
      "Model_8_5180 \t loss_train = 32880058.0 \t loss_valid = 27910056.0 \n",
      "Model_8_5190 \t loss_train = 32462808.0 \t loss_valid = 27595922.0 \n",
      "Model_8_5200 \t loss_train = 32558262.0 \t loss_valid = 27618550.0 \n",
      "Model_8_5210 \t loss_train = 32128298.0 \t loss_valid = 27310794.0 \n",
      "Model_8_5220 \t loss_train = 32700936.0 \t loss_valid = 27728412.0 \n",
      "Model_8_5230 \t loss_train = 32660026.0 \t loss_valid = 27727470.0 \n",
      "Model_8_5240 \t loss_train = 32273396.0 \t loss_valid = 27374870.0 \n",
      "Model_8_5250 \t loss_train = 32273702.0 \t loss_valid = 27451828.0 \n",
      "Model_8_5260 \t loss_train = 32379704.0 \t loss_valid = 27494374.0 \n",
      "Model_8_5270 \t loss_train = 32244482.0 \t loss_valid = 27329634.0 \n",
      "Model_8_5280 \t loss_train = 32451150.0 \t loss_valid = 27536302.0 \n",
      "Model_8_5290 \t loss_train = 32687406.0 \t loss_valid = 27775274.0 \n",
      "Model_8_5300 \t loss_train = 32850014.0 \t loss_valid = 27864270.0 \n",
      "Model_8_5310 \t loss_train = 32567288.0 \t loss_valid = 27609332.0 \n",
      "Model_8_5320 \t loss_train = 32236954.0 \t loss_valid = 27397436.0 \n",
      "Model_8_5330 \t loss_train = 32797794.0 \t loss_valid = 27755124.0 \n",
      "Model_8_5340 \t loss_train = 32543088.0 \t loss_valid = 27610476.0 \n",
      "Model_8_5350 \t loss_train = 32237400.0 \t loss_valid = 27399706.0 \n",
      "Model_8_5360 \t loss_train = 32406172.0 \t loss_valid = 27510682.0 \n",
      "Model_8_5370 \t loss_train = 32297204.0 \t loss_valid = 27367266.0 \n",
      "Model_8_5380 \t loss_train = 32457572.0 \t loss_valid = 27581418.0 \n",
      "Model_8_5390 \t loss_train = 32596482.0 \t loss_valid = 27619606.0 \n",
      "Model_8_5400 \t loss_train = 32345396.0 \t loss_valid = 27518814.0 \n",
      "Model_8_5410 \t loss_train = 32866404.0 \t loss_valid = 27869456.0 \n",
      "Model_8_5420 \t loss_train = 32981752.0 \t loss_valid = 28031470.0 \n",
      "Model_8_5430 \t loss_train = 32584160.0 \t loss_valid = 27719364.0 \n",
      "Model_8_5440 \t loss_train = 32966870.0 \t loss_valid = 27972090.0 \n",
      "Model_8_5450 \t loss_train = 32694958.0 \t loss_valid = 27756156.0 \n",
      "Model_8_5460 \t loss_train = 32415602.0 \t loss_valid = 27630838.0 \n",
      "Model_8_5470 \t loss_train = 32402204.0 \t loss_valid = 27413090.0 \n",
      "Model_8_5480 \t loss_train = 32231784.0 \t loss_valid = 27397094.0 \n",
      "Model_8_5490 \t loss_train = 33018776.0 \t loss_valid = 28037044.0 \n",
      "Model_8_5500 \t loss_train = 32340340.0 \t loss_valid = 27384930.0 \n",
      "Model_8_5510 \t loss_train = 32375646.0 \t loss_valid = 27503610.0 \n",
      "Model_8_5520 \t loss_train = 32786054.0 \t loss_valid = 27803104.0 \n",
      "Model_8_5530 \t loss_train = 32240354.0 \t loss_valid = 27334406.0 \n",
      "Model_8_5540 \t loss_train = 32488232.0 \t loss_valid = 27652700.0 \n",
      "Model_8_5550 \t loss_train = 33046406.0 \t loss_valid = 27970408.0 \n",
      "Model_8_5560 \t loss_train = 32162540.0 \t loss_valid = 27324972.0 \n",
      "Model_8_5570 \t loss_train = 31932024.0 \t loss_valid = 27115592.0 \n",
      "Model_8_5580 \t loss_train = 32564030.0 \t loss_valid = 27592056.0 \n",
      "Model_8_5590 \t loss_train = 32502892.0 \t loss_valid = 27623654.0 \n",
      "Model_8_5600 \t loss_train = 32351092.0 \t loss_valid = 27406228.0 \n",
      "Model_8_5610 \t loss_train = 32530514.0 \t loss_valid = 27580970.0 \n",
      "Model_8_5620 \t loss_train = 32262052.0 \t loss_valid = 27368286.0 \n",
      "Model_8_5630 \t loss_train = 32270282.0 \t loss_valid = 27339204.0 \n",
      "Model_8_5640 \t loss_train = 32738528.0 \t loss_valid = 27803622.0 \n",
      "Model_8_5650 \t loss_train = 32687524.0 \t loss_valid = 27769046.0 \n",
      "Model_8_5660 \t loss_train = 32507686.0 \t loss_valid = 27571504.0 \n",
      "Model_8_5670 \t loss_train = 32395076.0 \t loss_valid = 27423488.0 \n",
      "Model_8_5680 \t loss_train = 32541680.0 \t loss_valid = 27584092.0 \n",
      "Model_8_5690 \t loss_train = 32564830.0 \t loss_valid = 27604622.0 \n",
      "Model_8_5700 \t loss_train = 32688952.0 \t loss_valid = 27776538.0 \n",
      "Model_8_5710 \t loss_train = 32873846.0 \t loss_valid = 27804078.0 \n",
      "Model_8_5720 \t loss_train = 32824956.0 \t loss_valid = 27915574.0 \n",
      "Model_8_5730 \t loss_train = 33223414.0 \t loss_valid = 28209366.0 \n",
      "Model_8_5740 \t loss_train = 32752684.0 \t loss_valid = 27760836.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_8_5750 \t loss_train = 32674132.0 \t loss_valid = 27605718.0 \n",
      "Model_8_5760 \t loss_train = 32778832.0 \t loss_valid = 27768858.0 \n",
      "Model_8_5770 \t loss_train = 32342942.0 \t loss_valid = 27529188.0 \n",
      "Model_8_5780 \t loss_train = 32845288.0 \t loss_valid = 27873562.0 \n",
      "Model_8_5790 \t loss_train = 32829964.0 \t loss_valid = 27752640.0 \n",
      "Model_8_5800 \t loss_train = 32449470.0 \t loss_valid = 27495126.0 \n",
      "Model_8_5810 \t loss_train = 32856714.0 \t loss_valid = 27827472.0 \n",
      "Model_8_5820 \t loss_train = 32781430.0 \t loss_valid = 27852946.0 \n",
      "Model_8_5830 \t loss_train = 32338622.0 \t loss_valid = 27369652.0 \n",
      "Model_8_5840 \t loss_train = 32717576.0 \t loss_valid = 27711378.0 \n",
      "Model_8_5850 \t loss_train = 32815910.0 \t loss_valid = 27824418.0 \n",
      "Model_8_5860 \t loss_train = 32864752.0 \t loss_valid = 27808674.0 \n",
      "Model_8_5870 \t loss_train = 32424012.0 \t loss_valid = 27535274.0 \n",
      "Model_8_5880 \t loss_train = 32753520.0 \t loss_valid = 27714316.0 \n",
      "Model_8_5890 \t loss_train = 33073134.0 \t loss_valid = 28043036.0 \n",
      "Model_8_5900 \t loss_train = 32471856.0 \t loss_valid = 27526748.0 \n",
      "Model_8_5910 \t loss_train = 32303112.0 \t loss_valid = 27356292.0 \n",
      "Model_8_5920 \t loss_train = 32536840.0 \t loss_valid = 27554696.0 \n",
      "Model_8_5930 \t loss_train = 32638248.0 \t loss_valid = 27656284.0 \n",
      "Model_8_5940 \t loss_train = 33041742.0 \t loss_valid = 27910924.0 \n",
      "Model_8_5950 \t loss_train = 32540106.0 \t loss_valid = 27606200.0 \n",
      "Model_8_5960 \t loss_train = 32610428.0 \t loss_valid = 27640472.0 \n",
      "Model_8_5970 \t loss_train = 33104180.0 \t loss_valid = 27985992.0 \n",
      "Model_8_5980 \t loss_train = 32976264.0 \t loss_valid = 27963546.0 \n",
      "Model_8_5990 \t loss_train = 32873090.0 \t loss_valid = 27801806.0 \n",
      "Model_8_6000 \t loss_train = 32348570.0 \t loss_valid = 27404642.0 \n",
      "Model_8_6010 \t loss_train = 33545098.0 \t loss_valid = 28394296.0 \n",
      "Model_8_6020 \t loss_train = 33208546.0 \t loss_valid = 28080766.0 \n",
      "Model_8_6030 \t loss_train = 32326946.0 \t loss_valid = 27487238.0 \n",
      "Model_8_6040 \t loss_train = 33133002.0 \t loss_valid = 28032500.0 \n",
      "Model_8_6050 \t loss_train = 33371384.0 \t loss_valid = 28237922.0 \n",
      "Model_8_6060 \t loss_train = 32407944.0 \t loss_valid = 27486468.0 \n",
      "Model_8_6070 \t loss_train = 32755316.0 \t loss_valid = 27704484.0 \n",
      "Model_8_6080 \t loss_train = 32771192.0 \t loss_valid = 27788488.0 \n",
      "Model_8_6090 \t loss_train = 33221228.0 \t loss_valid = 28112232.0 \n",
      "Model_8_6100 \t loss_train = 32919286.0 \t loss_valid = 27861742.0 \n",
      "Model_8_6110 \t loss_train = 32931578.0 \t loss_valid = 27826088.0 \n",
      "Model_8_6120 \t loss_train = 32889660.0 \t loss_valid = 27877604.0 \n",
      "Model_8_6130 \t loss_train = 33230460.0 \t loss_valid = 28158806.0 \n",
      "Model_8_6140 \t loss_train = 32720324.0 \t loss_valid = 27696590.0 \n",
      "Model_8_6150 \t loss_train = 32422666.0 \t loss_valid = 27406762.0 \n",
      "Model_8_6160 \t loss_train = 33091274.0 \t loss_valid = 27940450.0 \n",
      "Model_8_6170 \t loss_train = 32688592.0 \t loss_valid = 27746490.0 \n",
      "Model_8_6180 \t loss_train = 32360636.0 \t loss_valid = 27402490.0 \n",
      "Model_8_6190 \t loss_train = 32825928.0 \t loss_valid = 27800768.0 \n",
      "Model_8_6200 \t loss_train = 33793104.0 \t loss_valid = 28561170.0 \n",
      "Model_8_6210 \t loss_train = 32892710.0 \t loss_valid = 27890928.0 \n",
      "Model_8_6220 \t loss_train = 32356996.0 \t loss_valid = 27313456.0 \n",
      "Model_8_6230 \t loss_train = 32733156.0 \t loss_valid = 27695528.0 \n",
      "Model_8_6240 \t loss_train = 33438548.0 \t loss_valid = 28293212.0 \n",
      "Model_8_6250 \t loss_train = 32818842.0 \t loss_valid = 27711226.0 \n",
      "Model_8_6260 \t loss_train = 32370890.0 \t loss_valid = 27401386.0 \n",
      "Model_8_6270 \t loss_train = 32848960.0 \t loss_valid = 27797946.0 \n",
      "Model_8_6280 \t loss_train = 32765146.0 \t loss_valid = 27687152.0 \n",
      "Model_8_6290 \t loss_train = 32314336.0 \t loss_valid = 27395896.0 \n",
      "Model_8_6300 \t loss_train = 33031388.0 \t loss_valid = 27931230.0 \n",
      "Model_8_6310 \t loss_train = 32680160.0 \t loss_valid = 27642308.0 \n",
      "Model_8_6320 \t loss_train = 33009562.0 \t loss_valid = 27869550.0 \n",
      "Model_8_6330 \t loss_train = 32859660.0 \t loss_valid = 27817504.0 \n",
      "Model_8_6340 \t loss_train = 33129542.0 \t loss_valid = 28011856.0 \n",
      "Model_8_6350 \t loss_train = 32625440.0 \t loss_valid = 27619492.0 \n",
      "Model_8_6360 \t loss_train = 32606146.0 \t loss_valid = 27616546.0 \n",
      "Model_8_6370 \t loss_train = 33239446.0 \t loss_valid = 28088898.0 \n",
      "Model_8_6380 \t loss_train = 32864672.0 \t loss_valid = 27773314.0 \n",
      "Model_8_6390 \t loss_train = 32656162.0 \t loss_valid = 27657438.0 \n",
      "Model_8_6400 \t loss_train = 33279188.0 \t loss_valid = 28162760.0 \n",
      "Model_8_6410 \t loss_train = 33197024.0 \t loss_valid = 28108586.0 \n",
      "Model_8_6420 \t loss_train = 32835362.0 \t loss_valid = 27794112.0 \n",
      "Model_8_6430 \t loss_train = 32424364.0 \t loss_valid = 27421168.0 \n",
      "Model_8_6440 \t loss_train = 33237904.0 \t loss_valid = 28058846.0 \n",
      "Model_8_6450 \t loss_train = 33314312.0 \t loss_valid = 28150936.0 \n",
      "Model_8_6460 \t loss_train = 32839882.0 \t loss_valid = 27784678.0 \n",
      "Model_8_6470 \t loss_train = 33012774.0 \t loss_valid = 27915586.0 \n",
      "Model_8_6480 \t loss_train = 32854552.0 \t loss_valid = 27785800.0 \n",
      "Model_8_6490 \t loss_train = 32730822.0 \t loss_valid = 27747508.0 \n",
      "Model_8_6500 \t loss_train = 33192676.0 \t loss_valid = 28019838.0 \n",
      "Model_8_6510 \t loss_train = 32763274.0 \t loss_valid = 27712162.0 \n",
      "Model_8_6520 \t loss_train = 32853808.0 \t loss_valid = 27779824.0 \n",
      "Model_8_6530 \t loss_train = 32905610.0 \t loss_valid = 27825938.0 \n",
      "Model_8_6540 \t loss_train = 33069170.0 \t loss_valid = 27898716.0 \n",
      "Model_8_6550 \t loss_train = 32892332.0 \t loss_valid = 27778128.0 \n",
      "Model_8_6560 \t loss_train = 33328090.0 \t loss_valid = 28158896.0 \n",
      "Model_8_6570 \t loss_train = 33623284.0 \t loss_valid = 28396850.0 \n",
      "Model_8_6580 \t loss_train = 33364452.0 \t loss_valid = 28165132.0 \n",
      "Model_8_6590 \t loss_train = 32771540.0 \t loss_valid = 27734664.0 \n",
      "Model_8_6600 \t loss_train = 33061032.0 \t loss_valid = 27887244.0 \n",
      "Model_8_6610 \t loss_train = 33216468.0 \t loss_valid = 28004054.0 \n",
      "Model_8_6620 \t loss_train = 32922962.0 \t loss_valid = 27809248.0 \n",
      "Model_8_6630 \t loss_train = 33283852.0 \t loss_valid = 28054156.0 \n",
      "Model_8_6640 \t loss_train = 33221690.0 \t loss_valid = 28028148.0 \n",
      "Model_8_6650 \t loss_train = 33475512.0 \t loss_valid = 28250996.0 \n",
      "Model_8_6660 \t loss_train = 32772844.0 \t loss_valid = 27674052.0 \n",
      "Model_8_6670 \t loss_train = 33152406.0 \t loss_valid = 28059446.0 \n",
      "Model_8_6680 \t loss_train = 33536504.0 \t loss_valid = 28251704.0 \n",
      "Model_8_6690 \t loss_train = 32941916.0 \t loss_valid = 27850086.0 \n",
      "Model_8_6700 \t loss_train = 32959892.0 \t loss_valid = 27870618.0 \n",
      "Model_8_6710 \t loss_train = 33226094.0 \t loss_valid = 28091682.0 \n",
      "Model_8_6720 \t loss_train = 33353698.0 \t loss_valid = 28162036.0 \n",
      "Model_8_6730 \t loss_train = 32817462.0 \t loss_valid = 27763610.0 \n",
      "Model_8_6740 \t loss_train = 32913786.0 \t loss_valid = 27888330.0 \n",
      "Model_8_6750 \t loss_train = 32986362.0 \t loss_valid = 27815058.0 \n",
      "Model_8_6760 \t loss_train = 32806404.0 \t loss_valid = 27772584.0 \n",
      "Model_8_6770 \t loss_train = 33492124.0 \t loss_valid = 28278058.0 \n",
      "Model_8_6780 \t loss_train = 33091444.0 \t loss_valid = 27966556.0 \n",
      "Model_8_6790 \t loss_train = 33290168.0 \t loss_valid = 28189924.0 \n",
      "Model_8_6800 \t loss_train = 33531914.0 \t loss_valid = 28297500.0 \n",
      "Model_8_6810 \t loss_train = 33240778.0 \t loss_valid = 28087416.0 \n",
      "Model_8_6820 \t loss_train = 33497910.0 \t loss_valid = 28353198.0 \n",
      "Model_8_6830 \t loss_train = 33020208.0 \t loss_valid = 27859934.0 \n",
      "Model_8_6840 \t loss_train = 33250142.0 \t loss_valid = 28084234.0 \n",
      "Model_8_6850 \t loss_train = 33515658.0 \t loss_valid = 28336558.0 \n",
      "Model_8_6860 \t loss_train = 33434732.0 \t loss_valid = 28286890.0 \n",
      "Model_8_6870 \t loss_train = 33139256.0 \t loss_valid = 27983540.0 \n",
      "Model_8_6880 \t loss_train = 33282726.0 \t loss_valid = 28138882.0 \n",
      "Model_8_6890 \t loss_train = 33343388.0 \t loss_valid = 28136596.0 \n",
      "Model_8_6900 \t loss_train = 33736696.0 \t loss_valid = 28504146.0 \n",
      "Model_8_6910 \t loss_train = 33939840.0 \t loss_valid = 28703150.0 \n",
      "Model_8_6920 \t loss_train = 32937710.0 \t loss_valid = 27831382.0 \n",
      "Model_8_6930 \t loss_train = 32980454.0 \t loss_valid = 27853556.0 \n",
      "Model_8_6940 \t loss_train = 33710128.0 \t loss_valid = 28440648.0 \n",
      "Model_8_6950 \t loss_train = 33101278.0 \t loss_valid = 27961954.0 \n",
      "Model_8_6960 \t loss_train = 33041482.0 \t loss_valid = 27801328.0 \n",
      "Model_8_6970 \t loss_train = 33522156.0 \t loss_valid = 28358480.0 \n",
      "Model_8_6980 \t loss_train = 33593728.0 \t loss_valid = 28453856.0 \n",
      "Model_8_6990 \t loss_train = 33187070.0 \t loss_valid = 27953524.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_8_7000 \t loss_train = 32949060.0 \t loss_valid = 27853218.0 \n",
      "Model_8_7010 \t loss_train = 33430784.0 \t loss_valid = 28179908.0 \n",
      "Model_8_7020 \t loss_train = 33606036.0 \t loss_valid = 28413022.0 \n",
      "Model_8_7030 \t loss_train = 33652468.0 \t loss_valid = 28373178.0 \n",
      "Model_8_7040 \t loss_train = 32867402.0 \t loss_valid = 27700670.0 \n",
      "Model_8_7050 \t loss_train = 32860988.0 \t loss_valid = 27683016.0 \n",
      "Model_8_7060 \t loss_train = 33402786.0 \t loss_valid = 28187850.0 \n",
      "Model_8_7070 \t loss_train = 33232974.0 \t loss_valid = 28018972.0 \n",
      "Model_8_7080 \t loss_train = 33305476.0 \t loss_valid = 28081610.0 \n",
      "Model_8_7090 \t loss_train = 33263432.0 \t loss_valid = 28029948.0 \n",
      "Model_8_7100 \t loss_train = 33204928.0 \t loss_valid = 28044124.0 \n",
      "Model_8_7110 \t loss_train = 33557572.0 \t loss_valid = 28227196.0 \n",
      "Model_8_7120 \t loss_train = 33610272.0 \t loss_valid = 28341542.0 \n",
      "Model_8_7130 \t loss_train = 33668348.0 \t loss_valid = 28362884.0 \n",
      "Model_8_7140 \t loss_train = 33595384.0 \t loss_valid = 28322066.0 \n",
      "Model_8_7150 \t loss_train = 33230416.0 \t loss_valid = 27945844.0 \n",
      "Model_8_7160 \t loss_train = 33588552.0 \t loss_valid = 28413984.0 \n",
      "Model_8_7170 \t loss_train = 33501424.0 \t loss_valid = 28252442.0 \n",
      "Model_8_7180 \t loss_train = 33541788.0 \t loss_valid = 28297668.0 \n",
      "Model_8_7190 \t loss_train = 33419702.0 \t loss_valid = 28181396.0 \n",
      "Model_8_7200 \t loss_train = 33768648.0 \t loss_valid = 28353264.0 \n",
      "Model_8_7210 \t loss_train = 33579328.0 \t loss_valid = 28388504.0 \n",
      "Model_8_7220 \t loss_train = 33535264.0 \t loss_valid = 28208448.0 \n",
      "Model_8_7230 \t loss_train = 33382000.0 \t loss_valid = 28143714.0 \n",
      "Model_8_7240 \t loss_train = 33369300.0 \t loss_valid = 28174854.0 \n",
      "Model_8_7250 \t loss_train = 33550532.0 \t loss_valid = 28274274.0 \n",
      "Model_8_7260 \t loss_train = 33588176.0 \t loss_valid = 28316166.0 \n",
      "Model_8_7270 \t loss_train = 33555664.0 \t loss_valid = 28309270.0 \n",
      "Model_8_7280 \t loss_train = 33462016.0 \t loss_valid = 28226234.0 \n",
      "Model_8_7290 \t loss_train = 33879928.0 \t loss_valid = 28594752.0 \n",
      "Model_8_7300 \t loss_train = 33491176.0 \t loss_valid = 28203410.0 \n",
      "Model_8_7310 \t loss_train = 33229682.0 \t loss_valid = 28070600.0 \n",
      "Model_8_7320 \t loss_train = 33599768.0 \t loss_valid = 28253210.0 \n",
      "Model_8_7330 \t loss_train = 33476896.0 \t loss_valid = 28216692.0 \n",
      "Model_8_7340 \t loss_train = 33009042.0 \t loss_valid = 27846750.0 \n",
      "Model_8_7350 \t loss_train = 33714196.0 \t loss_valid = 28410598.0 \n",
      "Model_8_7360 \t loss_train = 33685912.0 \t loss_valid = 28432094.0 \n",
      "Model_8_7370 \t loss_train = 33867704.0 \t loss_valid = 28471758.0 \n",
      "Model_8_7380 \t loss_train = 33596932.0 \t loss_valid = 28311602.0 \n",
      "Model_8_7390 \t loss_train = 33023326.0 \t loss_valid = 27860898.0 \n",
      "Model_8_7400 \t loss_train = 33799112.0 \t loss_valid = 28361904.0 \n",
      "Model_8_7410 \t loss_train = 33325804.0 \t loss_valid = 28077716.0 \n",
      "Model_8_7420 \t loss_train = 34010376.0 \t loss_valid = 28586000.0 \n",
      "Model_8_7430 \t loss_train = 33621744.0 \t loss_valid = 28237458.0 \n",
      "Model_8_7440 \t loss_train = 32953184.0 \t loss_valid = 27781350.0 \n",
      "Model_8_7450 \t loss_train = 34145648.0 \t loss_valid = 28734910.0 \n",
      "Model_8_7460 \t loss_train = 33408936.0 \t loss_valid = 28169778.0 \n",
      "Model_8_7470 \t loss_train = 33849812.0 \t loss_valid = 28572650.0 \n",
      "Model_8_7480 \t loss_train = 33800656.0 \t loss_valid = 28545030.0 \n",
      "Model_8_7490 \t loss_train = 33579044.0 \t loss_valid = 28200264.0 \n",
      "Model_8_7500 \t loss_train = 33604248.0 \t loss_valid = 28363232.0 \n",
      "Model_8_7510 \t loss_train = 33589392.0 \t loss_valid = 28265756.0 \n",
      "Model_8_7520 \t loss_train = 33898836.0 \t loss_valid = 28549496.0 \n",
      "Model_8_7530 \t loss_train = 33258274.0 \t loss_valid = 28065704.0 \n",
      "Model_8_7540 \t loss_train = 33452754.0 \t loss_valid = 28257056.0 \n",
      "Model_8_7550 \t loss_train = 33826916.0 \t loss_valid = 28506172.0 \n",
      "Model_8_7560 \t loss_train = 32776018.0 \t loss_valid = 27675630.0 \n",
      "Model_8_7570 \t loss_train = 34203036.0 \t loss_valid = 28753768.0 \n",
      "Model_8_7580 \t loss_train = 33387308.0 \t loss_valid = 28114672.0 \n",
      "Model_8_7590 \t loss_train = 33208742.0 \t loss_valid = 27969308.0 \n",
      "Model_8_7600 \t loss_train = 33984832.0 \t loss_valid = 28650764.0 \n",
      "Model_8_7610 \t loss_train = 33498050.0 \t loss_valid = 28206294.0 \n",
      "Model_8_7620 \t loss_train = 33424864.0 \t loss_valid = 28211602.0 \n",
      "Model_8_7630 \t loss_train = 33864772.0 \t loss_valid = 28531662.0 \n",
      "Model_8_7640 \t loss_train = 34094056.0 \t loss_valid = 28723750.0 \n",
      "Model_8_7650 \t loss_train = 33740436.0 \t loss_valid = 28447804.0 \n",
      "Model_8_7660 \t loss_train = 34169840.0 \t loss_valid = 28806660.0 \n",
      "Model_8_7670 \t loss_train = 33468468.0 \t loss_valid = 28199222.0 \n",
      "Model_8_7680 \t loss_train = 33764392.0 \t loss_valid = 28419976.0 \n",
      "Model_8_7690 \t loss_train = 33899684.0 \t loss_valid = 28589378.0 \n",
      "Model_8_7700 \t loss_train = 33676604.0 \t loss_valid = 28384562.0 \n",
      "Model_8_7710 \t loss_train = 33316994.0 \t loss_valid = 28106980.0 \n",
      "Model_8_7720 \t loss_train = 34064988.0 \t loss_valid = 28678978.0 \n",
      "Model_8_7730 \t loss_train = 33615400.0 \t loss_valid = 28322104.0 \n",
      "Model_8_7740 \t loss_train = 33745760.0 \t loss_valid = 28368132.0 \n",
      "Model_8_7750 \t loss_train = 33394390.0 \t loss_valid = 28171454.0 \n",
      "Model_8_7760 \t loss_train = 33843360.0 \t loss_valid = 28415498.0 \n",
      "Model_8_7770 \t loss_train = 33991340.0 \t loss_valid = 28620800.0 \n",
      "Model_8_7780 \t loss_train = 33602300.0 \t loss_valid = 28302190.0 \n",
      "Model_8_7790 \t loss_train = 33708640.0 \t loss_valid = 28377400.0 \n",
      "Model_8_7800 \t loss_train = 33793128.0 \t loss_valid = 28483710.0 \n",
      "Model_8_7810 \t loss_train = 34094400.0 \t loss_valid = 28772080.0 \n",
      "Model_8_7820 \t loss_train = 33632964.0 \t loss_valid = 28308092.0 \n",
      "Model_8_7830 \t loss_train = 33726596.0 \t loss_valid = 28446650.0 \n",
      "Model_8_7840 \t loss_train = 33839408.0 \t loss_valid = 28489250.0 \n",
      "Model_8_7850 \t loss_train = 33249584.0 \t loss_valid = 28074436.0 \n",
      "Model_8_7860 \t loss_train = 34112696.0 \t loss_valid = 28696788.0 \n",
      "Model_8_7870 \t loss_train = 33577424.0 \t loss_valid = 28310048.0 \n",
      "Model_8_7880 \t loss_train = 33901528.0 \t loss_valid = 28548482.0 \n",
      "Model_8_7890 \t loss_train = 34252392.0 \t loss_valid = 28859550.0 \n",
      "Model_8_7900 \t loss_train = 33373208.0 \t loss_valid = 28076488.0 \n",
      "Model_8_7910 \t loss_train = 34104980.0 \t loss_valid = 28686204.0 \n",
      "Model_8_7920 \t loss_train = 34179920.0 \t loss_valid = 28772494.0 \n",
      "Model_8_7930 \t loss_train = 34004872.0 \t loss_valid = 28665846.0 \n",
      "Model_8_7940 \t loss_train = 33656852.0 \t loss_valid = 28365748.0 \n",
      "Model_8_7950 \t loss_train = 33700460.0 \t loss_valid = 28355792.0 \n",
      "Model_8_7960 \t loss_train = 33937384.0 \t loss_valid = 28613726.0 \n",
      "Model_8_7970 \t loss_train = 33751744.0 \t loss_valid = 28409322.0 \n",
      "Model_8_7980 \t loss_train = 34723668.0 \t loss_valid = 29268414.0 \n",
      "Model_8_7990 \t loss_train = 33613068.0 \t loss_valid = 28334302.0 \n",
      "Model_8_8000 \t loss_train = 33904924.0 \t loss_valid = 28527622.0 \n",
      "Model_8_8010 \t loss_train = 33763076.0 \t loss_valid = 28449412.0 \n",
      "Model_8_8020 \t loss_train = 33579648.0 \t loss_valid = 28239512.0 \n",
      "Model_8_8030 \t loss_train = 34136768.0 \t loss_valid = 28754616.0 \n",
      "Model_8_8040 \t loss_train = 33649436.0 \t loss_valid = 28319434.0 \n",
      "Model_8_8050 \t loss_train = 33667580.0 \t loss_valid = 28301110.0 \n",
      "Model_8_8060 \t loss_train = 33944836.0 \t loss_valid = 28580520.0 \n",
      "Model_8_8070 \t loss_train = 33970444.0 \t loss_valid = 28602874.0 \n",
      "Model_8_8080 \t loss_train = 33544434.0 \t loss_valid = 28285452.0 \n",
      "Model_8_8090 \t loss_train = 33877704.0 \t loss_valid = 28587972.0 \n",
      "Model_8_8100 \t loss_train = 33661872.0 \t loss_valid = 28334482.0 \n",
      "Model_8_8110 \t loss_train = 33721912.0 \t loss_valid = 28425336.0 \n",
      "Model_8_8120 \t loss_train = 34052712.0 \t loss_valid = 28684856.0 \n",
      "Model_8_8130 \t loss_train = 33698644.0 \t loss_valid = 28404912.0 \n",
      "Model_8_8140 \t loss_train = 33942704.0 \t loss_valid = 28579442.0 \n",
      "Model_8_8150 \t loss_train = 33746748.0 \t loss_valid = 28417744.0 \n",
      "Model_8_8160 \t loss_train = 33961408.0 \t loss_valid = 28589736.0 \n",
      "Model_8_8170 \t loss_train = 34298852.0 \t loss_valid = 28883064.0 \n",
      "Model_8_8180 \t loss_train = 33374716.0 \t loss_valid = 28098120.0 \n",
      "Model_8_8190 \t loss_train = 34378380.0 \t loss_valid = 28939700.0 \n",
      "Model_8_8200 \t loss_train = 33403876.0 \t loss_valid = 28138672.0 \n",
      "Model_8_8210 \t loss_train = 34019408.0 \t loss_valid = 28669662.0 \n",
      "Model_8_8220 \t loss_train = 33740276.0 \t loss_valid = 28510746.0 \n",
      "Model_8_8230 \t loss_train = 33619680.0 \t loss_valid = 28303888.0 \n",
      "Model_8_8240 \t loss_train = 34377588.0 \t loss_valid = 28956676.0 \n",
      "Model_8_8250 \t loss_train = 33504338.0 \t loss_valid = 28254334.0 \n",
      "Model_8_8260 \t loss_train = 34431752.0 \t loss_valid = 28955862.0 \n",
      "Model_8_8270 \t loss_train = 34080520.0 \t loss_valid = 28711118.0 \n",
      "Model_8_8280 \t loss_train = 34017132.0 \t loss_valid = 28593004.0 \n",
      "Model_8_8290 \t loss_train = 34274340.0 \t loss_valid = 28877814.0 \n",
      "Model_8_8300 \t loss_train = 33900356.0 \t loss_valid = 28601312.0 \n",
      "Model_8_8310 \t loss_train = 33862016.0 \t loss_valid = 28500452.0 \n",
      "Model_8_8320 \t loss_train = 33915532.0 \t loss_valid = 28594820.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_8_8330 \t loss_train = 33966868.0 \t loss_valid = 28592324.0 \n",
      "Model_8_8340 \t loss_train = 33771904.0 \t loss_valid = 28449344.0 \n",
      "Model_8_8350 \t loss_train = 34435560.0 \t loss_valid = 28986608.0 \n",
      "Model_8_8360 \t loss_train = 33892336.0 \t loss_valid = 28527086.0 \n",
      "Model_8_8370 \t loss_train = 33902124.0 \t loss_valid = 28564022.0 \n",
      "Model_8_8380 \t loss_train = 34121500.0 \t loss_valid = 28752878.0 \n",
      "Model_8_8390 \t loss_train = 33539884.0 \t loss_valid = 28270302.0 \n",
      "Model_8_8400 \t loss_train = 34101600.0 \t loss_valid = 28737738.0 \n",
      "Model_8_8410 \t loss_train = 33896140.0 \t loss_valid = 28541130.0 \n",
      "Model_8_8420 \t loss_train = 34089028.0 \t loss_valid = 28710900.0 \n",
      "Model_8_8430 \t loss_train = 34255220.0 \t loss_valid = 28786618.0 \n",
      "Model_8_8440 \t loss_train = 33775152.0 \t loss_valid = 28460848.0 \n",
      "Model_8_8450 \t loss_train = 34115360.0 \t loss_valid = 28717126.0 \n",
      "Model_8_8460 \t loss_train = 33739708.0 \t loss_valid = 28442308.0 \n",
      "Model_8_8470 \t loss_train = 33852916.0 \t loss_valid = 28516010.0 \n",
      "Model_8_8480 \t loss_train = 34435744.0 \t loss_valid = 28969690.0 \n",
      "Model_8_8490 \t loss_train = 33936348.0 \t loss_valid = 28592380.0 \n",
      "Model_8_8500 \t loss_train = 34065576.0 \t loss_valid = 28654684.0 \n",
      "Model_8_8510 \t loss_train = 33899424.0 \t loss_valid = 28532698.0 \n",
      "Model_8_8520 \t loss_train = 34473220.0 \t loss_valid = 29016746.0 \n",
      "Model_8_8530 \t loss_train = 33233370.0 \t loss_valid = 28020816.0 \n",
      "Model_8_8540 \t loss_train = 34783268.0 \t loss_valid = 29198144.0 \n",
      "Model_8_8550 \t loss_train = 33992984.0 \t loss_valid = 28613862.0 \n",
      "Model_8_8560 \t loss_train = 33908384.0 \t loss_valid = 28540388.0 \n",
      "Model_8_8570 \t loss_train = 34653996.0 \t loss_valid = 29114614.0 \n",
      "Model_8_8580 \t loss_train = 33592484.0 \t loss_valid = 28264406.0 \n",
      "Model_8_8590 \t loss_train = 34127808.0 \t loss_valid = 28747688.0 \n",
      "Model_8_8600 \t loss_train = 34058560.0 \t loss_valid = 28625834.0 \n",
      "Model_8_8610 \t loss_train = 34377424.0 \t loss_valid = 28886762.0 \n",
      "Model_8_8620 \t loss_train = 34002508.0 \t loss_valid = 28560770.0 \n",
      "Model_8_8630 \t loss_train = 33614084.0 \t loss_valid = 28330702.0 \n",
      "Model_8_8640 \t loss_train = 34779172.0 \t loss_valid = 29215374.0 \n",
      "Model_8_8650 \t loss_train = 33925864.0 \t loss_valid = 28540110.0 \n",
      "Model_8_8660 \t loss_train = 34513460.0 \t loss_valid = 29067334.0 \n",
      "Model_8_8670 \t loss_train = 34110420.0 \t loss_valid = 28733490.0 \n",
      "Model_8_8680 \t loss_train = 34202448.0 \t loss_valid = 28799056.0 \n",
      "Model_8_8690 \t loss_train = 33866244.0 \t loss_valid = 28524224.0 \n",
      "Model_8_8700 \t loss_train = 34187552.0 \t loss_valid = 28768376.0 \n",
      "Model_8_8710 \t loss_train = 34162168.0 \t loss_valid = 28656340.0 \n",
      "Model_8_8720 \t loss_train = 34092032.0 \t loss_valid = 28688734.0 \n",
      "Model_8_8730 \t loss_train = 33948056.0 \t loss_valid = 28585514.0 \n",
      "Model_8_8740 \t loss_train = 34573024.0 \t loss_valid = 29113552.0 \n",
      "Model_8_8750 \t loss_train = 34086376.0 \t loss_valid = 28678014.0 \n",
      "Model_8_8760 \t loss_train = 34086480.0 \t loss_valid = 28743724.0 \n",
      "Model_8_8770 \t loss_train = 33914144.0 \t loss_valid = 28503324.0 \n",
      "Model_8_8780 \t loss_train = 34505244.0 \t loss_valid = 29017394.0 \n",
      "Model_8_8790 \t loss_train = 34087020.0 \t loss_valid = 28651526.0 \n",
      "Model_8_8800 \t loss_train = 34507992.0 \t loss_valid = 28935828.0 \n",
      "Model_8_8810 \t loss_train = 33851832.0 \t loss_valid = 28494626.0 \n",
      "Model_8_8820 \t loss_train = 34445252.0 \t loss_valid = 28933508.0 \n",
      "Model_8_8830 \t loss_train = 33948116.0 \t loss_valid = 28535420.0 \n",
      "Model_8_8840 \t loss_train = 34250888.0 \t loss_valid = 28798648.0 \n",
      "Model_8_8850 \t loss_train = 33949332.0 \t loss_valid = 28545586.0 \n",
      "Model_8_8860 \t loss_train = 34655988.0 \t loss_valid = 29087552.0 \n",
      "Model_8_8870 \t loss_train = 34389696.0 \t loss_valid = 28872324.0 \n",
      "Model_8_8880 \t loss_train = 34292236.0 \t loss_valid = 28812020.0 \n",
      "Model_8_8890 \t loss_train = 33959584.0 \t loss_valid = 28564514.0 \n",
      "Model_8_8900 \t loss_train = 34650852.0 \t loss_valid = 29124434.0 \n",
      "Model_8_8910 \t loss_train = 34109124.0 \t loss_valid = 28664124.0 \n",
      "Model_8_8920 \t loss_train = 34701596.0 \t loss_valid = 29120076.0 \n",
      "Model_8_8930 \t loss_train = 33811080.0 \t loss_valid = 28386184.0 \n",
      "Model_8_8940 \t loss_train = 34342576.0 \t loss_valid = 28793024.0 \n",
      "Model_8_8950 \t loss_train = 34530020.0 \t loss_valid = 28969874.0 \n",
      "Model_8_8960 \t loss_train = 34472452.0 \t loss_valid = 28911508.0 \n",
      "Model_8_8970 \t loss_train = 34024620.0 \t loss_valid = 28588462.0 \n",
      "Model_8_8980 \t loss_train = 34950964.0 \t loss_valid = 29268714.0 \n",
      "Model_8_8990 \t loss_train = 34466592.0 \t loss_valid = 28962782.0 \n",
      "Model_8_9000 \t loss_train = 34544440.0 \t loss_valid = 28995404.0 \n",
      "Model_8_9010 \t loss_train = 34078800.0 \t loss_valid = 28646886.0 \n",
      "Model_8_9020 \t loss_train = 34857536.0 \t loss_valid = 29264232.0 \n",
      "Model_8_9030 \t loss_train = 34340924.0 \t loss_valid = 28795524.0 \n",
      "Model_8_9040 \t loss_train = 34548284.0 \t loss_valid = 29046938.0 \n",
      "Model_8_9050 \t loss_train = 34170264.0 \t loss_valid = 28693618.0 \n",
      "Model_8_9060 \t loss_train = 34243856.0 \t loss_valid = 28753632.0 \n",
      "Model_8_9070 \t loss_train = 34388772.0 \t loss_valid = 28914106.0 \n",
      "Model_8_9080 \t loss_train = 34943876.0 \t loss_valid = 29295464.0 \n",
      "Model_8_9090 \t loss_train = 34576640.0 \t loss_valid = 29070016.0 \n",
      "Model_8_9100 \t loss_train = 34811464.0 \t loss_valid = 29252488.0 \n",
      "Model_8_9110 \t loss_train = 34226564.0 \t loss_valid = 28688598.0 \n",
      "Model_8_9120 \t loss_train = 35065820.0 \t loss_valid = 29409356.0 \n",
      "Model_8_9130 \t loss_train = 34253696.0 \t loss_valid = 28729814.0 \n",
      "Model_8_9140 \t loss_train = 34362856.0 \t loss_valid = 28865194.0 \n",
      "Model_8_9150 \t loss_train = 33951920.0 \t loss_valid = 28580674.0 \n",
      "Model_8_9160 \t loss_train = 34503608.0 \t loss_valid = 28934994.0 \n",
      "Model_8_9170 \t loss_train = 34760540.0 \t loss_valid = 29279684.0 \n",
      "Model_8_9180 \t loss_train = 33992952.0 \t loss_valid = 28512042.0 \n",
      "Model_8_9190 \t loss_train = 34871068.0 \t loss_valid = 29361364.0 \n",
      "Model_8_9200 \t loss_train = 34009964.0 \t loss_valid = 28521598.0 \n",
      "Model_8_9210 \t loss_train = 34651768.0 \t loss_valid = 29129178.0 \n",
      "Model_8_9220 \t loss_train = 34798508.0 \t loss_valid = 29218736.0 \n",
      "Model_8_9230 \t loss_train = 34072972.0 \t loss_valid = 28669276.0 \n",
      "Model_8_9240 \t loss_train = 34582984.0 \t loss_valid = 29076182.0 \n",
      "Model_8_9250 \t loss_train = 34354544.0 \t loss_valid = 28872066.0 \n",
      "Model_8_9260 \t loss_train = 34762540.0 \t loss_valid = 29168766.0 \n",
      "Model_8_9270 \t loss_train = 34513400.0 \t loss_valid = 29011190.0 \n",
      "Model_8_9280 \t loss_train = 34110916.0 \t loss_valid = 28568184.0 \n",
      "Model_8_9290 \t loss_train = 34777240.0 \t loss_valid = 29208090.0 \n",
      "Model_8_9300 \t loss_train = 34653784.0 \t loss_valid = 29097898.0 \n",
      "Model_8_9310 \t loss_train = 34941612.0 \t loss_valid = 29330160.0 \n",
      "Model_8_9320 \t loss_train = 34397768.0 \t loss_valid = 28886484.0 \n",
      "Model_8_9330 \t loss_train = 34626156.0 \t loss_valid = 29078734.0 \n",
      "Model_8_9340 \t loss_train = 34289584.0 \t loss_valid = 28870700.0 \n",
      "Model_8_9350 \t loss_train = 34329820.0 \t loss_valid = 28786526.0 \n",
      "Model_8_9360 \t loss_train = 35001004.0 \t loss_valid = 29366168.0 \n",
      "Model_8_9370 \t loss_train = 34338164.0 \t loss_valid = 28841586.0 \n",
      "Model_8_9380 \t loss_train = 34622292.0 \t loss_valid = 29049296.0 \n",
      "Model_8_9390 \t loss_train = 34593660.0 \t loss_valid = 28977532.0 \n",
      "Model_8_9400 \t loss_train = 34537276.0 \t loss_valid = 28990378.0 \n",
      "Model_8_9410 \t loss_train = 34241248.0 \t loss_valid = 28736762.0 \n",
      "Model_8_9420 \t loss_train = 34976716.0 \t loss_valid = 29370982.0 \n",
      "Model_8_9430 \t loss_train = 34246784.0 \t loss_valid = 28754910.0 \n",
      "Model_8_9440 \t loss_train = 34699616.0 \t loss_valid = 29142524.0 \n",
      "Model_8_9450 \t loss_train = 34543460.0 \t loss_valid = 28973414.0 \n",
      "Model_8_9460 \t loss_train = 34306896.0 \t loss_valid = 28712964.0 \n",
      "Model_8_9470 \t loss_train = 34556020.0 \t loss_valid = 28983960.0 \n",
      "Model_8_9480 \t loss_train = 34583024.0 \t loss_valid = 28982778.0 \n",
      "Model_8_9490 \t loss_train = 34628240.0 \t loss_valid = 29071440.0 \n",
      "Model_8_9500 \t loss_train = 34780056.0 \t loss_valid = 29173810.0 \n",
      "Model_8_9510 \t loss_train = 34993820.0 \t loss_valid = 29445430.0 \n",
      "Model_8_9520 \t loss_train = 34618924.0 \t loss_valid = 28985938.0 \n",
      "Model_8_9530 \t loss_train = 34878236.0 \t loss_valid = 29311074.0 \n",
      "Model_8_9540 \t loss_train = 34598560.0 \t loss_valid = 29078812.0 \n",
      "Model_8_9550 \t loss_train = 34560824.0 \t loss_valid = 28999984.0 \n",
      "Model_8_9560 \t loss_train = 34961244.0 \t loss_valid = 29348658.0 \n",
      "Model_8_9570 \t loss_train = 35107680.0 \t loss_valid = 29434678.0 \n",
      "Model_8_9580 \t loss_train = 34899200.0 \t loss_valid = 29286992.0 \n",
      "Model_8_9590 \t loss_train = 34785584.0 \t loss_valid = 29185652.0 \n",
      "Model_8_9600 \t loss_train = 35115800.0 \t loss_valid = 29466734.0 \n",
      "Model_8_9610 \t loss_train = 34668944.0 \t loss_valid = 29095234.0 \n",
      "Model_8_9620 \t loss_train = 34761788.0 \t loss_valid = 29202122.0 \n",
      "Model_8_9630 \t loss_train = 34847720.0 \t loss_valid = 29262792.0 \n",
      "Model_8_9640 \t loss_train = 34481016.0 \t loss_valid = 28974080.0 \n",
      "Model_8_9650 \t loss_train = 34992600.0 \t loss_valid = 29399246.0 \n",
      "Model_8_9660 \t loss_train = 35200852.0 \t loss_valid = 29489342.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_8_9670 \t loss_train = 34824848.0 \t loss_valid = 29265098.0 \n",
      "Model_8_9680 \t loss_train = 34857644.0 \t loss_valid = 29275964.0 \n",
      "Model_8_9690 \t loss_train = 34780596.0 \t loss_valid = 29200908.0 \n",
      "Model_8_9700 \t loss_train = 34994228.0 \t loss_valid = 29372890.0 \n",
      "Model_8_9710 \t loss_train = 34751456.0 \t loss_valid = 29174534.0 \n",
      "Model_8_9720 \t loss_train = 34641300.0 \t loss_valid = 29039066.0 \n",
      "Model_8_9730 \t loss_train = 34938324.0 \t loss_valid = 29302360.0 \n",
      "Model_8_9740 \t loss_train = 35392480.0 \t loss_valid = 29674714.0 \n",
      "Model_8_9750 \t loss_train = 34656896.0 \t loss_valid = 29025404.0 \n",
      "Model_8_9760 \t loss_train = 34906256.0 \t loss_valid = 29259878.0 \n",
      "Model_8_9770 \t loss_train = 34492340.0 \t loss_valid = 28925582.0 \n",
      "Model_8_9780 \t loss_train = 35349820.0 \t loss_valid = 29640606.0 \n",
      "Model_8_9790 \t loss_train = 34575076.0 \t loss_valid = 28988744.0 \n",
      "Model_8_9800 \t loss_train = 35099728.0 \t loss_valid = 29430702.0 \n",
      "Model_8_9810 \t loss_train = 35237084.0 \t loss_valid = 29531054.0 \n",
      "Model_8_9820 \t loss_train = 34734824.0 \t loss_valid = 29163794.0 \n",
      "Model_8_9830 \t loss_train = 34842404.0 \t loss_valid = 29245202.0 \n",
      "Model_8_9840 \t loss_train = 34481040.0 \t loss_valid = 28977202.0 \n",
      "Model_8_9850 \t loss_train = 34783744.0 \t loss_valid = 29188064.0 \n",
      "Model_8_9860 \t loss_train = 34813308.0 \t loss_valid = 29199792.0 \n",
      "Model_8_9870 \t loss_train = 34868812.0 \t loss_valid = 29177588.0 \n",
      "Model_8_9880 \t loss_train = 34655984.0 \t loss_valid = 29125840.0 \n",
      "Model_8_9890 \t loss_train = 35024740.0 \t loss_valid = 29368130.0 \n",
      "Model_8_9900 \t loss_train = 34743028.0 \t loss_valid = 29141378.0 \n",
      "Model_8_9910 \t loss_train = 35086164.0 \t loss_valid = 29427354.0 \n",
      "Model_8_9920 \t loss_train = 34489060.0 \t loss_valid = 28849348.0 \n",
      "Model_8_9930 \t loss_train = 34878796.0 \t loss_valid = 29240798.0 \n",
      "Model_8_9940 \t loss_train = 34378444.0 \t loss_valid = 28815606.0 \n",
      "Model_8_9950 \t loss_train = 35228356.0 \t loss_valid = 29574480.0 \n",
      "Model_8_9960 \t loss_train = 35182840.0 \t loss_valid = 29464896.0 \n",
      "Model_8_9970 \t loss_train = 34978564.0 \t loss_valid = 29303106.0 \n",
      "Model_8_9980 \t loss_train = 34960292.0 \t loss_valid = 29285436.0 \n",
      "Model_8_9990 \t loss_train = 35097852.0 \t loss_valid = 29390054.0 \n",
      "Model_8_10000 \t loss_train = 34932196.0 \t loss_valid = 29240338.0 \n",
      "Model_8_10010 \t loss_train = 34765200.0 \t loss_valid = 29146530.0 \n",
      "Model_8_10020 \t loss_train = 35088056.0 \t loss_valid = 29411044.0 \n",
      "Model_8_10030 \t loss_train = 35121212.0 \t loss_valid = 29438736.0 \n",
      "Model_8_10040 \t loss_train = 34644660.0 \t loss_valid = 29031212.0 \n",
      "Model_8_10050 \t loss_train = 35208264.0 \t loss_valid = 29492144.0 \n",
      "Model_8_10060 \t loss_train = 35007940.0 \t loss_valid = 29258316.0 \n",
      "Model_8_10070 \t loss_train = 34897332.0 \t loss_valid = 29213090.0 \n",
      "Model_8_10080 \t loss_train = 34947468.0 \t loss_valid = 29244232.0 \n",
      "Model_8_10090 \t loss_train = 35002928.0 \t loss_valid = 29318150.0 \n",
      "Model_8_10100 \t loss_train = 35183268.0 \t loss_valid = 29486282.0 \n",
      "Model_8_10110 \t loss_train = 34300260.0 \t loss_valid = 28785758.0 \n",
      "Model_8_10120 \t loss_train = 35452984.0 \t loss_valid = 29710030.0 \n",
      "Model_8_10130 \t loss_train = 34874836.0 \t loss_valid = 29253418.0 \n",
      "Model_8_10140 \t loss_train = 35345120.0 \t loss_valid = 29590620.0 \n",
      "Model_8_10150 \t loss_train = 35504820.0 \t loss_valid = 29724058.0 \n",
      "Model_8_10160 \t loss_train = 35109984.0 \t loss_valid = 29427430.0 \n",
      "Model_8_10170 \t loss_train = 35036156.0 \t loss_valid = 29398534.0 \n",
      "Model_8_10180 \t loss_train = 35067944.0 \t loss_valid = 29387144.0 \n",
      "Model_8_10190 \t loss_train = 35464940.0 \t loss_valid = 29694972.0 \n",
      "Model_8_10200 \t loss_train = 35823056.0 \t loss_valid = 30037592.0 \n",
      "Model_8_10210 \t loss_train = 34879244.0 \t loss_valid = 29187994.0 \n",
      "Model_8_10220 \t loss_train = 35145336.0 \t loss_valid = 29480878.0 \n",
      "Model_8_10230 \t loss_train = 34822992.0 \t loss_valid = 29147452.0 \n",
      "Model_8_10240 \t loss_train = 35361936.0 \t loss_valid = 29630174.0 \n",
      "Model_8_10250 \t loss_train = 35543120.0 \t loss_valid = 29728342.0 \n",
      "Model_8_10260 \t loss_train = 34910496.0 \t loss_valid = 29267678.0 \n",
      "Model_8_10270 \t loss_train = 35180548.0 \t loss_valid = 29499306.0 \n",
      "Model_8_10280 \t loss_train = 35033420.0 \t loss_valid = 29346332.0 \n",
      "Model_8_10290 \t loss_train = 35373704.0 \t loss_valid = 29646070.0 \n",
      "Model_8_10300 \t loss_train = 35265344.0 \t loss_valid = 29513058.0 \n",
      "Model_8_10310 \t loss_train = 35723896.0 \t loss_valid = 29881556.0 \n",
      "Model_8_10320 \t loss_train = 35151944.0 \t loss_valid = 29466130.0 \n",
      "Model_8_10330 \t loss_train = 35474152.0 \t loss_valid = 29669834.0 \n",
      "Model_8_10340 \t loss_train = 35638720.0 \t loss_valid = 29790910.0 \n",
      "Model_8_10350 \t loss_train = 34978716.0 \t loss_valid = 29289106.0 \n",
      "Model_8_10360 \t loss_train = 35562736.0 \t loss_valid = 29757886.0 \n",
      "Model_8_10370 \t loss_train = 35406332.0 \t loss_valid = 29639578.0 \n",
      "Model_8_10380 \t loss_train = 35599512.0 \t loss_valid = 29853370.0 \n",
      "Model_8_10390 \t loss_train = 35342120.0 \t loss_valid = 29618492.0 \n",
      "Model_8_10400 \t loss_train = 35141532.0 \t loss_valid = 29441978.0 \n",
      "Model_8_10410 \t loss_train = 35363468.0 \t loss_valid = 29635724.0 \n",
      "Model_8_10420 \t loss_train = 34935452.0 \t loss_valid = 29263088.0 \n",
      "Model_8_10430 \t loss_train = 34818496.0 \t loss_valid = 29173754.0 \n",
      "Model_8_10440 \t loss_train = 35447076.0 \t loss_valid = 29686004.0 \n",
      "Model_8_10450 \t loss_train = 35202728.0 \t loss_valid = 29499076.0 \n",
      "Model_8_10460 \t loss_train = 35056188.0 \t loss_valid = 29409394.0 \n",
      "Model_8_10470 \t loss_train = 35758864.0 \t loss_valid = 29973340.0 \n",
      "Model_8_10480 \t loss_train = 34940828.0 \t loss_valid = 29250490.0 \n",
      "Model_8_10490 \t loss_train = 35254660.0 \t loss_valid = 29499348.0 \n",
      "Model_8_10500 \t loss_train = 35045132.0 \t loss_valid = 29313934.0 \n",
      "Model_8_10510 \t loss_train = 35455636.0 \t loss_valid = 29696018.0 \n",
      "Model_8_10520 \t loss_train = 35190100.0 \t loss_valid = 29512188.0 \n",
      "Model_8_10530 \t loss_train = 35708328.0 \t loss_valid = 29847660.0 \n",
      "Model_8_10540 \t loss_train = 35232276.0 \t loss_valid = 29471162.0 \n",
      "Model_8_10550 \t loss_train = 35302652.0 \t loss_valid = 29469276.0 \n",
      "Model_8_10560 \t loss_train = 34996380.0 \t loss_valid = 29293948.0 \n",
      "Model_8_10570 \t loss_train = 35389596.0 \t loss_valid = 29582276.0 \n",
      "Model_8_10580 \t loss_train = 35063824.0 \t loss_valid = 29401966.0 \n",
      "Model_8_10590 \t loss_train = 36001944.0 \t loss_valid = 30161140.0 \n",
      "Model_8_10600 \t loss_train = 34789096.0 \t loss_valid = 29094072.0 \n",
      "Model_8_10610 \t loss_train = 35728640.0 \t loss_valid = 29900156.0 \n",
      "Model_8_10620 \t loss_train = 35396624.0 \t loss_valid = 29614702.0 \n",
      "Model_8_10630 \t loss_train = 35334868.0 \t loss_valid = 29618672.0 \n",
      "Model_8_10640 \t loss_train = 35524668.0 \t loss_valid = 29704672.0 \n",
      "Model_8_10650 \t loss_train = 35480424.0 \t loss_valid = 29738818.0 \n",
      "Model_8_10660 \t loss_train = 35395428.0 \t loss_valid = 29664148.0 \n",
      "Model_8_10670 \t loss_train = 35164648.0 \t loss_valid = 29496762.0 \n",
      "Model_8_10680 \t loss_train = 35432732.0 \t loss_valid = 29695068.0 \n",
      "Model_8_10690 \t loss_train = 35272976.0 \t loss_valid = 29520568.0 \n",
      "Model_8_10700 \t loss_train = 35152288.0 \t loss_valid = 29429614.0 \n",
      "Model_8_10710 \t loss_train = 35545268.0 \t loss_valid = 29779810.0 \n",
      "Model_8_10720 \t loss_train = 35217804.0 \t loss_valid = 29510134.0 \n",
      "Model_8_10730 \t loss_train = 35193404.0 \t loss_valid = 29531936.0 \n",
      "Model_8_10740 \t loss_train = 35748088.0 \t loss_valid = 29922446.0 \n",
      "Model_8_10750 \t loss_train = 35430456.0 \t loss_valid = 29684078.0 \n",
      "Model_8_10760 \t loss_train = 35456868.0 \t loss_valid = 29656564.0 \n",
      "Model_8_10770 \t loss_train = 35944904.0 \t loss_valid = 30057570.0 \n",
      "Model_8_10780 \t loss_train = 35558552.0 \t loss_valid = 29764488.0 \n",
      "Model_8_10790 \t loss_train = 34673916.0 \t loss_valid = 29055778.0 \n",
      "Model_8_10800 \t loss_train = 35578432.0 \t loss_valid = 29797164.0 \n",
      "Model_8_10810 \t loss_train = 35442468.0 \t loss_valid = 29679262.0 \n",
      "Model_8_10820 \t loss_train = 35407692.0 \t loss_valid = 29705090.0 \n",
      "Model_8_10830 \t loss_train = 35840692.0 \t loss_valid = 29935164.0 \n",
      "Model_8_10840 \t loss_train = 35262568.0 \t loss_valid = 29490126.0 \n",
      "Model_8_10850 \t loss_train = 35377404.0 \t loss_valid = 29564138.0 \n",
      "Model_8_10860 \t loss_train = 35742864.0 \t loss_valid = 29874634.0 \n",
      "Model_8_10870 \t loss_train = 35442972.0 \t loss_valid = 29694730.0 \n",
      "Model_8_10880 \t loss_train = 35791348.0 \t loss_valid = 29936296.0 \n",
      "Model_8_10890 \t loss_train = 35053980.0 \t loss_valid = 29347786.0 \n",
      "Model_8_10900 \t loss_train = 35902880.0 \t loss_valid = 30007688.0 \n",
      "Model_8_10910 \t loss_train = 35126740.0 \t loss_valid = 29336866.0 \n",
      "Model_8_10920 \t loss_train = 35762660.0 \t loss_valid = 29892782.0 \n",
      "Model_8_10930 \t loss_train = 34986804.0 \t loss_valid = 29327600.0 \n",
      "Model_8_10940 \t loss_train = 35221768.0 \t loss_valid = 29438558.0 \n",
      "Model_8_10950 \t loss_train = 35813884.0 \t loss_valid = 29996364.0 \n",
      "Model_8_10960 \t loss_train = 35273408.0 \t loss_valid = 29536582.0 \n",
      "Model_8_10970 \t loss_train = 35484276.0 \t loss_valid = 29734624.0 \n",
      "Model_8_10980 \t loss_train = 35698488.0 \t loss_valid = 29844120.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_8_10990 \t loss_train = 35610164.0 \t loss_valid = 29800050.0 \n",
      "Model_8_11000 \t loss_train = 35752624.0 \t loss_valid = 29887032.0 \n",
      "Model_8_11010 \t loss_train = 35807032.0 \t loss_valid = 29934658.0 \n",
      "Model_8_11020 \t loss_train = 35697160.0 \t loss_valid = 29879558.0 \n",
      "Model_8_11030 \t loss_train = 35359932.0 \t loss_valid = 29654388.0 \n",
      "Model_8_11040 \t loss_train = 36112588.0 \t loss_valid = 30235614.0 \n",
      "Model_8_11050 \t loss_train = 35662504.0 \t loss_valid = 29861888.0 \n",
      "Model_8_11060 \t loss_train = 35727064.0 \t loss_valid = 29855424.0 \n",
      "Model_8_11070 \t loss_train = 35840272.0 \t loss_valid = 29985710.0 \n",
      "Model_8_11080 \t loss_train = 35507756.0 \t loss_valid = 29708194.0 \n",
      "Model_8_11090 \t loss_train = 35908812.0 \t loss_valid = 30002482.0 \n",
      "Model_8_11100 \t loss_train = 35593896.0 \t loss_valid = 29769640.0 \n",
      "Model_8_11110 \t loss_train = 34975244.0 \t loss_valid = 29200508.0 \n",
      "Model_8_11120 \t loss_train = 35604016.0 \t loss_valid = 29760132.0 \n",
      "Model_8_11130 \t loss_train = 35675728.0 \t loss_valid = 29891324.0 \n",
      "Model_8_11140 \t loss_train = 35727196.0 \t loss_valid = 29858544.0 \n",
      "Model_8_11150 \t loss_train = 35595384.0 \t loss_valid = 29800280.0 \n",
      "Model_8_11160 \t loss_train = 35877840.0 \t loss_valid = 29967100.0 \n",
      "Model_8_11170 \t loss_train = 35593416.0 \t loss_valid = 29736714.0 \n",
      "Model_8_11180 \t loss_train = 35522268.0 \t loss_valid = 29721340.0 \n",
      "Model_8_11190 \t loss_train = 35552568.0 \t loss_valid = 29704972.0 \n",
      "Model_8_11200 \t loss_train = 36010928.0 \t loss_valid = 30080516.0 \n",
      "Model_8_11210 \t loss_train = 35669936.0 \t loss_valid = 29737886.0 \n",
      "Model_8_11220 \t loss_train = 35873676.0 \t loss_valid = 29962402.0 \n",
      "Early stopping!\n",
      "Model_9_0 \t loss_train = 119625504.0 \t loss_valid = 104748496.0 \n",
      "Model_9_10 \t loss_train = 118104344.0 \t loss_valid = 102958696.0 \n",
      "Model_9_20 \t loss_train = 114262048.0 \t loss_valid = 98235968.0 \n",
      "Model_9_30 \t loss_train = 103702936.0 \t loss_valid = 85851448.0 \n",
      "Model_9_40 \t loss_train = 79074848.0 \t loss_valid = 59945212.0 \n",
      "Model_9_50 \t loss_train = 62490584.0 \t loss_valid = 60601564.0 \n",
      "Model_9_60 \t loss_train = 60646316.0 \t loss_valid = 50317560.0 \n",
      "Model_9_70 \t loss_train = 59902492.0 \t loss_valid = 47838668.0 \n",
      "Model_9_80 \t loss_train = 57488088.0 \t loss_valid = 47190256.0 \n",
      "Model_9_90 \t loss_train = 56521292.0 \t loss_valid = 45343852.0 \n",
      "Model_9_100 \t loss_train = 56182576.0 \t loss_valid = 43883324.0 \n",
      "Model_9_110 \t loss_train = 54982264.0 \t loss_valid = 42882964.0 \n",
      "Model_9_120 \t loss_train = 54456036.0 \t loss_valid = 41990064.0 \n",
      "Model_9_130 \t loss_train = 54126128.0 \t loss_valid = 41431516.0 \n",
      "Model_9_140 \t loss_train = 53568204.0 \t loss_valid = 40870532.0 \n",
      "Model_9_150 \t loss_train = 53508464.0 \t loss_valid = 40585032.0 \n",
      "Model_9_160 \t loss_train = 52755264.0 \t loss_valid = 40013072.0 \n",
      "Model_9_170 \t loss_train = 52378484.0 \t loss_valid = 39739436.0 \n",
      "Model_9_180 \t loss_train = 52007376.0 \t loss_valid = 39382024.0 \n",
      "Model_9_190 \t loss_train = 51261888.0 \t loss_valid = 38705764.0 \n",
      "Model_9_200 \t loss_train = 50915892.0 \t loss_valid = 38439652.0 \n",
      "Model_9_210 \t loss_train = 50311508.0 \t loss_valid = 37952072.0 \n",
      "Model_9_220 \t loss_train = 50570800.0 \t loss_valid = 38252740.0 \n",
      "Model_9_230 \t loss_train = 49543592.0 \t loss_valid = 37619072.0 \n",
      "Model_9_240 \t loss_train = 48815932.0 \t loss_valid = 37295904.0 \n",
      "Model_9_250 \t loss_train = 48126212.0 \t loss_valid = 36933564.0 \n",
      "Model_9_260 \t loss_train = 47276032.0 \t loss_valid = 36422372.0 \n",
      "Model_9_270 \t loss_train = 46957008.0 \t loss_valid = 36252996.0 \n",
      "Model_9_280 \t loss_train = 45613736.0 \t loss_valid = 35571116.0 \n",
      "Model_9_290 \t loss_train = 45000484.0 \t loss_valid = 35043980.0 \n",
      "Model_9_300 \t loss_train = 44480752.0 \t loss_valid = 34744444.0 \n",
      "Model_9_310 \t loss_train = 43032668.0 \t loss_valid = 33998976.0 \n",
      "Model_9_320 \t loss_train = 41188760.0 \t loss_valid = 33264298.0 \n",
      "Model_9_330 \t loss_train = 39929412.0 \t loss_valid = 32316268.0 \n",
      "Model_9_340 \t loss_train = 38080972.0 \t loss_valid = 31749190.0 \n",
      "Model_9_350 \t loss_train = 36809776.0 \t loss_valid = 30569706.0 \n",
      "Model_9_360 \t loss_train = 35106080.0 \t loss_valid = 30044722.0 \n",
      "Model_9_370 \t loss_train = 33186898.0 \t loss_valid = 29513506.0 \n",
      "Model_9_380 \t loss_train = 31597650.0 \t loss_valid = 28021318.0 \n",
      "Model_9_390 \t loss_train = 30789526.0 \t loss_valid = 26972640.0 \n",
      "Model_9_400 \t loss_train = 30518512.0 \t loss_valid = 26855654.0 \n",
      "Model_9_410 \t loss_train = 28910220.0 \t loss_valid = 27191308.0 \n",
      "Model_9_420 \t loss_train = 28640160.0 \t loss_valid = 26369216.0 \n",
      "Model_9_430 \t loss_train = 29227320.0 \t loss_valid = 26213520.0 \n",
      "Model_9_440 \t loss_train = 29132506.0 \t loss_valid = 26083754.0 \n",
      "Model_9_450 \t loss_train = 28669440.0 \t loss_valid = 25875916.0 \n",
      "Model_9_460 \t loss_train = 28441876.0 \t loss_valid = 25771338.0 \n",
      "Model_9_470 \t loss_train = 28701784.0 \t loss_valid = 25704376.0 \n",
      "Model_9_480 \t loss_train = 28686818.0 \t loss_valid = 25727552.0 \n",
      "Model_9_490 \t loss_train = 28618370.0 \t loss_valid = 25667796.0 \n",
      "Model_9_500 \t loss_train = 29039894.0 \t loss_valid = 25869106.0 \n",
      "Model_9_510 \t loss_train = 28284990.0 \t loss_valid = 25784264.0 \n",
      "Model_9_520 \t loss_train = 28179606.0 \t loss_valid = 26028270.0 \n",
      "Model_9_530 \t loss_train = 28366072.0 \t loss_valid = 25670810.0 \n",
      "Model_9_540 \t loss_train = 28667810.0 \t loss_valid = 25633754.0 \n",
      "Model_9_550 \t loss_train = 28403454.0 \t loss_valid = 25647654.0 \n",
      "Model_9_560 \t loss_train = 28509480.0 \t loss_valid = 25640508.0 \n",
      "Model_9_570 \t loss_train = 28401712.0 \t loss_valid = 25639708.0 \n",
      "Model_9_580 \t loss_train = 28188724.0 \t loss_valid = 25959150.0 \n",
      "Model_9_590 \t loss_train = 28717116.0 \t loss_valid = 25607676.0 \n",
      "Model_9_600 \t loss_train = 28893692.0 \t loss_valid = 25695160.0 \n",
      "Model_9_610 \t loss_train = 28561826.0 \t loss_valid = 25581782.0 \n",
      "Model_9_620 \t loss_train = 28507566.0 \t loss_valid = 25574856.0 \n",
      "Model_9_630 \t loss_train = 28259712.0 \t loss_valid = 25706360.0 \n",
      "Model_9_640 \t loss_train = 28877448.0 \t loss_valid = 25747552.0 \n",
      "Model_9_650 \t loss_train = 28384670.0 \t loss_valid = 25641014.0 \n",
      "Model_9_660 \t loss_train = 28210770.0 \t loss_valid = 25880346.0 \n",
      "Model_9_670 \t loss_train = 28292318.0 \t loss_valid = 25763866.0 \n",
      "Model_9_680 \t loss_train = 28386430.0 \t loss_valid = 25607376.0 \n",
      "Model_9_690 \t loss_train = 28552352.0 \t loss_valid = 25605950.0 \n",
      "Model_9_700 \t loss_train = 28221902.0 \t loss_valid = 25775434.0 \n",
      "Model_9_710 \t loss_train = 28119904.0 \t loss_valid = 25780826.0 \n",
      "Model_9_720 \t loss_train = 28581534.0 \t loss_valid = 25623320.0 \n",
      "Model_9_730 \t loss_train = 29284090.0 \t loss_valid = 26063212.0 \n",
      "Model_9_740 \t loss_train = 28728636.0 \t loss_valid = 25644680.0 \n",
      "Model_9_750 \t loss_train = 28557440.0 \t loss_valid = 25588202.0 \n",
      "Model_9_760 \t loss_train = 28388228.0 \t loss_valid = 25632010.0 \n",
      "Model_9_770 \t loss_train = 28288826.0 \t loss_valid = 25634516.0 \n",
      "Model_9_780 \t loss_train = 28617324.0 \t loss_valid = 25578050.0 \n",
      "Model_9_790 \t loss_train = 28723924.0 \t loss_valid = 25625228.0 \n",
      "Model_9_800 \t loss_train = 28579296.0 \t loss_valid = 25559632.0 \n",
      "Model_9_810 \t loss_train = 28737704.0 \t loss_valid = 25589592.0 \n",
      "Model_9_820 \t loss_train = 28239274.0 \t loss_valid = 25699690.0 \n",
      "Model_9_830 \t loss_train = 28246040.0 \t loss_valid = 25661012.0 \n",
      "Model_9_840 \t loss_train = 28667788.0 \t loss_valid = 25612194.0 \n",
      "Model_9_850 \t loss_train = 28254244.0 \t loss_valid = 25654512.0 \n",
      "Model_9_860 \t loss_train = 28492232.0 \t loss_valid = 25565512.0 \n",
      "Model_9_870 \t loss_train = 28458680.0 \t loss_valid = 25551526.0 \n",
      "Model_9_880 \t loss_train = 28479862.0 \t loss_valid = 25562062.0 \n",
      "Model_9_890 \t loss_train = 28434134.0 \t loss_valid = 25555158.0 \n",
      "Model_9_900 \t loss_train = 28466570.0 \t loss_valid = 25601896.0 \n",
      "Model_9_910 \t loss_train = 28373028.0 \t loss_valid = 25526914.0 \n",
      "Model_9_920 \t loss_train = 28987788.0 \t loss_valid = 25684272.0 \n",
      "Model_9_930 \t loss_train = 29091372.0 \t loss_valid = 25730838.0 \n",
      "Model_9_940 \t loss_train = 28911422.0 \t loss_valid = 25656294.0 \n",
      "Model_9_950 \t loss_train = 28659708.0 \t loss_valid = 25568694.0 \n",
      "Model_9_960 \t loss_train = 28301828.0 \t loss_valid = 25615052.0 \n",
      "Model_9_970 \t loss_train = 28395224.0 \t loss_valid = 25521908.0 \n",
      "Model_9_980 \t loss_train = 28377390.0 \t loss_valid = 25487684.0 \n",
      "Model_9_990 \t loss_train = 28869586.0 \t loss_valid = 25586232.0 \n",
      "Model_9_1000 \t loss_train = 28956022.0 \t loss_valid = 25687294.0 \n",
      "Model_9_1010 \t loss_train = 29373442.0 \t loss_valid = 25830034.0 \n",
      "Model_9_1020 \t loss_train = 29077800.0 \t loss_valid = 25703368.0 \n",
      "Model_9_1030 \t loss_train = 28818316.0 \t loss_valid = 25615240.0 \n",
      "Model_9_1040 \t loss_train = 28650300.0 \t loss_valid = 25529258.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_9_1050 \t loss_train = 28963400.0 \t loss_valid = 25640972.0 \n",
      "Model_9_1060 \t loss_train = 28615512.0 \t loss_valid = 25509566.0 \n",
      "Model_9_1070 \t loss_train = 28340596.0 \t loss_valid = 25533006.0 \n",
      "Model_9_1080 \t loss_train = 28669104.0 \t loss_valid = 25543488.0 \n",
      "Model_9_1090 \t loss_train = 28846238.0 \t loss_valid = 25586620.0 \n",
      "Model_9_1100 \t loss_train = 28982536.0 \t loss_valid = 25652190.0 \n",
      "Model_9_1110 \t loss_train = 29067796.0 \t loss_valid = 25672016.0 \n",
      "Model_9_1120 \t loss_train = 28920788.0 \t loss_valid = 25596896.0 \n",
      "Model_9_1130 \t loss_train = 28771044.0 \t loss_valid = 25565556.0 \n",
      "Model_9_1140 \t loss_train = 29115572.0 \t loss_valid = 25716112.0 \n",
      "Model_9_1150 \t loss_train = 28877862.0 \t loss_valid = 25608286.0 \n",
      "Model_9_1160 \t loss_train = 28716662.0 \t loss_valid = 25558056.0 \n",
      "Model_9_1170 \t loss_train = 28849376.0 \t loss_valid = 25556238.0 \n",
      "Model_9_1180 \t loss_train = 28844612.0 \t loss_valid = 25530416.0 \n",
      "Model_9_1190 \t loss_train = 28760238.0 \t loss_valid = 25498886.0 \n",
      "Model_9_1200 \t loss_train = 28530906.0 \t loss_valid = 25465732.0 \n",
      "Model_9_1210 \t loss_train = 28632830.0 \t loss_valid = 25493960.0 \n",
      "Model_9_1220 \t loss_train = 28684718.0 \t loss_valid = 25515478.0 \n",
      "Model_9_1230 \t loss_train = 28747806.0 \t loss_valid = 25529030.0 \n",
      "Model_9_1240 \t loss_train = 29038118.0 \t loss_valid = 25616726.0 \n",
      "Model_9_1250 \t loss_train = 29438402.0 \t loss_valid = 25860932.0 \n",
      "Model_9_1260 \t loss_train = 29059786.0 \t loss_valid = 25651094.0 \n",
      "Model_9_1270 \t loss_train = 28836028.0 \t loss_valid = 25545912.0 \n",
      "Model_9_1280 \t loss_train = 29164280.0 \t loss_valid = 25654908.0 \n",
      "Model_9_1290 \t loss_train = 29551516.0 \t loss_valid = 25850248.0 \n",
      "Model_9_1300 \t loss_train = 29451130.0 \t loss_valid = 25813902.0 \n",
      "Model_9_1310 \t loss_train = 29929464.0 \t loss_valid = 26084724.0 \n",
      "Model_9_1320 \t loss_train = 30036206.0 \t loss_valid = 26229330.0 \n",
      "Model_9_1330 \t loss_train = 29598378.0 \t loss_valid = 25879368.0 \n",
      "Model_9_1340 \t loss_train = 29770892.0 \t loss_valid = 26051154.0 \n",
      "Model_9_1350 \t loss_train = 29445714.0 \t loss_valid = 25845982.0 \n",
      "Model_9_1360 \t loss_train = 29738848.0 \t loss_valid = 25971286.0 \n",
      "Model_9_1370 \t loss_train = 30094588.0 \t loss_valid = 26110460.0 \n",
      "Model_9_1380 \t loss_train = 30170248.0 \t loss_valid = 26265576.0 \n",
      "Model_9_1390 \t loss_train = 30024764.0 \t loss_valid = 26145322.0 \n",
      "Model_9_1400 \t loss_train = 30006130.0 \t loss_valid = 26072476.0 \n",
      "Model_9_1410 \t loss_train = 30223954.0 \t loss_valid = 26312290.0 \n",
      "Model_9_1420 \t loss_train = 30233730.0 \t loss_valid = 26239526.0 \n",
      "Model_9_1430 \t loss_train = 30268598.0 \t loss_valid = 26285874.0 \n",
      "Model_9_1440 \t loss_train = 30337544.0 \t loss_valid = 26319556.0 \n",
      "Model_9_1450 \t loss_train = 30084568.0 \t loss_valid = 26118984.0 \n",
      "Model_9_1460 \t loss_train = 30668548.0 \t loss_valid = 26554532.0 \n",
      "Model_9_1470 \t loss_train = 29860168.0 \t loss_valid = 26067328.0 \n",
      "Model_9_1480 \t loss_train = 29615248.0 \t loss_valid = 25844442.0 \n",
      "Model_9_1490 \t loss_train = 30247284.0 \t loss_valid = 26225938.0 \n",
      "Model_9_1500 \t loss_train = 30050870.0 \t loss_valid = 26065538.0 \n",
      "Model_9_1510 \t loss_train = 30510550.0 \t loss_valid = 26479372.0 \n",
      "Model_9_1520 \t loss_train = 30266316.0 \t loss_valid = 26308030.0 \n",
      "Model_9_1530 \t loss_train = 30278610.0 \t loss_valid = 26233214.0 \n",
      "Model_9_1540 \t loss_train = 30098026.0 \t loss_valid = 26047446.0 \n",
      "Model_9_1550 \t loss_train = 30222302.0 \t loss_valid = 26212712.0 \n",
      "Model_9_1560 \t loss_train = 30833428.0 \t loss_valid = 26667982.0 \n",
      "Model_9_1570 \t loss_train = 31027466.0 \t loss_valid = 26873780.0 \n",
      "Model_9_1580 \t loss_train = 30476204.0 \t loss_valid = 26283802.0 \n",
      "Model_9_1590 \t loss_train = 30421722.0 \t loss_valid = 26303908.0 \n",
      "Model_9_1600 \t loss_train = 30436654.0 \t loss_valid = 26275098.0 \n",
      "Model_9_1610 \t loss_train = 30091634.0 \t loss_valid = 26085270.0 \n",
      "Model_9_1620 \t loss_train = 30107678.0 \t loss_valid = 26123356.0 \n",
      "Model_9_1630 \t loss_train = 30129046.0 \t loss_valid = 26048296.0 \n",
      "Model_9_1640 \t loss_train = 30254944.0 \t loss_valid = 26224836.0 \n",
      "Model_9_1650 \t loss_train = 30286054.0 \t loss_valid = 26187078.0 \n",
      "Model_9_1660 \t loss_train = 30172766.0 \t loss_valid = 26106926.0 \n",
      "Model_9_1670 \t loss_train = 30212086.0 \t loss_valid = 26184124.0 \n",
      "Model_9_1680 \t loss_train = 30186984.0 \t loss_valid = 26147290.0 \n",
      "Model_9_1690 \t loss_train = 30145828.0 \t loss_valid = 26135952.0 \n",
      "Model_9_1700 \t loss_train = 30211686.0 \t loss_valid = 26137554.0 \n",
      "Model_9_1710 \t loss_train = 30579384.0 \t loss_valid = 26388206.0 \n",
      "Model_9_1720 \t loss_train = 30361450.0 \t loss_valid = 26309110.0 \n",
      "Model_9_1730 \t loss_train = 30894394.0 \t loss_valid = 26728568.0 \n",
      "Model_9_1740 \t loss_train = 31393852.0 \t loss_valid = 26975576.0 \n",
      "Model_9_1750 \t loss_train = 31419306.0 \t loss_valid = 27062146.0 \n",
      "Model_9_1760 \t loss_train = 31432590.0 \t loss_valid = 27067698.0 \n",
      "Model_9_1770 \t loss_train = 31386462.0 \t loss_valid = 26928976.0 \n",
      "Model_9_1780 \t loss_train = 31326270.0 \t loss_valid = 26938440.0 \n",
      "Model_9_1790 \t loss_train = 30566340.0 \t loss_valid = 26407766.0 \n",
      "Model_9_1800 \t loss_train = 30760460.0 \t loss_valid = 26536596.0 \n",
      "Model_9_1810 \t loss_train = 31399118.0 \t loss_valid = 26949636.0 \n",
      "Model_9_1820 \t loss_train = 31001336.0 \t loss_valid = 26655352.0 \n",
      "Model_9_1830 \t loss_train = 30609524.0 \t loss_valid = 26394592.0 \n",
      "Model_9_1840 \t loss_train = 31067000.0 \t loss_valid = 26743100.0 \n",
      "Model_9_1850 \t loss_train = 30755668.0 \t loss_valid = 26450366.0 \n",
      "Model_9_1860 \t loss_train = 30602130.0 \t loss_valid = 26366344.0 \n",
      "Model_9_1870 \t loss_train = 30383122.0 \t loss_valid = 26224140.0 \n",
      "Model_9_1880 \t loss_train = 30659726.0 \t loss_valid = 26354046.0 \n",
      "Model_9_1890 \t loss_train = 31053996.0 \t loss_valid = 26723158.0 \n",
      "Model_9_1900 \t loss_train = 31374940.0 \t loss_valid = 26925912.0 \n",
      "Model_9_1910 \t loss_train = 31169730.0 \t loss_valid = 26784120.0 \n",
      "Model_9_1920 \t loss_train = 31017446.0 \t loss_valid = 26612104.0 \n",
      "Model_9_1930 \t loss_train = 30934908.0 \t loss_valid = 26624462.0 \n",
      "Model_9_1940 \t loss_train = 31749776.0 \t loss_valid = 27219422.0 \n",
      "Model_9_1950 \t loss_train = 31559360.0 \t loss_valid = 27083646.0 \n",
      "Model_9_1960 \t loss_train = 31582922.0 \t loss_valid = 27068634.0 \n",
      "Model_9_1970 \t loss_train = 31396006.0 \t loss_valid = 26910388.0 \n",
      "Model_9_1980 \t loss_train = 31423244.0 \t loss_valid = 26898726.0 \n",
      "Model_9_1990 \t loss_train = 31515336.0 \t loss_valid = 27049270.0 \n",
      "Model_9_2000 \t loss_train = 31124112.0 \t loss_valid = 26621210.0 \n",
      "Model_9_2010 \t loss_train = 30900646.0 \t loss_valid = 26545822.0 \n",
      "Model_9_2020 \t loss_train = 31010782.0 \t loss_valid = 26545674.0 \n",
      "Model_9_2030 \t loss_train = 31258286.0 \t loss_valid = 26789380.0 \n",
      "Model_9_2040 \t loss_train = 30918458.0 \t loss_valid = 26564510.0 \n",
      "Model_9_2050 \t loss_train = 31276220.0 \t loss_valid = 26722602.0 \n",
      "Model_9_2060 \t loss_train = 31522560.0 \t loss_valid = 26968804.0 \n",
      "Model_9_2070 \t loss_train = 31761056.0 \t loss_valid = 27241112.0 \n",
      "Model_9_2080 \t loss_train = 32064686.0 \t loss_valid = 27388236.0 \n",
      "Model_9_2090 \t loss_train = 31683806.0 \t loss_valid = 27106534.0 \n",
      "Model_9_2100 \t loss_train = 31078474.0 \t loss_valid = 26651388.0 \n",
      "Model_9_2110 \t loss_train = 30868636.0 \t loss_valid = 26431886.0 \n",
      "Model_9_2120 \t loss_train = 31436064.0 \t loss_valid = 26919652.0 \n",
      "Model_9_2130 \t loss_train = 32529578.0 \t loss_valid = 27762820.0 \n",
      "Model_9_2140 \t loss_train = 32086136.0 \t loss_valid = 27390660.0 \n",
      "Model_9_2150 \t loss_train = 31554312.0 \t loss_valid = 27034488.0 \n",
      "Model_9_2160 \t loss_train = 31767286.0 \t loss_valid = 27194094.0 \n",
      "Model_9_2170 \t loss_train = 31858444.0 \t loss_valid = 27165620.0 \n",
      "Model_9_2180 \t loss_train = 31955926.0 \t loss_valid = 27352384.0 \n",
      "Model_9_2190 \t loss_train = 32118654.0 \t loss_valid = 27444752.0 \n",
      "Model_9_2200 \t loss_train = 32233900.0 \t loss_valid = 27461260.0 \n",
      "Model_9_2210 \t loss_train = 32080222.0 \t loss_valid = 27325038.0 \n",
      "Model_9_2220 \t loss_train = 32069778.0 \t loss_valid = 27446502.0 \n",
      "Model_9_2230 \t loss_train = 31934418.0 \t loss_valid = 27218150.0 \n",
      "Model_9_2240 \t loss_train = 32424478.0 \t loss_valid = 27643158.0 \n",
      "Model_9_2250 \t loss_train = 32288794.0 \t loss_valid = 27475000.0 \n",
      "Model_9_2260 \t loss_train = 32192928.0 \t loss_valid = 27391596.0 \n",
      "Model_9_2270 \t loss_train = 32170594.0 \t loss_valid = 27391782.0 \n",
      "Model_9_2280 \t loss_train = 32470092.0 \t loss_valid = 27644700.0 \n",
      "Model_9_2290 \t loss_train = 32445092.0 \t loss_valid = 27617852.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_9_2300 \t loss_train = 32350996.0 \t loss_valid = 27624398.0 \n",
      "Model_9_2310 \t loss_train = 31876732.0 \t loss_valid = 27152058.0 \n",
      "Model_9_2320 \t loss_train = 31639312.0 \t loss_valid = 26962622.0 \n",
      "Model_9_2330 \t loss_train = 32274344.0 \t loss_valid = 27459264.0 \n",
      "Model_9_2340 \t loss_train = 32212038.0 \t loss_valid = 27395502.0 \n",
      "Model_9_2350 \t loss_train = 32685054.0 \t loss_valid = 27789956.0 \n",
      "Model_9_2360 \t loss_train = 32705368.0 \t loss_valid = 27794154.0 \n",
      "Model_9_2370 \t loss_train = 32907736.0 \t loss_valid = 28118104.0 \n",
      "Model_9_2380 \t loss_train = 32865802.0 \t loss_valid = 27901048.0 \n",
      "Model_9_2390 \t loss_train = 32300274.0 \t loss_valid = 27465864.0 \n",
      "Model_9_2400 \t loss_train = 32125368.0 \t loss_valid = 27310738.0 \n",
      "Model_9_2410 \t loss_train = 33125410.0 \t loss_valid = 28083952.0 \n",
      "Model_9_2420 \t loss_train = 32968992.0 \t loss_valid = 28103028.0 \n",
      "Model_9_2430 \t loss_train = 32661204.0 \t loss_valid = 27784280.0 \n",
      "Model_9_2440 \t loss_train = 33047148.0 \t loss_valid = 28151742.0 \n",
      "Model_9_2450 \t loss_train = 32711790.0 \t loss_valid = 27867546.0 \n",
      "Model_9_2460 \t loss_train = 32827594.0 \t loss_valid = 27735638.0 \n",
      "Model_9_2470 \t loss_train = 32725450.0 \t loss_valid = 27760968.0 \n",
      "Model_9_2480 \t loss_train = 32626060.0 \t loss_valid = 27717850.0 \n",
      "Model_9_2490 \t loss_train = 33021426.0 \t loss_valid = 28007036.0 \n",
      "Model_9_2500 \t loss_train = 33227562.0 \t loss_valid = 28141068.0 \n",
      "Model_9_2510 \t loss_train = 32786456.0 \t loss_valid = 27836138.0 \n",
      "Model_9_2520 \t loss_train = 32648784.0 \t loss_valid = 27699320.0 \n",
      "Model_9_2530 \t loss_train = 32361700.0 \t loss_valid = 27514726.0 \n",
      "Model_9_2540 \t loss_train = 32739988.0 \t loss_valid = 27878492.0 \n",
      "Model_9_2550 \t loss_train = 33033556.0 \t loss_valid = 28001276.0 \n",
      "Model_9_2560 \t loss_train = 33258098.0 \t loss_valid = 28267210.0 \n",
      "Model_9_2570 \t loss_train = 32818530.0 \t loss_valid = 27869446.0 \n",
      "Model_9_2580 \t loss_train = 32619672.0 \t loss_valid = 27649428.0 \n",
      "Model_9_2590 \t loss_train = 33099674.0 \t loss_valid = 28031336.0 \n",
      "Model_9_2600 \t loss_train = 33219062.0 \t loss_valid = 28217024.0 \n",
      "Model_9_2610 \t loss_train = 32641378.0 \t loss_valid = 27618876.0 \n",
      "Model_9_2620 \t loss_train = 33207006.0 \t loss_valid = 28133530.0 \n",
      "Model_9_2630 \t loss_train = 33184710.0 \t loss_valid = 28360466.0 \n",
      "Model_9_2640 \t loss_train = 33879496.0 \t loss_valid = 28761186.0 \n",
      "Model_9_2650 \t loss_train = 33647360.0 \t loss_valid = 28617582.0 \n",
      "Model_9_2660 \t loss_train = 32953000.0 \t loss_valid = 27946572.0 \n",
      "Model_9_2670 \t loss_train = 32424592.0 \t loss_valid = 27488140.0 \n",
      "Model_9_2680 \t loss_train = 33013976.0 \t loss_valid = 28077732.0 \n",
      "Model_9_2690 \t loss_train = 33239236.0 \t loss_valid = 28163562.0 \n",
      "Model_9_2700 \t loss_train = 33560024.0 \t loss_valid = 28375568.0 \n",
      "Model_9_2710 \t loss_train = 32972502.0 \t loss_valid = 27834400.0 \n",
      "Model_9_2720 \t loss_train = 33592276.0 \t loss_valid = 28391646.0 \n",
      "Model_9_2730 \t loss_train = 32928488.0 \t loss_valid = 27882998.0 \n",
      "Model_9_2740 \t loss_train = 32465222.0 \t loss_valid = 27490664.0 \n",
      "Model_9_2750 \t loss_train = 32455960.0 \t loss_valid = 27462216.0 \n",
      "Model_9_2760 \t loss_train = 32765816.0 \t loss_valid = 27814118.0 \n",
      "Model_9_2770 \t loss_train = 32970282.0 \t loss_valid = 27939050.0 \n",
      "Model_9_2780 \t loss_train = 33755444.0 \t loss_valid = 28561610.0 \n",
      "Model_9_2790 \t loss_train = 33770044.0 \t loss_valid = 28627946.0 \n",
      "Model_9_2800 \t loss_train = 33594112.0 \t loss_valid = 28428510.0 \n",
      "Model_9_2810 \t loss_train = 33638476.0 \t loss_valid = 28477978.0 \n",
      "Model_9_2820 \t loss_train = 33470310.0 \t loss_valid = 28278216.0 \n",
      "Model_9_2830 \t loss_train = 32476174.0 \t loss_valid = 27584670.0 \n",
      "Model_9_2840 \t loss_train = 32893484.0 \t loss_valid = 27885590.0 \n",
      "Model_9_2850 \t loss_train = 33516308.0 \t loss_valid = 28281790.0 \n",
      "Model_9_2860 \t loss_train = 33267198.0 \t loss_valid = 28140544.0 \n",
      "Model_9_2870 \t loss_train = 32963978.0 \t loss_valid = 27929922.0 \n",
      "Model_9_2880 \t loss_train = 32881456.0 \t loss_valid = 27872512.0 \n",
      "Model_9_2890 \t loss_train = 32938022.0 \t loss_valid = 27849848.0 \n",
      "Model_9_2900 \t loss_train = 33414440.0 \t loss_valid = 28273110.0 \n",
      "Model_9_2910 \t loss_train = 33900500.0 \t loss_valid = 28729926.0 \n",
      "Model_9_2920 \t loss_train = 33406668.0 \t loss_valid = 28305322.0 \n",
      "Model_9_2930 \t loss_train = 33054802.0 \t loss_valid = 28001672.0 \n",
      "Model_9_2940 \t loss_train = 33323946.0 \t loss_valid = 28176798.0 \n",
      "Model_9_2950 \t loss_train = 33209072.0 \t loss_valid = 27998174.0 \n",
      "Model_9_2960 \t loss_train = 33297292.0 \t loss_valid = 28110624.0 \n",
      "Model_9_2970 \t loss_train = 32918946.0 \t loss_valid = 27809608.0 \n",
      "Model_9_2980 \t loss_train = 33218564.0 \t loss_valid = 28169446.0 \n",
      "Model_9_2990 \t loss_train = 33630704.0 \t loss_valid = 28379056.0 \n",
      "Model_9_3000 \t loss_train = 33776844.0 \t loss_valid = 28540984.0 \n",
      "Model_9_3010 \t loss_train = 33479010.0 \t loss_valid = 28331422.0 \n",
      "Model_9_3020 \t loss_train = 33465502.0 \t loss_valid = 28240922.0 \n",
      "Model_9_3030 \t loss_train = 33697628.0 \t loss_valid = 28545454.0 \n",
      "Model_9_3040 \t loss_train = 33538932.0 \t loss_valid = 28324890.0 \n",
      "Model_9_3050 \t loss_train = 33333714.0 \t loss_valid = 28213308.0 \n",
      "Model_9_3060 \t loss_train = 32936426.0 \t loss_valid = 27895706.0 \n",
      "Model_9_3070 \t loss_train = 33452252.0 \t loss_valid = 28335034.0 \n",
      "Model_9_3080 \t loss_train = 33985660.0 \t loss_valid = 28736936.0 \n",
      "Model_9_3090 \t loss_train = 33857920.0 \t loss_valid = 28597754.0 \n",
      "Model_9_3100 \t loss_train = 33639972.0 \t loss_valid = 28413544.0 \n",
      "Model_9_3110 \t loss_train = 33720108.0 \t loss_valid = 28574972.0 \n",
      "Model_9_3120 \t loss_train = 33609560.0 \t loss_valid = 28513526.0 \n",
      "Model_9_3130 \t loss_train = 32860848.0 \t loss_valid = 27846008.0 \n",
      "Model_9_3140 \t loss_train = 32867854.0 \t loss_valid = 27911702.0 \n",
      "Model_9_3150 \t loss_train = 33101064.0 \t loss_valid = 28037648.0 \n",
      "Model_9_3160 \t loss_train = 33695216.0 \t loss_valid = 28412760.0 \n",
      "Model_9_3170 \t loss_train = 33474774.0 \t loss_valid = 28272982.0 \n",
      "Model_9_3180 \t loss_train = 33486612.0 \t loss_valid = 28316880.0 \n",
      "Model_9_3190 \t loss_train = 33523808.0 \t loss_valid = 28319112.0 \n",
      "Model_9_3200 \t loss_train = 33585792.0 \t loss_valid = 28479068.0 \n",
      "Model_9_3210 \t loss_train = 33429652.0 \t loss_valid = 28313612.0 \n",
      "Model_9_3220 \t loss_train = 33095708.0 \t loss_valid = 27978600.0 \n",
      "Model_9_3230 \t loss_train = 32883368.0 \t loss_valid = 27789106.0 \n",
      "Model_9_3240 \t loss_train = 33527976.0 \t loss_valid = 28272230.0 \n",
      "Model_9_3250 \t loss_train = 33416502.0 \t loss_valid = 28195284.0 \n",
      "Model_9_3260 \t loss_train = 32848762.0 \t loss_valid = 27835168.0 \n",
      "Model_9_3270 \t loss_train = 33565740.0 \t loss_valid = 28378972.0 \n",
      "Model_9_3280 \t loss_train = 34180716.0 \t loss_valid = 28980710.0 \n",
      "Model_9_3290 \t loss_train = 34174472.0 \t loss_valid = 28873412.0 \n",
      "Model_9_3300 \t loss_train = 33657920.0 \t loss_valid = 28564234.0 \n",
      "Model_9_3310 \t loss_train = 33423396.0 \t loss_valid = 28178096.0 \n",
      "Model_9_3320 \t loss_train = 33254876.0 \t loss_valid = 28081360.0 \n",
      "Model_9_3330 \t loss_train = 33239806.0 \t loss_valid = 28159198.0 \n",
      "Model_9_3340 \t loss_train = 33496008.0 \t loss_valid = 28410688.0 \n",
      "Model_9_3350 \t loss_train = 33923684.0 \t loss_valid = 28641552.0 \n",
      "Model_9_3360 \t loss_train = 33199102.0 \t loss_valid = 28073778.0 \n",
      "Model_9_3370 \t loss_train = 32782394.0 \t loss_valid = 27730792.0 \n",
      "Model_9_3380 \t loss_train = 33449798.0 \t loss_valid = 28243340.0 \n",
      "Model_9_3390 \t loss_train = 33440698.0 \t loss_valid = 28238182.0 \n",
      "Model_9_3400 \t loss_train = 33109702.0 \t loss_valid = 27956098.0 \n",
      "Model_9_3410 \t loss_train = 32903684.0 \t loss_valid = 27866728.0 \n",
      "Model_9_3420 \t loss_train = 33733208.0 \t loss_valid = 28487074.0 \n",
      "Model_9_3430 \t loss_train = 33776548.0 \t loss_valid = 28500268.0 \n",
      "Model_9_3440 \t loss_train = 33257522.0 \t loss_valid = 28140936.0 \n",
      "Model_9_3450 \t loss_train = 33049508.0 \t loss_valid = 27971944.0 \n",
      "Model_9_3460 \t loss_train = 32849298.0 \t loss_valid = 27813616.0 \n",
      "Model_9_3470 \t loss_train = 33305186.0 \t loss_valid = 28126136.0 \n",
      "Model_9_3480 \t loss_train = 33569668.0 \t loss_valid = 28333248.0 \n",
      "Model_9_3490 \t loss_train = 33543072.0 \t loss_valid = 28314814.0 \n",
      "Model_9_3500 \t loss_train = 33384942.0 \t loss_valid = 28311368.0 \n",
      "Model_9_3510 \t loss_train = 33556376.0 \t loss_valid = 28265054.0 \n",
      "Model_9_3520 \t loss_train = 33534962.0 \t loss_valid = 28301368.0 \n",
      "Model_9_3530 \t loss_train = 33424486.0 \t loss_valid = 28287892.0 \n",
      "Model_9_3540 \t loss_train = 33631656.0 \t loss_valid = 28388538.0 \n",
      "Model_9_3550 \t loss_train = 33464420.0 \t loss_valid = 28281998.0 \n",
      "Model_9_3560 \t loss_train = 33383108.0 \t loss_valid = 28218416.0 \n",
      "Model_9_3570 \t loss_train = 33520516.0 \t loss_valid = 28345034.0 \n",
      "Model_9_3580 \t loss_train = 33268992.0 \t loss_valid = 28149902.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_9_3590 \t loss_train = 33129114.0 \t loss_valid = 28060388.0 \n",
      "Model_9_3600 \t loss_train = 33146718.0 \t loss_valid = 28012556.0 \n",
      "Model_9_3610 \t loss_train = 33284354.0 \t loss_valid = 28144854.0 \n",
      "Model_9_3620 \t loss_train = 33135036.0 \t loss_valid = 27959514.0 \n",
      "Model_9_3630 \t loss_train = 33085614.0 \t loss_valid = 28052010.0 \n",
      "Model_9_3640 \t loss_train = 33326828.0 \t loss_valid = 28068870.0 \n",
      "Model_9_3650 \t loss_train = 33341750.0 \t loss_valid = 28199698.0 \n",
      "Model_9_3660 \t loss_train = 33490938.0 \t loss_valid = 28344218.0 \n",
      "Model_9_3670 \t loss_train = 33629888.0 \t loss_valid = 28356868.0 \n",
      "Model_9_3680 \t loss_train = 34310672.0 \t loss_valid = 29003102.0 \n",
      "Model_9_3690 \t loss_train = 33420068.0 \t loss_valid = 28306362.0 \n",
      "Model_9_3700 \t loss_train = 33311640.0 \t loss_valid = 28007616.0 \n",
      "Model_9_3710 \t loss_train = 33527110.0 \t loss_valid = 28475212.0 \n",
      "Model_9_3720 \t loss_train = 33156610.0 \t loss_valid = 27953734.0 \n",
      "Model_9_3730 \t loss_train = 33481930.0 \t loss_valid = 28312178.0 \n",
      "Model_9_3740 \t loss_train = 33413442.0 \t loss_valid = 28206836.0 \n",
      "Model_9_3750 \t loss_train = 33409054.0 \t loss_valid = 28261892.0 \n",
      "Model_9_3760 \t loss_train = 33461914.0 \t loss_valid = 28219240.0 \n",
      "Model_9_3770 \t loss_train = 33433286.0 \t loss_valid = 28247284.0 \n",
      "Model_9_3780 \t loss_train = 33386546.0 \t loss_valid = 28194876.0 \n",
      "Model_9_3790 \t loss_train = 34037332.0 \t loss_valid = 28721882.0 \n",
      "Model_9_3800 \t loss_train = 33592888.0 \t loss_valid = 28433358.0 \n",
      "Model_9_3810 \t loss_train = 33567636.0 \t loss_valid = 28379544.0 \n",
      "Model_9_3820 \t loss_train = 33661268.0 \t loss_valid = 28444814.0 \n",
      "Model_9_3830 \t loss_train = 33394038.0 \t loss_valid = 28269362.0 \n",
      "Model_9_3840 \t loss_train = 33775620.0 \t loss_valid = 28460582.0 \n",
      "Model_9_3850 \t loss_train = 33581904.0 \t loss_valid = 28416764.0 \n",
      "Model_9_3860 \t loss_train = 32995924.0 \t loss_valid = 27899146.0 \n",
      "Model_9_3870 \t loss_train = 34182408.0 \t loss_valid = 28895836.0 \n",
      "Model_9_3880 \t loss_train = 33646580.0 \t loss_valid = 28338700.0 \n",
      "Model_9_3890 \t loss_train = 33484046.0 \t loss_valid = 28298442.0 \n",
      "Model_9_3900 \t loss_train = 34124816.0 \t loss_valid = 28722100.0 \n",
      "Model_9_3910 \t loss_train = 33665876.0 \t loss_valid = 28435746.0 \n",
      "Model_9_3920 \t loss_train = 33569500.0 \t loss_valid = 28302498.0 \n",
      "Model_9_3930 \t loss_train = 33329044.0 \t loss_valid = 28109720.0 \n",
      "Model_9_3940 \t loss_train = 33820480.0 \t loss_valid = 28609846.0 \n",
      "Model_9_3950 \t loss_train = 33894796.0 \t loss_valid = 28577640.0 \n",
      "Model_9_3960 \t loss_train = 33538508.0 \t loss_valid = 28386510.0 \n",
      "Model_9_3970 \t loss_train = 32933128.0 \t loss_valid = 27776228.0 \n",
      "Model_9_3980 \t loss_train = 32732048.0 \t loss_valid = 27666644.0 \n",
      "Model_9_3990 \t loss_train = 33024420.0 \t loss_valid = 27998034.0 \n",
      "Model_9_4000 \t loss_train = 33594332.0 \t loss_valid = 28458632.0 \n",
      "Model_9_4010 \t loss_train = 33875308.0 \t loss_valid = 28542836.0 \n",
      "Model_9_4020 \t loss_train = 33100140.0 \t loss_valid = 28012952.0 \n",
      "Model_9_4030 \t loss_train = 33037570.0 \t loss_valid = 27863148.0 \n",
      "Model_9_4040 \t loss_train = 33226534.0 \t loss_valid = 28076118.0 \n",
      "Model_9_4050 \t loss_train = 33484598.0 \t loss_valid = 28272244.0 \n",
      "Model_9_4060 \t loss_train = 33846096.0 \t loss_valid = 28564310.0 \n",
      "Model_9_4070 \t loss_train = 33682616.0 \t loss_valid = 28446868.0 \n",
      "Model_9_4080 \t loss_train = 33089352.0 \t loss_valid = 27839242.0 \n",
      "Model_9_4090 \t loss_train = 32991220.0 \t loss_valid = 27879850.0 \n",
      "Model_9_4100 \t loss_train = 33132328.0 \t loss_valid = 27951110.0 \n",
      "Model_9_4110 \t loss_train = 33112462.0 \t loss_valid = 27914552.0 \n",
      "Model_9_4120 \t loss_train = 33302422.0 \t loss_valid = 28115822.0 \n",
      "Model_9_4130 \t loss_train = 33919244.0 \t loss_valid = 28593810.0 \n",
      "Model_9_4140 \t loss_train = 33697732.0 \t loss_valid = 28474722.0 \n",
      "Model_9_4150 \t loss_train = 33336236.0 \t loss_valid = 28215340.0 \n",
      "Model_9_4160 \t loss_train = 32960202.0 \t loss_valid = 27933104.0 \n",
      "Model_9_4170 \t loss_train = 32862514.0 \t loss_valid = 27729548.0 \n",
      "Model_9_4180 \t loss_train = 33001706.0 \t loss_valid = 27831362.0 \n",
      "Model_9_4190 \t loss_train = 33552564.0 \t loss_valid = 28384736.0 \n",
      "Model_9_4200 \t loss_train = 32784438.0 \t loss_valid = 27712190.0 \n",
      "Model_9_4210 \t loss_train = 32810484.0 \t loss_valid = 27717500.0 \n",
      "Model_9_4220 \t loss_train = 32981132.0 \t loss_valid = 27782540.0 \n",
      "Model_9_4230 \t loss_train = 33460772.0 \t loss_valid = 28345496.0 \n",
      "Model_9_4240 \t loss_train = 33432034.0 \t loss_valid = 28238702.0 \n",
      "Model_9_4250 \t loss_train = 33466376.0 \t loss_valid = 28285218.0 \n",
      "Model_9_4260 \t loss_train = 32823274.0 \t loss_valid = 27707164.0 \n",
      "Model_9_4270 \t loss_train = 32507664.0 \t loss_valid = 27423640.0 \n",
      "Model_9_4280 \t loss_train = 33509068.0 \t loss_valid = 28316350.0 \n",
      "Model_9_4290 \t loss_train = 33403726.0 \t loss_valid = 28176146.0 \n",
      "Model_9_4300 \t loss_train = 33410448.0 \t loss_valid = 28185846.0 \n",
      "Model_9_4310 \t loss_train = 32769570.0 \t loss_valid = 27858172.0 \n",
      "Model_9_4320 \t loss_train = 32845004.0 \t loss_valid = 27680876.0 \n",
      "Model_9_4330 \t loss_train = 32753852.0 \t loss_valid = 27731632.0 \n",
      "Model_9_4340 \t loss_train = 33526964.0 \t loss_valid = 28268942.0 \n",
      "Model_9_4350 \t loss_train = 33249394.0 \t loss_valid = 28213160.0 \n",
      "Model_9_4360 \t loss_train = 32570906.0 \t loss_valid = 27477112.0 \n",
      "Model_9_4370 \t loss_train = 32944700.0 \t loss_valid = 27862202.0 \n",
      "Model_9_4380 \t loss_train = 33369660.0 \t loss_valid = 28179396.0 \n",
      "Model_9_4390 \t loss_train = 33132570.0 \t loss_valid = 27947690.0 \n",
      "Model_9_4400 \t loss_train = 33000386.0 \t loss_valid = 27888286.0 \n",
      "Model_9_4410 \t loss_train = 33163582.0 \t loss_valid = 28066158.0 \n",
      "Model_9_4420 \t loss_train = 33333462.0 \t loss_valid = 28151278.0 \n",
      "Model_9_4430 \t loss_train = 33243398.0 \t loss_valid = 27997474.0 \n",
      "Model_9_4440 \t loss_train = 32839516.0 \t loss_valid = 27788914.0 \n",
      "Model_9_4450 \t loss_train = 32692584.0 \t loss_valid = 27667422.0 \n",
      "Model_9_4460 \t loss_train = 32930970.0 \t loss_valid = 27799202.0 \n",
      "Model_9_4470 \t loss_train = 33354652.0 \t loss_valid = 28105642.0 \n",
      "Model_9_4480 \t loss_train = 33260052.0 \t loss_valid = 28165462.0 \n",
      "Model_9_4490 \t loss_train = 32986284.0 \t loss_valid = 27822634.0 \n",
      "Model_9_4500 \t loss_train = 32569526.0 \t loss_valid = 27607774.0 \n",
      "Model_9_4510 \t loss_train = 32818904.0 \t loss_valid = 27662330.0 \n",
      "Model_9_4520 \t loss_train = 33211140.0 \t loss_valid = 28117252.0 \n",
      "Model_9_4530 \t loss_train = 32958174.0 \t loss_valid = 27744894.0 \n",
      "Model_9_4540 \t loss_train = 32687084.0 \t loss_valid = 27618512.0 \n",
      "Model_9_4550 \t loss_train = 32686534.0 \t loss_valid = 27636852.0 \n",
      "Model_9_4560 \t loss_train = 33301454.0 \t loss_valid = 28100134.0 \n",
      "Model_9_4570 \t loss_train = 32800122.0 \t loss_valid = 27689128.0 \n",
      "Model_9_4580 \t loss_train = 33015438.0 \t loss_valid = 27870378.0 \n",
      "Model_9_4590 \t loss_train = 33286974.0 \t loss_valid = 28097040.0 \n",
      "Model_9_4600 \t loss_train = 33177666.0 \t loss_valid = 28023960.0 \n",
      "Model_9_4610 \t loss_train = 33456460.0 \t loss_valid = 28227824.0 \n",
      "Model_9_4620 \t loss_train = 33059696.0 \t loss_valid = 27861778.0 \n",
      "Model_9_4630 \t loss_train = 33210410.0 \t loss_valid = 28024782.0 \n",
      "Model_9_4640 \t loss_train = 33031634.0 \t loss_valid = 27961054.0 \n",
      "Model_9_4650 \t loss_train = 33487570.0 \t loss_valid = 28233456.0 \n",
      "Model_9_4660 \t loss_train = 33156494.0 \t loss_valid = 27986786.0 \n",
      "Model_9_4670 \t loss_train = 32969416.0 \t loss_valid = 27913318.0 \n",
      "Model_9_4680 \t loss_train = 33582100.0 \t loss_valid = 28275392.0 \n",
      "Model_9_4690 \t loss_train = 34033644.0 \t loss_valid = 28731604.0 \n",
      "Model_9_4700 \t loss_train = 33320666.0 \t loss_valid = 27995810.0 \n",
      "Model_9_4710 \t loss_train = 32780278.0 \t loss_valid = 27713880.0 \n",
      "Model_9_4720 \t loss_train = 33291588.0 \t loss_valid = 28127036.0 \n",
      "Model_9_4730 \t loss_train = 32974642.0 \t loss_valid = 27892394.0 \n",
      "Model_9_4740 \t loss_train = 32545088.0 \t loss_valid = 27505134.0 \n",
      "Model_9_4750 \t loss_train = 33342880.0 \t loss_valid = 28122048.0 \n",
      "Model_9_4760 \t loss_train = 33442576.0 \t loss_valid = 28222436.0 \n",
      "Model_9_4770 \t loss_train = 33215848.0 \t loss_valid = 28069496.0 \n",
      "Model_9_4780 \t loss_train = 32598000.0 \t loss_valid = 27547060.0 \n",
      "Model_9_4790 \t loss_train = 33526996.0 \t loss_valid = 28222420.0 \n",
      "Model_9_4800 \t loss_train = 33364842.0 \t loss_valid = 28116306.0 \n",
      "Model_9_4810 \t loss_train = 33050098.0 \t loss_valid = 27995622.0 \n",
      "Model_9_4820 \t loss_train = 33214194.0 \t loss_valid = 27933200.0 \n",
      "Model_9_4830 \t loss_train = 32994310.0 \t loss_valid = 27903438.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_9_4840 \t loss_train = 33354772.0 \t loss_valid = 28183846.0 \n",
      "Model_9_4850 \t loss_train = 33722660.0 \t loss_valid = 28492600.0 \n",
      "Model_9_4860 \t loss_train = 33119396.0 \t loss_valid = 27885142.0 \n",
      "Model_9_4870 \t loss_train = 32967508.0 \t loss_valid = 27834628.0 \n",
      "Model_9_4880 \t loss_train = 32810138.0 \t loss_valid = 27736854.0 \n",
      "Model_9_4890 \t loss_train = 32919792.0 \t loss_valid = 27784906.0 \n",
      "Model_9_4900 \t loss_train = 33295180.0 \t loss_valid = 28130016.0 \n",
      "Model_9_4910 \t loss_train = 33170680.0 \t loss_valid = 27970014.0 \n",
      "Model_9_4920 \t loss_train = 33098562.0 \t loss_valid = 27976072.0 \n",
      "Model_9_4930 \t loss_train = 32935306.0 \t loss_valid = 27844238.0 \n",
      "Model_9_4940 \t loss_train = 33552634.0 \t loss_valid = 28291474.0 \n",
      "Model_9_4950 \t loss_train = 33183152.0 \t loss_valid = 28192534.0 \n",
      "Model_9_4960 \t loss_train = 33494186.0 \t loss_valid = 28157632.0 \n",
      "Model_9_4970 \t loss_train = 33722296.0 \t loss_valid = 28491510.0 \n",
      "Model_9_4980 \t loss_train = 32939368.0 \t loss_valid = 27724224.0 \n",
      "Model_9_4990 \t loss_train = 32945246.0 \t loss_valid = 27850626.0 \n",
      "Model_9_5000 \t loss_train = 33434636.0 \t loss_valid = 28180408.0 \n",
      "Model_9_5010 \t loss_train = 33276172.0 \t loss_valid = 28073204.0 \n",
      "Model_9_5020 \t loss_train = 33548318.0 \t loss_valid = 28327572.0 \n",
      "Model_9_5030 \t loss_train = 33297432.0 \t loss_valid = 28009250.0 \n",
      "Model_9_5040 \t loss_train = 32903806.0 \t loss_valid = 27794970.0 \n",
      "Model_9_5050 \t loss_train = 33152950.0 \t loss_valid = 27965506.0 \n",
      "Model_9_5060 \t loss_train = 32989360.0 \t loss_valid = 27921044.0 \n",
      "Model_9_5070 \t loss_train = 33311214.0 \t loss_valid = 28158496.0 \n",
      "Model_9_5080 \t loss_train = 33385930.0 \t loss_valid = 28194788.0 \n",
      "Model_9_5090 \t loss_train = 33527408.0 \t loss_valid = 28345506.0 \n",
      "Model_9_5100 \t loss_train = 32879980.0 \t loss_valid = 27801164.0 \n",
      "Model_9_5110 \t loss_train = 33401414.0 \t loss_valid = 28169370.0 \n",
      "Model_9_5120 \t loss_train = 33117016.0 \t loss_valid = 27928986.0 \n",
      "Model_9_5130 \t loss_train = 33150774.0 \t loss_valid = 28018432.0 \n",
      "Model_9_5140 \t loss_train = 32967270.0 \t loss_valid = 27830608.0 \n",
      "Model_9_5150 \t loss_train = 33524916.0 \t loss_valid = 28286512.0 \n",
      "Model_9_5160 \t loss_train = 33051690.0 \t loss_valid = 27879724.0 \n",
      "Model_9_5170 \t loss_train = 33725296.0 \t loss_valid = 28441078.0 \n",
      "Model_9_5180 \t loss_train = 33710900.0 \t loss_valid = 28394528.0 \n",
      "Model_9_5190 \t loss_train = 33227700.0 \t loss_valid = 27961840.0 \n",
      "Model_9_5200 \t loss_train = 33377776.0 \t loss_valid = 28189850.0 \n",
      "Model_9_5210 \t loss_train = 33753060.0 \t loss_valid = 28479740.0 \n",
      "Model_9_5220 \t loss_train = 33379674.0 \t loss_valid = 28175598.0 \n",
      "Model_9_5230 \t loss_train = 33145404.0 \t loss_valid = 27946726.0 \n",
      "Model_9_5240 \t loss_train = 33421778.0 \t loss_valid = 28149448.0 \n",
      "Model_9_5250 \t loss_train = 33494054.0 \t loss_valid = 28128132.0 \n",
      "Model_9_5260 \t loss_train = 33526236.0 \t loss_valid = 28305408.0 \n",
      "Model_9_5270 \t loss_train = 33156322.0 \t loss_valid = 27952366.0 \n",
      "Model_9_5280 \t loss_train = 33261686.0 \t loss_valid = 28094056.0 \n",
      "Model_9_5290 \t loss_train = 33931476.0 \t loss_valid = 28554354.0 \n",
      "Model_9_5300 \t loss_train = 33878920.0 \t loss_valid = 28540970.0 \n",
      "Model_9_5310 \t loss_train = 33671636.0 \t loss_valid = 28399682.0 \n",
      "Model_9_5320 \t loss_train = 33712960.0 \t loss_valid = 28420498.0 \n",
      "Model_9_5330 \t loss_train = 33358420.0 \t loss_valid = 28090582.0 \n",
      "Model_9_5340 \t loss_train = 33675076.0 \t loss_valid = 28475524.0 \n",
      "Model_9_5350 \t loss_train = 33941456.0 \t loss_valid = 28633132.0 \n",
      "Model_9_5360 \t loss_train = 34023728.0 \t loss_valid = 28603870.0 \n",
      "Model_9_5370 \t loss_train = 33511234.0 \t loss_valid = 28220612.0 \n",
      "Model_9_5380 \t loss_train = 33461128.0 \t loss_valid = 28228146.0 \n",
      "Model_9_5390 \t loss_train = 33506680.0 \t loss_valid = 28162658.0 \n",
      "Model_9_5400 \t loss_train = 33778152.0 \t loss_valid = 28491552.0 \n",
      "Model_9_5410 \t loss_train = 33629860.0 \t loss_valid = 28319308.0 \n",
      "Model_9_5420 \t loss_train = 33468002.0 \t loss_valid = 28102254.0 \n",
      "Model_9_5430 \t loss_train = 33371978.0 \t loss_valid = 28073612.0 \n",
      "Model_9_5440 \t loss_train = 33669164.0 \t loss_valid = 28314868.0 \n",
      "Model_9_5450 \t loss_train = 33874588.0 \t loss_valid = 28512850.0 \n",
      "Model_9_5460 \t loss_train = 33650532.0 \t loss_valid = 28396642.0 \n",
      "Model_9_5470 \t loss_train = 33897692.0 \t loss_valid = 28514614.0 \n",
      "Model_9_5480 \t loss_train = 34546484.0 \t loss_valid = 29145262.0 \n",
      "Model_9_5490 \t loss_train = 34016836.0 \t loss_valid = 28633906.0 \n",
      "Model_9_5500 \t loss_train = 33568960.0 \t loss_valid = 28273278.0 \n",
      "Model_9_5510 \t loss_train = 33679936.0 \t loss_valid = 28408990.0 \n",
      "Model_9_5520 \t loss_train = 33686504.0 \t loss_valid = 28297770.0 \n",
      "Model_9_5530 \t loss_train = 33868672.0 \t loss_valid = 28495350.0 \n",
      "Model_9_5540 \t loss_train = 34145112.0 \t loss_valid = 28693140.0 \n",
      "Model_9_5550 \t loss_train = 34291928.0 \t loss_valid = 28895432.0 \n",
      "Model_9_5560 \t loss_train = 33361448.0 \t loss_valid = 28104444.0 \n",
      "Model_9_5570 \t loss_train = 34526736.0 \t loss_valid = 29035652.0 \n",
      "Model_9_5580 \t loss_train = 34418960.0 \t loss_valid = 28999572.0 \n",
      "Model_9_5590 \t loss_train = 34234732.0 \t loss_valid = 28753980.0 \n",
      "Model_9_5600 \t loss_train = 33727448.0 \t loss_valid = 28430892.0 \n",
      "Model_9_5610 \t loss_train = 33734828.0 \t loss_valid = 28320898.0 \n",
      "Model_9_5620 \t loss_train = 33672964.0 \t loss_valid = 28360438.0 \n",
      "Model_9_5630 \t loss_train = 33876444.0 \t loss_valid = 28399268.0 \n",
      "Model_9_5640 \t loss_train = 33492416.0 \t loss_valid = 28179504.0 \n",
      "Model_9_5650 \t loss_train = 34087052.0 \t loss_valid = 28668738.0 \n",
      "Model_9_5660 \t loss_train = 34343088.0 \t loss_valid = 28944132.0 \n",
      "Model_9_5670 \t loss_train = 34134264.0 \t loss_valid = 28737498.0 \n",
      "Model_9_5680 \t loss_train = 33846344.0 \t loss_valid = 28456896.0 \n",
      "Model_9_5690 \t loss_train = 33794488.0 \t loss_valid = 28337316.0 \n",
      "Model_9_5700 \t loss_train = 34435940.0 \t loss_valid = 29034192.0 \n",
      "Model_9_5710 \t loss_train = 34327364.0 \t loss_valid = 28729708.0 \n",
      "Model_9_5720 \t loss_train = 34131516.0 \t loss_valid = 28675324.0 \n",
      "Model_9_5730 \t loss_train = 34365260.0 \t loss_valid = 28834880.0 \n",
      "Model_9_5740 \t loss_train = 34453504.0 \t loss_valid = 28979158.0 \n",
      "Model_9_5750 \t loss_train = 33724852.0 \t loss_valid = 28342544.0 \n",
      "Model_9_5760 \t loss_train = 33956008.0 \t loss_valid = 28563908.0 \n",
      "Model_9_5770 \t loss_train = 34399948.0 \t loss_valid = 28868882.0 \n",
      "Model_9_5780 \t loss_train = 34300364.0 \t loss_valid = 28962440.0 \n",
      "Model_9_5790 \t loss_train = 33968388.0 \t loss_valid = 28481976.0 \n",
      "Model_9_5800 \t loss_train = 34672652.0 \t loss_valid = 29090516.0 \n",
      "Model_9_5810 \t loss_train = 34758264.0 \t loss_valid = 29257264.0 \n",
      "Model_9_5820 \t loss_train = 34155336.0 \t loss_valid = 28653612.0 \n",
      "Model_9_5830 \t loss_train = 34000100.0 \t loss_valid = 28630478.0 \n",
      "Model_9_5840 \t loss_train = 34526416.0 \t loss_valid = 28931742.0 \n",
      "Model_9_5850 \t loss_train = 34368060.0 \t loss_valid = 28768664.0 \n",
      "Model_9_5860 \t loss_train = 34188104.0 \t loss_valid = 28628186.0 \n",
      "Model_9_5870 \t loss_train = 34435548.0 \t loss_valid = 28903696.0 \n",
      "Model_9_5880 \t loss_train = 34575760.0 \t loss_valid = 29067770.0 \n",
      "Model_9_5890 \t loss_train = 34792144.0 \t loss_valid = 29197508.0 \n",
      "Model_9_5900 \t loss_train = 34376592.0 \t loss_valid = 28858074.0 \n",
      "Model_9_5910 \t loss_train = 34606692.0 \t loss_valid = 29032926.0 \n",
      "Model_9_5920 \t loss_train = 34286456.0 \t loss_valid = 28822414.0 \n",
      "Model_9_5930 \t loss_train = 34895716.0 \t loss_valid = 29228368.0 \n",
      "Model_9_5940 \t loss_train = 34385532.0 \t loss_valid = 28846984.0 \n",
      "Model_9_5950 \t loss_train = 34165068.0 \t loss_valid = 28616000.0 \n",
      "Model_9_5960 \t loss_train = 34784348.0 \t loss_valid = 29033506.0 \n",
      "Model_9_5970 \t loss_train = 34302248.0 \t loss_valid = 28799204.0 \n",
      "Model_9_5980 \t loss_train = 34509568.0 \t loss_valid = 28879644.0 \n",
      "Model_9_5990 \t loss_train = 34341568.0 \t loss_valid = 28795336.0 \n",
      "Model_9_6000 \t loss_train = 34237272.0 \t loss_valid = 28702338.0 \n",
      "Model_9_6010 \t loss_train = 34902152.0 \t loss_valid = 29189456.0 \n",
      "Model_9_6020 \t loss_train = 34520596.0 \t loss_valid = 28972702.0 \n",
      "Model_9_6030 \t loss_train = 34439480.0 \t loss_valid = 28789096.0 \n",
      "Model_9_6040 \t loss_train = 34511048.0 \t loss_valid = 28919766.0 \n",
      "Model_9_6050 \t loss_train = 34404532.0 \t loss_valid = 28816720.0 \n",
      "Model_9_6060 \t loss_train = 34554220.0 \t loss_valid = 29029344.0 \n",
      "Model_9_6070 \t loss_train = 34690160.0 \t loss_valid = 29056948.0 \n",
      "Model_9_6080 \t loss_train = 34475868.0 \t loss_valid = 28879936.0 \n",
      "Model_9_6090 \t loss_train = 34393468.0 \t loss_valid = 28880982.0 \n",
      "Model_9_6100 \t loss_train = 34522912.0 \t loss_valid = 28860612.0 \n",
      "Model_9_6110 \t loss_train = 34715112.0 \t loss_valid = 29129580.0 \n",
      "Model_9_6120 \t loss_train = 34491428.0 \t loss_valid = 28788572.0 \n",
      "Model_9_6130 \t loss_train = 34350000.0 \t loss_valid = 28850864.0 \n",
      "Model_9_6140 \t loss_train = 34819388.0 \t loss_valid = 29031026.0 \n",
      "Model_9_6150 \t loss_train = 35229268.0 \t loss_valid = 29494044.0 \n",
      "Model_9_6160 \t loss_train = 34734192.0 \t loss_valid = 29008438.0 \n",
      "Model_9_6170 \t loss_train = 35006384.0 \t loss_valid = 29229896.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_9_6180 \t loss_train = 35336392.0 \t loss_valid = 29568698.0 \n",
      "Model_9_6190 \t loss_train = 34600688.0 \t loss_valid = 28974178.0 \n",
      "Model_9_6200 \t loss_train = 34048548.0 \t loss_valid = 28475392.0 \n",
      "Model_9_6210 \t loss_train = 34923136.0 \t loss_valid = 29361506.0 \n",
      "Model_9_6220 \t loss_train = 34724308.0 \t loss_valid = 29111044.0 \n",
      "Model_9_6230 \t loss_train = 35180676.0 \t loss_valid = 29437472.0 \n",
      "Model_9_6240 \t loss_train = 34882192.0 \t loss_valid = 29185154.0 \n",
      "Model_9_6250 \t loss_train = 34935196.0 \t loss_valid = 29264726.0 \n",
      "Model_9_6260 \t loss_train = 34140600.0 \t loss_valid = 28549610.0 \n",
      "Model_9_6270 \t loss_train = 35048184.0 \t loss_valid = 29338364.0 \n",
      "Model_9_6280 \t loss_train = 35285272.0 \t loss_valid = 29569246.0 \n",
      "Model_9_6290 \t loss_train = 34962360.0 \t loss_valid = 29224136.0 \n",
      "Model_9_6300 \t loss_train = 34334424.0 \t loss_valid = 28739558.0 \n",
      "Model_9_6310 \t loss_train = 34534488.0 \t loss_valid = 28876212.0 \n",
      "Model_9_6320 \t loss_train = 34451380.0 \t loss_valid = 28902444.0 \n",
      "Model_9_6330 \t loss_train = 34562916.0 \t loss_valid = 28967288.0 \n",
      "Model_9_6340 \t loss_train = 35016632.0 \t loss_valid = 29369732.0 \n",
      "Model_9_6350 \t loss_train = 35024840.0 \t loss_valid = 29357850.0 \n",
      "Model_9_6360 \t loss_train = 34328732.0 \t loss_valid = 28741560.0 \n",
      "Model_9_6370 \t loss_train = 34714844.0 \t loss_valid = 29027496.0 \n",
      "Model_9_6380 \t loss_train = 34980296.0 \t loss_valid = 29289026.0 \n",
      "Model_9_6390 \t loss_train = 34837612.0 \t loss_valid = 29140550.0 \n",
      "Model_9_6400 \t loss_train = 35396500.0 \t loss_valid = 29616002.0 \n",
      "Model_9_6410 \t loss_train = 35234932.0 \t loss_valid = 29378624.0 \n",
      "Model_9_6420 \t loss_train = 35551188.0 \t loss_valid = 29674948.0 \n",
      "Model_9_6430 \t loss_train = 35355996.0 \t loss_valid = 29579366.0 \n",
      "Model_9_6440 \t loss_train = 34437880.0 \t loss_valid = 28750482.0 \n",
      "Model_9_6450 \t loss_train = 35202532.0 \t loss_valid = 29527884.0 \n",
      "Model_9_6460 \t loss_train = 34826880.0 \t loss_valid = 29042134.0 \n",
      "Model_9_6470 \t loss_train = 35136700.0 \t loss_valid = 29374612.0 \n",
      "Model_9_6480 \t loss_train = 35869976.0 \t loss_valid = 29885962.0 \n",
      "Model_9_6490 \t loss_train = 35119680.0 \t loss_valid = 29288480.0 \n",
      "Model_9_6500 \t loss_train = 34603092.0 \t loss_valid = 28894638.0 \n",
      "Model_9_6510 \t loss_train = 35434044.0 \t loss_valid = 29540200.0 \n",
      "Model_9_6520 \t loss_train = 34854568.0 \t loss_valid = 29167414.0 \n",
      "Model_9_6530 \t loss_train = 34552824.0 \t loss_valid = 28842584.0 \n",
      "Model_9_6540 \t loss_train = 35284028.0 \t loss_valid = 29554542.0 \n",
      "Model_9_6550 \t loss_train = 34980208.0 \t loss_valid = 29208264.0 \n",
      "Model_9_6560 \t loss_train = 35298456.0 \t loss_valid = 29439204.0 \n",
      "Model_9_6570 \t loss_train = 35564664.0 \t loss_valid = 29615910.0 \n",
      "Model_9_6580 \t loss_train = 35014044.0 \t loss_valid = 29251452.0 \n",
      "Model_9_6590 \t loss_train = 35820056.0 \t loss_valid = 29865700.0 \n",
      "Model_9_6600 \t loss_train = 35344088.0 \t loss_valid = 29418018.0 \n",
      "Model_9_6610 \t loss_train = 35289144.0 \t loss_valid = 29450538.0 \n",
      "Model_9_6620 \t loss_train = 35188316.0 \t loss_valid = 29427730.0 \n",
      "Model_9_6630 \t loss_train = 35498096.0 \t loss_valid = 29501832.0 \n",
      "Model_9_6640 \t loss_train = 35432400.0 \t loss_valid = 29509528.0 \n",
      "Model_9_6650 \t loss_train = 34759844.0 \t loss_valid = 28989250.0 \n",
      "Model_9_6660 \t loss_train = 35142476.0 \t loss_valid = 29304778.0 \n",
      "Model_9_6670 \t loss_train = 35707256.0 \t loss_valid = 29779168.0 \n",
      "Model_9_6680 \t loss_train = 35427432.0 \t loss_valid = 29515286.0 \n",
      "Model_9_6690 \t loss_train = 35280012.0 \t loss_valid = 29357492.0 \n",
      "Model_9_6700 \t loss_train = 35190380.0 \t loss_valid = 29356436.0 \n",
      "Model_9_6710 \t loss_train = 34833340.0 \t loss_valid = 29033658.0 \n",
      "Model_9_6720 \t loss_train = 35297760.0 \t loss_valid = 29442128.0 \n",
      "Model_9_6730 \t loss_train = 35567232.0 \t loss_valid = 29667416.0 \n",
      "Model_9_6740 \t loss_train = 34916936.0 \t loss_valid = 29096230.0 \n",
      "Model_9_6750 \t loss_train = 35432012.0 \t loss_valid = 29593046.0 \n",
      "Model_9_6760 \t loss_train = 36407056.0 \t loss_valid = 30334822.0 \n",
      "Model_9_6770 \t loss_train = 35316084.0 \t loss_valid = 29478384.0 \n",
      "Model_9_6780 \t loss_train = 35122864.0 \t loss_valid = 29309602.0 \n",
      "Model_9_6790 \t loss_train = 35755480.0 \t loss_valid = 29759092.0 \n",
      "Model_9_6800 \t loss_train = 35257616.0 \t loss_valid = 29455148.0 \n",
      "Model_9_6810 \t loss_train = 35614192.0 \t loss_valid = 29595598.0 \n",
      "Model_9_6820 \t loss_train = 35143880.0 \t loss_valid = 29289672.0 \n",
      "Model_9_6830 \t loss_train = 35449472.0 \t loss_valid = 29551676.0 \n",
      "Model_9_6840 \t loss_train = 35535936.0 \t loss_valid = 29599124.0 \n",
      "Model_9_6850 \t loss_train = 35566516.0 \t loss_valid = 29633706.0 \n",
      "Model_9_6860 \t loss_train = 35321652.0 \t loss_valid = 29408168.0 \n",
      "Model_9_6870 \t loss_train = 35723420.0 \t loss_valid = 29788324.0 \n",
      "Model_9_6880 \t loss_train = 35434572.0 \t loss_valid = 29451132.0 \n",
      "Model_9_6890 \t loss_train = 35438432.0 \t loss_valid = 29490378.0 \n",
      "Model_9_6900 \t loss_train = 35861292.0 \t loss_valid = 29861572.0 \n",
      "Model_9_6910 \t loss_train = 35295400.0 \t loss_valid = 29352776.0 \n",
      "Model_9_6920 \t loss_train = 35871452.0 \t loss_valid = 29876816.0 \n",
      "Model_9_6930 \t loss_train = 36208560.0 \t loss_valid = 30161598.0 \n",
      "Model_9_6940 \t loss_train = 36461564.0 \t loss_valid = 30341942.0 \n",
      "Model_9_6950 \t loss_train = 35366540.0 \t loss_valid = 29445696.0 \n",
      "Model_9_6960 \t loss_train = 36039308.0 \t loss_valid = 29972424.0 \n",
      "Model_9_6970 \t loss_train = 36054248.0 \t loss_valid = 29980918.0 \n",
      "Model_9_6980 \t loss_train = 35850640.0 \t loss_valid = 29888844.0 \n",
      "Model_9_6990 \t loss_train = 35785208.0 \t loss_valid = 29802354.0 \n",
      "Model_9_7000 \t loss_train = 35680236.0 \t loss_valid = 29762086.0 \n",
      "Model_9_7010 \t loss_train = 35991972.0 \t loss_valid = 29944166.0 \n",
      "Model_9_7020 \t loss_train = 35713480.0 \t loss_valid = 29750680.0 \n",
      "Model_9_7030 \t loss_train = 35750944.0 \t loss_valid = 29746344.0 \n",
      "Model_9_7040 \t loss_train = 35904216.0 \t loss_valid = 29792674.0 \n",
      "Model_9_7050 \t loss_train = 36106816.0 \t loss_valid = 30182766.0 \n",
      "Model_9_7060 \t loss_train = 36387716.0 \t loss_valid = 30221638.0 \n",
      "Model_9_7070 \t loss_train = 35527352.0 \t loss_valid = 29596910.0 \n",
      "Model_9_7080 \t loss_train = 35482604.0 \t loss_valid = 29485122.0 \n",
      "Model_9_7090 \t loss_train = 36137020.0 \t loss_valid = 30071890.0 \n",
      "Model_9_7100 \t loss_train = 35709024.0 \t loss_valid = 29781004.0 \n",
      "Model_9_7110 \t loss_train = 35666744.0 \t loss_valid = 29577332.0 \n",
      "Model_9_7120 \t loss_train = 35927548.0 \t loss_valid = 29890256.0 \n",
      "Model_9_7130 \t loss_train = 35587056.0 \t loss_valid = 29547504.0 \n",
      "Model_9_7140 \t loss_train = 35953348.0 \t loss_valid = 29992252.0 \n",
      "Model_9_7150 \t loss_train = 35742548.0 \t loss_valid = 29741474.0 \n",
      "Model_9_7160 \t loss_train = 35669688.0 \t loss_valid = 29671308.0 \n",
      "Model_9_7170 \t loss_train = 36540044.0 \t loss_valid = 30369960.0 \n",
      "Model_9_7180 \t loss_train = 35887204.0 \t loss_valid = 29826112.0 \n",
      "Model_9_7190 \t loss_train = 36054872.0 \t loss_valid = 30032302.0 \n",
      "Model_9_7200 \t loss_train = 35987508.0 \t loss_valid = 29868834.0 \n",
      "Model_9_7210 \t loss_train = 35786680.0 \t loss_valid = 29767380.0 \n",
      "Model_9_7220 \t loss_train = 35552364.0 \t loss_valid = 29508580.0 \n",
      "Model_9_7230 \t loss_train = 36096644.0 \t loss_valid = 29995908.0 \n",
      "Model_9_7240 \t loss_train = 36015820.0 \t loss_valid = 29898076.0 \n",
      "Model_9_7250 \t loss_train = 36121376.0 \t loss_valid = 30018300.0 \n",
      "Model_9_7260 \t loss_train = 35681388.0 \t loss_valid = 29701222.0 \n",
      "Model_9_7270 \t loss_train = 35661412.0 \t loss_valid = 29662024.0 \n",
      "Model_9_7280 \t loss_train = 35913756.0 \t loss_valid = 29911236.0 \n",
      "Model_9_7290 \t loss_train = 35788744.0 \t loss_valid = 29684470.0 \n",
      "Model_9_7300 \t loss_train = 36428140.0 \t loss_valid = 30311564.0 \n",
      "Model_9_7310 \t loss_train = 35786128.0 \t loss_valid = 29771214.0 \n",
      "Model_9_7320 \t loss_train = 35472344.0 \t loss_valid = 29435578.0 \n",
      "Model_9_7330 \t loss_train = 36115280.0 \t loss_valid = 30146620.0 \n",
      "Model_9_7340 \t loss_train = 36099248.0 \t loss_valid = 29887552.0 \n",
      "Model_9_7350 \t loss_train = 36412420.0 \t loss_valid = 30231226.0 \n",
      "Model_9_7360 \t loss_train = 36358164.0 \t loss_valid = 30216508.0 \n",
      "Model_9_7370 \t loss_train = 36524200.0 \t loss_valid = 30280806.0 \n",
      "Model_9_7380 \t loss_train = 35726220.0 \t loss_valid = 29725662.0 \n",
      "Model_9_7390 \t loss_train = 36203872.0 \t loss_valid = 30085910.0 \n",
      "Model_9_7400 \t loss_train = 35913180.0 \t loss_valid = 29857090.0 \n",
      "Model_9_7410 \t loss_train = 36317392.0 \t loss_valid = 30172192.0 \n",
      "Model_9_7420 \t loss_train = 36346680.0 \t loss_valid = 30210970.0 \n",
      "Model_9_7430 \t loss_train = 35980224.0 \t loss_valid = 29834448.0 \n",
      "Model_9_7440 \t loss_train = 36443192.0 \t loss_valid = 30223560.0 \n",
      "Model_9_7450 \t loss_train = 36659220.0 \t loss_valid = 30468494.0 \n",
      "Model_9_7460 \t loss_train = 36153924.0 \t loss_valid = 29902886.0 \n",
      "Model_9_7470 \t loss_train = 36222180.0 \t loss_valid = 30206138.0 \n",
      "Model_9_7480 \t loss_train = 35953964.0 \t loss_valid = 29863222.0 \n",
      "Model_9_7490 \t loss_train = 36249020.0 \t loss_valid = 30078748.0 \n",
      "Model_9_7500 \t loss_train = 36108692.0 \t loss_valid = 29970502.0 \n",
      "Model_9_7510 \t loss_train = 35476668.0 \t loss_valid = 29481864.0 \n",
      "Model_9_7520 \t loss_train = 36438640.0 \t loss_valid = 30237744.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_9_7530 \t loss_train = 35963292.0 \t loss_valid = 29891610.0 \n",
      "Model_9_7540 \t loss_train = 36708988.0 \t loss_valid = 30362024.0 \n",
      "Model_9_7550 \t loss_train = 36314924.0 \t loss_valid = 30136136.0 \n",
      "Model_9_7560 \t loss_train = 36202864.0 \t loss_valid = 30030294.0 \n",
      "Model_9_7570 \t loss_train = 36050532.0 \t loss_valid = 29943232.0 \n",
      "Model_9_7580 \t loss_train = 36690840.0 \t loss_valid = 30499012.0 \n",
      "Model_9_7590 \t loss_train = 36059812.0 \t loss_valid = 29896862.0 \n",
      "Model_9_7600 \t loss_train = 36092264.0 \t loss_valid = 30032402.0 \n",
      "Model_9_7610 \t loss_train = 36171176.0 \t loss_valid = 30029622.0 \n",
      "Model_9_7620 \t loss_train = 36302404.0 \t loss_valid = 30142944.0 \n",
      "Model_9_7630 \t loss_train = 36103524.0 \t loss_valid = 29934950.0 \n",
      "Model_9_7640 \t loss_train = 36070812.0 \t loss_valid = 29884306.0 \n",
      "Model_9_7650 \t loss_train = 36332688.0 \t loss_valid = 30078806.0 \n",
      "Model_9_7660 \t loss_train = 35901552.0 \t loss_valid = 29836586.0 \n",
      "Model_9_7670 \t loss_train = 36478208.0 \t loss_valid = 30271832.0 \n",
      "Model_9_7680 \t loss_train = 36240488.0 \t loss_valid = 30123982.0 \n",
      "Model_9_7690 \t loss_train = 36274988.0 \t loss_valid = 30031642.0 \n",
      "Model_9_7700 \t loss_train = 36276324.0 \t loss_valid = 30097158.0 \n",
      "Model_9_7710 \t loss_train = 36945348.0 \t loss_valid = 30560108.0 \n",
      "Model_9_7720 \t loss_train = 36830716.0 \t loss_valid = 30478478.0 \n",
      "Model_9_7730 \t loss_train = 36558320.0 \t loss_valid = 30370112.0 \n",
      "Model_9_7740 \t loss_train = 36713640.0 \t loss_valid = 30451630.0 \n",
      "Model_9_7750 \t loss_train = 36499556.0 \t loss_valid = 30208534.0 \n",
      "Model_9_7760 \t loss_train = 36837736.0 \t loss_valid = 30591824.0 \n",
      "Model_9_7770 \t loss_train = 36324036.0 \t loss_valid = 30103526.0 \n",
      "Model_9_7780 \t loss_train = 36442000.0 \t loss_valid = 30212700.0 \n",
      "Model_9_7790 \t loss_train = 36227084.0 \t loss_valid = 30013496.0 \n",
      "Model_9_7800 \t loss_train = 36674168.0 \t loss_valid = 30431086.0 \n",
      "Model_9_7810 \t loss_train = 36850736.0 \t loss_valid = 30503010.0 \n",
      "Model_9_7820 \t loss_train = 36900248.0 \t loss_valid = 30537626.0 \n",
      "Model_9_7830 \t loss_train = 36566344.0 \t loss_valid = 30339240.0 \n",
      "Model_9_7840 \t loss_train = 36859532.0 \t loss_valid = 30521834.0 \n",
      "Model_9_7850 \t loss_train = 36348364.0 \t loss_valid = 30170542.0 \n",
      "Model_9_7860 \t loss_train = 36561424.0 \t loss_valid = 30391966.0 \n",
      "Model_9_7870 \t loss_train = 36365024.0 \t loss_valid = 30080688.0 \n",
      "Model_9_7880 \t loss_train = 36851308.0 \t loss_valid = 30651986.0 \n",
      "Model_9_7890 \t loss_train = 36604808.0 \t loss_valid = 30335748.0 \n",
      "Model_9_7900 \t loss_train = 36335256.0 \t loss_valid = 30139426.0 \n",
      "Model_9_7910 \t loss_train = 36216864.0 \t loss_valid = 30039058.0 \n",
      "Model_9_7920 \t loss_train = 36834468.0 \t loss_valid = 30504466.0 \n",
      "Model_9_7930 \t loss_train = 37086384.0 \t loss_valid = 30780268.0 \n",
      "Model_9_7940 \t loss_train = 37042228.0 \t loss_valid = 30720884.0 \n",
      "Model_9_7950 \t loss_train = 37049420.0 \t loss_valid = 30703402.0 \n",
      "Model_9_7960 \t loss_train = 37078300.0 \t loss_valid = 30675924.0 \n",
      "Model_9_7970 \t loss_train = 36803508.0 \t loss_valid = 30531922.0 \n",
      "Model_9_7980 \t loss_train = 37236008.0 \t loss_valid = 30829368.0 \n",
      "Model_9_7990 \t loss_train = 37011328.0 \t loss_valid = 30736738.0 \n",
      "Model_9_8000 \t loss_train = 36587680.0 \t loss_valid = 30391488.0 \n",
      "Model_9_8010 \t loss_train = 36843716.0 \t loss_valid = 30561078.0 \n",
      "Model_9_8020 \t loss_train = 37036012.0 \t loss_valid = 30716890.0 \n",
      "Model_9_8030 \t loss_train = 36934020.0 \t loss_valid = 30633680.0 \n",
      "Model_9_8040 \t loss_train = 37182148.0 \t loss_valid = 30840708.0 \n",
      "Model_9_8050 \t loss_train = 36582516.0 \t loss_valid = 30271854.0 \n",
      "Model_9_8060 \t loss_train = 36596348.0 \t loss_valid = 30318386.0 \n",
      "Model_9_8070 \t loss_train = 36494488.0 \t loss_valid = 30210330.0 \n",
      "Model_9_8080 \t loss_train = 36387532.0 \t loss_valid = 30299072.0 \n",
      "Model_9_8090 \t loss_train = 36603612.0 \t loss_valid = 30272158.0 \n",
      "Model_9_8100 \t loss_train = 36439572.0 \t loss_valid = 30194204.0 \n",
      "Model_9_8110 \t loss_train = 36701208.0 \t loss_valid = 30532304.0 \n",
      "Model_9_8120 \t loss_train = 37087096.0 \t loss_valid = 30675504.0 \n",
      "Model_9_8130 \t loss_train = 36569416.0 \t loss_valid = 30390472.0 \n",
      "Model_9_8140 \t loss_train = 37076444.0 \t loss_valid = 30753344.0 \n",
      "Model_9_8150 \t loss_train = 36800664.0 \t loss_valid = 30475798.0 \n",
      "Model_9_8160 \t loss_train = 36674872.0 \t loss_valid = 30470792.0 \n",
      "Model_9_8170 \t loss_train = 37004104.0 \t loss_valid = 30686790.0 \n",
      "Model_9_8180 \t loss_train = 36922664.0 \t loss_valid = 30726868.0 \n",
      "Model_9_8190 \t loss_train = 37171408.0 \t loss_valid = 30805340.0 \n",
      "Model_9_8200 \t loss_train = 36354900.0 \t loss_valid = 30172426.0 \n",
      "Model_9_8210 \t loss_train = 36826604.0 \t loss_valid = 30534002.0 \n",
      "Model_9_8220 \t loss_train = 37098816.0 \t loss_valid = 30699938.0 \n",
      "Model_9_8230 \t loss_train = 36870800.0 \t loss_valid = 30628160.0 \n",
      "Model_9_8240 \t loss_train = 37390784.0 \t loss_valid = 30893818.0 \n",
      "Model_9_8250 \t loss_train = 37095244.0 \t loss_valid = 30805564.0 \n",
      "Model_9_8260 \t loss_train = 36848688.0 \t loss_valid = 30597604.0 \n",
      "Model_9_8270 \t loss_train = 36759936.0 \t loss_valid = 30434542.0 \n",
      "Model_9_8280 \t loss_train = 36998908.0 \t loss_valid = 30678952.0 \n",
      "Model_9_8290 \t loss_train = 36842124.0 \t loss_valid = 30570878.0 \n",
      "Model_9_8300 \t loss_train = 37104424.0 \t loss_valid = 30741062.0 \n",
      "Model_9_8310 \t loss_train = 37087716.0 \t loss_valid = 30728584.0 \n",
      "Model_9_8320 \t loss_train = 37255028.0 \t loss_valid = 30838480.0 \n",
      "Model_9_8330 \t loss_train = 36816728.0 \t loss_valid = 30483652.0 \n",
      "Model_9_8340 \t loss_train = 37695064.0 \t loss_valid = 31253652.0 \n",
      "Model_9_8350 \t loss_train = 37132352.0 \t loss_valid = 30751228.0 \n",
      "Model_9_8360 \t loss_train = 37559096.0 \t loss_valid = 31083406.0 \n",
      "Model_9_8370 \t loss_train = 36871172.0 \t loss_valid = 30422206.0 \n",
      "Model_9_8380 \t loss_train = 36984876.0 \t loss_valid = 30600770.0 \n",
      "Model_9_8390 \t loss_train = 37278356.0 \t loss_valid = 30761830.0 \n",
      "Model_9_8400 \t loss_train = 37356860.0 \t loss_valid = 30905424.0 \n",
      "Model_9_8410 \t loss_train = 37039052.0 \t loss_valid = 30606558.0 \n",
      "Model_9_8420 \t loss_train = 36504780.0 \t loss_valid = 30276494.0 \n",
      "Model_9_8430 \t loss_train = 37232200.0 \t loss_valid = 30869244.0 \n",
      "Model_9_8440 \t loss_train = 37152464.0 \t loss_valid = 30750278.0 \n",
      "Model_9_8450 \t loss_train = 36979860.0 \t loss_valid = 30646878.0 \n",
      "Model_9_8460 \t loss_train = 37724952.0 \t loss_valid = 31154660.0 \n",
      "Model_9_8470 \t loss_train = 37150848.0 \t loss_valid = 30798690.0 \n",
      "Model_9_8480 \t loss_train = 37351140.0 \t loss_valid = 30903644.0 \n",
      "Model_9_8490 \t loss_train = 36750760.0 \t loss_valid = 30438078.0 \n",
      "Model_9_8500 \t loss_train = 37050616.0 \t loss_valid = 30711128.0 \n",
      "Model_9_8510 \t loss_train = 37010892.0 \t loss_valid = 30665248.0 \n",
      "Model_9_8520 \t loss_train = 37226936.0 \t loss_valid = 30872664.0 \n",
      "Model_9_8530 \t loss_train = 36749268.0 \t loss_valid = 30480464.0 \n",
      "Model_9_8540 \t loss_train = 36926720.0 \t loss_valid = 30485930.0 \n",
      "Model_9_8550 \t loss_train = 37058064.0 \t loss_valid = 30652132.0 \n",
      "Model_9_8560 \t loss_train = 36785056.0 \t loss_valid = 30469004.0 \n",
      "Model_9_8570 \t loss_train = 36983636.0 \t loss_valid = 30568302.0 \n",
      "Model_9_8580 \t loss_train = 37220212.0 \t loss_valid = 30822638.0 \n",
      "Model_9_8590 \t loss_train = 36845736.0 \t loss_valid = 30423744.0 \n",
      "Model_9_8600 \t loss_train = 37638420.0 \t loss_valid = 31199482.0 \n",
      "Model_9_8610 \t loss_train = 37509420.0 \t loss_valid = 31005428.0 \n",
      "Model_9_8620 \t loss_train = 37289000.0 \t loss_valid = 30968866.0 \n",
      "Model_9_8630 \t loss_train = 37420992.0 \t loss_valid = 30876558.0 \n",
      "Model_9_8640 \t loss_train = 36853128.0 \t loss_valid = 30636186.0 \n",
      "Model_9_8650 \t loss_train = 36929656.0 \t loss_valid = 30639350.0 \n",
      "Model_9_8660 \t loss_train = 37297872.0 \t loss_valid = 30874004.0 \n",
      "Model_9_8670 \t loss_train = 37727144.0 \t loss_valid = 31252240.0 \n",
      "Model_9_8680 \t loss_train = 37229124.0 \t loss_valid = 30829960.0 \n",
      "Model_9_8690 \t loss_train = 37104808.0 \t loss_valid = 30721340.0 \n",
      "Model_9_8700 \t loss_train = 37079816.0 \t loss_valid = 30758552.0 \n",
      "Model_9_8710 \t loss_train = 37105392.0 \t loss_valid = 30776168.0 \n",
      "Model_9_8720 \t loss_train = 36610316.0 \t loss_valid = 30380370.0 \n",
      "Model_9_8730 \t loss_train = 37817432.0 \t loss_valid = 31364618.0 \n",
      "Model_9_8740 \t loss_train = 37378280.0 \t loss_valid = 30927786.0 \n",
      "Model_9_8750 \t loss_train = 37261348.0 \t loss_valid = 30880614.0 \n",
      "Model_9_8760 \t loss_train = 37268548.0 \t loss_valid = 30838866.0 \n",
      "Model_9_8770 \t loss_train = 38023552.0 \t loss_valid = 31410770.0 \n",
      "Model_9_8780 \t loss_train = 37096732.0 \t loss_valid = 30680152.0 \n",
      "Model_9_8790 \t loss_train = 37302912.0 \t loss_valid = 30897872.0 \n",
      "Model_9_8800 \t loss_train = 37060256.0 \t loss_valid = 30641468.0 \n",
      "Model_9_8810 \t loss_train = 37636036.0 \t loss_valid = 31199984.0 \n",
      "Model_9_8820 \t loss_train = 37564044.0 \t loss_valid = 31029960.0 \n",
      "Model_9_8830 \t loss_train = 37835576.0 \t loss_valid = 31356700.0 \n",
      "Model_9_8840 \t loss_train = 37329228.0 \t loss_valid = 30894150.0 \n",
      "Model_9_8850 \t loss_train = 37676320.0 \t loss_valid = 31179058.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_9_8860 \t loss_train = 37646772.0 \t loss_valid = 31127546.0 \n",
      "Model_9_8870 \t loss_train = 37550796.0 \t loss_valid = 31130416.0 \n",
      "Model_9_8880 \t loss_train = 36972896.0 \t loss_valid = 30606090.0 \n",
      "Model_9_8890 \t loss_train = 37121964.0 \t loss_valid = 30768418.0 \n",
      "Model_9_8900 \t loss_train = 37277740.0 \t loss_valid = 30910114.0 \n",
      "Model_9_8910 \t loss_train = 38003688.0 \t loss_valid = 31307470.0 \n",
      "Model_9_8920 \t loss_train = 37101724.0 \t loss_valid = 30699880.0 \n",
      "Model_9_8930 \t loss_train = 36953292.0 \t loss_valid = 30561182.0 \n",
      "Model_9_8940 \t loss_train = 37572800.0 \t loss_valid = 31103754.0 \n",
      "Model_9_8950 \t loss_train = 36922528.0 \t loss_valid = 30580236.0 \n",
      "Model_9_8960 \t loss_train = 37128516.0 \t loss_valid = 30722948.0 \n",
      "Model_9_8970 \t loss_train = 37475524.0 \t loss_valid = 31063836.0 \n",
      "Model_9_8980 \t loss_train = 37569136.0 \t loss_valid = 31137554.0 \n",
      "Model_9_8990 \t loss_train = 37560852.0 \t loss_valid = 31085768.0 \n",
      "Model_9_9000 \t loss_train = 37966484.0 \t loss_valid = 31373066.0 \n",
      "Model_9_9010 \t loss_train = 37912256.0 \t loss_valid = 31361924.0 \n",
      "Model_9_9020 \t loss_train = 37650368.0 \t loss_valid = 31102812.0 \n",
      "Model_9_9030 \t loss_train = 37711848.0 \t loss_valid = 31217254.0 \n",
      "Model_9_9040 \t loss_train = 37820696.0 \t loss_valid = 31300334.0 \n",
      "Model_9_9050 \t loss_train = 37527580.0 \t loss_valid = 31075120.0 \n",
      "Model_9_9060 \t loss_train = 37395188.0 \t loss_valid = 30963244.0 \n",
      "Model_9_9070 \t loss_train = 37108460.0 \t loss_valid = 30649280.0 \n",
      "Model_9_9080 \t loss_train = 38224684.0 \t loss_valid = 31557088.0 \n",
      "Model_9_9090 \t loss_train = 37322776.0 \t loss_valid = 30825924.0 \n",
      "Model_9_9100 \t loss_train = 37574144.0 \t loss_valid = 31062894.0 \n",
      "Model_9_9110 \t loss_train = 37444760.0 \t loss_valid = 31031268.0 \n",
      "Model_9_9120 \t loss_train = 37812572.0 \t loss_valid = 31233700.0 \n",
      "Model_9_9130 \t loss_train = 37550944.0 \t loss_valid = 31066744.0 \n",
      "Model_9_9140 \t loss_train = 38118200.0 \t loss_valid = 31513198.0 \n",
      "Model_9_9150 \t loss_train = 37398804.0 \t loss_valid = 30939468.0 \n",
      "Model_9_9160 \t loss_train = 37801956.0 \t loss_valid = 31221166.0 \n",
      "Model_9_9170 \t loss_train = 37889308.0 \t loss_valid = 31370256.0 \n",
      "Model_9_9180 \t loss_train = 37640308.0 \t loss_valid = 31182854.0 \n",
      "Model_9_9190 \t loss_train = 38141660.0 \t loss_valid = 31566422.0 \n",
      "Model_9_9200 \t loss_train = 37242460.0 \t loss_valid = 30807464.0 \n",
      "Model_9_9210 \t loss_train = 37364176.0 \t loss_valid = 30923418.0 \n",
      "Model_9_9220 \t loss_train = 37670220.0 \t loss_valid = 31190370.0 \n",
      "Model_9_9230 \t loss_train = 37762828.0 \t loss_valid = 31211836.0 \n",
      "Model_9_9240 \t loss_train = 37784844.0 \t loss_valid = 31323072.0 \n",
      "Model_9_9250 \t loss_train = 37572624.0 \t loss_valid = 31072124.0 \n",
      "Model_9_9260 \t loss_train = 37210468.0 \t loss_valid = 30853360.0 \n",
      "Model_9_9270 \t loss_train = 37936460.0 \t loss_valid = 31327434.0 \n",
      "Model_9_9280 \t loss_train = 37657248.0 \t loss_valid = 31154368.0 \n",
      "Model_9_9290 \t loss_train = 37868076.0 \t loss_valid = 31386726.0 \n",
      "Model_9_9300 \t loss_train = 38173444.0 \t loss_valid = 31559804.0 \n",
      "Model_9_9310 \t loss_train = 37460012.0 \t loss_valid = 31011060.0 \n",
      "Model_9_9320 \t loss_train = 37433364.0 \t loss_valid = 30955990.0 \n",
      "Model_9_9330 \t loss_train = 38006688.0 \t loss_valid = 31394594.0 \n",
      "Model_9_9340 \t loss_train = 37624168.0 \t loss_valid = 31161900.0 \n",
      "Model_9_9350 \t loss_train = 37524720.0 \t loss_valid = 30988886.0 \n",
      "Model_9_9360 \t loss_train = 37800180.0 \t loss_valid = 31267362.0 \n",
      "Model_9_9370 \t loss_train = 38414140.0 \t loss_valid = 31755128.0 \n",
      "Model_9_9380 \t loss_train = 37755720.0 \t loss_valid = 31201018.0 \n",
      "Model_9_9390 \t loss_train = 37298996.0 \t loss_valid = 30869160.0 \n",
      "Model_9_9400 \t loss_train = 37464040.0 \t loss_valid = 30994158.0 \n",
      "Model_9_9410 \t loss_train = 37436992.0 \t loss_valid = 30974944.0 \n",
      "Model_9_9420 \t loss_train = 36710172.0 \t loss_valid = 30488238.0 \n",
      "Model_9_9430 \t loss_train = 38149148.0 \t loss_valid = 31542366.0 \n",
      "Model_9_9440 \t loss_train = 38293000.0 \t loss_valid = 31618924.0 \n",
      "Model_9_9450 \t loss_train = 37878544.0 \t loss_valid = 31407366.0 \n",
      "Model_9_9460 \t loss_train = 38143840.0 \t loss_valid = 31616860.0 \n",
      "Model_9_9470 \t loss_train = 37725356.0 \t loss_valid = 31197424.0 \n",
      "Model_9_9480 \t loss_train = 37817740.0 \t loss_valid = 31279720.0 \n",
      "Model_9_9490 \t loss_train = 37305680.0 \t loss_valid = 30875168.0 \n",
      "Model_9_9500 \t loss_train = 37578532.0 \t loss_valid = 31118706.0 \n",
      "Model_9_9510 \t loss_train = 37379060.0 \t loss_valid = 30921864.0 \n",
      "Model_9_9520 \t loss_train = 38253260.0 \t loss_valid = 31628004.0 \n",
      "Model_9_9530 \t loss_train = 38414968.0 \t loss_valid = 31742476.0 \n",
      "Model_9_9540 \t loss_train = 37941456.0 \t loss_valid = 31321372.0 \n",
      "Model_9_9550 \t loss_train = 38359108.0 \t loss_valid = 31678632.0 \n",
      "Model_9_9560 \t loss_train = 37727816.0 \t loss_valid = 31119982.0 \n",
      "Model_9_9570 \t loss_train = 38273676.0 \t loss_valid = 31573788.0 \n",
      "Model_9_9580 \t loss_train = 37914528.0 \t loss_valid = 31357472.0 \n",
      "Model_9_9590 \t loss_train = 38011604.0 \t loss_valid = 31443586.0 \n",
      "Model_9_9600 \t loss_train = 38257408.0 \t loss_valid = 31605334.0 \n",
      "Model_9_9610 \t loss_train = 37798616.0 \t loss_valid = 31244664.0 \n",
      "Model_9_9620 \t loss_train = 37462912.0 \t loss_valid = 30929208.0 \n",
      "Model_9_9630 \t loss_train = 38232476.0 \t loss_valid = 31631132.0 \n",
      "Model_9_9640 \t loss_train = 37728084.0 \t loss_valid = 31157718.0 \n",
      "Model_9_9650 \t loss_train = 37593856.0 \t loss_valid = 31026616.0 \n",
      "Model_9_9660 \t loss_train = 37839176.0 \t loss_valid = 31322704.0 \n",
      "Model_9_9670 \t loss_train = 37654560.0 \t loss_valid = 31152222.0 \n",
      "Model_9_9680 \t loss_train = 38096568.0 \t loss_valid = 31534348.0 \n",
      "Model_9_9690 \t loss_train = 37834568.0 \t loss_valid = 31332576.0 \n",
      "Model_9_9700 \t loss_train = 37710060.0 \t loss_valid = 31189308.0 \n",
      "Model_9_9710 \t loss_train = 37932620.0 \t loss_valid = 31403478.0 \n",
      "Model_9_9720 \t loss_train = 38043656.0 \t loss_valid = 31427012.0 \n",
      "Model_9_9730 \t loss_train = 37870852.0 \t loss_valid = 31370692.0 \n",
      "Model_9_9740 \t loss_train = 37889960.0 \t loss_valid = 31353660.0 \n",
      "Model_9_9750 \t loss_train = 37852748.0 \t loss_valid = 31346864.0 \n",
      "Model_9_9760 \t loss_train = 37844732.0 \t loss_valid = 31271592.0 \n",
      "Model_9_9770 \t loss_train = 37618424.0 \t loss_valid = 31184630.0 \n",
      "Model_9_9780 \t loss_train = 37251864.0 \t loss_valid = 30837624.0 \n",
      "Model_9_9790 \t loss_train = 37495104.0 \t loss_valid = 31062974.0 \n",
      "Model_9_9800 \t loss_train = 37658640.0 \t loss_valid = 31135096.0 \n",
      "Model_9_9810 \t loss_train = 37717708.0 \t loss_valid = 31241030.0 \n",
      "Model_9_9820 \t loss_train = 37399836.0 \t loss_valid = 30912522.0 \n",
      "Model_9_9830 \t loss_train = 38010088.0 \t loss_valid = 31482476.0 \n",
      "Model_9_9840 \t loss_train = 37881372.0 \t loss_valid = 31337990.0 \n",
      "Model_9_9850 \t loss_train = 37897360.0 \t loss_valid = 31519788.0 \n",
      "Model_9_9860 \t loss_train = 38109468.0 \t loss_valid = 31599426.0 \n",
      "Model_9_9870 \t loss_train = 37707940.0 \t loss_valid = 31265292.0 \n",
      "Model_9_9880 \t loss_train = 37435384.0 \t loss_valid = 31020026.0 \n",
      "Model_9_9890 \t loss_train = 37839684.0 \t loss_valid = 31401618.0 \n",
      "Model_9_9900 \t loss_train = 37587768.0 \t loss_valid = 31182658.0 \n",
      "Model_9_9910 \t loss_train = 38110140.0 \t loss_valid = 31653920.0 \n",
      "Model_9_9920 \t loss_train = 37881776.0 \t loss_valid = 31388046.0 \n",
      "Model_9_9930 \t loss_train = 38220708.0 \t loss_valid = 31793752.0 \n",
      "Model_9_9940 \t loss_train = 38145304.0 \t loss_valid = 31645462.0 \n",
      "Model_9_9950 \t loss_train = 37693428.0 \t loss_valid = 31323086.0 \n",
      "Model_9_9960 \t loss_train = 37620304.0 \t loss_valid = 31192206.0 \n",
      "Model_9_9970 \t loss_train = 37676032.0 \t loss_valid = 31181262.0 \n",
      "Model_9_9980 \t loss_train = 38165044.0 \t loss_valid = 31682478.0 \n",
      "Model_9_9990 \t loss_train = 37597192.0 \t loss_valid = 31117518.0 \n",
      "Model_9_10000 \t loss_train = 37478580.0 \t loss_valid = 30975858.0 \n",
      "Model_9_10010 \t loss_train = 38486908.0 \t loss_valid = 31895496.0 \n",
      "Model_9_10020 \t loss_train = 37281732.0 \t loss_valid = 30905664.0 \n",
      "Model_9_10030 \t loss_train = 37743216.0 \t loss_valid = 31373444.0 \n",
      "Model_9_10040 \t loss_train = 37901424.0 \t loss_valid = 31459416.0 \n",
      "Model_9_10050 \t loss_train = 37547936.0 \t loss_valid = 31147840.0 \n",
      "Model_9_10060 \t loss_train = 37656436.0 \t loss_valid = 31271026.0 \n",
      "Model_9_10070 \t loss_train = 38310836.0 \t loss_valid = 31831738.0 \n",
      "Model_9_10080 \t loss_train = 37982112.0 \t loss_valid = 31436322.0 \n",
      "Model_9_10090 \t loss_train = 37703440.0 \t loss_valid = 31267780.0 \n",
      "Model_9_10100 \t loss_train = 38067960.0 \t loss_valid = 31562246.0 \n",
      "Model_9_10110 \t loss_train = 37875416.0 \t loss_valid = 31373836.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_9_10120 \t loss_train = 37449060.0 \t loss_valid = 31032668.0 \n",
      "Model_9_10130 \t loss_train = 38186784.0 \t loss_valid = 31633756.0 \n",
      "Model_9_10140 \t loss_train = 38052844.0 \t loss_valid = 31504340.0 \n",
      "Model_9_10150 \t loss_train = 37374640.0 \t loss_valid = 31049844.0 \n",
      "Model_9_10160 \t loss_train = 37739704.0 \t loss_valid = 31255792.0 \n",
      "Model_9_10170 \t loss_train = 37766684.0 \t loss_valid = 31355168.0 \n",
      "Model_9_10180 \t loss_train = 38027104.0 \t loss_valid = 31580406.0 \n",
      "Model_9_10190 \t loss_train = 38379384.0 \t loss_valid = 31801476.0 \n",
      "Model_9_10200 \t loss_train = 37449540.0 \t loss_valid = 31055650.0 \n",
      "Model_9_10210 \t loss_train = 37969396.0 \t loss_valid = 31409278.0 \n",
      "Model_9_10220 \t loss_train = 37707888.0 \t loss_valid = 31191558.0 \n",
      "Model_9_10230 \t loss_train = 37446832.0 \t loss_valid = 31039206.0 \n",
      "Model_9_10240 \t loss_train = 37914612.0 \t loss_valid = 31446124.0 \n",
      "Model_9_10250 \t loss_train = 38023568.0 \t loss_valid = 31536744.0 \n",
      "Model_9_10260 \t loss_train = 37784336.0 \t loss_valid = 31312312.0 \n",
      "Model_9_10270 \t loss_train = 37322264.0 \t loss_valid = 30928732.0 \n",
      "Model_9_10280 \t loss_train = 37652476.0 \t loss_valid = 31130416.0 \n",
      "Model_9_10290 \t loss_train = 38108572.0 \t loss_valid = 31506694.0 \n",
      "Model_9_10300 \t loss_train = 37720952.0 \t loss_valid = 31272888.0 \n",
      "Model_9_10310 \t loss_train = 37917664.0 \t loss_valid = 31427028.0 \n",
      "Model_9_10320 \t loss_train = 37724252.0 \t loss_valid = 31209168.0 \n",
      "Model_9_10330 \t loss_train = 37716776.0 \t loss_valid = 31218150.0 \n",
      "Model_9_10340 \t loss_train = 38189364.0 \t loss_valid = 31568878.0 \n",
      "Model_9_10350 \t loss_train = 37808552.0 \t loss_valid = 31306176.0 \n",
      "Model_9_10360 \t loss_train = 37462404.0 \t loss_valid = 31061276.0 \n",
      "Model_9_10370 \t loss_train = 38060680.0 \t loss_valid = 31496044.0 \n",
      "Model_9_10380 \t loss_train = 38306628.0 \t loss_valid = 31745644.0 \n",
      "Model_9_10390 \t loss_train = 38086312.0 \t loss_valid = 31546946.0 \n",
      "Model_9_10400 \t loss_train = 37657268.0 \t loss_valid = 31214766.0 \n",
      "Model_9_10410 \t loss_train = 37801976.0 \t loss_valid = 31392268.0 \n",
      "Model_9_10420 \t loss_train = 37906960.0 \t loss_valid = 31433058.0 \n",
      "Model_9_10430 \t loss_train = 38148400.0 \t loss_valid = 31589410.0 \n",
      "Model_9_10440 \t loss_train = 38314568.0 \t loss_valid = 31693444.0 \n",
      "Model_9_10450 \t loss_train = 38137120.0 \t loss_valid = 31578336.0 \n",
      "Model_9_10460 \t loss_train = 38036632.0 \t loss_valid = 31497614.0 \n",
      "Model_9_10470 \t loss_train = 38030048.0 \t loss_valid = 31516088.0 \n",
      "Model_9_10480 \t loss_train = 38335364.0 \t loss_valid = 31728064.0 \n",
      "Model_9_10490 \t loss_train = 37928736.0 \t loss_valid = 31432432.0 \n",
      "Model_9_10500 \t loss_train = 38229172.0 \t loss_valid = 31688590.0 \n",
      "Model_9_10510 \t loss_train = 37815988.0 \t loss_valid = 31311116.0 \n",
      "Model_9_10520 \t loss_train = 38309100.0 \t loss_valid = 31753620.0 \n",
      "Model_9_10530 \t loss_train = 37939572.0 \t loss_valid = 31416712.0 \n",
      "Model_9_10540 \t loss_train = 37832080.0 \t loss_valid = 31394506.0 \n",
      "Model_9_10550 \t loss_train = 37732024.0 \t loss_valid = 31231994.0 \n",
      "Model_9_10560 \t loss_train = 37900668.0 \t loss_valid = 31379182.0 \n",
      "Model_9_10570 \t loss_train = 37418028.0 \t loss_valid = 31023840.0 \n",
      "Model_9_10580 \t loss_train = 37821272.0 \t loss_valid = 31300260.0 \n",
      "Model_9_10590 \t loss_train = 38031764.0 \t loss_valid = 31493538.0 \n",
      "Model_9_10600 \t loss_train = 38203248.0 \t loss_valid = 31648250.0 \n",
      "Model_9_10610 \t loss_train = 37513528.0 \t loss_valid = 31003742.0 \n",
      "Model_9_10620 \t loss_train = 37908060.0 \t loss_valid = 31450974.0 \n",
      "Model_9_10630 \t loss_train = 37646024.0 \t loss_valid = 31231408.0 \n",
      "Model_9_10640 \t loss_train = 37243360.0 \t loss_valid = 30899052.0 \n",
      "Model_9_10650 \t loss_train = 37740048.0 \t loss_valid = 31261632.0 \n",
      "Model_9_10660 \t loss_train = 38289300.0 \t loss_valid = 31677374.0 \n",
      "Model_9_10670 \t loss_train = 39042680.0 \t loss_valid = 32252312.0 \n",
      "Model_9_10680 \t loss_train = 38657608.0 \t loss_valid = 32031548.0 \n",
      "Model_9_10690 \t loss_train = 37746916.0 \t loss_valid = 31218906.0 \n",
      "Model_9_10700 \t loss_train = 38657564.0 \t loss_valid = 31982294.0 \n",
      "Model_9_10710 \t loss_train = 38440536.0 \t loss_valid = 31799508.0 \n",
      "Model_9_10720 \t loss_train = 38020140.0 \t loss_valid = 31518376.0 \n",
      "Model_9_10730 \t loss_train = 37594000.0 \t loss_valid = 31104028.0 \n",
      "Model_9_10740 \t loss_train = 38111760.0 \t loss_valid = 31521154.0 \n",
      "Model_9_10750 \t loss_train = 38586776.0 \t loss_valid = 31920426.0 \n",
      "Model_9_10760 \t loss_train = 38099764.0 \t loss_valid = 31488218.0 \n",
      "Model_9_10770 \t loss_train = 38693044.0 \t loss_valid = 32012578.0 \n",
      "Model_9_10780 \t loss_train = 37855284.0 \t loss_valid = 31390384.0 \n",
      "Model_9_10790 \t loss_train = 38254336.0 \t loss_valid = 31660698.0 \n",
      "Model_9_10800 \t loss_train = 37986860.0 \t loss_valid = 31434648.0 \n",
      "Model_9_10810 \t loss_train = 37454308.0 \t loss_valid = 31075796.0 \n",
      "Model_9_10820 \t loss_train = 38075384.0 \t loss_valid = 31528160.0 \n",
      "Model_9_10830 \t loss_train = 37461912.0 \t loss_valid = 31050282.0 \n",
      "Model_9_10840 \t loss_train = 37836728.0 \t loss_valid = 31267476.0 \n",
      "Model_9_10850 \t loss_train = 37935628.0 \t loss_valid = 31365906.0 \n",
      "Model_9_10860 \t loss_train = 37755824.0 \t loss_valid = 31251986.0 \n",
      "Model_9_10870 \t loss_train = 37922756.0 \t loss_valid = 31420104.0 \n",
      "Model_9_10880 \t loss_train = 37836784.0 \t loss_valid = 31325560.0 \n",
      "Model_9_10890 \t loss_train = 37709456.0 \t loss_valid = 31185744.0 \n",
      "Model_9_10900 \t loss_train = 37680504.0 \t loss_valid = 31159524.0 \n",
      "Model_9_10910 \t loss_train = 38015588.0 \t loss_valid = 31500872.0 \n",
      "Model_9_10920 \t loss_train = 38042992.0 \t loss_valid = 31465130.0 \n",
      "Model_9_10930 \t loss_train = 38635288.0 \t loss_valid = 32049512.0 \n",
      "Model_9_10940 \t loss_train = 37862984.0 \t loss_valid = 31341754.0 \n",
      "Model_9_10950 \t loss_train = 37909380.0 \t loss_valid = 31459900.0 \n",
      "Model_9_10960 \t loss_train = 37296512.0 \t loss_valid = 30860184.0 \n",
      "Model_9_10970 \t loss_train = 38093560.0 \t loss_valid = 31574370.0 \n",
      "Model_9_10980 \t loss_train = 37936224.0 \t loss_valid = 31374400.0 \n",
      "Model_9_10990 \t loss_train = 37463532.0 \t loss_valid = 31002254.0 \n",
      "Model_9_11000 \t loss_train = 38171392.0 \t loss_valid = 31601070.0 \n",
      "Model_9_11010 \t loss_train = 38080172.0 \t loss_valid = 31485946.0 \n",
      "Model_9_11020 \t loss_train = 37909292.0 \t loss_valid = 31434250.0 \n",
      "Model_9_11030 \t loss_train = 37729796.0 \t loss_valid = 31285542.0 \n",
      "Model_9_11040 \t loss_train = 38343848.0 \t loss_valid = 31800232.0 \n",
      "Model_9_11050 \t loss_train = 37664108.0 \t loss_valid = 31246046.0 \n",
      "Model_9_11060 \t loss_train = 38273180.0 \t loss_valid = 31736446.0 \n",
      "Model_9_11070 \t loss_train = 38777876.0 \t loss_valid = 32092770.0 \n",
      "Model_9_11080 \t loss_train = 37492920.0 \t loss_valid = 31003458.0 \n",
      "Model_9_11090 \t loss_train = 37957824.0 \t loss_valid = 31437976.0 \n",
      "Model_9_11100 \t loss_train = 37660516.0 \t loss_valid = 31190920.0 \n",
      "Model_9_11110 \t loss_train = 37657864.0 \t loss_valid = 31193680.0 \n",
      "Model_9_11120 \t loss_train = 37905880.0 \t loss_valid = 31447186.0 \n",
      "Model_9_11130 \t loss_train = 37602592.0 \t loss_valid = 31202872.0 \n",
      "Model_9_11140 \t loss_train = 37594584.0 \t loss_valid = 31144226.0 \n",
      "Model_9_11150 \t loss_train = 37636432.0 \t loss_valid = 31125440.0 \n",
      "Model_9_11160 \t loss_train = 37963704.0 \t loss_valid = 31432942.0 \n",
      "Model_9_11170 \t loss_train = 37440612.0 \t loss_valid = 30955128.0 \n",
      "Model_9_11180 \t loss_train = 37696932.0 \t loss_valid = 31270480.0 \n",
      "Model_9_11190 \t loss_train = 37426532.0 \t loss_valid = 30991666.0 \n",
      "Model_9_11200 \t loss_train = 37760320.0 \t loss_valid = 31257942.0 \n",
      "Model_9_11210 \t loss_train = 37894240.0 \t loss_valid = 31371688.0 \n",
      "Early stopping!\n",
      "Model_10_0 \t loss_train = 118966920.0 \t loss_valid = 103780704.0 \n",
      "Model_10_10 \t loss_train = 115377088.0 \t loss_valid = 99442752.0 \n",
      "Model_10_20 \t loss_train = 106560184.0 \t loss_valid = 88886224.0 \n",
      "Model_10_30 \t loss_train = 85589824.0 \t loss_valid = 66213236.0 \n",
      "Model_10_40 \t loss_train = 62895744.0 \t loss_valid = 57330996.0 \n",
      "Model_10_50 \t loss_train = 62032284.0 \t loss_valid = 60572672.0 \n",
      "Model_10_60 \t loss_train = 61295964.0 \t loss_valid = 50295320.0 \n",
      "Model_10_70 \t loss_train = 58663568.0 \t loss_valid = 50167704.0 \n",
      "Model_10_80 \t loss_train = 57372960.0 \t loss_valid = 48715780.0 \n",
      "Model_10_90 \t loss_train = 56868496.0 \t loss_valid = 46272772.0 \n",
      "Model_10_100 \t loss_train = 55226040.0 \t loss_valid = 45383656.0 \n",
      "Model_10_110 \t loss_train = 54460676.0 \t loss_valid = 43793704.0 \n",
      "Model_10_120 \t loss_train = 53472556.0 \t loss_valid = 42496060.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_10_130 \t loss_train = 52417284.0 \t loss_valid = 41357812.0 \n",
      "Model_10_140 \t loss_train = 52194992.0 \t loss_valid = 40736916.0 \n",
      "Model_10_150 \t loss_train = 50953304.0 \t loss_valid = 39594256.0 \n",
      "Model_10_160 \t loss_train = 50618448.0 \t loss_valid = 39249680.0 \n",
      "Model_10_170 \t loss_train = 49419988.0 \t loss_valid = 38293800.0 \n",
      "Model_10_180 \t loss_train = 49106040.0 \t loss_valid = 38132096.0 \n",
      "Model_10_190 \t loss_train = 48833044.0 \t loss_valid = 37960156.0 \n",
      "Model_10_200 \t loss_train = 48318852.0 \t loss_valid = 37557060.0 \n",
      "Model_10_210 \t loss_train = 47382028.0 \t loss_valid = 37151676.0 \n",
      "Model_10_220 \t loss_train = 47007996.0 \t loss_valid = 36978444.0 \n",
      "Model_10_230 \t loss_train = 47235484.0 \t loss_valid = 37150632.0 \n",
      "Model_10_240 \t loss_train = 46299116.0 \t loss_valid = 36596364.0 \n",
      "Model_10_250 \t loss_train = 45638896.0 \t loss_valid = 36330836.0 \n",
      "Model_10_260 \t loss_train = 45443436.0 \t loss_valid = 36228632.0 \n",
      "Model_10_270 \t loss_train = 44608804.0 \t loss_valid = 35872140.0 \n",
      "Model_10_280 \t loss_train = 43774144.0 \t loss_valid = 35552000.0 \n",
      "Model_10_290 \t loss_train = 43513760.0 \t loss_valid = 35373780.0 \n",
      "Model_10_300 \t loss_train = 43173132.0 \t loss_valid = 35311660.0 \n",
      "Model_10_310 \t loss_train = 41577048.0 \t loss_valid = 34648284.0 \n",
      "Model_10_320 \t loss_train = 40412460.0 \t loss_valid = 34646176.0 \n",
      "Model_10_330 \t loss_train = 39453628.0 \t loss_valid = 34035852.0 \n",
      "Model_10_340 \t loss_train = 38453564.0 \t loss_valid = 33239666.0 \n",
      "Model_10_350 \t loss_train = 38208592.0 \t loss_valid = 33025716.0 \n",
      "Model_10_360 \t loss_train = 36845944.0 \t loss_valid = 32370752.0 \n",
      "Model_10_370 \t loss_train = 34868300.0 \t loss_valid = 31969710.0 \n",
      "Model_10_380 \t loss_train = 33670824.0 \t loss_valid = 31371820.0 \n",
      "Model_10_390 \t loss_train = 32640032.0 \t loss_valid = 30878648.0 \n",
      "Model_10_400 \t loss_train = 31912478.0 \t loss_valid = 29779504.0 \n",
      "Model_10_410 \t loss_train = 31120524.0 \t loss_valid = 28781846.0 \n",
      "Model_10_420 \t loss_train = 30331994.0 \t loss_valid = 28082738.0 \n",
      "Model_10_430 \t loss_train = 29583680.0 \t loss_valid = 28218532.0 \n",
      "Model_10_440 \t loss_train = 29659944.0 \t loss_valid = 27219456.0 \n",
      "Model_10_450 \t loss_train = 29202632.0 \t loss_valid = 26659644.0 \n",
      "Model_10_460 \t loss_train = 29067276.0 \t loss_valid = 26517210.0 \n",
      "Model_10_470 \t loss_train = 29072500.0 \t loss_valid = 26339908.0 \n",
      "Model_10_480 \t loss_train = 29430976.0 \t loss_valid = 26320172.0 \n",
      "Model_10_490 \t loss_train = 28782508.0 \t loss_valid = 26045460.0 \n",
      "Model_10_500 \t loss_train = 28904112.0 \t loss_valid = 25870632.0 \n",
      "Model_10_510 \t loss_train = 28637672.0 \t loss_valid = 25746954.0 \n",
      "Model_10_520 \t loss_train = 28564384.0 \t loss_valid = 25947186.0 \n",
      "Model_10_530 \t loss_train = 28431140.0 \t loss_valid = 25783760.0 \n",
      "Model_10_540 \t loss_train = 29239344.0 \t loss_valid = 25878818.0 \n",
      "Model_10_550 \t loss_train = 28764138.0 \t loss_valid = 25670744.0 \n",
      "Model_10_560 \t loss_train = 29035880.0 \t loss_valid = 25758370.0 \n",
      "Model_10_570 \t loss_train = 29979534.0 \t loss_valid = 26406480.0 \n",
      "Model_10_580 \t loss_train = 28399550.0 \t loss_valid = 25686004.0 \n",
      "Model_10_590 \t loss_train = 29550400.0 \t loss_valid = 25982086.0 \n",
      "Model_10_600 \t loss_train = 28684918.0 \t loss_valid = 25529820.0 \n",
      "Model_10_610 \t loss_train = 28762726.0 \t loss_valid = 25571472.0 \n",
      "Model_10_620 \t loss_train = 29403532.0 \t loss_valid = 25822950.0 \n",
      "Model_10_630 \t loss_train = 28786950.0 \t loss_valid = 25499062.0 \n",
      "Model_10_640 \t loss_train = 28723848.0 \t loss_valid = 25497278.0 \n",
      "Model_10_650 \t loss_train = 29638230.0 \t loss_valid = 25988032.0 \n",
      "Model_10_660 \t loss_train = 28621980.0 \t loss_valid = 25641904.0 \n",
      "Model_10_670 \t loss_train = 29024480.0 \t loss_valid = 25549632.0 \n",
      "Model_10_680 \t loss_train = 28659632.0 \t loss_valid = 25641618.0 \n",
      "Model_10_690 \t loss_train = 28550938.0 \t loss_valid = 25522518.0 \n",
      "Model_10_700 \t loss_train = 29793498.0 \t loss_valid = 25962448.0 \n",
      "Model_10_710 \t loss_train = 28803014.0 \t loss_valid = 25521136.0 \n",
      "Model_10_720 \t loss_train = 30272208.0 \t loss_valid = 26389946.0 \n",
      "Model_10_730 \t loss_train = 28829384.0 \t loss_valid = 25477828.0 \n",
      "Model_10_740 \t loss_train = 29961322.0 \t loss_valid = 26101116.0 \n",
      "Model_10_750 \t loss_train = 28729718.0 \t loss_valid = 25562346.0 \n",
      "Model_10_760 \t loss_train = 29766044.0 \t loss_valid = 25958706.0 \n",
      "Model_10_770 \t loss_train = 28657374.0 \t loss_valid = 25526146.0 \n",
      "Model_10_780 \t loss_train = 28981864.0 \t loss_valid = 25513958.0 \n",
      "Model_10_790 \t loss_train = 30111838.0 \t loss_valid = 26172488.0 \n",
      "Model_10_800 \t loss_train = 28664904.0 \t loss_valid = 25629228.0 \n",
      "Model_10_810 \t loss_train = 29540866.0 \t loss_valid = 25761758.0 \n",
      "Model_10_820 \t loss_train = 29578746.0 \t loss_valid = 25779914.0 \n",
      "Model_10_830 \t loss_train = 29406100.0 \t loss_valid = 25674032.0 \n",
      "Model_10_840 \t loss_train = 29720790.0 \t loss_valid = 25808742.0 \n",
      "Model_10_850 \t loss_train = 29267594.0 \t loss_valid = 25612258.0 \n",
      "Model_10_860 \t loss_train = 29647960.0 \t loss_valid = 25743502.0 \n",
      "Model_10_870 \t loss_train = 29022406.0 \t loss_valid = 25514116.0 \n",
      "Model_10_880 \t loss_train = 29862502.0 \t loss_valid = 25888098.0 \n",
      "Model_10_890 \t loss_train = 29843026.0 \t loss_valid = 25972402.0 \n",
      "Model_10_900 \t loss_train = 29541386.0 \t loss_valid = 25740924.0 \n",
      "Model_10_910 \t loss_train = 29286122.0 \t loss_valid = 25614342.0 \n",
      "Model_10_920 \t loss_train = 30031434.0 \t loss_valid = 26100256.0 \n",
      "Model_10_930 \t loss_train = 29240008.0 \t loss_valid = 25582648.0 \n",
      "Model_10_940 \t loss_train = 29735296.0 \t loss_valid = 25784708.0 \n",
      "Model_10_950 \t loss_train = 29892910.0 \t loss_valid = 25862902.0 \n",
      "Model_10_960 \t loss_train = 29111864.0 \t loss_valid = 25499990.0 \n",
      "Model_10_970 \t loss_train = 30047036.0 \t loss_valid = 25948042.0 \n",
      "Model_10_980 \t loss_train = 30037226.0 \t loss_valid = 26021760.0 \n",
      "Model_10_990 \t loss_train = 30028928.0 \t loss_valid = 25902878.0 \n",
      "Model_10_1000 \t loss_train = 30324118.0 \t loss_valid = 26206556.0 \n",
      "Model_10_1010 \t loss_train = 28975894.0 \t loss_valid = 25522602.0 \n",
      "Model_10_1020 \t loss_train = 30691426.0 \t loss_valid = 26524258.0 \n",
      "Model_10_1030 \t loss_train = 29612362.0 \t loss_valid = 25715084.0 \n",
      "Model_10_1040 \t loss_train = 30501070.0 \t loss_valid = 26265296.0 \n",
      "Model_10_1050 \t loss_train = 29880934.0 \t loss_valid = 25828680.0 \n",
      "Model_10_1060 \t loss_train = 29868198.0 \t loss_valid = 25871614.0 \n",
      "Model_10_1070 \t loss_train = 30115802.0 \t loss_valid = 26006178.0 \n",
      "Model_10_1080 \t loss_train = 29775518.0 \t loss_valid = 25802448.0 \n",
      "Model_10_1090 \t loss_train = 29910682.0 \t loss_valid = 25910888.0 \n",
      "Model_10_1100 \t loss_train = 30219214.0 \t loss_valid = 25998574.0 \n",
      "Model_10_1110 \t loss_train = 30082752.0 \t loss_valid = 25933530.0 \n",
      "Model_10_1120 \t loss_train = 29926412.0 \t loss_valid = 25783428.0 \n",
      "Model_10_1130 \t loss_train = 30129442.0 \t loss_valid = 26058334.0 \n",
      "Model_10_1140 \t loss_train = 30510176.0 \t loss_valid = 26221172.0 \n",
      "Model_10_1150 \t loss_train = 29898590.0 \t loss_valid = 25854550.0 \n",
      "Model_10_1160 \t loss_train = 30320950.0 \t loss_valid = 26068870.0 \n",
      "Model_10_1170 \t loss_train = 30073934.0 \t loss_valid = 25977232.0 \n",
      "Model_10_1180 \t loss_train = 30569704.0 \t loss_valid = 26319008.0 \n",
      "Model_10_1190 \t loss_train = 30765652.0 \t loss_valid = 26434892.0 \n",
      "Model_10_1200 \t loss_train = 29548330.0 \t loss_valid = 25660410.0 \n",
      "Model_10_1210 \t loss_train = 30523430.0 \t loss_valid = 26223906.0 \n",
      "Model_10_1220 \t loss_train = 30439698.0 \t loss_valid = 26101794.0 \n",
      "Model_10_1230 \t loss_train = 30934478.0 \t loss_valid = 26589466.0 \n",
      "Model_10_1240 \t loss_train = 30365978.0 \t loss_valid = 26042396.0 \n",
      "Model_10_1250 \t loss_train = 30322210.0 \t loss_valid = 25978036.0 \n",
      "Model_10_1260 \t loss_train = 30501612.0 \t loss_valid = 26197734.0 \n",
      "Model_10_1270 \t loss_train = 30393534.0 \t loss_valid = 25996782.0 \n",
      "Model_10_1280 \t loss_train = 30448432.0 \t loss_valid = 26094484.0 \n",
      "Model_10_1290 \t loss_train = 31075098.0 \t loss_valid = 26502390.0 \n",
      "Model_10_1300 \t loss_train = 30602466.0 \t loss_valid = 26280068.0 \n",
      "Model_10_1310 \t loss_train = 30263322.0 \t loss_valid = 26035498.0 \n",
      "Model_10_1320 \t loss_train = 30632848.0 \t loss_valid = 26215240.0 \n",
      "Model_10_1330 \t loss_train = 30860812.0 \t loss_valid = 26373646.0 \n",
      "Model_10_1340 \t loss_train = 30728532.0 \t loss_valid = 26197402.0 \n",
      "Model_10_1350 \t loss_train = 30063668.0 \t loss_valid = 25931684.0 \n",
      "Model_10_1360 \t loss_train = 31021082.0 \t loss_valid = 26455312.0 \n",
      "Model_10_1370 \t loss_train = 30736100.0 \t loss_valid = 26208774.0 \n",
      "Model_10_1380 \t loss_train = 30674270.0 \t loss_valid = 26280770.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_10_1390 \t loss_train = 30760800.0 \t loss_valid = 26229950.0 \n",
      "Model_10_1400 \t loss_train = 30628942.0 \t loss_valid = 26251932.0 \n",
      "Model_10_1410 \t loss_train = 30283662.0 \t loss_valid = 25955824.0 \n",
      "Model_10_1420 \t loss_train = 31375850.0 \t loss_valid = 26793842.0 \n",
      "Model_10_1430 \t loss_train = 31021496.0 \t loss_valid = 26456016.0 \n",
      "Model_10_1440 \t loss_train = 30657322.0 \t loss_valid = 26209054.0 \n",
      "Model_10_1450 \t loss_train = 31572372.0 \t loss_valid = 26957176.0 \n",
      "Model_10_1460 \t loss_train = 30799014.0 \t loss_valid = 26423262.0 \n",
      "Model_10_1470 \t loss_train = 31445072.0 \t loss_valid = 26785584.0 \n",
      "Model_10_1480 \t loss_train = 30592482.0 \t loss_valid = 26258862.0 \n",
      "Model_10_1490 \t loss_train = 30817100.0 \t loss_valid = 26268224.0 \n",
      "Model_10_1500 \t loss_train = 30895360.0 \t loss_valid = 26356916.0 \n",
      "Model_10_1510 \t loss_train = 30813584.0 \t loss_valid = 26423338.0 \n",
      "Model_10_1520 \t loss_train = 31627504.0 \t loss_valid = 27052336.0 \n",
      "Model_10_1530 \t loss_train = 30306196.0 \t loss_valid = 25997194.0 \n",
      "Model_10_1540 \t loss_train = 31995984.0 \t loss_valid = 27197908.0 \n",
      "Model_10_1550 \t loss_train = 31571074.0 \t loss_valid = 26982498.0 \n",
      "Model_10_1560 \t loss_train = 30825414.0 \t loss_valid = 26231240.0 \n",
      "Model_10_1570 \t loss_train = 31402938.0 \t loss_valid = 26859890.0 \n",
      "Model_10_1580 \t loss_train = 30746316.0 \t loss_valid = 26379232.0 \n",
      "Model_10_1590 \t loss_train = 31503396.0 \t loss_valid = 26814338.0 \n",
      "Model_10_1600 \t loss_train = 31732322.0 \t loss_valid = 27109730.0 \n",
      "Model_10_1610 \t loss_train = 30620542.0 \t loss_valid = 26203790.0 \n",
      "Model_10_1620 \t loss_train = 32013718.0 \t loss_valid = 27352488.0 \n",
      "Model_10_1630 \t loss_train = 30255724.0 \t loss_valid = 25990454.0 \n",
      "Model_10_1640 \t loss_train = 31702218.0 \t loss_valid = 27146240.0 \n",
      "Model_10_1650 \t loss_train = 30780832.0 \t loss_valid = 26412488.0 \n",
      "Model_10_1660 \t loss_train = 31220866.0 \t loss_valid = 26610548.0 \n",
      "Model_10_1670 \t loss_train = 31390924.0 \t loss_valid = 26808912.0 \n",
      "Model_10_1680 \t loss_train = 31525306.0 \t loss_valid = 26831882.0 \n",
      "Model_10_1690 \t loss_train = 32470792.0 \t loss_valid = 27765128.0 \n",
      "Model_10_1700 \t loss_train = 31267936.0 \t loss_valid = 26597410.0 \n",
      "Model_10_1710 \t loss_train = 31288670.0 \t loss_valid = 26732452.0 \n",
      "Model_10_1720 \t loss_train = 31121720.0 \t loss_valid = 26507182.0 \n",
      "Model_10_1730 \t loss_train = 31003054.0 \t loss_valid = 26409396.0 \n",
      "Model_10_1740 \t loss_train = 31680580.0 \t loss_valid = 27092524.0 \n",
      "Model_10_1750 \t loss_train = 31989212.0 \t loss_valid = 27055720.0 \n",
      "Model_10_1760 \t loss_train = 30982396.0 \t loss_valid = 26418900.0 \n",
      "Model_10_1770 \t loss_train = 31570588.0 \t loss_valid = 26782376.0 \n",
      "Model_10_1780 \t loss_train = 31718282.0 \t loss_valid = 26962264.0 \n",
      "Model_10_1790 \t loss_train = 30769196.0 \t loss_valid = 26267722.0 \n",
      "Model_10_1800 \t loss_train = 31308526.0 \t loss_valid = 26711420.0 \n",
      "Model_10_1810 \t loss_train = 31660006.0 \t loss_valid = 26984490.0 \n",
      "Model_10_1820 \t loss_train = 31489578.0 \t loss_valid = 26731124.0 \n",
      "Model_10_1830 \t loss_train = 31487390.0 \t loss_valid = 26842772.0 \n",
      "Model_10_1840 \t loss_train = 32148382.0 \t loss_valid = 27385256.0 \n",
      "Model_10_1850 \t loss_train = 31008470.0 \t loss_valid = 26516922.0 \n",
      "Model_10_1860 \t loss_train = 31795434.0 \t loss_valid = 27069886.0 \n",
      "Model_10_1870 \t loss_train = 31948570.0 \t loss_valid = 27289072.0 \n",
      "Model_10_1880 \t loss_train = 30993210.0 \t loss_valid = 26350906.0 \n",
      "Model_10_1890 \t loss_train = 31472834.0 \t loss_valid = 26713416.0 \n",
      "Model_10_1900 \t loss_train = 31301110.0 \t loss_valid = 26765382.0 \n",
      "Model_10_1910 \t loss_train = 32146562.0 \t loss_valid = 27216816.0 \n",
      "Model_10_1920 \t loss_train = 31279810.0 \t loss_valid = 26659934.0 \n",
      "Model_10_1930 \t loss_train = 32136902.0 \t loss_valid = 27303668.0 \n",
      "Model_10_1940 \t loss_train = 31525464.0 \t loss_valid = 26827220.0 \n",
      "Model_10_1950 \t loss_train = 31502684.0 \t loss_valid = 26866890.0 \n",
      "Model_10_1960 \t loss_train = 32906502.0 \t loss_valid = 27928718.0 \n",
      "Model_10_1970 \t loss_train = 31517552.0 \t loss_valid = 26888294.0 \n",
      "Model_10_1980 \t loss_train = 31995210.0 \t loss_valid = 27138810.0 \n",
      "Model_10_1990 \t loss_train = 32270132.0 \t loss_valid = 27488152.0 \n",
      "Model_10_2000 \t loss_train = 31842122.0 \t loss_valid = 27147548.0 \n",
      "Model_10_2010 \t loss_train = 32056224.0 \t loss_valid = 27280946.0 \n",
      "Model_10_2020 \t loss_train = 31626054.0 \t loss_valid = 26849002.0 \n",
      "Model_10_2030 \t loss_train = 31920874.0 \t loss_valid = 27103226.0 \n",
      "Model_10_2040 \t loss_train = 32729842.0 \t loss_valid = 27776494.0 \n",
      "Model_10_2050 \t loss_train = 31408272.0 \t loss_valid = 26779958.0 \n",
      "Model_10_2060 \t loss_train = 32453492.0 \t loss_valid = 27587520.0 \n",
      "Model_10_2070 \t loss_train = 31610180.0 \t loss_valid = 26915360.0 \n",
      "Model_10_2080 \t loss_train = 32586692.0 \t loss_valid = 27614322.0 \n",
      "Model_10_2090 \t loss_train = 31317434.0 \t loss_valid = 26644904.0 \n",
      "Model_10_2100 \t loss_train = 32116878.0 \t loss_valid = 27310364.0 \n",
      "Model_10_2110 \t loss_train = 33101350.0 \t loss_valid = 28282852.0 \n",
      "Model_10_2120 \t loss_train = 31849670.0 \t loss_valid = 27050354.0 \n",
      "Model_10_2130 \t loss_train = 32074516.0 \t loss_valid = 27311512.0 \n",
      "Model_10_2140 \t loss_train = 31511226.0 \t loss_valid = 26779284.0 \n",
      "Model_10_2150 \t loss_train = 32672304.0 \t loss_valid = 27751364.0 \n",
      "Model_10_2160 \t loss_train = 32342480.0 \t loss_valid = 27529696.0 \n",
      "Model_10_2170 \t loss_train = 32035218.0 \t loss_valid = 27295462.0 \n",
      "Model_10_2180 \t loss_train = 31762428.0 \t loss_valid = 27012784.0 \n",
      "Model_10_2190 \t loss_train = 32448432.0 \t loss_valid = 27513612.0 \n",
      "Model_10_2200 \t loss_train = 31768006.0 \t loss_valid = 27025118.0 \n",
      "Model_10_2210 \t loss_train = 32207312.0 \t loss_valid = 27365702.0 \n",
      "Model_10_2220 \t loss_train = 31726726.0 \t loss_valid = 26967382.0 \n",
      "Model_10_2230 \t loss_train = 31840388.0 \t loss_valid = 27014208.0 \n",
      "Model_10_2240 \t loss_train = 33201726.0 \t loss_valid = 28358056.0 \n",
      "Model_10_2250 \t loss_train = 31592560.0 \t loss_valid = 26775428.0 \n",
      "Model_10_2260 \t loss_train = 32407598.0 \t loss_valid = 27615762.0 \n",
      "Model_10_2270 \t loss_train = 31939914.0 \t loss_valid = 27152498.0 \n",
      "Model_10_2280 \t loss_train = 32469566.0 \t loss_valid = 27624916.0 \n",
      "Model_10_2290 \t loss_train = 32498584.0 \t loss_valid = 27650664.0 \n",
      "Model_10_2300 \t loss_train = 32003804.0 \t loss_valid = 27219466.0 \n",
      "Model_10_2310 \t loss_train = 32801992.0 \t loss_valid = 27883110.0 \n",
      "Model_10_2320 \t loss_train = 32110838.0 \t loss_valid = 27163320.0 \n",
      "Model_10_2330 \t loss_train = 32760378.0 \t loss_valid = 27832314.0 \n",
      "Model_10_2340 \t loss_train = 32089244.0 \t loss_valid = 27371924.0 \n",
      "Model_10_2350 \t loss_train = 33400922.0 \t loss_valid = 28376888.0 \n",
      "Model_10_2360 \t loss_train = 31952624.0 \t loss_valid = 27191154.0 \n",
      "Model_10_2370 \t loss_train = 33526464.0 \t loss_valid = 28529790.0 \n",
      "Model_10_2380 \t loss_train = 32048112.0 \t loss_valid = 27131930.0 \n",
      "Model_10_2390 \t loss_train = 33029110.0 \t loss_valid = 28060148.0 \n",
      "Model_10_2400 \t loss_train = 32129094.0 \t loss_valid = 27247670.0 \n",
      "Model_10_2410 \t loss_train = 32319572.0 \t loss_valid = 27464546.0 \n",
      "Model_10_2420 \t loss_train = 32527732.0 \t loss_valid = 27668338.0 \n",
      "Model_10_2430 \t loss_train = 31652106.0 \t loss_valid = 26848718.0 \n",
      "Model_10_2440 \t loss_train = 33206290.0 \t loss_valid = 28261838.0 \n",
      "Model_10_2450 \t loss_train = 32554092.0 \t loss_valid = 27701972.0 \n",
      "Model_10_2460 \t loss_train = 32126888.0 \t loss_valid = 27178708.0 \n",
      "Model_10_2470 \t loss_train = 33140844.0 \t loss_valid = 28114444.0 \n",
      "Model_10_2480 \t loss_train = 32411474.0 \t loss_valid = 27384800.0 \n",
      "Model_10_2490 \t loss_train = 33291370.0 \t loss_valid = 28263822.0 \n",
      "Model_10_2500 \t loss_train = 32606986.0 \t loss_valid = 27748838.0 \n",
      "Model_10_2510 \t loss_train = 32480978.0 \t loss_valid = 27627874.0 \n",
      "Model_10_2520 \t loss_train = 32426470.0 \t loss_valid = 27436392.0 \n",
      "Model_10_2530 \t loss_train = 32908384.0 \t loss_valid = 27981444.0 \n",
      "Model_10_2540 \t loss_train = 32069974.0 \t loss_valid = 27233684.0 \n",
      "Model_10_2550 \t loss_train = 33075442.0 \t loss_valid = 28046656.0 \n",
      "Model_10_2560 \t loss_train = 33560868.0 \t loss_valid = 28564950.0 \n",
      "Model_10_2570 \t loss_train = 32414806.0 \t loss_valid = 27337772.0 \n",
      "Model_10_2580 \t loss_train = 32224682.0 \t loss_valid = 27368474.0 \n",
      "Model_10_2590 \t loss_train = 33644512.0 \t loss_valid = 28640322.0 \n",
      "Model_10_2600 \t loss_train = 32313946.0 \t loss_valid = 27404706.0 \n",
      "Model_10_2610 \t loss_train = 32754584.0 \t loss_valid = 27852070.0 \n",
      "Model_10_2620 \t loss_train = 32772176.0 \t loss_valid = 27700964.0 \n",
      "Model_10_2630 \t loss_train = 32525058.0 \t loss_valid = 27625750.0 \n",
      "Model_10_2640 \t loss_train = 33144946.0 \t loss_valid = 28087296.0 \n",
      "Model_10_2650 \t loss_train = 32753180.0 \t loss_valid = 27703030.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_10_2660 \t loss_train = 32753786.0 \t loss_valid = 27989568.0 \n",
      "Model_10_2670 \t loss_train = 32410586.0 \t loss_valid = 27536500.0 \n",
      "Model_10_2680 \t loss_train = 32601052.0 \t loss_valid = 27554358.0 \n",
      "Model_10_2690 \t loss_train = 33106588.0 \t loss_valid = 28226168.0 \n",
      "Model_10_2700 \t loss_train = 32503240.0 \t loss_valid = 27433674.0 \n",
      "Model_10_2710 \t loss_train = 32637298.0 \t loss_valid = 27727056.0 \n",
      "Model_10_2720 \t loss_train = 32830100.0 \t loss_valid = 27775990.0 \n",
      "Model_10_2730 \t loss_train = 32847118.0 \t loss_valid = 27946158.0 \n",
      "Model_10_2740 \t loss_train = 32708242.0 \t loss_valid = 27737882.0 \n",
      "Model_10_2750 \t loss_train = 33472130.0 \t loss_valid = 28339468.0 \n",
      "Model_10_2760 \t loss_train = 32672092.0 \t loss_valid = 27784492.0 \n",
      "Model_10_2770 \t loss_train = 32555626.0 \t loss_valid = 27474670.0 \n",
      "Model_10_2780 \t loss_train = 33716368.0 \t loss_valid = 28556800.0 \n",
      "Model_10_2790 \t loss_train = 32223634.0 \t loss_valid = 27348954.0 \n",
      "Model_10_2800 \t loss_train = 33797360.0 \t loss_valid = 28585904.0 \n",
      "Model_10_2810 \t loss_train = 32844160.0 \t loss_valid = 27860242.0 \n",
      "Model_10_2820 \t loss_train = 33246590.0 \t loss_valid = 28073852.0 \n",
      "Model_10_2830 \t loss_train = 33019540.0 \t loss_valid = 27998084.0 \n",
      "Model_10_2840 \t loss_train = 33305846.0 \t loss_valid = 28333306.0 \n",
      "Model_10_2850 \t loss_train = 32991272.0 \t loss_valid = 27917512.0 \n",
      "Model_10_2860 \t loss_train = 32649782.0 \t loss_valid = 27682052.0 \n",
      "Model_10_2870 \t loss_train = 33024096.0 \t loss_valid = 27894886.0 \n",
      "Model_10_2880 \t loss_train = 32787206.0 \t loss_valid = 27894974.0 \n",
      "Model_10_2890 \t loss_train = 32962210.0 \t loss_valid = 27927880.0 \n",
      "Model_10_2900 \t loss_train = 32907522.0 \t loss_valid = 27849912.0 \n",
      "Model_10_2910 \t loss_train = 32810520.0 \t loss_valid = 27964592.0 \n",
      "Model_10_2920 \t loss_train = 32844964.0 \t loss_valid = 27825736.0 \n",
      "Model_10_2930 \t loss_train = 33353460.0 \t loss_valid = 28281716.0 \n",
      "Model_10_2940 \t loss_train = 32976138.0 \t loss_valid = 27869738.0 \n",
      "Model_10_2950 \t loss_train = 33039390.0 \t loss_valid = 28032402.0 \n",
      "Model_10_2960 \t loss_train = 33450002.0 \t loss_valid = 28240176.0 \n",
      "Model_10_2970 \t loss_train = 32685668.0 \t loss_valid = 27696318.0 \n",
      "Model_10_2980 \t loss_train = 33360086.0 \t loss_valid = 28205274.0 \n",
      "Model_10_2990 \t loss_train = 32651194.0 \t loss_valid = 27592360.0 \n",
      "Model_10_3000 \t loss_train = 33461588.0 \t loss_valid = 28478116.0 \n",
      "Model_10_3010 \t loss_train = 32584842.0 \t loss_valid = 27597406.0 \n",
      "Model_10_3020 \t loss_train = 33541194.0 \t loss_valid = 28520670.0 \n",
      "Model_10_3030 \t loss_train = 33421152.0 \t loss_valid = 28278414.0 \n",
      "Model_10_3040 \t loss_train = 32973288.0 \t loss_valid = 28083248.0 \n",
      "Model_10_3050 \t loss_train = 33609988.0 \t loss_valid = 28475690.0 \n",
      "Model_10_3060 \t loss_train = 32761594.0 \t loss_valid = 27832692.0 \n",
      "Model_10_3070 \t loss_train = 33260754.0 \t loss_valid = 28125016.0 \n",
      "Model_10_3080 \t loss_train = 33051632.0 \t loss_valid = 28061570.0 \n",
      "Model_10_3090 \t loss_train = 33312898.0 \t loss_valid = 28200404.0 \n",
      "Model_10_3100 \t loss_train = 33194148.0 \t loss_valid = 28127700.0 \n",
      "Model_10_3110 \t loss_train = 33484252.0 \t loss_valid = 28346320.0 \n",
      "Model_10_3120 \t loss_train = 32782728.0 \t loss_valid = 27726242.0 \n",
      "Model_10_3130 \t loss_train = 33849756.0 \t loss_valid = 28734720.0 \n",
      "Model_10_3140 \t loss_train = 32950930.0 \t loss_valid = 27927420.0 \n",
      "Model_10_3150 \t loss_train = 33756200.0 \t loss_valid = 28462528.0 \n",
      "Model_10_3160 \t loss_train = 33315272.0 \t loss_valid = 28196188.0 \n",
      "Model_10_3170 \t loss_train = 33306294.0 \t loss_valid = 28199058.0 \n",
      "Model_10_3180 \t loss_train = 32827186.0 \t loss_valid = 27775772.0 \n",
      "Model_10_3190 \t loss_train = 33706164.0 \t loss_valid = 28538798.0 \n",
      "Model_10_3200 \t loss_train = 32855184.0 \t loss_valid = 27857572.0 \n",
      "Model_10_3210 \t loss_train = 33597188.0 \t loss_valid = 28433272.0 \n",
      "Model_10_3220 \t loss_train = 33286358.0 \t loss_valid = 28256708.0 \n",
      "Model_10_3230 \t loss_train = 33700596.0 \t loss_valid = 28423162.0 \n",
      "Model_10_3240 \t loss_train = 33137512.0 \t loss_valid = 28129220.0 \n",
      "Model_10_3250 \t loss_train = 33612400.0 \t loss_valid = 28607846.0 \n",
      "Model_10_3260 \t loss_train = 33022652.0 \t loss_valid = 27913308.0 \n",
      "Model_10_3270 \t loss_train = 33740548.0 \t loss_valid = 28548672.0 \n",
      "Model_10_3280 \t loss_train = 33055550.0 \t loss_valid = 27994018.0 \n",
      "Model_10_3290 \t loss_train = 34340500.0 \t loss_valid = 29148982.0 \n",
      "Model_10_3300 \t loss_train = 33171630.0 \t loss_valid = 27947818.0 \n",
      "Model_10_3310 \t loss_train = 33558980.0 \t loss_valid = 28544360.0 \n",
      "Model_10_3320 \t loss_train = 32666348.0 \t loss_valid = 27533084.0 \n",
      "Model_10_3330 \t loss_train = 34337068.0 \t loss_valid = 29296772.0 \n",
      "Model_10_3340 \t loss_train = 33293722.0 \t loss_valid = 28067790.0 \n",
      "Model_10_3350 \t loss_train = 33222674.0 \t loss_valid = 28195798.0 \n",
      "Model_10_3360 \t loss_train = 33254956.0 \t loss_valid = 28143002.0 \n",
      "Model_10_3370 \t loss_train = 33202720.0 \t loss_valid = 28115772.0 \n",
      "Model_10_3380 \t loss_train = 33518648.0 \t loss_valid = 28400486.0 \n",
      "Model_10_3390 \t loss_train = 34182072.0 \t loss_valid = 28916596.0 \n",
      "Model_10_3400 \t loss_train = 32989870.0 \t loss_valid = 27873760.0 \n",
      "Model_10_3410 \t loss_train = 33630356.0 \t loss_valid = 28558722.0 \n",
      "Model_10_3420 \t loss_train = 33037996.0 \t loss_valid = 28003508.0 \n",
      "Model_10_3430 \t loss_train = 33621500.0 \t loss_valid = 28594960.0 \n",
      "Model_10_3440 \t loss_train = 33934372.0 \t loss_valid = 28861158.0 \n",
      "Model_10_3450 \t loss_train = 33424674.0 \t loss_valid = 28196276.0 \n",
      "Model_10_3460 \t loss_train = 33689720.0 \t loss_valid = 28664010.0 \n",
      "Model_10_3470 \t loss_train = 33021118.0 \t loss_valid = 27971808.0 \n",
      "Model_10_3480 \t loss_train = 33918480.0 \t loss_valid = 28738496.0 \n",
      "Model_10_3490 \t loss_train = 33297982.0 \t loss_valid = 28193810.0 \n",
      "Model_10_3500 \t loss_train = 33568260.0 \t loss_valid = 28419002.0 \n",
      "Model_10_3510 \t loss_train = 33492670.0 \t loss_valid = 28321052.0 \n",
      "Model_10_3520 \t loss_train = 33441152.0 \t loss_valid = 28379430.0 \n",
      "Model_10_3530 \t loss_train = 33083708.0 \t loss_valid = 27930380.0 \n",
      "Model_10_3540 \t loss_train = 34605944.0 \t loss_valid = 29438104.0 \n",
      "Model_10_3550 \t loss_train = 33489624.0 \t loss_valid = 28268284.0 \n",
      "Model_10_3560 \t loss_train = 33951220.0 \t loss_valid = 28657300.0 \n",
      "Model_10_3570 \t loss_train = 33133530.0 \t loss_valid = 28080770.0 \n",
      "Model_10_3580 \t loss_train = 33691872.0 \t loss_valid = 28471754.0 \n",
      "Model_10_3590 \t loss_train = 33652564.0 \t loss_valid = 28402112.0 \n",
      "Model_10_3600 \t loss_train = 33452054.0 \t loss_valid = 28319210.0 \n",
      "Model_10_3610 \t loss_train = 33548470.0 \t loss_valid = 28306782.0 \n",
      "Model_10_3620 \t loss_train = 34109352.0 \t loss_valid = 28972860.0 \n",
      "Model_10_3630 \t loss_train = 33574460.0 \t loss_valid = 28512546.0 \n",
      "Model_10_3640 \t loss_train = 33055646.0 \t loss_valid = 27919534.0 \n",
      "Model_10_3650 \t loss_train = 33382648.0 \t loss_valid = 28294738.0 \n",
      "Model_10_3660 \t loss_train = 34006000.0 \t loss_valid = 28832686.0 \n",
      "Model_10_3670 \t loss_train = 34214132.0 \t loss_valid = 28900288.0 \n",
      "Model_10_3680 \t loss_train = 33179874.0 \t loss_valid = 28077878.0 \n",
      "Model_10_3690 \t loss_train = 34307568.0 \t loss_valid = 29147540.0 \n",
      "Model_10_3700 \t loss_train = 33229498.0 \t loss_valid = 27986096.0 \n",
      "Model_10_3710 \t loss_train = 33897448.0 \t loss_valid = 28767308.0 \n",
      "Model_10_3720 \t loss_train = 33418648.0 \t loss_valid = 28212844.0 \n",
      "Model_10_3730 \t loss_train = 34160952.0 \t loss_valid = 28956360.0 \n",
      "Model_10_3740 \t loss_train = 33674912.0 \t loss_valid = 28479536.0 \n",
      "Model_10_3750 \t loss_train = 33934144.0 \t loss_valid = 28784738.0 \n",
      "Model_10_3760 \t loss_train = 34050612.0 \t loss_valid = 28827958.0 \n",
      "Model_10_3770 \t loss_train = 33934908.0 \t loss_valid = 28823570.0 \n",
      "Model_10_3780 \t loss_train = 33515996.0 \t loss_valid = 28336232.0 \n",
      "Model_10_3790 \t loss_train = 33991544.0 \t loss_valid = 28902678.0 \n",
      "Model_10_3800 \t loss_train = 33811540.0 \t loss_valid = 28627798.0 \n",
      "Model_10_3810 \t loss_train = 33610976.0 \t loss_valid = 28310130.0 \n",
      "Model_10_3820 \t loss_train = 34178040.0 \t loss_valid = 29122076.0 \n",
      "Model_10_3830 \t loss_train = 33965112.0 \t loss_valid = 28713172.0 \n",
      "Model_10_3840 \t loss_train = 34019788.0 \t loss_valid = 28758216.0 \n",
      "Model_10_3850 \t loss_train = 33817112.0 \t loss_valid = 28559152.0 \n",
      "Model_10_3860 \t loss_train = 33449578.0 \t loss_valid = 28186378.0 \n",
      "Model_10_3870 \t loss_train = 34315104.0 \t loss_valid = 29111928.0 \n",
      "Model_10_3880 \t loss_train = 33733640.0 \t loss_valid = 28479086.0 \n",
      "Model_10_3890 \t loss_train = 33874968.0 \t loss_valid = 28649876.0 \n",
      "Model_10_3900 \t loss_train = 34256736.0 \t loss_valid = 29013536.0 \n",
      "Model_10_3910 \t loss_train = 34456544.0 \t loss_valid = 29157214.0 \n",
      "Model_10_3920 \t loss_train = 33019524.0 \t loss_valid = 27896270.0 \n",
      "Model_10_3930 \t loss_train = 34124016.0 \t loss_valid = 28873466.0 \n",
      "Model_10_3940 \t loss_train = 33817468.0 \t loss_valid = 28578586.0 \n",
      "Model_10_3950 \t loss_train = 33905108.0 \t loss_valid = 28583104.0 \n",
      "Model_10_3960 \t loss_train = 33862192.0 \t loss_valid = 28781986.0 \n",
      "Model_10_3970 \t loss_train = 34055728.0 \t loss_valid = 28783732.0 \n",
      "Model_10_3980 \t loss_train = 33092676.0 \t loss_valid = 27965772.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_10_3990 \t loss_train = 33988424.0 \t loss_valid = 28806568.0 \n",
      "Model_10_4000 \t loss_train = 33416846.0 \t loss_valid = 28339684.0 \n",
      "Model_10_4010 \t loss_train = 33985656.0 \t loss_valid = 28695594.0 \n",
      "Model_10_4020 \t loss_train = 33557808.0 \t loss_valid = 28435042.0 \n",
      "Model_10_4030 \t loss_train = 33966208.0 \t loss_valid = 28788996.0 \n",
      "Model_10_4040 \t loss_train = 32994944.0 \t loss_valid = 27919304.0 \n",
      "Model_10_4050 \t loss_train = 34057480.0 \t loss_valid = 28879784.0 \n",
      "Model_10_4060 \t loss_train = 34122340.0 \t loss_valid = 28875482.0 \n",
      "Model_10_4070 \t loss_train = 33623296.0 \t loss_valid = 28393684.0 \n",
      "Model_10_4080 \t loss_train = 33403106.0 \t loss_valid = 28136666.0 \n",
      "Model_10_4090 \t loss_train = 34536560.0 \t loss_valid = 29211544.0 \n",
      "Model_10_4100 \t loss_train = 33514382.0 \t loss_valid = 28344218.0 \n",
      "Model_10_4110 \t loss_train = 33835920.0 \t loss_valid = 28624922.0 \n",
      "Model_10_4120 \t loss_train = 34525900.0 \t loss_valid = 29286514.0 \n",
      "Model_10_4130 \t loss_train = 33527502.0 \t loss_valid = 28462844.0 \n",
      "Model_10_4140 \t loss_train = 34024816.0 \t loss_valid = 28770032.0 \n",
      "Model_10_4150 \t loss_train = 33959152.0 \t loss_valid = 28849250.0 \n",
      "Model_10_4160 \t loss_train = 33250502.0 \t loss_valid = 28081696.0 \n",
      "Model_10_4170 \t loss_train = 33826924.0 \t loss_valid = 28673498.0 \n",
      "Model_10_4180 \t loss_train = 33890888.0 \t loss_valid = 28638640.0 \n",
      "Model_10_4190 \t loss_train = 34321140.0 \t loss_valid = 29140370.0 \n",
      "Model_10_4200 \t loss_train = 33526916.0 \t loss_valid = 28322206.0 \n",
      "Model_10_4210 \t loss_train = 33973228.0 \t loss_valid = 28719544.0 \n",
      "Model_10_4220 \t loss_train = 34026260.0 \t loss_valid = 28903746.0 \n",
      "Model_10_4230 \t loss_train = 33411006.0 \t loss_valid = 28214942.0 \n",
      "Model_10_4240 \t loss_train = 34483340.0 \t loss_valid = 29189108.0 \n",
      "Model_10_4250 \t loss_train = 33139684.0 \t loss_valid = 28028508.0 \n",
      "Model_10_4260 \t loss_train = 33713652.0 \t loss_valid = 28529484.0 \n",
      "Model_10_4270 \t loss_train = 33342418.0 \t loss_valid = 28222474.0 \n",
      "Model_10_4280 \t loss_train = 33489596.0 \t loss_valid = 28443746.0 \n",
      "Model_10_4290 \t loss_train = 33886728.0 \t loss_valid = 28548688.0 \n",
      "Model_10_4300 \t loss_train = 33822812.0 \t loss_valid = 28554758.0 \n",
      "Model_10_4310 \t loss_train = 33617328.0 \t loss_valid = 28496520.0 \n",
      "Model_10_4320 \t loss_train = 33921748.0 \t loss_valid = 28591916.0 \n",
      "Model_10_4330 \t loss_train = 34091160.0 \t loss_valid = 29007916.0 \n",
      "Model_10_4340 \t loss_train = 33740316.0 \t loss_valid = 28587464.0 \n",
      "Model_10_4350 \t loss_train = 33773848.0 \t loss_valid = 28514164.0 \n",
      "Model_10_4360 \t loss_train = 33174238.0 \t loss_valid = 28098806.0 \n",
      "Model_10_4370 \t loss_train = 34172736.0 \t loss_valid = 28964892.0 \n",
      "Model_10_4380 \t loss_train = 33453034.0 \t loss_valid = 28282868.0 \n",
      "Model_10_4390 \t loss_train = 33650216.0 \t loss_valid = 28412542.0 \n",
      "Model_10_4400 \t loss_train = 33763824.0 \t loss_valid = 28576104.0 \n",
      "Model_10_4410 \t loss_train = 33385998.0 \t loss_valid = 28215362.0 \n",
      "Model_10_4420 \t loss_train = 33585680.0 \t loss_valid = 28357904.0 \n",
      "Model_10_4430 \t loss_train = 34127280.0 \t loss_valid = 28843634.0 \n",
      "Model_10_4440 \t loss_train = 34060500.0 \t loss_valid = 28884710.0 \n",
      "Model_10_4450 \t loss_train = 33539560.0 \t loss_valid = 28289390.0 \n",
      "Model_10_4460 \t loss_train = 34306460.0 \t loss_valid = 28908140.0 \n",
      "Model_10_4470 \t loss_train = 34005044.0 \t loss_valid = 28841896.0 \n",
      "Model_10_4480 \t loss_train = 33450532.0 \t loss_valid = 28163786.0 \n",
      "Model_10_4490 \t loss_train = 33998156.0 \t loss_valid = 28786584.0 \n",
      "Model_10_4500 \t loss_train = 34185380.0 \t loss_valid = 28849632.0 \n",
      "Model_10_4510 \t loss_train = 33867984.0 \t loss_valid = 28733384.0 \n",
      "Model_10_4520 \t loss_train = 33358600.0 \t loss_valid = 28215998.0 \n",
      "Model_10_4530 \t loss_train = 34280884.0 \t loss_valid = 28999218.0 \n",
      "Model_10_4540 \t loss_train = 33954768.0 \t loss_valid = 28685934.0 \n",
      "Model_10_4550 \t loss_train = 33879476.0 \t loss_valid = 28606024.0 \n",
      "Model_10_4560 \t loss_train = 33758536.0 \t loss_valid = 28561222.0 \n",
      "Model_10_4570 \t loss_train = 33580256.0 \t loss_valid = 28408656.0 \n",
      "Model_10_4580 \t loss_train = 33821684.0 \t loss_valid = 28672132.0 \n",
      "Model_10_4590 \t loss_train = 33575904.0 \t loss_valid = 28383266.0 \n",
      "Model_10_4600 \t loss_train = 34100720.0 \t loss_valid = 28801982.0 \n",
      "Model_10_4610 \t loss_train = 34058224.0 \t loss_valid = 28735924.0 \n",
      "Model_10_4620 \t loss_train = 33556032.0 \t loss_valid = 28405216.0 \n",
      "Model_10_4630 \t loss_train = 33893076.0 \t loss_valid = 28669686.0 \n",
      "Model_10_4640 \t loss_train = 33649308.0 \t loss_valid = 28453982.0 \n",
      "Model_10_4650 \t loss_train = 33759076.0 \t loss_valid = 28529414.0 \n",
      "Model_10_4660 \t loss_train = 33767452.0 \t loss_valid = 28563238.0 \n",
      "Model_10_4670 \t loss_train = 33743556.0 \t loss_valid = 28361930.0 \n",
      "Model_10_4680 \t loss_train = 33377012.0 \t loss_valid = 28199648.0 \n",
      "Model_10_4690 \t loss_train = 34051076.0 \t loss_valid = 28789292.0 \n",
      "Model_10_4700 \t loss_train = 34309944.0 \t loss_valid = 29067738.0 \n",
      "Model_10_4710 \t loss_train = 34076924.0 \t loss_valid = 28712866.0 \n",
      "Model_10_4720 \t loss_train = 33462596.0 \t loss_valid = 28209714.0 \n",
      "Model_10_4730 \t loss_train = 33894408.0 \t loss_valid = 28639778.0 \n",
      "Model_10_4740 \t loss_train = 33400992.0 \t loss_valid = 28197622.0 \n",
      "Model_10_4750 \t loss_train = 33832308.0 \t loss_valid = 28561816.0 \n",
      "Model_10_4760 \t loss_train = 33503362.0 \t loss_valid = 28255424.0 \n",
      "Model_10_4770 \t loss_train = 33741632.0 \t loss_valid = 28532524.0 \n",
      "Model_10_4780 \t loss_train = 34062440.0 \t loss_valid = 28688056.0 \n",
      "Model_10_4790 \t loss_train = 33621344.0 \t loss_valid = 28377814.0 \n",
      "Model_10_4800 \t loss_train = 33993468.0 \t loss_valid = 28661912.0 \n",
      "Model_10_4810 \t loss_train = 33362310.0 \t loss_valid = 28174234.0 \n",
      "Model_10_4820 \t loss_train = 33948704.0 \t loss_valid = 28621404.0 \n",
      "Model_10_4830 \t loss_train = 33859832.0 \t loss_valid = 28541276.0 \n",
      "Model_10_4840 \t loss_train = 33995080.0 \t loss_valid = 28670482.0 \n",
      "Model_10_4850 \t loss_train = 33540900.0 \t loss_valid = 28321456.0 \n",
      "Model_10_4860 \t loss_train = 34023124.0 \t loss_valid = 28815944.0 \n",
      "Model_10_4870 \t loss_train = 33564232.0 \t loss_valid = 28287982.0 \n",
      "Model_10_4880 \t loss_train = 34308580.0 \t loss_valid = 29045166.0 \n",
      "Model_10_4890 \t loss_train = 33627652.0 \t loss_valid = 28376924.0 \n",
      "Model_10_4900 \t loss_train = 34121664.0 \t loss_valid = 28899114.0 \n",
      "Model_10_4910 \t loss_train = 33440726.0 \t loss_valid = 28202180.0 \n",
      "Model_10_4920 \t loss_train = 33873164.0 \t loss_valid = 28610066.0 \n",
      "Model_10_4930 \t loss_train = 34239576.0 \t loss_valid = 28882104.0 \n",
      "Model_10_4940 \t loss_train = 34021088.0 \t loss_valid = 28744520.0 \n",
      "Model_10_4950 \t loss_train = 33462454.0 \t loss_valid = 28268254.0 \n",
      "Model_10_4960 \t loss_train = 34042448.0 \t loss_valid = 28766518.0 \n",
      "Model_10_4970 \t loss_train = 33893608.0 \t loss_valid = 28510144.0 \n",
      "Model_10_4980 \t loss_train = 33269380.0 \t loss_valid = 28104318.0 \n",
      "Model_10_4990 \t loss_train = 33772324.0 \t loss_valid = 28506772.0 \n",
      "Model_10_5000 \t loss_train = 33506592.0 \t loss_valid = 28240292.0 \n",
      "Model_10_5010 \t loss_train = 34362808.0 \t loss_valid = 28999276.0 \n",
      "Model_10_5020 \t loss_train = 34213276.0 \t loss_valid = 28802458.0 \n",
      "Model_10_5030 \t loss_train = 33972648.0 \t loss_valid = 28668798.0 \n",
      "Model_10_5040 \t loss_train = 33790928.0 \t loss_valid = 28428556.0 \n",
      "Model_10_5050 \t loss_train = 34575400.0 \t loss_valid = 29305530.0 \n",
      "Model_10_5060 \t loss_train = 33545412.0 \t loss_valid = 28206716.0 \n",
      "Model_10_5070 \t loss_train = 33738560.0 \t loss_valid = 28491530.0 \n",
      "Model_10_5080 \t loss_train = 33980272.0 \t loss_valid = 28637190.0 \n",
      "Model_10_5090 \t loss_train = 34306388.0 \t loss_valid = 28982578.0 \n",
      "Model_10_5100 \t loss_train = 33749832.0 \t loss_valid = 28459998.0 \n",
      "Model_10_5110 \t loss_train = 33403396.0 \t loss_valid = 28249486.0 \n",
      "Model_10_5120 \t loss_train = 33383896.0 \t loss_valid = 28185748.0 \n",
      "Model_10_5130 \t loss_train = 34196600.0 \t loss_valid = 28972316.0 \n",
      "Model_10_5140 \t loss_train = 33497014.0 \t loss_valid = 28241072.0 \n",
      "Model_10_5150 \t loss_train = 34605736.0 \t loss_valid = 29211278.0 \n",
      "Model_10_5160 \t loss_train = 34193108.0 \t loss_valid = 28847604.0 \n",
      "Model_10_5170 \t loss_train = 34047360.0 \t loss_valid = 28782302.0 \n",
      "Model_10_5180 \t loss_train = 33805708.0 \t loss_valid = 28491726.0 \n",
      "Model_10_5190 \t loss_train = 33989972.0 \t loss_valid = 28665284.0 \n",
      "Model_10_5200 \t loss_train = 34387072.0 \t loss_valid = 29095496.0 \n",
      "Model_10_5210 \t loss_train = 33591620.0 \t loss_valid = 28363428.0 \n",
      "Model_10_5220 \t loss_train = 33845368.0 \t loss_valid = 28583228.0 \n",
      "Model_10_5230 \t loss_train = 34102620.0 \t loss_valid = 28782614.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_10_5240 \t loss_train = 34257116.0 \t loss_valid = 28843056.0 \n",
      "Model_10_5250 \t loss_train = 34019876.0 \t loss_valid = 28667358.0 \n",
      "Model_10_5260 \t loss_train = 33468490.0 \t loss_valid = 28191238.0 \n",
      "Model_10_5270 \t loss_train = 34668060.0 \t loss_valid = 29203368.0 \n",
      "Model_10_5280 \t loss_train = 33473638.0 \t loss_valid = 28218940.0 \n",
      "Model_10_5290 \t loss_train = 33786672.0 \t loss_valid = 28553462.0 \n",
      "Model_10_5300 \t loss_train = 33869708.0 \t loss_valid = 28610210.0 \n",
      "Model_10_5310 \t loss_train = 33972916.0 \t loss_valid = 28580630.0 \n",
      "Model_10_5320 \t loss_train = 33942612.0 \t loss_valid = 28468160.0 \n",
      "Model_10_5330 \t loss_train = 34251580.0 \t loss_valid = 29017780.0 \n",
      "Model_10_5340 \t loss_train = 34131976.0 \t loss_valid = 28698086.0 \n",
      "Model_10_5350 \t loss_train = 34102124.0 \t loss_valid = 28908604.0 \n",
      "Model_10_5360 \t loss_train = 33563252.0 \t loss_valid = 28192516.0 \n",
      "Model_10_5370 \t loss_train = 34169480.0 \t loss_valid = 28863990.0 \n",
      "Model_10_5380 \t loss_train = 33697392.0 \t loss_valid = 28426326.0 \n",
      "Model_10_5390 \t loss_train = 34103320.0 \t loss_valid = 28644276.0 \n",
      "Model_10_5400 \t loss_train = 33888928.0 \t loss_valid = 28622798.0 \n",
      "Model_10_5410 \t loss_train = 34508200.0 \t loss_valid = 29162312.0 \n",
      "Model_10_5420 \t loss_train = 34722724.0 \t loss_valid = 29274216.0 \n",
      "Model_10_5430 \t loss_train = 33886872.0 \t loss_valid = 28629026.0 \n",
      "Model_10_5440 \t loss_train = 34451804.0 \t loss_valid = 29114886.0 \n",
      "Model_10_5450 \t loss_train = 33997532.0 \t loss_valid = 28603606.0 \n",
      "Model_10_5460 \t loss_train = 34228160.0 \t loss_valid = 28866064.0 \n",
      "Model_10_5470 \t loss_train = 34470244.0 \t loss_valid = 29030564.0 \n",
      "Model_10_5480 \t loss_train = 33206686.0 \t loss_valid = 28064054.0 \n",
      "Model_10_5490 \t loss_train = 34504084.0 \t loss_valid = 29137342.0 \n",
      "Model_10_5500 \t loss_train = 33441244.0 \t loss_valid = 28196260.0 \n",
      "Model_10_5510 \t loss_train = 34750516.0 \t loss_valid = 29216636.0 \n",
      "Model_10_5520 \t loss_train = 33294196.0 \t loss_valid = 28114264.0 \n",
      "Model_10_5530 \t loss_train = 34843512.0 \t loss_valid = 29344516.0 \n",
      "Model_10_5540 \t loss_train = 33709528.0 \t loss_valid = 28421736.0 \n",
      "Model_10_5550 \t loss_train = 34106776.0 \t loss_valid = 28837420.0 \n",
      "Model_10_5560 \t loss_train = 33788984.0 \t loss_valid = 28437770.0 \n",
      "Model_10_5570 \t loss_train = 34128016.0 \t loss_valid = 28745444.0 \n",
      "Model_10_5580 \t loss_train = 33998972.0 \t loss_valid = 28647124.0 \n",
      "Model_10_5590 \t loss_train = 34509792.0 \t loss_valid = 29184344.0 \n",
      "Model_10_5600 \t loss_train = 33703460.0 \t loss_valid = 28348666.0 \n",
      "Model_10_5610 \t loss_train = 34681752.0 \t loss_valid = 29329522.0 \n",
      "Model_10_5620 \t loss_train = 33573780.0 \t loss_valid = 28320812.0 \n",
      "Model_10_5630 \t loss_train = 34281696.0 \t loss_valid = 28830774.0 \n",
      "Model_10_5640 \t loss_train = 33868804.0 \t loss_valid = 28605450.0 \n",
      "Model_10_5650 \t loss_train = 34022196.0 \t loss_valid = 28680988.0 \n",
      "Model_10_5660 \t loss_train = 34107584.0 \t loss_valid = 28712174.0 \n",
      "Model_10_5670 \t loss_train = 34095612.0 \t loss_valid = 28759090.0 \n",
      "Model_10_5680 \t loss_train = 33364306.0 \t loss_valid = 28191864.0 \n",
      "Model_10_5690 \t loss_train = 33831232.0 \t loss_valid = 28457058.0 \n",
      "Model_10_5700 \t loss_train = 34095624.0 \t loss_valid = 28861550.0 \n",
      "Model_10_5710 \t loss_train = 34041044.0 \t loss_valid = 28673472.0 \n",
      "Model_10_5720 \t loss_train = 33710996.0 \t loss_valid = 28300070.0 \n",
      "Model_10_5730 \t loss_train = 34293516.0 \t loss_valid = 29042432.0 \n",
      "Model_10_5740 \t loss_train = 33088072.0 \t loss_valid = 27972920.0 \n",
      "Model_10_5750 \t loss_train = 33646792.0 \t loss_valid = 28407068.0 \n",
      "Model_10_5760 \t loss_train = 33732036.0 \t loss_valid = 28490244.0 \n",
      "Model_10_5770 \t loss_train = 34109712.0 \t loss_valid = 28723550.0 \n",
      "Model_10_5780 \t loss_train = 33923472.0 \t loss_valid = 28656274.0 \n",
      "Model_10_5790 \t loss_train = 34533336.0 \t loss_valid = 29127766.0 \n",
      "Model_10_5800 \t loss_train = 33505516.0 \t loss_valid = 28310518.0 \n",
      "Model_10_5810 \t loss_train = 33654964.0 \t loss_valid = 28375606.0 \n",
      "Model_10_5820 \t loss_train = 33686664.0 \t loss_valid = 28435038.0 \n",
      "Model_10_5830 \t loss_train = 33719220.0 \t loss_valid = 28414054.0 \n",
      "Model_10_5840 \t loss_train = 34659820.0 \t loss_valid = 29162512.0 \n",
      "Model_10_5850 \t loss_train = 34398648.0 \t loss_valid = 28992110.0 \n",
      "Model_10_5860 \t loss_train = 34835656.0 \t loss_valid = 29289826.0 \n",
      "Model_10_5870 \t loss_train = 34517712.0 \t loss_valid = 28971394.0 \n",
      "Model_10_5880 \t loss_train = 34462060.0 \t loss_valid = 29074938.0 \n",
      "Model_10_5890 \t loss_train = 33560244.0 \t loss_valid = 28303146.0 \n",
      "Model_10_5900 \t loss_train = 33954268.0 \t loss_valid = 28660394.0 \n",
      "Model_10_5910 \t loss_train = 33843720.0 \t loss_valid = 28584284.0 \n",
      "Model_10_5920 \t loss_train = 34478492.0 \t loss_valid = 29107218.0 \n",
      "Model_10_5930 \t loss_train = 33992716.0 \t loss_valid = 28584726.0 \n",
      "Model_10_5940 \t loss_train = 33457260.0 \t loss_valid = 28308632.0 \n",
      "Model_10_5950 \t loss_train = 34328488.0 \t loss_valid = 28885132.0 \n",
      "Model_10_5960 \t loss_train = 33670912.0 \t loss_valid = 28425766.0 \n",
      "Model_10_5970 \t loss_train = 35073656.0 \t loss_valid = 29516706.0 \n",
      "Model_10_5980 \t loss_train = 33666140.0 \t loss_valid = 28307106.0 \n",
      "Model_10_5990 \t loss_train = 34587788.0 \t loss_valid = 29163754.0 \n",
      "Model_10_6000 \t loss_train = 33887856.0 \t loss_valid = 28573520.0 \n",
      "Model_10_6010 \t loss_train = 34375172.0 \t loss_valid = 28921362.0 \n",
      "Model_10_6020 \t loss_train = 34762512.0 \t loss_valid = 29189256.0 \n",
      "Model_10_6030 \t loss_train = 33308004.0 \t loss_valid = 28122612.0 \n",
      "Model_10_6040 \t loss_train = 34671344.0 \t loss_valid = 29225580.0 \n",
      "Model_10_6050 \t loss_train = 33627560.0 \t loss_valid = 28344392.0 \n",
      "Model_10_6060 \t loss_train = 34481672.0 \t loss_valid = 29092384.0 \n",
      "Model_10_6070 \t loss_train = 33565652.0 \t loss_valid = 28283012.0 \n",
      "Model_10_6080 \t loss_train = 33938516.0 \t loss_valid = 28659902.0 \n",
      "Model_10_6090 \t loss_train = 34264840.0 \t loss_valid = 28860902.0 \n",
      "Model_10_6100 \t loss_train = 34378412.0 \t loss_valid = 28939722.0 \n",
      "Model_10_6110 \t loss_train = 34120332.0 \t loss_valid = 28734362.0 \n",
      "Model_10_6120 \t loss_train = 34303556.0 \t loss_valid = 28969332.0 \n",
      "Model_10_6130 \t loss_train = 34273892.0 \t loss_valid = 28826358.0 \n",
      "Model_10_6140 \t loss_train = 33215012.0 \t loss_valid = 27980256.0 \n",
      "Model_10_6150 \t loss_train = 33790384.0 \t loss_valid = 28456976.0 \n",
      "Model_10_6160 \t loss_train = 34020548.0 \t loss_valid = 28704148.0 \n",
      "Model_10_6170 \t loss_train = 34089316.0 \t loss_valid = 28673434.0 \n",
      "Model_10_6180 \t loss_train = 34214576.0 \t loss_valid = 28790908.0 \n",
      "Model_10_6190 \t loss_train = 33982296.0 \t loss_valid = 28533036.0 \n",
      "Model_10_6200 \t loss_train = 34149400.0 \t loss_valid = 28775690.0 \n",
      "Model_10_6210 \t loss_train = 34301472.0 \t loss_valid = 28830736.0 \n",
      "Model_10_6220 \t loss_train = 34528472.0 \t loss_valid = 29076838.0 \n",
      "Model_10_6230 \t loss_train = 34168936.0 \t loss_valid = 28704170.0 \n",
      "Model_10_6240 \t loss_train = 34009652.0 \t loss_valid = 28652342.0 \n",
      "Model_10_6250 \t loss_train = 34249132.0 \t loss_valid = 28821982.0 \n",
      "Model_10_6260 \t loss_train = 34163916.0 \t loss_valid = 28726426.0 \n",
      "Model_10_6270 \t loss_train = 34038652.0 \t loss_valid = 28562082.0 \n",
      "Model_10_6280 \t loss_train = 33633616.0 \t loss_valid = 28338366.0 \n",
      "Model_10_6290 \t loss_train = 34306948.0 \t loss_valid = 28908800.0 \n",
      "Model_10_6300 \t loss_train = 33963832.0 \t loss_valid = 28649292.0 \n",
      "Model_10_6310 \t loss_train = 34530648.0 \t loss_valid = 29058150.0 \n",
      "Model_10_6320 \t loss_train = 34496000.0 \t loss_valid = 29089638.0 \n",
      "Model_10_6330 \t loss_train = 34306592.0 \t loss_valid = 28810064.0 \n",
      "Model_10_6340 \t loss_train = 34383920.0 \t loss_valid = 29039262.0 \n",
      "Model_10_6350 \t loss_train = 34008968.0 \t loss_valid = 28663058.0 \n",
      "Model_10_6360 \t loss_train = 33852092.0 \t loss_valid = 28538750.0 \n",
      "Model_10_6370 \t loss_train = 34297104.0 \t loss_valid = 28898374.0 \n",
      "Model_10_6380 \t loss_train = 34155660.0 \t loss_valid = 28714778.0 \n",
      "Model_10_6390 \t loss_train = 34659628.0 \t loss_valid = 29226948.0 \n",
      "Model_10_6400 \t loss_train = 34239232.0 \t loss_valid = 28805082.0 \n",
      "Model_10_6410 \t loss_train = 34366276.0 \t loss_valid = 28938954.0 \n",
      "Model_10_6420 \t loss_train = 33884788.0 \t loss_valid = 28525452.0 \n",
      "Model_10_6430 \t loss_train = 34991236.0 \t loss_valid = 29381954.0 \n",
      "Model_10_6440 \t loss_train = 33774272.0 \t loss_valid = 28405906.0 \n",
      "Model_10_6450 \t loss_train = 34345112.0 \t loss_valid = 28918316.0 \n",
      "Model_10_6460 \t loss_train = 33976660.0 \t loss_valid = 28542382.0 \n",
      "Model_10_6470 \t loss_train = 34336396.0 \t loss_valid = 28788882.0 \n",
      "Model_10_6480 \t loss_train = 34624408.0 \t loss_valid = 29135512.0 \n",
      "Model_10_6490 \t loss_train = 33845680.0 \t loss_valid = 28468024.0 \n",
      "Model_10_6500 \t loss_train = 34651568.0 \t loss_valid = 29063212.0 \n",
      "Model_10_6510 \t loss_train = 34313680.0 \t loss_valid = 28856892.0 \n",
      "Model_10_6520 \t loss_train = 34536396.0 \t loss_valid = 29012572.0 \n",
      "Model_10_6530 \t loss_train = 33955804.0 \t loss_valid = 28605244.0 \n",
      "Model_10_6540 \t loss_train = 34140748.0 \t loss_valid = 28690072.0 \n",
      "Model_10_6550 \t loss_train = 33599056.0 \t loss_valid = 28346842.0 \n",
      "Model_10_6560 \t loss_train = 34814636.0 \t loss_valid = 29210800.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_10_6570 \t loss_train = 33562604.0 \t loss_valid = 28265716.0 \n",
      "Model_10_6580 \t loss_train = 34169580.0 \t loss_valid = 28739204.0 \n",
      "Model_10_6590 \t loss_train = 34110328.0 \t loss_valid = 28676792.0 \n",
      "Model_10_6600 \t loss_train = 33818976.0 \t loss_valid = 28371804.0 \n",
      "Model_10_6610 \t loss_train = 34335288.0 \t loss_valid = 28846210.0 \n",
      "Model_10_6620 \t loss_train = 34498928.0 \t loss_valid = 29029822.0 \n",
      "Model_10_6630 \t loss_train = 33075486.0 \t loss_valid = 27869368.0 \n",
      "Model_10_6640 \t loss_train = 34370344.0 \t loss_valid = 28984632.0 \n",
      "Model_10_6650 \t loss_train = 34206388.0 \t loss_valid = 28651776.0 \n",
      "Model_10_6660 \t loss_train = 34873412.0 \t loss_valid = 29325066.0 \n",
      "Model_10_6670 \t loss_train = 33911492.0 \t loss_valid = 28603524.0 \n",
      "Model_10_6680 \t loss_train = 34025440.0 \t loss_valid = 28544566.0 \n",
      "Model_10_6690 \t loss_train = 34135028.0 \t loss_valid = 28651154.0 \n",
      "Model_10_6700 \t loss_train = 34541044.0 \t loss_valid = 29017524.0 \n",
      "Model_10_6710 \t loss_train = 34721152.0 \t loss_valid = 29119026.0 \n",
      "Model_10_6720 \t loss_train = 34391472.0 \t loss_valid = 28897308.0 \n",
      "Model_10_6730 \t loss_train = 34446160.0 \t loss_valid = 28948334.0 \n",
      "Model_10_6740 \t loss_train = 34253068.0 \t loss_valid = 28810026.0 \n",
      "Model_10_6750 \t loss_train = 34276260.0 \t loss_valid = 28804678.0 \n",
      "Model_10_6760 \t loss_train = 34363908.0 \t loss_valid = 28824338.0 \n",
      "Model_10_6770 \t loss_train = 34675256.0 \t loss_valid = 29050100.0 \n",
      "Model_10_6780 \t loss_train = 34001800.0 \t loss_valid = 28582894.0 \n",
      "Model_10_6790 \t loss_train = 33692024.0 \t loss_valid = 28312580.0 \n",
      "Model_10_6800 \t loss_train = 34745720.0 \t loss_valid = 29231568.0 \n",
      "Model_10_6810 \t loss_train = 33870052.0 \t loss_valid = 28478148.0 \n",
      "Model_10_6820 \t loss_train = 34368640.0 \t loss_valid = 28928916.0 \n",
      "Model_10_6830 \t loss_train = 34222656.0 \t loss_valid = 28691662.0 \n",
      "Model_10_6840 \t loss_train = 33683040.0 \t loss_valid = 28254132.0 \n",
      "Model_10_6850 \t loss_train = 34641368.0 \t loss_valid = 29070782.0 \n",
      "Model_10_6860 \t loss_train = 34600872.0 \t loss_valid = 28994260.0 \n",
      "Model_10_6870 \t loss_train = 33966272.0 \t loss_valid = 28464772.0 \n",
      "Model_10_6880 \t loss_train = 34527232.0 \t loss_valid = 28962640.0 \n",
      "Model_10_6890 \t loss_train = 33812872.0 \t loss_valid = 28403738.0 \n",
      "Model_10_6900 \t loss_train = 34076504.0 \t loss_valid = 28552448.0 \n",
      "Model_10_6910 \t loss_train = 34620752.0 \t loss_valid = 29087188.0 \n",
      "Model_10_6920 \t loss_train = 34442600.0 \t loss_valid = 28871782.0 \n",
      "Model_10_6930 \t loss_train = 34310248.0 \t loss_valid = 28792414.0 \n",
      "Model_10_6940 \t loss_train = 34813040.0 \t loss_valid = 29145410.0 \n",
      "Model_10_6950 \t loss_train = 34376836.0 \t loss_valid = 28906142.0 \n",
      "Model_10_6960 \t loss_train = 34335940.0 \t loss_valid = 28780060.0 \n",
      "Model_10_6970 \t loss_train = 34223944.0 \t loss_valid = 28769214.0 \n",
      "Model_10_6980 \t loss_train = 34503808.0 \t loss_valid = 28925188.0 \n",
      "Model_10_6990 \t loss_train = 34053212.0 \t loss_valid = 28601228.0 \n",
      "Model_10_7000 \t loss_train = 34544972.0 \t loss_valid = 28962532.0 \n",
      "Model_10_7010 \t loss_train = 34477120.0 \t loss_valid = 28920200.0 \n",
      "Model_10_7020 \t loss_train = 34130852.0 \t loss_valid = 28646488.0 \n",
      "Model_10_7030 \t loss_train = 34463208.0 \t loss_valid = 28917832.0 \n",
      "Model_10_7040 \t loss_train = 34654288.0 \t loss_valid = 29140340.0 \n",
      "Model_10_7050 \t loss_train = 34353928.0 \t loss_valid = 28748386.0 \n",
      "Model_10_7060 \t loss_train = 34312324.0 \t loss_valid = 28735596.0 \n",
      "Model_10_7070 \t loss_train = 34526348.0 \t loss_valid = 29061012.0 \n",
      "Model_10_7080 \t loss_train = 34306272.0 \t loss_valid = 28769148.0 \n",
      "Model_10_7090 \t loss_train = 34763804.0 \t loss_valid = 29202900.0 \n",
      "Model_10_7100 \t loss_train = 34176948.0 \t loss_valid = 28732836.0 \n",
      "Model_10_7110 \t loss_train = 34537164.0 \t loss_valid = 28910378.0 \n",
      "Model_10_7120 \t loss_train = 35090492.0 \t loss_valid = 29502800.0 \n",
      "Model_10_7130 \t loss_train = 34471412.0 \t loss_valid = 28790418.0 \n",
      "Model_10_7140 \t loss_train = 34767724.0 \t loss_valid = 29157446.0 \n",
      "Model_10_7150 \t loss_train = 34201880.0 \t loss_valid = 28621672.0 \n",
      "Model_10_7160 \t loss_train = 34513460.0 \t loss_valid = 28969124.0 \n",
      "Model_10_7170 \t loss_train = 34526884.0 \t loss_valid = 28949906.0 \n",
      "Model_10_7180 \t loss_train = 34611892.0 \t loss_valid = 28971378.0 \n",
      "Model_10_7190 \t loss_train = 34546524.0 \t loss_valid = 28938484.0 \n",
      "Model_10_7200 \t loss_train = 34901792.0 \t loss_valid = 29251136.0 \n",
      "Model_10_7210 \t loss_train = 34236712.0 \t loss_valid = 28721366.0 \n",
      "Model_10_7220 \t loss_train = 34861680.0 \t loss_valid = 29156636.0 \n",
      "Model_10_7230 \t loss_train = 34788504.0 \t loss_valid = 29143454.0 \n",
      "Model_10_7240 \t loss_train = 34275680.0 \t loss_valid = 28751696.0 \n",
      "Model_10_7250 \t loss_train = 34406228.0 \t loss_valid = 28841996.0 \n",
      "Model_10_7260 \t loss_train = 34813420.0 \t loss_valid = 29256028.0 \n",
      "Model_10_7270 \t loss_train = 34472184.0 \t loss_valid = 28847212.0 \n",
      "Model_10_7280 \t loss_train = 33799432.0 \t loss_valid = 28337518.0 \n",
      "Model_10_7290 \t loss_train = 34812060.0 \t loss_valid = 29144348.0 \n",
      "Model_10_7300 \t loss_train = 34465224.0 \t loss_valid = 28878430.0 \n",
      "Model_10_7310 \t loss_train = 34380988.0 \t loss_valid = 28877158.0 \n",
      "Model_10_7320 \t loss_train = 34377828.0 \t loss_valid = 28802200.0 \n",
      "Model_10_7330 \t loss_train = 35214224.0 \t loss_valid = 29429918.0 \n",
      "Model_10_7340 \t loss_train = 34920108.0 \t loss_valid = 29306738.0 \n",
      "Model_10_7350 \t loss_train = 34947116.0 \t loss_valid = 29261922.0 \n",
      "Model_10_7360 \t loss_train = 34615380.0 \t loss_valid = 29010078.0 \n",
      "Model_10_7370 \t loss_train = 34556964.0 \t loss_valid = 29009352.0 \n",
      "Model_10_7380 \t loss_train = 34532248.0 \t loss_valid = 28947804.0 \n",
      "Model_10_7390 \t loss_train = 34754856.0 \t loss_valid = 29079668.0 \n",
      "Model_10_7400 \t loss_train = 34403076.0 \t loss_valid = 28795652.0 \n",
      "Model_10_7410 \t loss_train = 34388184.0 \t loss_valid = 28851700.0 \n",
      "Model_10_7420 \t loss_train = 35067668.0 \t loss_valid = 29297562.0 \n",
      "Model_10_7430 \t loss_train = 34483764.0 \t loss_valid = 28955212.0 \n",
      "Model_10_7440 \t loss_train = 35172680.0 \t loss_valid = 29432248.0 \n",
      "Model_10_7450 \t loss_train = 34611420.0 \t loss_valid = 29051838.0 \n",
      "Model_10_7460 \t loss_train = 34962572.0 \t loss_valid = 29183678.0 \n",
      "Model_10_7470 \t loss_train = 34512540.0 \t loss_valid = 29003100.0 \n",
      "Model_10_7480 \t loss_train = 34613536.0 \t loss_valid = 28964996.0 \n",
      "Model_10_7490 \t loss_train = 35106604.0 \t loss_valid = 29392440.0 \n",
      "Model_10_7500 \t loss_train = 34806096.0 \t loss_valid = 29115066.0 \n",
      "Model_10_7510 \t loss_train = 35271532.0 \t loss_valid = 29518734.0 \n",
      "Model_10_7520 \t loss_train = 35322032.0 \t loss_valid = 29635780.0 \n",
      "Model_10_7530 \t loss_train = 35184164.0 \t loss_valid = 29445420.0 \n",
      "Model_10_7540 \t loss_train = 35093148.0 \t loss_valid = 29415386.0 \n",
      "Model_10_7550 \t loss_train = 34958256.0 \t loss_valid = 29255760.0 \n",
      "Model_10_7560 \t loss_train = 34833000.0 \t loss_valid = 29187360.0 \n",
      "Model_10_7570 \t loss_train = 34673348.0 \t loss_valid = 29023520.0 \n",
      "Model_10_7580 \t loss_train = 34758108.0 \t loss_valid = 29077868.0 \n",
      "Model_10_7590 \t loss_train = 34873784.0 \t loss_valid = 29147424.0 \n",
      "Model_10_7600 \t loss_train = 34691980.0 \t loss_valid = 29098432.0 \n",
      "Model_10_7610 \t loss_train = 35349364.0 \t loss_valid = 29573772.0 \n",
      "Model_10_7620 \t loss_train = 34884172.0 \t loss_valid = 29156918.0 \n",
      "Model_10_7630 \t loss_train = 34721056.0 \t loss_valid = 29106160.0 \n",
      "Model_10_7640 \t loss_train = 35437576.0 \t loss_valid = 29535836.0 \n",
      "Model_10_7650 \t loss_train = 34994548.0 \t loss_valid = 29212744.0 \n",
      "Model_10_7660 \t loss_train = 34811916.0 \t loss_valid = 29127272.0 \n",
      "Model_10_7670 \t loss_train = 35290468.0 \t loss_valid = 29409634.0 \n",
      "Model_10_7680 \t loss_train = 34878080.0 \t loss_valid = 29248920.0 \n",
      "Model_10_7690 \t loss_train = 34857300.0 \t loss_valid = 29197258.0 \n",
      "Model_10_7700 \t loss_train = 35384320.0 \t loss_valid = 29517940.0 \n",
      "Model_10_7710 \t loss_train = 35230916.0 \t loss_valid = 29385040.0 \n",
      "Model_10_7720 \t loss_train = 35529428.0 \t loss_valid = 29691682.0 \n",
      "Model_10_7730 \t loss_train = 35048304.0 \t loss_valid = 29280222.0 \n",
      "Model_10_7740 \t loss_train = 34943320.0 \t loss_valid = 29192230.0 \n",
      "Model_10_7750 \t loss_train = 34746960.0 \t loss_valid = 29023150.0 \n",
      "Model_10_7760 \t loss_train = 35618560.0 \t loss_valid = 29736786.0 \n",
      "Model_10_7770 \t loss_train = 35008768.0 \t loss_valid = 29214482.0 \n",
      "Model_10_7780 \t loss_train = 35401248.0 \t loss_valid = 29554846.0 \n",
      "Model_10_7790 \t loss_train = 35434172.0 \t loss_valid = 29549188.0 \n",
      "Model_10_7800 \t loss_train = 35456904.0 \t loss_valid = 29537460.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_10_7810 \t loss_train = 34928552.0 \t loss_valid = 29154408.0 \n",
      "Model_10_7820 \t loss_train = 35522504.0 \t loss_valid = 29649502.0 \n",
      "Model_10_7830 \t loss_train = 35686976.0 \t loss_valid = 29770576.0 \n",
      "Model_10_7840 \t loss_train = 35164660.0 \t loss_valid = 29308472.0 \n",
      "Model_10_7850 \t loss_train = 35751288.0 \t loss_valid = 29794560.0 \n",
      "Model_10_7860 \t loss_train = 35149020.0 \t loss_valid = 29368624.0 \n",
      "Model_10_7870 \t loss_train = 35250124.0 \t loss_valid = 29386718.0 \n",
      "Model_10_7880 \t loss_train = 34785148.0 \t loss_valid = 29024452.0 \n",
      "Model_10_7890 \t loss_train = 35171900.0 \t loss_valid = 29410128.0 \n",
      "Model_10_7900 \t loss_train = 36127448.0 \t loss_valid = 30176936.0 \n",
      "Model_10_7910 \t loss_train = 34699728.0 \t loss_valid = 28970800.0 \n",
      "Model_10_7920 \t loss_train = 35564396.0 \t loss_valid = 29661964.0 \n",
      "Model_10_7930 \t loss_train = 35779000.0 \t loss_valid = 29805624.0 \n",
      "Model_10_7940 \t loss_train = 35000872.0 \t loss_valid = 29159276.0 \n",
      "Model_10_7950 \t loss_train = 35739624.0 \t loss_valid = 29842040.0 \n",
      "Model_10_7960 \t loss_train = 35280620.0 \t loss_valid = 29426726.0 \n",
      "Model_10_7970 \t loss_train = 35440328.0 \t loss_valid = 29472862.0 \n",
      "Model_10_7980 \t loss_train = 34685788.0 \t loss_valid = 29003198.0 \n",
      "Model_10_7990 \t loss_train = 35951888.0 \t loss_valid = 29988560.0 \n",
      "Model_10_8000 \t loss_train = 35643956.0 \t loss_valid = 29648508.0 \n",
      "Model_10_8010 \t loss_train = 35412644.0 \t loss_valid = 29598354.0 \n",
      "Model_10_8020 \t loss_train = 35656964.0 \t loss_valid = 29714742.0 \n",
      "Model_10_8030 \t loss_train = 35503776.0 \t loss_valid = 29643302.0 \n",
      "Model_10_8040 \t loss_train = 35768076.0 \t loss_valid = 29786482.0 \n",
      "Model_10_8050 \t loss_train = 35918868.0 \t loss_valid = 29899074.0 \n",
      "Model_10_8060 \t loss_train = 35223192.0 \t loss_valid = 29341398.0 \n",
      "Model_10_8070 \t loss_train = 35447568.0 \t loss_valid = 29538086.0 \n",
      "Model_10_8080 \t loss_train = 35596156.0 \t loss_valid = 29680258.0 \n",
      "Model_10_8090 \t loss_train = 34891156.0 \t loss_valid = 29189740.0 \n",
      "Model_10_8100 \t loss_train = 35297224.0 \t loss_valid = 29431846.0 \n",
      "Model_10_8110 \t loss_train = 34694324.0 \t loss_valid = 28970470.0 \n",
      "Model_10_8120 \t loss_train = 35776912.0 \t loss_valid = 29777970.0 \n",
      "Model_10_8130 \t loss_train = 35084576.0 \t loss_valid = 29343298.0 \n",
      "Model_10_8140 \t loss_train = 35476764.0 \t loss_valid = 29553058.0 \n",
      "Model_10_8150 \t loss_train = 35206304.0 \t loss_valid = 29397470.0 \n",
      "Model_10_8160 \t loss_train = 35713772.0 \t loss_valid = 29784270.0 \n",
      "Model_10_8170 \t loss_train = 35134896.0 \t loss_valid = 29308624.0 \n",
      "Model_10_8180 \t loss_train = 35640092.0 \t loss_valid = 29692586.0 \n",
      "Model_10_8190 \t loss_train = 36034512.0 \t loss_valid = 30004988.0 \n",
      "Model_10_8200 \t loss_train = 35338904.0 \t loss_valid = 29496466.0 \n",
      "Model_10_8210 \t loss_train = 35888784.0 \t loss_valid = 29946422.0 \n",
      "Model_10_8220 \t loss_train = 35516220.0 \t loss_valid = 29586720.0 \n",
      "Model_10_8230 \t loss_train = 35441660.0 \t loss_valid = 29492000.0 \n",
      "Model_10_8240 \t loss_train = 36472360.0 \t loss_valid = 30425326.0 \n",
      "Model_10_8250 \t loss_train = 35440388.0 \t loss_valid = 29504136.0 \n",
      "Model_10_8260 \t loss_train = 35389888.0 \t loss_valid = 29515988.0 \n",
      "Model_10_8270 \t loss_train = 35972220.0 \t loss_valid = 29956906.0 \n",
      "Model_10_8280 \t loss_train = 35742164.0 \t loss_valid = 29749936.0 \n",
      "Model_10_8290 \t loss_train = 35851072.0 \t loss_valid = 29783334.0 \n",
      "Model_10_8300 \t loss_train = 35865016.0 \t loss_valid = 29891442.0 \n",
      "Model_10_8310 \t loss_train = 35948492.0 \t loss_valid = 29909252.0 \n",
      "Model_10_8320 \t loss_train = 35815704.0 \t loss_valid = 29843854.0 \n",
      "Model_10_8330 \t loss_train = 35491180.0 \t loss_valid = 29552106.0 \n",
      "Model_10_8340 \t loss_train = 35614848.0 \t loss_valid = 29692314.0 \n",
      "Model_10_8350 \t loss_train = 35766764.0 \t loss_valid = 29820578.0 \n",
      "Model_10_8360 \t loss_train = 36036552.0 \t loss_valid = 29933610.0 \n",
      "Model_10_8370 \t loss_train = 36032276.0 \t loss_valid = 29978552.0 \n",
      "Model_10_8380 \t loss_train = 35905000.0 \t loss_valid = 29899472.0 \n",
      "Model_10_8390 \t loss_train = 35616052.0 \t loss_valid = 29700620.0 \n",
      "Model_10_8400 \t loss_train = 35339104.0 \t loss_valid = 29420316.0 \n",
      "Model_10_8410 \t loss_train = 36305588.0 \t loss_valid = 30239408.0 \n",
      "Model_10_8420 \t loss_train = 35329120.0 \t loss_valid = 29483884.0 \n",
      "Model_10_8430 \t loss_train = 35403976.0 \t loss_valid = 29469706.0 \n",
      "Model_10_8440 \t loss_train = 35936300.0 \t loss_valid = 29983560.0 \n",
      "Model_10_8450 \t loss_train = 35493584.0 \t loss_valid = 29631544.0 \n",
      "Model_10_8460 \t loss_train = 35650924.0 \t loss_valid = 29688778.0 \n",
      "Model_10_8470 \t loss_train = 35748556.0 \t loss_valid = 29779918.0 \n",
      "Model_10_8480 \t loss_train = 35722352.0 \t loss_valid = 29707592.0 \n",
      "Model_10_8490 \t loss_train = 35253084.0 \t loss_valid = 29360738.0 \n",
      "Model_10_8500 \t loss_train = 36115444.0 \t loss_valid = 30088376.0 \n",
      "Model_10_8510 \t loss_train = 35300032.0 \t loss_valid = 29411430.0 \n",
      "Model_10_8520 \t loss_train = 35652560.0 \t loss_valid = 29627958.0 \n",
      "Model_10_8530 \t loss_train = 35706420.0 \t loss_valid = 29689944.0 \n",
      "Model_10_8540 \t loss_train = 36612844.0 \t loss_valid = 30482926.0 \n",
      "Model_10_8550 \t loss_train = 35790172.0 \t loss_valid = 29734540.0 \n",
      "Model_10_8560 \t loss_train = 36158984.0 \t loss_valid = 30078776.0 \n",
      "Model_10_8570 \t loss_train = 36330900.0 \t loss_valid = 30248018.0 \n",
      "Model_10_8580 \t loss_train = 35683380.0 \t loss_valid = 29724476.0 \n",
      "Model_10_8590 \t loss_train = 35690544.0 \t loss_valid = 29720046.0 \n",
      "Model_10_8600 \t loss_train = 36299064.0 \t loss_valid = 30188380.0 \n",
      "Model_10_8610 \t loss_train = 35705000.0 \t loss_valid = 29715766.0 \n",
      "Model_10_8620 \t loss_train = 35938496.0 \t loss_valid = 29901878.0 \n",
      "Model_10_8630 \t loss_train = 36127572.0 \t loss_valid = 30091656.0 \n",
      "Model_10_8640 \t loss_train = 35967980.0 \t loss_valid = 29960028.0 \n",
      "Model_10_8650 \t loss_train = 35890420.0 \t loss_valid = 29895668.0 \n",
      "Model_10_8660 \t loss_train = 35580236.0 \t loss_valid = 29626312.0 \n",
      "Model_10_8670 \t loss_train = 36314376.0 \t loss_valid = 30230582.0 \n",
      "Model_10_8680 \t loss_train = 35366472.0 \t loss_valid = 29435904.0 \n",
      "Model_10_8690 \t loss_train = 36068732.0 \t loss_valid = 30038560.0 \n",
      "Model_10_8700 \t loss_train = 36088284.0 \t loss_valid = 30008640.0 \n",
      "Model_10_8710 \t loss_train = 35602744.0 \t loss_valid = 29643466.0 \n",
      "Model_10_8720 \t loss_train = 36043976.0 \t loss_valid = 29954968.0 \n",
      "Model_10_8730 \t loss_train = 35784652.0 \t loss_valid = 29744658.0 \n",
      "Model_10_8740 \t loss_train = 36615192.0 \t loss_valid = 30444930.0 \n",
      "Model_10_8750 \t loss_train = 36417912.0 \t loss_valid = 30247986.0 \n",
      "Model_10_8760 \t loss_train = 36228952.0 \t loss_valid = 30095916.0 \n",
      "Model_10_8770 \t loss_train = 36101092.0 \t loss_valid = 30008150.0 \n",
      "Model_10_8780 \t loss_train = 35847252.0 \t loss_valid = 29688594.0 \n",
      "Model_10_8790 \t loss_train = 36686612.0 \t loss_valid = 30534612.0 \n",
      "Model_10_8800 \t loss_train = 36357168.0 \t loss_valid = 30206664.0 \n",
      "Model_10_8810 \t loss_train = 35815468.0 \t loss_valid = 29821272.0 \n",
      "Model_10_8820 \t loss_train = 36551096.0 \t loss_valid = 30304796.0 \n",
      "Model_10_8830 \t loss_train = 36022452.0 \t loss_valid = 29969118.0 \n",
      "Model_10_8840 \t loss_train = 35943148.0 \t loss_valid = 29831130.0 \n",
      "Model_10_8850 \t loss_train = 36536796.0 \t loss_valid = 30336054.0 \n",
      "Model_10_8860 \t loss_train = 36157072.0 \t loss_valid = 30127844.0 \n",
      "Model_10_8870 \t loss_train = 36421740.0 \t loss_valid = 30257086.0 \n",
      "Model_10_8880 \t loss_train = 36157696.0 \t loss_valid = 30087932.0 \n",
      "Model_10_8890 \t loss_train = 36327480.0 \t loss_valid = 30177848.0 \n",
      "Model_10_8900 \t loss_train = 36148548.0 \t loss_valid = 30070186.0 \n",
      "Model_10_8910 \t loss_train = 36180008.0 \t loss_valid = 30062062.0 \n",
      "Model_10_8920 \t loss_train = 36062336.0 \t loss_valid = 29964630.0 \n",
      "Model_10_8930 \t loss_train = 35906196.0 \t loss_valid = 29848156.0 \n",
      "Model_10_8940 \t loss_train = 36135844.0 \t loss_valid = 30028348.0 \n",
      "Model_10_8950 \t loss_train = 36079884.0 \t loss_valid = 30056280.0 \n",
      "Model_10_8960 \t loss_train = 36359632.0 \t loss_valid = 30143574.0 \n",
      "Model_10_8970 \t loss_train = 36632708.0 \t loss_valid = 30421912.0 \n",
      "Model_10_8980 \t loss_train = 36265776.0 \t loss_valid = 30088476.0 \n",
      "Model_10_8990 \t loss_train = 36339596.0 \t loss_valid = 30152166.0 \n",
      "Model_10_9000 \t loss_train = 36203612.0 \t loss_valid = 30104114.0 \n",
      "Model_10_9010 \t loss_train = 36155016.0 \t loss_valid = 29988288.0 \n",
      "Model_10_9020 \t loss_train = 36256832.0 \t loss_valid = 30120578.0 \n",
      "Model_10_9030 \t loss_train = 35819548.0 \t loss_valid = 29826414.0 \n",
      "Model_10_9040 \t loss_train = 36386616.0 \t loss_valid = 30294184.0 \n",
      "Model_10_9050 \t loss_train = 36320416.0 \t loss_valid = 30182384.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_10_9060 \t loss_train = 36454936.0 \t loss_valid = 30302758.0 \n",
      "Model_10_9070 \t loss_train = 36646964.0 \t loss_valid = 30441444.0 \n",
      "Model_10_9080 \t loss_train = 36610188.0 \t loss_valid = 30444576.0 \n",
      "Model_10_9090 \t loss_train = 36575892.0 \t loss_valid = 30379456.0 \n",
      "Model_10_9100 \t loss_train = 36029008.0 \t loss_valid = 29952600.0 \n",
      "Model_10_9110 \t loss_train = 35978776.0 \t loss_valid = 29902310.0 \n",
      "Model_10_9120 \t loss_train = 35924080.0 \t loss_valid = 29851572.0 \n",
      "Model_10_9130 \t loss_train = 36900636.0 \t loss_valid = 30597180.0 \n",
      "Model_10_9140 \t loss_train = 36575864.0 \t loss_valid = 30452910.0 \n",
      "Model_10_9150 \t loss_train = 36780872.0 \t loss_valid = 30568280.0 \n",
      "Model_10_9160 \t loss_train = 36749184.0 \t loss_valid = 30468722.0 \n",
      "Model_10_9170 \t loss_train = 36539544.0 \t loss_valid = 30337694.0 \n",
      "Model_10_9180 \t loss_train = 36351324.0 \t loss_valid = 30142046.0 \n",
      "Model_10_9190 \t loss_train = 36772168.0 \t loss_valid = 30552880.0 \n",
      "Model_10_9200 \t loss_train = 36995100.0 \t loss_valid = 30691170.0 \n",
      "Model_10_9210 \t loss_train = 36413820.0 \t loss_valid = 30216688.0 \n",
      "Model_10_9220 \t loss_train = 36656260.0 \t loss_valid = 30429964.0 \n",
      "Model_10_9230 \t loss_train = 37025644.0 \t loss_valid = 30734674.0 \n",
      "Model_10_9240 \t loss_train = 36697248.0 \t loss_valid = 30460122.0 \n",
      "Model_10_9250 \t loss_train = 36353808.0 \t loss_valid = 30163016.0 \n",
      "Model_10_9260 \t loss_train = 36405468.0 \t loss_valid = 30278126.0 \n",
      "Model_10_9270 \t loss_train = 36182896.0 \t loss_valid = 30076644.0 \n",
      "Model_10_9280 \t loss_train = 36618220.0 \t loss_valid = 30472148.0 \n",
      "Model_10_9290 \t loss_train = 37023756.0 \t loss_valid = 30697358.0 \n",
      "Model_10_9300 \t loss_train = 36368040.0 \t loss_valid = 30178168.0 \n",
      "Model_10_9310 \t loss_train = 36071760.0 \t loss_valid = 29934112.0 \n",
      "Model_10_9320 \t loss_train = 36263144.0 \t loss_valid = 30133728.0 \n",
      "Model_10_9330 \t loss_train = 36713824.0 \t loss_valid = 30471112.0 \n",
      "Model_10_9340 \t loss_train = 36968184.0 \t loss_valid = 30716144.0 \n",
      "Model_10_9350 \t loss_train = 36597936.0 \t loss_valid = 30368518.0 \n",
      "Model_10_9360 \t loss_train = 35803420.0 \t loss_valid = 29721204.0 \n",
      "Model_10_9370 \t loss_train = 36829204.0 \t loss_valid = 30490156.0 \n",
      "Model_10_9380 \t loss_train = 37025000.0 \t loss_valid = 30799658.0 \n",
      "Model_10_9390 \t loss_train = 36384392.0 \t loss_valid = 30230794.0 \n",
      "Model_10_9400 \t loss_train = 37071584.0 \t loss_valid = 30731592.0 \n",
      "Model_10_9410 \t loss_train = 36371360.0 \t loss_valid = 30220902.0 \n",
      "Model_10_9420 \t loss_train = 36629768.0 \t loss_valid = 30329420.0 \n",
      "Model_10_9430 \t loss_train = 36821576.0 \t loss_valid = 30574332.0 \n",
      "Model_10_9440 \t loss_train = 36629020.0 \t loss_valid = 30390352.0 \n",
      "Model_10_9450 \t loss_train = 36504996.0 \t loss_valid = 30354836.0 \n",
      "Model_10_9460 \t loss_train = 35856864.0 \t loss_valid = 29799964.0 \n",
      "Model_10_9470 \t loss_train = 36242604.0 \t loss_valid = 30146992.0 \n",
      "Model_10_9480 \t loss_train = 36715132.0 \t loss_valid = 30408414.0 \n",
      "Model_10_9490 \t loss_train = 36425300.0 \t loss_valid = 30273600.0 \n",
      "Model_10_9500 \t loss_train = 36413804.0 \t loss_valid = 30252812.0 \n",
      "Model_10_9510 \t loss_train = 36619208.0 \t loss_valid = 30367242.0 \n",
      "Model_10_9520 \t loss_train = 36247756.0 \t loss_valid = 30058812.0 \n",
      "Model_10_9530 \t loss_train = 36686532.0 \t loss_valid = 30367368.0 \n",
      "Model_10_9540 \t loss_train = 36638872.0 \t loss_valid = 30426608.0 \n",
      "Model_10_9550 \t loss_train = 36488500.0 \t loss_valid = 30319104.0 \n",
      "Model_10_9560 \t loss_train = 36928520.0 \t loss_valid = 30608062.0 \n",
      "Model_10_9570 \t loss_train = 36798960.0 \t loss_valid = 30471740.0 \n",
      "Model_10_9580 \t loss_train = 36275652.0 \t loss_valid = 30094304.0 \n",
      "Model_10_9590 \t loss_train = 36716644.0 \t loss_valid = 30455352.0 \n",
      "Model_10_9600 \t loss_train = 37065904.0 \t loss_valid = 30775780.0 \n",
      "Model_10_9610 \t loss_train = 36898288.0 \t loss_valid = 30579630.0 \n",
      "Model_10_9620 \t loss_train = 36871048.0 \t loss_valid = 30595884.0 \n",
      "Model_10_9630 \t loss_train = 37159560.0 \t loss_valid = 30886754.0 \n",
      "Model_10_9640 \t loss_train = 36922440.0 \t loss_valid = 30556262.0 \n",
      "Model_10_9650 \t loss_train = 37089448.0 \t loss_valid = 30797404.0 \n",
      "Model_10_9660 \t loss_train = 37342012.0 \t loss_valid = 30982252.0 \n",
      "Model_10_9670 \t loss_train = 36757916.0 \t loss_valid = 30494142.0 \n",
      "Model_10_9680 \t loss_train = 37082476.0 \t loss_valid = 30723176.0 \n",
      "Model_10_9690 \t loss_train = 36819124.0 \t loss_valid = 30452898.0 \n",
      "Model_10_9700 \t loss_train = 36548352.0 \t loss_valid = 30395670.0 \n",
      "Model_10_9710 \t loss_train = 36612848.0 \t loss_valid = 30425404.0 \n",
      "Model_10_9720 \t loss_train = 36902200.0 \t loss_valid = 30625678.0 \n",
      "Model_10_9730 \t loss_train = 36843464.0 \t loss_valid = 30567250.0 \n",
      "Model_10_9740 \t loss_train = 36444328.0 \t loss_valid = 30246732.0 \n",
      "Model_10_9750 \t loss_train = 36621280.0 \t loss_valid = 30383474.0 \n",
      "Model_10_9760 \t loss_train = 36955508.0 \t loss_valid = 30657428.0 \n",
      "Model_10_9770 \t loss_train = 36534468.0 \t loss_valid = 30332292.0 \n",
      "Model_10_9780 \t loss_train = 36516780.0 \t loss_valid = 30358374.0 \n",
      "Model_10_9790 \t loss_train = 36442680.0 \t loss_valid = 30283438.0 \n",
      "Model_10_9800 \t loss_train = 36582132.0 \t loss_valid = 30381258.0 \n",
      "Model_10_9810 \t loss_train = 36139236.0 \t loss_valid = 30048344.0 \n",
      "Model_10_9820 \t loss_train = 36717476.0 \t loss_valid = 30486358.0 \n",
      "Model_10_9830 \t loss_train = 37022732.0 \t loss_valid = 30708578.0 \n",
      "Model_10_9840 \t loss_train = 36540020.0 \t loss_valid = 30343662.0 \n",
      "Model_10_9850 \t loss_train = 36804488.0 \t loss_valid = 30566540.0 \n",
      "Model_10_9860 \t loss_train = 36860856.0 \t loss_valid = 30607856.0 \n",
      "Model_10_9870 \t loss_train = 37227992.0 \t loss_valid = 30873182.0 \n",
      "Model_10_9880 \t loss_train = 36615116.0 \t loss_valid = 30407000.0 \n",
      "Model_10_9890 \t loss_train = 36957384.0 \t loss_valid = 30642606.0 \n",
      "Model_10_9900 \t loss_train = 36735436.0 \t loss_valid = 30486644.0 \n",
      "Model_10_9910 \t loss_train = 36623244.0 \t loss_valid = 30391556.0 \n",
      "Model_10_9920 \t loss_train = 36704340.0 \t loss_valid = 30512662.0 \n",
      "Model_10_9930 \t loss_train = 36549440.0 \t loss_valid = 30338572.0 \n",
      "Model_10_9940 \t loss_train = 36775360.0 \t loss_valid = 30577930.0 \n",
      "Model_10_9950 \t loss_train = 36900452.0 \t loss_valid = 30623912.0 \n",
      "Model_10_9960 \t loss_train = 36837548.0 \t loss_valid = 30574592.0 \n",
      "Model_10_9970 \t loss_train = 37144032.0 \t loss_valid = 30784834.0 \n",
      "Model_10_9980 \t loss_train = 37012388.0 \t loss_valid = 30669050.0 \n",
      "Model_10_9990 \t loss_train = 36741184.0 \t loss_valid = 30544380.0 \n",
      "Model_10_10000 \t loss_train = 36902660.0 \t loss_valid = 30573824.0 \n",
      "Model_10_10010 \t loss_train = 36506164.0 \t loss_valid = 30300428.0 \n",
      "Model_10_10020 \t loss_train = 36634984.0 \t loss_valid = 30474922.0 \n",
      "Model_10_10030 \t loss_train = 36843948.0 \t loss_valid = 30487594.0 \n",
      "Model_10_10040 \t loss_train = 36963128.0 \t loss_valid = 30654204.0 \n",
      "Model_10_10050 \t loss_train = 36610620.0 \t loss_valid = 30342418.0 \n",
      "Model_10_10060 \t loss_train = 36498720.0 \t loss_valid = 30353238.0 \n",
      "Model_10_10070 \t loss_train = 37040220.0 \t loss_valid = 30723682.0 \n",
      "Model_10_10080 \t loss_train = 37409368.0 \t loss_valid = 31052782.0 \n",
      "Model_10_10090 \t loss_train = 36998300.0 \t loss_valid = 30715304.0 \n",
      "Model_10_10100 \t loss_train = 36997132.0 \t loss_valid = 30687738.0 \n",
      "Model_10_10110 \t loss_train = 36710352.0 \t loss_valid = 30416516.0 \n",
      "Model_10_10120 \t loss_train = 36636256.0 \t loss_valid = 30336026.0 \n",
      "Model_10_10130 \t loss_train = 36550232.0 \t loss_valid = 30303374.0 \n",
      "Model_10_10140 \t loss_train = 36907456.0 \t loss_valid = 30506698.0 \n",
      "Model_10_10150 \t loss_train = 36864456.0 \t loss_valid = 30565414.0 \n",
      "Model_10_10160 \t loss_train = 36650592.0 \t loss_valid = 30338124.0 \n",
      "Model_10_10170 \t loss_train = 36701644.0 \t loss_valid = 30400550.0 \n",
      "Model_10_10180 \t loss_train = 37204232.0 \t loss_valid = 30807742.0 \n",
      "Model_10_10190 \t loss_train = 36670276.0 \t loss_valid = 30443478.0 \n",
      "Model_10_10200 \t loss_train = 36803976.0 \t loss_valid = 30422800.0 \n",
      "Model_10_10210 \t loss_train = 36618944.0 \t loss_valid = 30357542.0 \n",
      "Model_10_10220 \t loss_train = 37357108.0 \t loss_valid = 30923998.0 \n",
      "Model_10_10230 \t loss_train = 37474540.0 \t loss_valid = 31070716.0 \n",
      "Model_10_10240 \t loss_train = 37541648.0 \t loss_valid = 31161862.0 \n",
      "Model_10_10250 \t loss_train = 37052416.0 \t loss_valid = 30681284.0 \n",
      "Model_10_10260 \t loss_train = 36536596.0 \t loss_valid = 30335552.0 \n",
      "Model_10_10270 \t loss_train = 36740928.0 \t loss_valid = 30477426.0 \n",
      "Model_10_10280 \t loss_train = 36913832.0 \t loss_valid = 30625798.0 \n",
      "Model_10_10290 \t loss_train = 36852832.0 \t loss_valid = 30517952.0 \n",
      "Model_10_10300 \t loss_train = 37056892.0 \t loss_valid = 30756526.0 \n",
      "Model_10_10310 \t loss_train = 37260496.0 \t loss_valid = 30899212.0 \n",
      "Model_10_10320 \t loss_train = 37183772.0 \t loss_valid = 30827230.0 \n",
      "Model_10_10330 \t loss_train = 37147708.0 \t loss_valid = 30760334.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_10_10340 \t loss_train = 37047208.0 \t loss_valid = 30763720.0 \n",
      "Model_10_10350 \t loss_train = 36915228.0 \t loss_valid = 30673322.0 \n",
      "Model_10_10360 \t loss_train = 36703468.0 \t loss_valid = 30454360.0 \n",
      "Model_10_10370 \t loss_train = 37218608.0 \t loss_valid = 30817426.0 \n",
      "Model_10_10380 \t loss_train = 36929676.0 \t loss_valid = 30564994.0 \n",
      "Model_10_10390 \t loss_train = 37133956.0 \t loss_valid = 30766560.0 \n",
      "Model_10_10400 \t loss_train = 37022848.0 \t loss_valid = 30649322.0 \n",
      "Model_10_10410 \t loss_train = 36973972.0 \t loss_valid = 30650456.0 \n",
      "Model_10_10420 \t loss_train = 36912012.0 \t loss_valid = 30639268.0 \n",
      "Model_10_10430 \t loss_train = 36869112.0 \t loss_valid = 30587818.0 \n",
      "Model_10_10440 \t loss_train = 37379776.0 \t loss_valid = 31011000.0 \n",
      "Model_10_10450 \t loss_train = 37400284.0 \t loss_valid = 31019482.0 \n",
      "Model_10_10460 \t loss_train = 36971816.0 \t loss_valid = 30713628.0 \n",
      "Model_10_10470 \t loss_train = 36868356.0 \t loss_valid = 30538590.0 \n",
      "Model_10_10480 \t loss_train = 36756172.0 \t loss_valid = 30525052.0 \n",
      "Model_10_10490 \t loss_train = 36797920.0 \t loss_valid = 30504394.0 \n",
      "Model_10_10500 \t loss_train = 37435596.0 \t loss_valid = 31073836.0 \n",
      "Model_10_10510 \t loss_train = 37438476.0 \t loss_valid = 31059096.0 \n",
      "Model_10_10520 \t loss_train = 37188124.0 \t loss_valid = 30836894.0 \n",
      "Model_10_10530 \t loss_train = 37064816.0 \t loss_valid = 30699336.0 \n",
      "Model_10_10540 \t loss_train = 37421108.0 \t loss_valid = 31012446.0 \n",
      "Model_10_10550 \t loss_train = 37280648.0 \t loss_valid = 30919316.0 \n",
      "Model_10_10560 \t loss_train = 37179748.0 \t loss_valid = 30847972.0 \n",
      "Model_10_10570 \t loss_train = 37333448.0 \t loss_valid = 30973636.0 \n",
      "Model_10_10580 \t loss_train = 37326084.0 \t loss_valid = 30974628.0 \n",
      "Model_10_10590 \t loss_train = 37538844.0 \t loss_valid = 31125230.0 \n",
      "Model_10_10600 \t loss_train = 37292428.0 \t loss_valid = 30894030.0 \n",
      "Model_10_10610 \t loss_train = 37397988.0 \t loss_valid = 30963724.0 \n",
      "Model_10_10620 \t loss_train = 37309144.0 \t loss_valid = 30937770.0 \n",
      "Model_10_10630 \t loss_train = 37387364.0 \t loss_valid = 30985080.0 \n",
      "Model_10_10640 \t loss_train = 37362676.0 \t loss_valid = 31006998.0 \n",
      "Model_10_10650 \t loss_train = 37679660.0 \t loss_valid = 31255790.0 \n",
      "Model_10_10660 \t loss_train = 37300504.0 \t loss_valid = 30940432.0 \n",
      "Model_10_10670 \t loss_train = 36958624.0 \t loss_valid = 30672914.0 \n",
      "Model_10_10680 \t loss_train = 36877864.0 \t loss_valid = 30509774.0 \n",
      "Model_10_10690 \t loss_train = 37315200.0 \t loss_valid = 30929898.0 \n",
      "Model_10_10700 \t loss_train = 37307056.0 \t loss_valid = 30933968.0 \n",
      "Model_10_10710 \t loss_train = 37092036.0 \t loss_valid = 30755520.0 \n",
      "Model_10_10720 \t loss_train = 37177056.0 \t loss_valid = 30827824.0 \n",
      "Model_10_10730 \t loss_train = 37294476.0 \t loss_valid = 30953112.0 \n",
      "Model_10_10740 \t loss_train = 37182504.0 \t loss_valid = 30873476.0 \n",
      "Early stopping!\n",
      "Model_11_0 \t loss_train = 119294488.0 \t loss_valid = 104437240.0 \n",
      "Model_11_10 \t loss_train = 113859600.0 \t loss_valid = 97910072.0 \n",
      "Model_11_20 \t loss_train = 99771456.0 \t loss_valid = 81787888.0 \n",
      "Model_11_30 \t loss_train = 69188400.0 \t loss_valid = 52983712.0 \n",
      "Model_11_40 \t loss_train = 62196444.0 \t loss_valid = 66413632.0 \n",
      "Model_11_50 \t loss_train = 59708224.0 \t loss_valid = 49171028.0 \n",
      "Model_11_60 \t loss_train = 56928024.0 \t loss_valid = 48509732.0 \n",
      "Model_11_70 \t loss_train = 55080756.0 \t loss_valid = 48130492.0 \n",
      "Model_11_80 \t loss_train = 54811492.0 \t loss_valid = 44771368.0 \n",
      "Model_11_90 \t loss_train = 52788916.0 \t loss_valid = 44403420.0 \n",
      "Model_11_100 \t loss_train = 52436664.0 \t loss_valid = 42751984.0 \n",
      "Model_11_110 \t loss_train = 50994852.0 \t loss_valid = 42195072.0 \n",
      "Model_11_120 \t loss_train = 50752940.0 \t loss_valid = 41360320.0 \n",
      "Model_11_130 \t loss_train = 49448844.0 \t loss_valid = 40718208.0 \n",
      "Model_11_140 \t loss_train = 49217104.0 \t loss_valid = 40171132.0 \n",
      "Model_11_150 \t loss_train = 48299972.0 \t loss_valid = 39385440.0 \n",
      "Model_11_160 \t loss_train = 47273072.0 \t loss_valid = 38783868.0 \n",
      "Model_11_170 \t loss_train = 46545828.0 \t loss_valid = 38353536.0 \n",
      "Model_11_180 \t loss_train = 46286276.0 \t loss_valid = 38046396.0 \n",
      "Model_11_190 \t loss_train = 45304320.0 \t loss_valid = 37455788.0 \n",
      "Model_11_200 \t loss_train = 44521564.0 \t loss_valid = 37066076.0 \n",
      "Model_11_210 \t loss_train = 43874696.0 \t loss_valid = 36637464.0 \n",
      "Model_11_220 \t loss_train = 43017680.0 \t loss_valid = 36673048.0 \n",
      "Model_11_230 \t loss_train = 42318492.0 \t loss_valid = 36497376.0 \n",
      "Model_11_240 \t loss_train = 41749116.0 \t loss_valid = 36246504.0 \n",
      "Model_11_250 \t loss_train = 41351956.0 \t loss_valid = 35849196.0 \n",
      "Model_11_260 \t loss_train = 40799516.0 \t loss_valid = 35779804.0 \n",
      "Model_11_270 \t loss_train = 39493720.0 \t loss_valid = 35590612.0 \n",
      "Model_11_280 \t loss_train = 38478808.0 \t loss_valid = 35576980.0 \n",
      "Model_11_290 \t loss_train = 37696036.0 \t loss_valid = 34854680.0 \n",
      "Model_11_300 \t loss_train = 36742224.0 \t loss_valid = 34571200.0 \n",
      "Model_11_310 \t loss_train = 35377660.0 \t loss_valid = 34531896.0 \n",
      "Model_11_320 \t loss_train = 35130420.0 \t loss_valid = 32976170.0 \n",
      "Model_11_330 \t loss_train = 33038852.0 \t loss_valid = 33189670.0 \n",
      "Model_11_340 \t loss_train = 32211876.0 \t loss_valid = 32445684.0 \n",
      "Model_11_350 \t loss_train = 31338830.0 \t loss_valid = 33125882.0 \n",
      "Model_11_360 \t loss_train = 31568838.0 \t loss_valid = 29839926.0 \n",
      "Model_11_370 \t loss_train = 30135164.0 \t loss_valid = 31327830.0 \n",
      "Model_11_380 \t loss_train = 30559454.0 \t loss_valid = 28905130.0 \n",
      "Model_11_390 \t loss_train = 29525398.0 \t loss_valid = 29768872.0 \n",
      "Model_11_400 \t loss_train = 29750212.0 \t loss_valid = 28741102.0 \n",
      "Model_11_410 \t loss_train = 29328992.0 \t loss_valid = 27933048.0 \n",
      "Model_11_420 \t loss_train = 29205524.0 \t loss_valid = 27392252.0 \n",
      "Model_11_430 \t loss_train = 29045282.0 \t loss_valid = 27417638.0 \n",
      "Model_11_440 \t loss_train = 28831980.0 \t loss_valid = 27537288.0 \n",
      "Model_11_450 \t loss_train = 28524270.0 \t loss_valid = 27750002.0 \n",
      "Model_11_460 \t loss_train = 29350712.0 \t loss_valid = 26846790.0 \n",
      "Model_11_470 \t loss_train = 28694104.0 \t loss_valid = 26745906.0 \n",
      "Model_11_480 \t loss_train = 29261676.0 \t loss_valid = 26476070.0 \n",
      "Model_11_490 \t loss_train = 28483636.0 \t loss_valid = 26915536.0 \n",
      "Model_11_500 \t loss_train = 28646342.0 \t loss_valid = 26272710.0 \n",
      "Model_11_510 \t loss_train = 28522064.0 \t loss_valid = 26369346.0 \n",
      "Model_11_520 \t loss_train = 28692550.0 \t loss_valid = 26255266.0 \n",
      "Model_11_530 \t loss_train = 28409894.0 \t loss_valid = 26293584.0 \n",
      "Model_11_540 \t loss_train = 28631620.0 \t loss_valid = 26089106.0 \n",
      "Model_11_550 \t loss_train = 28734674.0 \t loss_valid = 26001548.0 \n",
      "Model_11_560 \t loss_train = 28764710.0 \t loss_valid = 25974728.0 \n",
      "Model_11_570 \t loss_train = 28363916.0 \t loss_valid = 26115128.0 \n",
      "Model_11_580 \t loss_train = 28559268.0 \t loss_valid = 25938318.0 \n",
      "Model_11_590 \t loss_train = 28988534.0 \t loss_valid = 26107584.0 \n",
      "Model_11_600 \t loss_train = 28814898.0 \t loss_valid = 25975058.0 \n",
      "Model_11_610 \t loss_train = 28597002.0 \t loss_valid = 25967286.0 \n",
      "Model_11_620 \t loss_train = 28471902.0 \t loss_valid = 26037294.0 \n",
      "Model_11_630 \t loss_train = 28356164.0 \t loss_valid = 26054242.0 \n",
      "Model_11_640 \t loss_train = 28891536.0 \t loss_valid = 25995852.0 \n",
      "Model_11_650 \t loss_train = 28590106.0 \t loss_valid = 25953504.0 \n",
      "Model_11_660 \t loss_train = 28762230.0 \t loss_valid = 25935802.0 \n",
      "Model_11_670 \t loss_train = 28374694.0 \t loss_valid = 25866552.0 \n",
      "Model_11_680 \t loss_train = 29084724.0 \t loss_valid = 26028186.0 \n",
      "Model_11_690 \t loss_train = 28403908.0 \t loss_valid = 25906436.0 \n",
      "Model_11_700 \t loss_train = 28689698.0 \t loss_valid = 25904324.0 \n",
      "Model_11_710 \t loss_train = 28412566.0 \t loss_valid = 25987900.0 \n",
      "Model_11_720 \t loss_train = 28739352.0 \t loss_valid = 25874996.0 \n",
      "Model_11_730 \t loss_train = 28682366.0 \t loss_valid = 25854204.0 \n",
      "Model_11_740 \t loss_train = 28492706.0 \t loss_valid = 25819516.0 \n",
      "Model_11_750 \t loss_train = 28535924.0 \t loss_valid = 25800600.0 \n",
      "Model_11_760 \t loss_train = 28729750.0 \t loss_valid = 25810608.0 \n",
      "Model_11_770 \t loss_train = 28280650.0 \t loss_valid = 25935412.0 \n",
      "Model_11_780 \t loss_train = 28927198.0 \t loss_valid = 26029072.0 \n",
      "Model_11_790 \t loss_train = 29443454.0 \t loss_valid = 26243012.0 \n",
      "Model_11_800 \t loss_train = 28317672.0 \t loss_valid = 25945114.0 \n",
      "Model_11_810 \t loss_train = 28548330.0 \t loss_valid = 25751206.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_11_820 \t loss_train = 28483918.0 \t loss_valid = 25774892.0 \n",
      "Model_11_830 \t loss_train = 29158646.0 \t loss_valid = 25914936.0 \n",
      "Model_11_840 \t loss_train = 28310630.0 \t loss_valid = 25812224.0 \n",
      "Model_11_850 \t loss_train = 28821584.0 \t loss_valid = 25818858.0 \n",
      "Model_11_860 \t loss_train = 29503184.0 \t loss_valid = 26057266.0 \n",
      "Model_11_870 \t loss_train = 28323998.0 \t loss_valid = 25817522.0 \n",
      "Model_11_880 \t loss_train = 29345776.0 \t loss_valid = 25957982.0 \n",
      "Model_11_890 \t loss_train = 28625224.0 \t loss_valid = 25710970.0 \n",
      "Model_11_900 \t loss_train = 28772178.0 \t loss_valid = 25736244.0 \n",
      "Model_11_910 \t loss_train = 29213794.0 \t loss_valid = 25991380.0 \n",
      "Model_11_920 \t loss_train = 28588722.0 \t loss_valid = 25713226.0 \n",
      "Model_11_930 \t loss_train = 28671940.0 \t loss_valid = 25703632.0 \n",
      "Model_11_940 \t loss_train = 29023172.0 \t loss_valid = 25829112.0 \n",
      "Model_11_950 \t loss_train = 28972672.0 \t loss_valid = 25790492.0 \n",
      "Model_11_960 \t loss_train = 28865810.0 \t loss_valid = 25730240.0 \n",
      "Model_11_970 \t loss_train = 29185596.0 \t loss_valid = 25946930.0 \n",
      "Model_11_980 \t loss_train = 28811580.0 \t loss_valid = 25634408.0 \n",
      "Model_11_990 \t loss_train = 28839942.0 \t loss_valid = 25700742.0 \n",
      "Model_11_1000 \t loss_train = 28886396.0 \t loss_valid = 25668528.0 \n",
      "Model_11_1010 \t loss_train = 29352290.0 \t loss_valid = 25904910.0 \n",
      "Model_11_1020 \t loss_train = 28779206.0 \t loss_valid = 25662938.0 \n",
      "Model_11_1030 \t loss_train = 28931422.0 \t loss_valid = 25715286.0 \n",
      "Model_11_1040 \t loss_train = 29036128.0 \t loss_valid = 25709508.0 \n",
      "Model_11_1050 \t loss_train = 28631410.0 \t loss_valid = 25613688.0 \n",
      "Model_11_1060 \t loss_train = 29406214.0 \t loss_valid = 25973788.0 \n",
      "Model_11_1070 \t loss_train = 29567864.0 \t loss_valid = 26020422.0 \n",
      "Model_11_1080 \t loss_train = 28392740.0 \t loss_valid = 25671564.0 \n",
      "Model_11_1090 \t loss_train = 29550430.0 \t loss_valid = 26010590.0 \n",
      "Model_11_1100 \t loss_train = 29586368.0 \t loss_valid = 26097714.0 \n",
      "Model_11_1110 \t loss_train = 29277314.0 \t loss_valid = 25777930.0 \n",
      "Model_11_1120 \t loss_train = 29867306.0 \t loss_valid = 26264564.0 \n",
      "Model_11_1130 \t loss_train = 29343648.0 \t loss_valid = 25765704.0 \n",
      "Model_11_1140 \t loss_train = 29512446.0 \t loss_valid = 25917562.0 \n",
      "Model_11_1150 \t loss_train = 29861938.0 \t loss_valid = 26146882.0 \n",
      "Model_11_1160 \t loss_train = 29301262.0 \t loss_valid = 25860396.0 \n",
      "Model_11_1170 \t loss_train = 29596472.0 \t loss_valid = 25990256.0 \n",
      "Model_11_1180 \t loss_train = 29389980.0 \t loss_valid = 25847008.0 \n",
      "Model_11_1190 \t loss_train = 29628444.0 \t loss_valid = 26042160.0 \n",
      "Model_11_1200 \t loss_train = 29116538.0 \t loss_valid = 25712366.0 \n",
      "Model_11_1210 \t loss_train = 30662648.0 \t loss_valid = 26716592.0 \n",
      "Model_11_1220 \t loss_train = 29585322.0 \t loss_valid = 25960158.0 \n",
      "Model_11_1230 \t loss_train = 30116000.0 \t loss_valid = 26342102.0 \n",
      "Model_11_1240 \t loss_train = 29874660.0 \t loss_valid = 26241034.0 \n",
      "Model_11_1250 \t loss_train = 29363434.0 \t loss_valid = 25750302.0 \n",
      "Model_11_1260 \t loss_train = 30076656.0 \t loss_valid = 26236614.0 \n",
      "Model_11_1270 \t loss_train = 29771272.0 \t loss_valid = 26049218.0 \n",
      "Model_11_1280 \t loss_train = 29839320.0 \t loss_valid = 26066334.0 \n",
      "Model_11_1290 \t loss_train = 29410514.0 \t loss_valid = 25768202.0 \n",
      "Model_11_1300 \t loss_train = 29889342.0 \t loss_valid = 26069104.0 \n",
      "Model_11_1310 \t loss_train = 29952820.0 \t loss_valid = 26157150.0 \n",
      "Model_11_1320 \t loss_train = 29964742.0 \t loss_valid = 26192640.0 \n",
      "Model_11_1330 \t loss_train = 29812336.0 \t loss_valid = 26024044.0 \n",
      "Model_11_1340 \t loss_train = 30844206.0 \t loss_valid = 26940662.0 \n",
      "Model_11_1350 \t loss_train = 29697964.0 \t loss_valid = 25908936.0 \n",
      "Model_11_1360 \t loss_train = 30505996.0 \t loss_valid = 26536366.0 \n",
      "Model_11_1370 \t loss_train = 30765612.0 \t loss_valid = 26712446.0 \n",
      "Model_11_1380 \t loss_train = 29954412.0 \t loss_valid = 26127430.0 \n",
      "Model_11_1390 \t loss_train = 30872308.0 \t loss_valid = 26764382.0 \n",
      "Model_11_1400 \t loss_train = 29919034.0 \t loss_valid = 26036334.0 \n",
      "Model_11_1410 \t loss_train = 31202430.0 \t loss_valid = 27008562.0 \n",
      "Model_11_1420 \t loss_train = 30322630.0 \t loss_valid = 26327564.0 \n",
      "Model_11_1430 \t loss_train = 30429924.0 \t loss_valid = 26364078.0 \n",
      "Model_11_1440 \t loss_train = 30714934.0 \t loss_valid = 26569140.0 \n",
      "Model_11_1450 \t loss_train = 30367670.0 \t loss_valid = 26303792.0 \n",
      "Model_11_1460 \t loss_train = 30719386.0 \t loss_valid = 26582970.0 \n",
      "Model_11_1470 \t loss_train = 31160946.0 \t loss_valid = 26881688.0 \n",
      "Model_11_1480 \t loss_train = 29988862.0 \t loss_valid = 26012558.0 \n",
      "Model_11_1490 \t loss_train = 30976466.0 \t loss_valid = 26839390.0 \n",
      "Model_11_1500 \t loss_train = 31185214.0 \t loss_valid = 26963550.0 \n",
      "Model_11_1510 \t loss_train = 30577860.0 \t loss_valid = 26420888.0 \n",
      "Model_11_1520 \t loss_train = 30049972.0 \t loss_valid = 26074612.0 \n",
      "Model_11_1530 \t loss_train = 31779446.0 \t loss_valid = 27519800.0 \n",
      "Model_11_1540 \t loss_train = 31245296.0 \t loss_valid = 26926102.0 \n",
      "Model_11_1550 \t loss_train = 31596248.0 \t loss_valid = 27167402.0 \n",
      "Model_11_1560 \t loss_train = 30735526.0 \t loss_valid = 26523636.0 \n",
      "Model_11_1570 \t loss_train = 31184712.0 \t loss_valid = 26883498.0 \n",
      "Model_11_1580 \t loss_train = 31140118.0 \t loss_valid = 26798618.0 \n",
      "Model_11_1590 \t loss_train = 31499598.0 \t loss_valid = 27178670.0 \n",
      "Model_11_1600 \t loss_train = 30937880.0 \t loss_valid = 26607272.0 \n",
      "Model_11_1610 \t loss_train = 30936162.0 \t loss_valid = 26682862.0 \n",
      "Model_11_1620 \t loss_train = 32007722.0 \t loss_valid = 27446456.0 \n",
      "Model_11_1630 \t loss_train = 30813522.0 \t loss_valid = 26474874.0 \n",
      "Model_11_1640 \t loss_train = 30726164.0 \t loss_valid = 26661724.0 \n",
      "Model_11_1650 \t loss_train = 31442918.0 \t loss_valid = 26983910.0 \n",
      "Model_11_1660 \t loss_train = 31950228.0 \t loss_valid = 27505272.0 \n",
      "Model_11_1670 \t loss_train = 31550594.0 \t loss_valid = 27113882.0 \n",
      "Model_11_1680 \t loss_train = 31147522.0 \t loss_valid = 26842222.0 \n",
      "Model_11_1690 \t loss_train = 31437286.0 \t loss_valid = 26979830.0 \n",
      "Model_11_1700 \t loss_train = 32170854.0 \t loss_valid = 27818078.0 \n",
      "Model_11_1710 \t loss_train = 30993280.0 \t loss_valid = 26643996.0 \n",
      "Model_11_1720 \t loss_train = 31362744.0 \t loss_valid = 26939338.0 \n",
      "Model_11_1730 \t loss_train = 31436522.0 \t loss_valid = 26991982.0 \n",
      "Model_11_1740 \t loss_train = 31817440.0 \t loss_valid = 27285584.0 \n",
      "Model_11_1750 \t loss_train = 31448778.0 \t loss_valid = 27030000.0 \n",
      "Model_11_1760 \t loss_train = 31489316.0 \t loss_valid = 26885746.0 \n",
      "Model_11_1770 \t loss_train = 31864858.0 \t loss_valid = 27389630.0 \n",
      "Model_11_1780 \t loss_train = 32245066.0 \t loss_valid = 27709156.0 \n",
      "Model_11_1790 \t loss_train = 31721522.0 \t loss_valid = 27352670.0 \n",
      "Model_11_1800 \t loss_train = 32048276.0 \t loss_valid = 27358640.0 \n",
      "Model_11_1810 \t loss_train = 31838854.0 \t loss_valid = 27204296.0 \n",
      "Model_11_1820 \t loss_train = 32344574.0 \t loss_valid = 27654848.0 \n",
      "Model_11_1830 \t loss_train = 31812548.0 \t loss_valid = 27202130.0 \n",
      "Model_11_1840 \t loss_train = 31013944.0 \t loss_valid = 26603378.0 \n",
      "Model_11_1850 \t loss_train = 33192368.0 \t loss_valid = 28369314.0 \n",
      "Model_11_1860 \t loss_train = 30980092.0 \t loss_valid = 26480714.0 \n",
      "Model_11_1870 \t loss_train = 32231552.0 \t loss_valid = 27672646.0 \n",
      "Model_11_1880 \t loss_train = 31583854.0 \t loss_valid = 27076102.0 \n",
      "Model_11_1890 \t loss_train = 31928788.0 \t loss_valid = 27335752.0 \n",
      "Model_11_1900 \t loss_train = 32547348.0 \t loss_valid = 27742142.0 \n",
      "Model_11_1910 \t loss_train = 31625628.0 \t loss_valid = 27005904.0 \n",
      "Model_11_1920 \t loss_train = 31864090.0 \t loss_valid = 27211422.0 \n",
      "Model_11_1930 \t loss_train = 31965228.0 \t loss_valid = 27374994.0 \n",
      "Model_11_1940 \t loss_train = 32435702.0 \t loss_valid = 27737520.0 \n",
      "Model_11_1950 \t loss_train = 32449832.0 \t loss_valid = 27580040.0 \n",
      "Model_11_1960 \t loss_train = 32071870.0 \t loss_valid = 27459542.0 \n",
      "Model_11_1970 \t loss_train = 32663960.0 \t loss_valid = 27863202.0 \n",
      "Model_11_1980 \t loss_train = 31534438.0 \t loss_valid = 26963838.0 \n",
      "Model_11_1990 \t loss_train = 32590122.0 \t loss_valid = 27710072.0 \n",
      "Model_11_2000 \t loss_train = 32371794.0 \t loss_valid = 27581348.0 \n",
      "Model_11_2010 \t loss_train = 32115322.0 \t loss_valid = 27396384.0 \n",
      "Model_11_2020 \t loss_train = 32798254.0 \t loss_valid = 27981154.0 \n",
      "Model_11_2030 \t loss_train = 32770946.0 \t loss_valid = 27927618.0 \n",
      "Model_11_2040 \t loss_train = 31487486.0 \t loss_valid = 26862646.0 \n",
      "Model_11_2050 \t loss_train = 33443926.0 \t loss_valid = 28567608.0 \n",
      "Model_11_2060 \t loss_train = 32378390.0 \t loss_valid = 27535256.0 \n",
      "Model_11_2070 \t loss_train = 32321062.0 \t loss_valid = 27572164.0 \n",
      "Model_11_2080 \t loss_train = 32899696.0 \t loss_valid = 27987950.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_11_2090 \t loss_train = 32487620.0 \t loss_valid = 27779894.0 \n",
      "Model_11_2100 \t loss_train = 33127278.0 \t loss_valid = 28174386.0 \n",
      "Model_11_2110 \t loss_train = 32321612.0 \t loss_valid = 27461682.0 \n",
      "Model_11_2120 \t loss_train = 32756684.0 \t loss_valid = 27896304.0 \n",
      "Model_11_2130 \t loss_train = 33029418.0 \t loss_valid = 28090166.0 \n",
      "Model_11_2140 \t loss_train = 33627384.0 \t loss_valid = 28552144.0 \n",
      "Model_11_2150 \t loss_train = 32419620.0 \t loss_valid = 27533574.0 \n",
      "Model_11_2160 \t loss_train = 32589374.0 \t loss_valid = 27742758.0 \n",
      "Model_11_2170 \t loss_train = 33371656.0 \t loss_valid = 28351092.0 \n",
      "Model_11_2180 \t loss_train = 32953634.0 \t loss_valid = 28026134.0 \n",
      "Model_11_2190 \t loss_train = 32723554.0 \t loss_valid = 27864978.0 \n",
      "Model_11_2200 \t loss_train = 33102338.0 \t loss_valid = 28317708.0 \n",
      "Model_11_2210 \t loss_train = 32859444.0 \t loss_valid = 27882616.0 \n",
      "Model_11_2220 \t loss_train = 32750578.0 \t loss_valid = 27867170.0 \n",
      "Model_11_2230 \t loss_train = 33344208.0 \t loss_valid = 28341862.0 \n",
      "Model_11_2240 \t loss_train = 32534924.0 \t loss_valid = 27715724.0 \n",
      "Model_11_2250 \t loss_train = 33043008.0 \t loss_valid = 28133958.0 \n",
      "Model_11_2260 \t loss_train = 33586280.0 \t loss_valid = 28719922.0 \n",
      "Model_11_2270 \t loss_train = 32931424.0 \t loss_valid = 27985576.0 \n",
      "Model_11_2280 \t loss_train = 33700440.0 \t loss_valid = 28616202.0 \n",
      "Model_11_2290 \t loss_train = 32241246.0 \t loss_valid = 27484254.0 \n",
      "Model_11_2300 \t loss_train = 33505640.0 \t loss_valid = 28537982.0 \n",
      "Model_11_2310 \t loss_train = 32866576.0 \t loss_valid = 27903694.0 \n",
      "Model_11_2320 \t loss_train = 33022160.0 \t loss_valid = 28161006.0 \n",
      "Model_11_2330 \t loss_train = 33528570.0 \t loss_valid = 28604176.0 \n",
      "Model_11_2340 \t loss_train = 32712824.0 \t loss_valid = 27627388.0 \n",
      "Model_11_2350 \t loss_train = 33871724.0 \t loss_valid = 28798578.0 \n",
      "Model_11_2360 \t loss_train = 33619348.0 \t loss_valid = 28594868.0 \n",
      "Model_11_2370 \t loss_train = 33179948.0 \t loss_valid = 28316438.0 \n",
      "Model_11_2380 \t loss_train = 33623872.0 \t loss_valid = 28696642.0 \n",
      "Model_11_2390 \t loss_train = 32995340.0 \t loss_valid = 28131858.0 \n",
      "Model_11_2400 \t loss_train = 32949826.0 \t loss_valid = 27847466.0 \n",
      "Model_11_2410 \t loss_train = 33712088.0 \t loss_valid = 28800582.0 \n",
      "Model_11_2420 \t loss_train = 33354116.0 \t loss_valid = 28195606.0 \n",
      "Model_11_2430 \t loss_train = 33404606.0 \t loss_valid = 28412346.0 \n",
      "Model_11_2440 \t loss_train = 33313292.0 \t loss_valid = 28324972.0 \n",
      "Model_11_2450 \t loss_train = 32777130.0 \t loss_valid = 27836066.0 \n",
      "Model_11_2460 \t loss_train = 33759140.0 \t loss_valid = 28796706.0 \n",
      "Model_11_2470 \t loss_train = 33380858.0 \t loss_valid = 28330076.0 \n",
      "Model_11_2480 \t loss_train = 33177584.0 \t loss_valid = 28273180.0 \n",
      "Model_11_2490 \t loss_train = 32555708.0 \t loss_valid = 27735100.0 \n",
      "Model_11_2500 \t loss_train = 33661956.0 \t loss_valid = 28623948.0 \n",
      "Model_11_2510 \t loss_train = 33306614.0 \t loss_valid = 28266710.0 \n",
      "Model_11_2520 \t loss_train = 33629332.0 \t loss_valid = 28589928.0 \n",
      "Model_11_2530 \t loss_train = 33656764.0 \t loss_valid = 28488128.0 \n",
      "Model_11_2540 \t loss_train = 32844308.0 \t loss_valid = 27931154.0 \n",
      "Model_11_2550 \t loss_train = 32842418.0 \t loss_valid = 27922248.0 \n",
      "Model_11_2560 \t loss_train = 34008664.0 \t loss_valid = 28601774.0 \n",
      "Model_11_2570 \t loss_train = 33510206.0 \t loss_valid = 28576516.0 \n",
      "Model_11_2580 \t loss_train = 33663448.0 \t loss_valid = 28549708.0 \n",
      "Model_11_2590 \t loss_train = 33596704.0 \t loss_valid = 28523378.0 \n",
      "Model_11_2600 \t loss_train = 33560388.0 \t loss_valid = 28559446.0 \n",
      "Model_11_2610 \t loss_train = 33210694.0 \t loss_valid = 28128142.0 \n",
      "Model_11_2620 \t loss_train = 33440808.0 \t loss_valid = 28387574.0 \n",
      "Model_11_2630 \t loss_train = 33891308.0 \t loss_valid = 28789396.0 \n",
      "Model_11_2640 \t loss_train = 33136620.0 \t loss_valid = 28057736.0 \n",
      "Model_11_2650 \t loss_train = 33998692.0 \t loss_valid = 28859886.0 \n",
      "Model_11_2660 \t loss_train = 33031890.0 \t loss_valid = 28071594.0 \n",
      "Model_11_2670 \t loss_train = 33568260.0 \t loss_valid = 28384682.0 \n",
      "Model_11_2680 \t loss_train = 33172968.0 \t loss_valid = 28197132.0 \n",
      "Model_11_2690 \t loss_train = 34039788.0 \t loss_valid = 28896708.0 \n",
      "Model_11_2700 \t loss_train = 33279416.0 \t loss_valid = 28217376.0 \n",
      "Model_11_2710 \t loss_train = 32973362.0 \t loss_valid = 27974656.0 \n",
      "Model_11_2720 \t loss_train = 33930952.0 \t loss_valid = 28735568.0 \n",
      "Model_11_2730 \t loss_train = 33664632.0 \t loss_valid = 28723538.0 \n",
      "Model_11_2740 \t loss_train = 33110432.0 \t loss_valid = 28039528.0 \n",
      "Model_11_2750 \t loss_train = 34241972.0 \t loss_valid = 29086242.0 \n",
      "Model_11_2760 \t loss_train = 33699144.0 \t loss_valid = 28684360.0 \n",
      "Model_11_2770 \t loss_train = 33583324.0 \t loss_valid = 28579678.0 \n",
      "Model_11_2780 \t loss_train = 33241520.0 \t loss_valid = 28233206.0 \n",
      "Model_11_2790 \t loss_train = 33531694.0 \t loss_valid = 28283682.0 \n",
      "Model_11_2800 \t loss_train = 34440072.0 \t loss_valid = 29146842.0 \n",
      "Model_11_2810 \t loss_train = 33413244.0 \t loss_valid = 28444978.0 \n",
      "Model_11_2820 \t loss_train = 34039032.0 \t loss_valid = 28788774.0 \n",
      "Model_11_2830 \t loss_train = 33646268.0 \t loss_valid = 28445872.0 \n",
      "Model_11_2840 \t loss_train = 33194522.0 \t loss_valid = 28226120.0 \n",
      "Model_11_2850 \t loss_train = 33888504.0 \t loss_valid = 28593674.0 \n",
      "Model_11_2860 \t loss_train = 34410448.0 \t loss_valid = 29232204.0 \n",
      "Model_11_2870 \t loss_train = 33190552.0 \t loss_valid = 28099534.0 \n",
      "Model_11_2880 \t loss_train = 34660632.0 \t loss_valid = 29360304.0 \n",
      "Model_11_2890 \t loss_train = 33070804.0 \t loss_valid = 27932950.0 \n",
      "Model_11_2900 \t loss_train = 33932864.0 \t loss_valid = 28853522.0 \n",
      "Model_11_2910 \t loss_train = 33967572.0 \t loss_valid = 28821058.0 \n",
      "Model_11_2920 \t loss_train = 34090984.0 \t loss_valid = 28871974.0 \n",
      "Model_11_2930 \t loss_train = 33198800.0 \t loss_valid = 28048002.0 \n",
      "Model_11_2940 \t loss_train = 34570096.0 \t loss_valid = 29341740.0 \n",
      "Model_11_2950 \t loss_train = 33332566.0 \t loss_valid = 28233770.0 \n",
      "Model_11_2960 \t loss_train = 33282028.0 \t loss_valid = 28063266.0 \n",
      "Model_11_2970 \t loss_train = 33657620.0 \t loss_valid = 28570362.0 \n",
      "Model_11_2980 \t loss_train = 33866524.0 \t loss_valid = 28563882.0 \n",
      "Model_11_2990 \t loss_train = 33797464.0 \t loss_valid = 28654026.0 \n",
      "Model_11_3000 \t loss_train = 33858664.0 \t loss_valid = 28539430.0 \n",
      "Model_11_3010 \t loss_train = 34253888.0 \t loss_valid = 29026506.0 \n",
      "Model_11_3020 \t loss_train = 34075204.0 \t loss_valid = 28976192.0 \n",
      "Model_11_3030 \t loss_train = 33881576.0 \t loss_valid = 28725956.0 \n",
      "Model_11_3040 \t loss_train = 33752536.0 \t loss_valid = 28559802.0 \n",
      "Model_11_3050 \t loss_train = 34177784.0 \t loss_valid = 28978002.0 \n",
      "Model_11_3060 \t loss_train = 34384772.0 \t loss_valid = 29147380.0 \n",
      "Model_11_3070 \t loss_train = 34467120.0 \t loss_valid = 29217532.0 \n",
      "Model_11_3080 \t loss_train = 34083244.0 \t loss_valid = 28828008.0 \n",
      "Model_11_3090 \t loss_train = 33182326.0 \t loss_valid = 28118306.0 \n",
      "Model_11_3100 \t loss_train = 34720172.0 \t loss_valid = 29539296.0 \n",
      "Model_11_3110 \t loss_train = 33480448.0 \t loss_valid = 28345294.0 \n",
      "Model_11_3120 \t loss_train = 34159692.0 \t loss_valid = 29006456.0 \n",
      "Model_11_3130 \t loss_train = 33998792.0 \t loss_valid = 28754180.0 \n",
      "Model_11_3140 \t loss_train = 34288456.0 \t loss_valid = 29118714.0 \n",
      "Model_11_3150 \t loss_train = 34053068.0 \t loss_valid = 28853424.0 \n",
      "Model_11_3160 \t loss_train = 34165772.0 \t loss_valid = 28957456.0 \n",
      "Model_11_3170 \t loss_train = 33120688.0 \t loss_valid = 28060488.0 \n",
      "Model_11_3180 \t loss_train = 33744804.0 \t loss_valid = 28579884.0 \n",
      "Model_11_3190 \t loss_train = 33862904.0 \t loss_valid = 28536038.0 \n",
      "Model_11_3200 \t loss_train = 33990844.0 \t loss_valid = 28802178.0 \n",
      "Model_11_3210 \t loss_train = 34115332.0 \t loss_valid = 28776802.0 \n",
      "Model_11_3220 \t loss_train = 34304596.0 \t loss_valid = 29086202.0 \n",
      "Model_11_3230 \t loss_train = 33486502.0 \t loss_valid = 28200328.0 \n",
      "Model_11_3240 \t loss_train = 34341816.0 \t loss_valid = 29064306.0 \n",
      "Model_11_3250 \t loss_train = 34026764.0 \t loss_valid = 28896648.0 \n",
      "Model_11_3260 \t loss_train = 33463476.0 \t loss_valid = 28233070.0 \n",
      "Model_11_3270 \t loss_train = 34407864.0 \t loss_valid = 29103328.0 \n",
      "Model_11_3280 \t loss_train = 34156064.0 \t loss_valid = 28770774.0 \n",
      "Model_11_3290 \t loss_train = 33769976.0 \t loss_valid = 28755446.0 \n",
      "Model_11_3300 \t loss_train = 34140496.0 \t loss_valid = 28851146.0 \n",
      "Model_11_3310 \t loss_train = 33827120.0 \t loss_valid = 28623628.0 \n",
      "Model_11_3320 \t loss_train = 34223452.0 \t loss_valid = 28916206.0 \n",
      "Model_11_3330 \t loss_train = 34658928.0 \t loss_valid = 29387088.0 \n",
      "Model_11_3340 \t loss_train = 34302736.0 \t loss_valid = 29037622.0 \n",
      "Model_11_3350 \t loss_train = 34412628.0 \t loss_valid = 29159112.0 \n",
      "Model_11_3360 \t loss_train = 34070892.0 \t loss_valid = 28764024.0 \n",
      "Model_11_3370 \t loss_train = 33505912.0 \t loss_valid = 28379976.0 \n",
      "Model_11_3380 \t loss_train = 34243108.0 \t loss_valid = 29053692.0 \n",
      "Model_11_3390 \t loss_train = 33802972.0 \t loss_valid = 28597792.0 \n",
      "Model_11_3400 \t loss_train = 33598436.0 \t loss_valid = 28375186.0 \n",
      "Model_11_3410 \t loss_train = 34018628.0 \t loss_valid = 28767248.0 \n",
      "Model_11_3420 \t loss_train = 34021648.0 \t loss_valid = 28733730.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_11_3430 \t loss_train = 34048824.0 \t loss_valid = 28717534.0 \n",
      "Model_11_3440 \t loss_train = 33751072.0 \t loss_valid = 28444050.0 \n",
      "Model_11_3450 \t loss_train = 34857140.0 \t loss_valid = 29430206.0 \n",
      "Model_11_3460 \t loss_train = 33930632.0 \t loss_valid = 28603114.0 \n",
      "Model_11_3470 \t loss_train = 34567252.0 \t loss_valid = 29193874.0 \n",
      "Model_11_3480 \t loss_train = 34193300.0 \t loss_valid = 28963346.0 \n",
      "Model_11_3490 \t loss_train = 33912832.0 \t loss_valid = 28692890.0 \n",
      "Model_11_3500 \t loss_train = 33849356.0 \t loss_valid = 28647816.0 \n",
      "Model_11_3510 \t loss_train = 34465248.0 \t loss_valid = 29200840.0 \n",
      "Model_11_3520 \t loss_train = 34151080.0 \t loss_valid = 28939072.0 \n",
      "Model_11_3530 \t loss_train = 33371952.0 \t loss_valid = 28256740.0 \n",
      "Model_11_3540 \t loss_train = 34127964.0 \t loss_valid = 28915020.0 \n",
      "Model_11_3550 \t loss_train = 33736240.0 \t loss_valid = 28532066.0 \n",
      "Model_11_3560 \t loss_train = 34280644.0 \t loss_valid = 29101000.0 \n",
      "Model_11_3570 \t loss_train = 33887888.0 \t loss_valid = 28637118.0 \n",
      "Model_11_3580 \t loss_train = 34115428.0 \t loss_valid = 28942896.0 \n",
      "Model_11_3590 \t loss_train = 33564460.0 \t loss_valid = 28404512.0 \n",
      "Model_11_3600 \t loss_train = 34716468.0 \t loss_valid = 29451144.0 \n",
      "Model_11_3610 \t loss_train = 35063412.0 \t loss_valid = 29910338.0 \n",
      "Model_11_3620 \t loss_train = 33231802.0 \t loss_valid = 28178640.0 \n",
      "Model_11_3630 \t loss_train = 33831336.0 \t loss_valid = 28779896.0 \n",
      "Model_11_3640 \t loss_train = 34895000.0 \t loss_valid = 29621406.0 \n",
      "Model_11_3650 \t loss_train = 34062052.0 \t loss_valid = 28811558.0 \n",
      "Model_11_3660 \t loss_train = 34481304.0 \t loss_valid = 29128294.0 \n",
      "Model_11_3670 \t loss_train = 33312516.0 \t loss_valid = 28178770.0 \n",
      "Model_11_3680 \t loss_train = 34405356.0 \t loss_valid = 29023074.0 \n",
      "Model_11_3690 \t loss_train = 34346432.0 \t loss_valid = 29044926.0 \n",
      "Model_11_3700 \t loss_train = 33586268.0 \t loss_valid = 28498656.0 \n",
      "Model_11_3710 \t loss_train = 33862840.0 \t loss_valid = 28662414.0 \n",
      "Model_11_3720 \t loss_train = 34399200.0 \t loss_valid = 29171820.0 \n",
      "Model_11_3730 \t loss_train = 34015760.0 \t loss_valid = 28722094.0 \n",
      "Model_11_3740 \t loss_train = 32782612.0 \t loss_valid = 27792080.0 \n",
      "Model_11_3750 \t loss_train = 34497668.0 \t loss_valid = 29231028.0 \n",
      "Model_11_3760 \t loss_train = 34265120.0 \t loss_valid = 29056032.0 \n",
      "Model_11_3770 \t loss_train = 33611088.0 \t loss_valid = 28361762.0 \n",
      "Model_11_3780 \t loss_train = 34101060.0 \t loss_valid = 28793950.0 \n",
      "Model_11_3790 \t loss_train = 34723368.0 \t loss_valid = 29311772.0 \n",
      "Model_11_3800 \t loss_train = 33953324.0 \t loss_valid = 28688798.0 \n",
      "Model_11_3810 \t loss_train = 33889852.0 \t loss_valid = 28730700.0 \n",
      "Model_11_3820 \t loss_train = 33863948.0 \t loss_valid = 28601192.0 \n",
      "Model_11_3830 \t loss_train = 34266184.0 \t loss_valid = 28928604.0 \n",
      "Model_11_3840 \t loss_train = 34291652.0 \t loss_valid = 28924216.0 \n",
      "Model_11_3850 \t loss_train = 33467916.0 \t loss_valid = 28254824.0 \n",
      "Model_11_3860 \t loss_train = 34234440.0 \t loss_valid = 29002600.0 \n",
      "Model_11_3870 \t loss_train = 34445860.0 \t loss_valid = 29140138.0 \n",
      "Model_11_3880 \t loss_train = 33739548.0 \t loss_valid = 28488716.0 \n",
      "Model_11_3890 \t loss_train = 35209028.0 \t loss_valid = 29833032.0 \n",
      "Model_11_3900 \t loss_train = 34395700.0 \t loss_valid = 29065318.0 \n",
      "Model_11_3910 \t loss_train = 33832280.0 \t loss_valid = 28601802.0 \n",
      "Model_11_3920 \t loss_train = 34819132.0 \t loss_valid = 29388218.0 \n",
      "Model_11_3930 \t loss_train = 33835420.0 \t loss_valid = 28622250.0 \n",
      "Model_11_3940 \t loss_train = 33965576.0 \t loss_valid = 28705660.0 \n",
      "Model_11_3950 \t loss_train = 34220228.0 \t loss_valid = 28810304.0 \n",
      "Model_11_3960 \t loss_train = 34121800.0 \t loss_valid = 28778696.0 \n",
      "Model_11_3970 \t loss_train = 33397862.0 \t loss_valid = 28130430.0 \n",
      "Model_11_3980 \t loss_train = 34088296.0 \t loss_valid = 28879202.0 \n",
      "Model_11_3990 \t loss_train = 33880792.0 \t loss_valid = 28726518.0 \n",
      "Model_11_4000 \t loss_train = 34560260.0 \t loss_valid = 29171980.0 \n",
      "Model_11_4010 \t loss_train = 34815580.0 \t loss_valid = 29436906.0 \n",
      "Model_11_4020 \t loss_train = 34371112.0 \t loss_valid = 28991108.0 \n",
      "Model_11_4030 \t loss_train = 33715668.0 \t loss_valid = 28446738.0 \n",
      "Model_11_4040 \t loss_train = 33589800.0 \t loss_valid = 28336440.0 \n",
      "Model_11_4050 \t loss_train = 34135932.0 \t loss_valid = 28797030.0 \n",
      "Model_11_4060 \t loss_train = 34300804.0 \t loss_valid = 29061954.0 \n",
      "Model_11_4070 \t loss_train = 33305570.0 \t loss_valid = 28157244.0 \n",
      "Model_11_4080 \t loss_train = 33927792.0 \t loss_valid = 28741072.0 \n",
      "Model_11_4090 \t loss_train = 33782492.0 \t loss_valid = 28607498.0 \n",
      "Model_11_4100 \t loss_train = 33698872.0 \t loss_valid = 28420652.0 \n",
      "Model_11_4110 \t loss_train = 34956312.0 \t loss_valid = 29648952.0 \n",
      "Model_11_4120 \t loss_train = 34102452.0 \t loss_valid = 28729132.0 \n",
      "Model_11_4130 \t loss_train = 34675244.0 \t loss_valid = 29106888.0 \n",
      "Model_11_4140 \t loss_train = 33714652.0 \t loss_valid = 28564474.0 \n",
      "Model_11_4150 \t loss_train = 35231252.0 \t loss_valid = 29781732.0 \n",
      "Model_11_4160 \t loss_train = 33852368.0 \t loss_valid = 28619574.0 \n",
      "Model_11_4170 \t loss_train = 33767960.0 \t loss_valid = 28561436.0 \n",
      "Model_11_4180 \t loss_train = 34155672.0 \t loss_valid = 28875166.0 \n",
      "Model_11_4190 \t loss_train = 33796844.0 \t loss_valid = 28535286.0 \n",
      "Model_11_4200 \t loss_train = 34022684.0 \t loss_valid = 28688668.0 \n",
      "Model_11_4210 \t loss_train = 34565008.0 \t loss_valid = 29168274.0 \n",
      "Model_11_4220 \t loss_train = 33781300.0 \t loss_valid = 28645996.0 \n",
      "Model_11_4230 \t loss_train = 33609612.0 \t loss_valid = 28328900.0 \n",
      "Model_11_4240 \t loss_train = 34667524.0 \t loss_valid = 29275898.0 \n",
      "Model_11_4250 \t loss_train = 34193480.0 \t loss_valid = 28966504.0 \n",
      "Model_11_4260 \t loss_train = 34160452.0 \t loss_valid = 28794870.0 \n",
      "Model_11_4270 \t loss_train = 34382332.0 \t loss_valid = 29075842.0 \n",
      "Model_11_4280 \t loss_train = 33279896.0 \t loss_valid = 28140398.0 \n",
      "Model_11_4290 \t loss_train = 34734184.0 \t loss_valid = 29276128.0 \n",
      "Model_11_4300 \t loss_train = 34494124.0 \t loss_valid = 29140922.0 \n",
      "Model_11_4310 \t loss_train = 34101348.0 \t loss_valid = 28811258.0 \n",
      "Model_11_4320 \t loss_train = 34731608.0 \t loss_valid = 29175496.0 \n",
      "Model_11_4330 \t loss_train = 34124044.0 \t loss_valid = 28699670.0 \n",
      "Model_11_4340 \t loss_train = 35044916.0 \t loss_valid = 29491390.0 \n",
      "Model_11_4350 \t loss_train = 33740160.0 \t loss_valid = 28541374.0 \n",
      "Model_11_4360 \t loss_train = 34253312.0 \t loss_valid = 28836842.0 \n",
      "Model_11_4370 \t loss_train = 34353760.0 \t loss_valid = 28935152.0 \n",
      "Model_11_4380 \t loss_train = 34208900.0 \t loss_valid = 28888934.0 \n",
      "Model_11_4390 \t loss_train = 33672480.0 \t loss_valid = 28254468.0 \n",
      "Model_11_4400 \t loss_train = 33342440.0 \t loss_valid = 28179172.0 \n",
      "Model_11_4410 \t loss_train = 34821396.0 \t loss_valid = 29333592.0 \n",
      "Model_11_4420 \t loss_train = 34869988.0 \t loss_valid = 29428114.0 \n",
      "Model_11_4430 \t loss_train = 33932708.0 \t loss_valid = 28650370.0 \n",
      "Model_11_4440 \t loss_train = 34191392.0 \t loss_valid = 28872786.0 \n",
      "Model_11_4450 \t loss_train = 34552532.0 \t loss_valid = 29242868.0 \n",
      "Model_11_4460 \t loss_train = 34931148.0 \t loss_valid = 29513710.0 \n",
      "Model_11_4470 \t loss_train = 34431828.0 \t loss_valid = 28991394.0 \n",
      "Model_11_4480 \t loss_train = 34267396.0 \t loss_valid = 28974118.0 \n",
      "Model_11_4490 \t loss_train = 33707676.0 \t loss_valid = 28489304.0 \n",
      "Model_11_4500 \t loss_train = 34347924.0 \t loss_valid = 29069062.0 \n",
      "Model_11_4510 \t loss_train = 34587688.0 \t loss_valid = 29118034.0 \n",
      "Model_11_4520 \t loss_train = 35060316.0 \t loss_valid = 29517452.0 \n",
      "Model_11_4530 \t loss_train = 34744628.0 \t loss_valid = 29231218.0 \n",
      "Model_11_4540 \t loss_train = 33898552.0 \t loss_valid = 28556044.0 \n",
      "Model_11_4550 \t loss_train = 34162140.0 \t loss_valid = 28907576.0 \n",
      "Model_11_4560 \t loss_train = 34139756.0 \t loss_valid = 28787700.0 \n",
      "Model_11_4570 \t loss_train = 34281356.0 \t loss_valid = 29014316.0 \n",
      "Model_11_4580 \t loss_train = 34013604.0 \t loss_valid = 28496232.0 \n",
      "Model_11_4590 \t loss_train = 34204692.0 \t loss_valid = 28910990.0 \n",
      "Model_11_4600 \t loss_train = 34873548.0 \t loss_valid = 29413508.0 \n",
      "Model_11_4610 \t loss_train = 33465744.0 \t loss_valid = 28309514.0 \n",
      "Model_11_4620 \t loss_train = 34751308.0 \t loss_valid = 29283248.0 \n",
      "Model_11_4630 \t loss_train = 34226904.0 \t loss_valid = 28787396.0 \n",
      "Model_11_4640 \t loss_train = 34103332.0 \t loss_valid = 28781142.0 \n",
      "Model_11_4650 \t loss_train = 34477196.0 \t loss_valid = 29061366.0 \n",
      "Model_11_4660 \t loss_train = 34210400.0 \t loss_valid = 28806728.0 \n",
      "Model_11_4670 \t loss_train = 33723740.0 \t loss_valid = 28425390.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_11_4680 \t loss_train = 34563064.0 \t loss_valid = 29171690.0 \n",
      "Model_11_4690 \t loss_train = 35219712.0 \t loss_valid = 29616160.0 \n",
      "Model_11_4700 \t loss_train = 33901764.0 \t loss_valid = 28691422.0 \n",
      "Model_11_4710 \t loss_train = 34286888.0 \t loss_valid = 28866838.0 \n",
      "Model_11_4720 \t loss_train = 34495416.0 \t loss_valid = 29033332.0 \n",
      "Model_11_4730 \t loss_train = 34442996.0 \t loss_valid = 28917444.0 \n",
      "Model_11_4740 \t loss_train = 33999336.0 \t loss_valid = 28761568.0 \n",
      "Model_11_4750 \t loss_train = 34623700.0 \t loss_valid = 29096820.0 \n",
      "Model_11_4760 \t loss_train = 34280172.0 \t loss_valid = 28928094.0 \n",
      "Model_11_4770 \t loss_train = 35329996.0 \t loss_valid = 29808672.0 \n",
      "Model_11_4780 \t loss_train = 33764428.0 \t loss_valid = 28541860.0 \n",
      "Model_11_4790 \t loss_train = 34170664.0 \t loss_valid = 28884138.0 \n",
      "Model_11_4800 \t loss_train = 34831152.0 \t loss_valid = 29409700.0 \n",
      "Model_11_4810 \t loss_train = 34125540.0 \t loss_valid = 28739174.0 \n",
      "Model_11_4820 \t loss_train = 35365180.0 \t loss_valid = 29848020.0 \n",
      "Model_11_4830 \t loss_train = 34765524.0 \t loss_valid = 29179584.0 \n",
      "Model_11_4840 \t loss_train = 34901472.0 \t loss_valid = 29416496.0 \n",
      "Model_11_4850 \t loss_train = 34389000.0 \t loss_valid = 29052624.0 \n",
      "Model_11_4860 \t loss_train = 34137884.0 \t loss_valid = 28750680.0 \n",
      "Model_11_4870 \t loss_train = 35189460.0 \t loss_valid = 29650608.0 \n",
      "Model_11_4880 \t loss_train = 34894308.0 \t loss_valid = 29393992.0 \n",
      "Model_11_4890 \t loss_train = 34209556.0 \t loss_valid = 28828774.0 \n",
      "Model_11_4900 \t loss_train = 33611156.0 \t loss_valid = 28395754.0 \n",
      "Model_11_4910 \t loss_train = 35293708.0 \t loss_valid = 29678618.0 \n",
      "Model_11_4920 \t loss_train = 34405672.0 \t loss_valid = 28966062.0 \n",
      "Model_11_4930 \t loss_train = 34770864.0 \t loss_valid = 29236534.0 \n",
      "Model_11_4940 \t loss_train = 34821876.0 \t loss_valid = 29345448.0 \n",
      "Model_11_4950 \t loss_train = 35728572.0 \t loss_valid = 30096952.0 \n",
      "Model_11_4960 \t loss_train = 34359800.0 \t loss_valid = 28802418.0 \n",
      "Model_11_4970 \t loss_train = 34041088.0 \t loss_valid = 28739268.0 \n",
      "Model_11_4980 \t loss_train = 34844584.0 \t loss_valid = 29272952.0 \n",
      "Model_11_4990 \t loss_train = 34774596.0 \t loss_valid = 29203256.0 \n",
      "Model_11_5000 \t loss_train = 34350576.0 \t loss_valid = 28813262.0 \n",
      "Model_11_5010 \t loss_train = 34941872.0 \t loss_valid = 29485426.0 \n",
      "Model_11_5020 \t loss_train = 34591248.0 \t loss_valid = 28983268.0 \n",
      "Model_11_5030 \t loss_train = 34386292.0 \t loss_valid = 28977996.0 \n",
      "Model_11_5040 \t loss_train = 34285552.0 \t loss_valid = 28812010.0 \n",
      "Model_11_5050 \t loss_train = 34997272.0 \t loss_valid = 29372814.0 \n",
      "Model_11_5060 \t loss_train = 33722356.0 \t loss_valid = 28298626.0 \n",
      "Model_11_5070 \t loss_train = 35028236.0 \t loss_valid = 29460424.0 \n",
      "Model_11_5080 \t loss_train = 34416476.0 \t loss_valid = 28890886.0 \n",
      "Model_11_5090 \t loss_train = 34788124.0 \t loss_valid = 29182446.0 \n",
      "Model_11_5100 \t loss_train = 35007308.0 \t loss_valid = 29343614.0 \n",
      "Model_11_5110 \t loss_train = 34534160.0 \t loss_valid = 28993428.0 \n",
      "Model_11_5120 \t loss_train = 35480536.0 \t loss_valid = 29918654.0 \n",
      "Model_11_5130 \t loss_train = 33645412.0 \t loss_valid = 28424198.0 \n",
      "Model_11_5140 \t loss_train = 34901848.0 \t loss_valid = 29330950.0 \n",
      "Model_11_5150 \t loss_train = 35106532.0 \t loss_valid = 29375712.0 \n",
      "Model_11_5160 \t loss_train = 35282744.0 \t loss_valid = 29740500.0 \n",
      "Model_11_5170 \t loss_train = 35229288.0 \t loss_valid = 29577522.0 \n",
      "Model_11_5180 \t loss_train = 35599684.0 \t loss_valid = 29888016.0 \n",
      "Model_11_5190 \t loss_train = 35347924.0 \t loss_valid = 29734362.0 \n",
      "Model_11_5200 \t loss_train = 34575024.0 \t loss_valid = 28916830.0 \n",
      "Model_11_5210 \t loss_train = 35557284.0 \t loss_valid = 29904546.0 \n",
      "Model_11_5220 \t loss_train = 34907348.0 \t loss_valid = 29379192.0 \n",
      "Model_11_5230 \t loss_train = 34316872.0 \t loss_valid = 28779568.0 \n",
      "Model_11_5240 \t loss_train = 34981860.0 \t loss_valid = 29512610.0 \n",
      "Model_11_5250 \t loss_train = 34367572.0 \t loss_valid = 28789824.0 \n",
      "Model_11_5260 \t loss_train = 35249468.0 \t loss_valid = 29591608.0 \n",
      "Model_11_5270 \t loss_train = 34849948.0 \t loss_valid = 29286090.0 \n",
      "Model_11_5280 \t loss_train = 34326848.0 \t loss_valid = 28943010.0 \n",
      "Model_11_5290 \t loss_train = 35307320.0 \t loss_valid = 29653754.0 \n",
      "Model_11_5300 \t loss_train = 34589992.0 \t loss_valid = 29130262.0 \n",
      "Model_11_5310 \t loss_train = 34513668.0 \t loss_valid = 28998276.0 \n",
      "Model_11_5320 \t loss_train = 35094336.0 \t loss_valid = 29533640.0 \n",
      "Model_11_5330 \t loss_train = 35077752.0 \t loss_valid = 29379094.0 \n",
      "Model_11_5340 \t loss_train = 35073680.0 \t loss_valid = 29389172.0 \n",
      "Model_11_5350 \t loss_train = 34473152.0 \t loss_valid = 29041632.0 \n",
      "Model_11_5360 \t loss_train = 34963984.0 \t loss_valid = 29358806.0 \n",
      "Model_11_5370 \t loss_train = 35312628.0 \t loss_valid = 29583296.0 \n",
      "Model_11_5380 \t loss_train = 34934952.0 \t loss_valid = 29421126.0 \n",
      "Model_11_5390 \t loss_train = 35301344.0 \t loss_valid = 29514306.0 \n",
      "Model_11_5400 \t loss_train = 34034756.0 \t loss_valid = 28610910.0 \n",
      "Model_11_5410 \t loss_train = 35374320.0 \t loss_valid = 29610562.0 \n",
      "Model_11_5420 \t loss_train = 35245692.0 \t loss_valid = 29456232.0 \n",
      "Model_11_5430 \t loss_train = 34981476.0 \t loss_valid = 29494260.0 \n",
      "Model_11_5440 \t loss_train = 35286288.0 \t loss_valid = 29545808.0 \n",
      "Model_11_5450 \t loss_train = 34319324.0 \t loss_valid = 28936046.0 \n",
      "Model_11_5460 \t loss_train = 35330780.0 \t loss_valid = 29740850.0 \n",
      "Model_11_5470 \t loss_train = 34900912.0 \t loss_valid = 29365998.0 \n",
      "Model_11_5480 \t loss_train = 34784156.0 \t loss_valid = 29199632.0 \n",
      "Model_11_5490 \t loss_train = 34591020.0 \t loss_valid = 29111644.0 \n",
      "Model_11_5500 \t loss_train = 34471696.0 \t loss_valid = 28827230.0 \n",
      "Model_11_5510 \t loss_train = 35554920.0 \t loss_valid = 29892864.0 \n",
      "Model_11_5520 \t loss_train = 35104484.0 \t loss_valid = 29306940.0 \n",
      "Model_11_5530 \t loss_train = 35847872.0 \t loss_valid = 30016468.0 \n",
      "Model_11_5540 \t loss_train = 35133888.0 \t loss_valid = 29482360.0 \n",
      "Model_11_5550 \t loss_train = 35093472.0 \t loss_valid = 29511134.0 \n",
      "Model_11_5560 \t loss_train = 35312648.0 \t loss_valid = 29567046.0 \n",
      "Model_11_5570 \t loss_train = 35210460.0 \t loss_valid = 29679160.0 \n",
      "Model_11_5580 \t loss_train = 35493560.0 \t loss_valid = 29630120.0 \n",
      "Model_11_5590 \t loss_train = 35161932.0 \t loss_valid = 29538322.0 \n",
      "Model_11_5600 \t loss_train = 34590828.0 \t loss_valid = 29013776.0 \n",
      "Model_11_5610 \t loss_train = 35543440.0 \t loss_valid = 29836648.0 \n",
      "Model_11_5620 \t loss_train = 35054360.0 \t loss_valid = 29354584.0 \n",
      "Model_11_5630 \t loss_train = 34948760.0 \t loss_valid = 29236702.0 \n",
      "Model_11_5640 \t loss_train = 35194568.0 \t loss_valid = 29574176.0 \n",
      "Model_11_5650 \t loss_train = 34568436.0 \t loss_valid = 29081296.0 \n",
      "Model_11_5660 \t loss_train = 35828380.0 \t loss_valid = 29984628.0 \n",
      "Model_11_5670 \t loss_train = 34926240.0 \t loss_valid = 29348608.0 \n",
      "Model_11_5680 \t loss_train = 34368500.0 \t loss_valid = 28755602.0 \n",
      "Model_11_5690 \t loss_train = 35677480.0 \t loss_valid = 29920266.0 \n",
      "Model_11_5700 \t loss_train = 34835752.0 \t loss_valid = 29226082.0 \n",
      "Model_11_5710 \t loss_train = 35306160.0 \t loss_valid = 29539600.0 \n",
      "Model_11_5720 \t loss_train = 35049404.0 \t loss_valid = 29538910.0 \n",
      "Model_11_5730 \t loss_train = 34725432.0 \t loss_valid = 29049944.0 \n",
      "Model_11_5740 \t loss_train = 35727964.0 \t loss_valid = 29908762.0 \n",
      "Model_11_5750 \t loss_train = 34612828.0 \t loss_valid = 28996694.0 \n",
      "Model_11_5760 \t loss_train = 35551668.0 \t loss_valid = 29922706.0 \n",
      "Model_11_5770 \t loss_train = 34805996.0 \t loss_valid = 29174714.0 \n",
      "Model_11_5780 \t loss_train = 35254232.0 \t loss_valid = 29529622.0 \n",
      "Model_11_5790 \t loss_train = 35413784.0 \t loss_valid = 29743212.0 \n",
      "Model_11_5800 \t loss_train = 35179136.0 \t loss_valid = 29381152.0 \n",
      "Model_11_5810 \t loss_train = 35179252.0 \t loss_valid = 29539790.0 \n",
      "Model_11_5820 \t loss_train = 34800088.0 \t loss_valid = 29226920.0 \n",
      "Model_11_5830 \t loss_train = 35405588.0 \t loss_valid = 29680116.0 \n",
      "Model_11_5840 \t loss_train = 35625136.0 \t loss_valid = 29839170.0 \n",
      "Model_11_5850 \t loss_train = 35273348.0 \t loss_valid = 29530586.0 \n",
      "Model_11_5860 \t loss_train = 35139244.0 \t loss_valid = 29413206.0 \n",
      "Model_11_5870 \t loss_train = 35861668.0 \t loss_valid = 29941756.0 \n",
      "Model_11_5880 \t loss_train = 35178056.0 \t loss_valid = 29473094.0 \n",
      "Model_11_5890 \t loss_train = 35482120.0 \t loss_valid = 29628590.0 \n",
      "Model_11_5900 \t loss_train = 34851892.0 \t loss_valid = 29139250.0 \n",
      "Model_11_5910 \t loss_train = 35709304.0 \t loss_valid = 29895092.0 \n",
      "Model_11_5920 \t loss_train = 35353552.0 \t loss_valid = 29664104.0 \n",
      "Model_11_5930 \t loss_train = 36078104.0 \t loss_valid = 30157242.0 \n",
      "Model_11_5940 \t loss_train = 35336528.0 \t loss_valid = 29706462.0 \n",
      "Model_11_5950 \t loss_train = 35474876.0 \t loss_valid = 29693550.0 \n",
      "Model_11_5960 \t loss_train = 35206028.0 \t loss_valid = 29462724.0 \n",
      "Model_11_5970 \t loss_train = 35658348.0 \t loss_valid = 29817572.0 \n",
      "Model_11_5980 \t loss_train = 35261584.0 \t loss_valid = 29562592.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_11_5990 \t loss_train = 36033716.0 \t loss_valid = 30192584.0 \n",
      "Model_11_6000 \t loss_train = 35241224.0 \t loss_valid = 29555652.0 \n",
      "Model_11_6010 \t loss_train = 35670736.0 \t loss_valid = 29751254.0 \n",
      "Model_11_6020 \t loss_train = 35633248.0 \t loss_valid = 29867820.0 \n",
      "Model_11_6030 \t loss_train = 35395700.0 \t loss_valid = 29472922.0 \n",
      "Model_11_6040 \t loss_train = 35546648.0 \t loss_valid = 29711436.0 \n",
      "Model_11_6050 \t loss_train = 36005552.0 \t loss_valid = 29984954.0 \n",
      "Model_11_6060 \t loss_train = 35293436.0 \t loss_valid = 29471096.0 \n",
      "Model_11_6070 \t loss_train = 36439400.0 \t loss_valid = 30429604.0 \n",
      "Model_11_6080 \t loss_train = 35210268.0 \t loss_valid = 29369372.0 \n",
      "Model_11_6090 \t loss_train = 35977224.0 \t loss_valid = 30097180.0 \n",
      "Model_11_6100 \t loss_train = 35033772.0 \t loss_valid = 29283054.0 \n",
      "Model_11_6110 \t loss_train = 35826704.0 \t loss_valid = 29987082.0 \n",
      "Model_11_6120 \t loss_train = 35836552.0 \t loss_valid = 29896820.0 \n",
      "Model_11_6130 \t loss_train = 35462876.0 \t loss_valid = 29684126.0 \n",
      "Model_11_6140 \t loss_train = 35701688.0 \t loss_valid = 29829882.0 \n",
      "Model_11_6150 \t loss_train = 35106592.0 \t loss_valid = 29432816.0 \n",
      "Model_11_6160 \t loss_train = 36054508.0 \t loss_valid = 30165870.0 \n",
      "Model_11_6170 \t loss_train = 35254796.0 \t loss_valid = 29427918.0 \n",
      "Model_11_6180 \t loss_train = 36004744.0 \t loss_valid = 30088376.0 \n",
      "Model_11_6190 \t loss_train = 35436744.0 \t loss_valid = 29620976.0 \n",
      "Model_11_6200 \t loss_train = 35180076.0 \t loss_valid = 29480278.0 \n",
      "Model_11_6210 \t loss_train = 35822404.0 \t loss_valid = 30000248.0 \n",
      "Model_11_6220 \t loss_train = 35516628.0 \t loss_valid = 29649288.0 \n",
      "Model_11_6230 \t loss_train = 34872388.0 \t loss_valid = 29220100.0 \n",
      "Model_11_6240 \t loss_train = 35848332.0 \t loss_valid = 29927940.0 \n",
      "Model_11_6250 \t loss_train = 35615920.0 \t loss_valid = 29758416.0 \n",
      "Model_11_6260 \t loss_train = 36077308.0 \t loss_valid = 30158902.0 \n",
      "Model_11_6270 \t loss_train = 35757332.0 \t loss_valid = 29807072.0 \n",
      "Model_11_6280 \t loss_train = 36166148.0 \t loss_valid = 30332956.0 \n",
      "Model_11_6290 \t loss_train = 35274196.0 \t loss_valid = 29480732.0 \n",
      "Model_11_6300 \t loss_train = 35782380.0 \t loss_valid = 29986210.0 \n",
      "Model_11_6310 \t loss_train = 35318564.0 \t loss_valid = 29505840.0 \n",
      "Model_11_6320 \t loss_train = 35297956.0 \t loss_valid = 29662748.0 \n",
      "Model_11_6330 \t loss_train = 35933904.0 \t loss_valid = 30025450.0 \n",
      "Model_11_6340 \t loss_train = 35562508.0 \t loss_valid = 29761660.0 \n",
      "Model_11_6350 \t loss_train = 36023372.0 \t loss_valid = 30077000.0 \n",
      "Model_11_6360 \t loss_train = 35429400.0 \t loss_valid = 29663580.0 \n",
      "Model_11_6370 \t loss_train = 35135932.0 \t loss_valid = 29413512.0 \n",
      "Model_11_6380 \t loss_train = 35828424.0 \t loss_valid = 29805966.0 \n",
      "Model_11_6390 \t loss_train = 35744040.0 \t loss_valid = 29899902.0 \n",
      "Model_11_6400 \t loss_train = 35123900.0 \t loss_valid = 29454520.0 \n",
      "Model_11_6410 \t loss_train = 35903704.0 \t loss_valid = 30025734.0 \n",
      "Model_11_6420 \t loss_train = 34992404.0 \t loss_valid = 29209098.0 \n",
      "Model_11_6430 \t loss_train = 35852588.0 \t loss_valid = 29967740.0 \n",
      "Model_11_6440 \t loss_train = 35633796.0 \t loss_valid = 29752854.0 \n",
      "Model_11_6450 \t loss_train = 35509868.0 \t loss_valid = 29665242.0 \n",
      "Model_11_6460 \t loss_train = 35644592.0 \t loss_valid = 29772648.0 \n",
      "Model_11_6470 \t loss_train = 35264912.0 \t loss_valid = 29527918.0 \n",
      "Model_11_6480 \t loss_train = 35259748.0 \t loss_valid = 29497920.0 \n",
      "Model_11_6490 \t loss_train = 35442096.0 \t loss_valid = 29625588.0 \n",
      "Model_11_6500 \t loss_train = 35570116.0 \t loss_valid = 29644736.0 \n",
      "Model_11_6510 \t loss_train = 36157524.0 \t loss_valid = 30237762.0 \n",
      "Model_11_6520 \t loss_train = 35367272.0 \t loss_valid = 29428806.0 \n",
      "Model_11_6530 \t loss_train = 35754428.0 \t loss_valid = 29981828.0 \n",
      "Model_11_6540 \t loss_train = 35867044.0 \t loss_valid = 29869814.0 \n",
      "Model_11_6550 \t loss_train = 35408840.0 \t loss_valid = 29540440.0 \n",
      "Model_11_6560 \t loss_train = 35504536.0 \t loss_valid = 29651256.0 \n",
      "Model_11_6570 \t loss_train = 35437720.0 \t loss_valid = 29557532.0 \n",
      "Model_11_6580 \t loss_train = 36245604.0 \t loss_valid = 30269124.0 \n",
      "Model_11_6590 \t loss_train = 35396580.0 \t loss_valid = 29603790.0 \n",
      "Model_11_6600 \t loss_train = 36171244.0 \t loss_valid = 30141168.0 \n",
      "Model_11_6610 \t loss_train = 35418668.0 \t loss_valid = 29677444.0 \n",
      "Model_11_6620 \t loss_train = 35727476.0 \t loss_valid = 29832214.0 \n",
      "Model_11_6630 \t loss_train = 35623164.0 \t loss_valid = 29724760.0 \n",
      "Model_11_6640 \t loss_train = 35349424.0 \t loss_valid = 29474322.0 \n",
      "Model_11_6650 \t loss_train = 35434604.0 \t loss_valid = 29615560.0 \n",
      "Model_11_6660 \t loss_train = 35850856.0 \t loss_valid = 29895946.0 \n",
      "Model_11_6670 \t loss_train = 35525908.0 \t loss_valid = 29654446.0 \n",
      "Model_11_6680 \t loss_train = 36142604.0 \t loss_valid = 30202808.0 \n",
      "Model_11_6690 \t loss_train = 35677040.0 \t loss_valid = 29793804.0 \n",
      "Model_11_6700 \t loss_train = 35866460.0 \t loss_valid = 29937012.0 \n",
      "Model_11_6710 \t loss_train = 35893968.0 \t loss_valid = 29966076.0 \n",
      "Model_11_6720 \t loss_train = 35194704.0 \t loss_valid = 29378360.0 \n",
      "Model_11_6730 \t loss_train = 35659752.0 \t loss_valid = 29737298.0 \n",
      "Model_11_6740 \t loss_train = 36136332.0 \t loss_valid = 30157960.0 \n",
      "Model_11_6750 \t loss_train = 35732896.0 \t loss_valid = 29805448.0 \n",
      "Model_11_6760 \t loss_train = 35711956.0 \t loss_valid = 29757626.0 \n",
      "Model_11_6770 \t loss_train = 35984048.0 \t loss_valid = 30071232.0 \n",
      "Model_11_6780 \t loss_train = 35429672.0 \t loss_valid = 29588284.0 \n",
      "Model_11_6790 \t loss_train = 35616068.0 \t loss_valid = 29718892.0 \n",
      "Model_11_6800 \t loss_train = 36372144.0 \t loss_valid = 30327204.0 \n",
      "Model_11_6810 \t loss_train = 35575232.0 \t loss_valid = 29750938.0 \n",
      "Model_11_6820 \t loss_train = 36077356.0 \t loss_valid = 30133242.0 \n",
      "Model_11_6830 \t loss_train = 36077548.0 \t loss_valid = 30059824.0 \n",
      "Model_11_6840 \t loss_train = 35528568.0 \t loss_valid = 29597036.0 \n",
      "Model_11_6850 \t loss_train = 35720208.0 \t loss_valid = 29803938.0 \n",
      "Model_11_6860 \t loss_train = 35832356.0 \t loss_valid = 29854502.0 \n",
      "Model_11_6870 \t loss_train = 35766596.0 \t loss_valid = 29895774.0 \n",
      "Model_11_6880 \t loss_train = 35754312.0 \t loss_valid = 29782746.0 \n",
      "Model_11_6890 \t loss_train = 35541636.0 \t loss_valid = 29682436.0 \n",
      "Model_11_6900 \t loss_train = 35942884.0 \t loss_valid = 30041702.0 \n",
      "Model_11_6910 \t loss_train = 35918096.0 \t loss_valid = 29903988.0 \n",
      "Model_11_6920 \t loss_train = 35879920.0 \t loss_valid = 29931090.0 \n",
      "Model_11_6930 \t loss_train = 35851036.0 \t loss_valid = 29828650.0 \n",
      "Model_11_6940 \t loss_train = 36032928.0 \t loss_valid = 30082750.0 \n",
      "Model_11_6950 \t loss_train = 36472196.0 \t loss_valid = 30377934.0 \n",
      "Model_11_6960 \t loss_train = 35329856.0 \t loss_valid = 29560598.0 \n",
      "Model_11_6970 \t loss_train = 36259216.0 \t loss_valid = 30255244.0 \n",
      "Model_11_6980 \t loss_train = 35815072.0 \t loss_valid = 29863022.0 \n",
      "Model_11_6990 \t loss_train = 36278744.0 \t loss_valid = 30235186.0 \n",
      "Model_11_7000 \t loss_train = 35024048.0 \t loss_valid = 29289896.0 \n",
      "Model_11_7010 \t loss_train = 36283932.0 \t loss_valid = 30231044.0 \n",
      "Model_11_7020 \t loss_train = 35678632.0 \t loss_valid = 29736818.0 \n",
      "Model_11_7030 \t loss_train = 36117304.0 \t loss_valid = 30072512.0 \n",
      "Model_11_7040 \t loss_train = 35874108.0 \t loss_valid = 29907390.0 \n",
      "Model_11_7050 \t loss_train = 35501192.0 \t loss_valid = 29540010.0 \n",
      "Model_11_7060 \t loss_train = 35928624.0 \t loss_valid = 29971134.0 \n",
      "Model_11_7070 \t loss_train = 35807812.0 \t loss_valid = 29777060.0 \n",
      "Model_11_7080 \t loss_train = 35864136.0 \t loss_valid = 29939896.0 \n",
      "Model_11_7090 \t loss_train = 36260080.0 \t loss_valid = 30156038.0 \n",
      "Model_11_7100 \t loss_train = 35989280.0 \t loss_valid = 30004992.0 \n",
      "Model_11_7110 \t loss_train = 36160732.0 \t loss_valid = 30114932.0 \n",
      "Model_11_7120 \t loss_train = 36211268.0 \t loss_valid = 30079372.0 \n",
      "Model_11_7130 \t loss_train = 36406408.0 \t loss_valid = 30346070.0 \n",
      "Model_11_7140 \t loss_train = 35853492.0 \t loss_valid = 29823476.0 \n",
      "Model_11_7150 \t loss_train = 36066432.0 \t loss_valid = 30105792.0 \n",
      "Model_11_7160 \t loss_train = 36128616.0 \t loss_valid = 30144032.0 \n",
      "Model_11_7170 \t loss_train = 36225924.0 \t loss_valid = 30181980.0 \n",
      "Model_11_7180 \t loss_train = 36267460.0 \t loss_valid = 30251764.0 \n",
      "Model_11_7190 \t loss_train = 36382464.0 \t loss_valid = 30360558.0 \n",
      "Model_11_7200 \t loss_train = 35916252.0 \t loss_valid = 29904744.0 \n",
      "Model_11_7210 \t loss_train = 36339720.0 \t loss_valid = 30216786.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_11_7220 \t loss_train = 36389664.0 \t loss_valid = 30215632.0 \n",
      "Model_11_7230 \t loss_train = 35677156.0 \t loss_valid = 29722102.0 \n",
      "Model_11_7240 \t loss_train = 36705032.0 \t loss_valid = 30608396.0 \n",
      "Model_11_7250 \t loss_train = 35860832.0 \t loss_valid = 29905354.0 \n",
      "Model_11_7260 \t loss_train = 36173852.0 \t loss_valid = 30132114.0 \n",
      "Model_11_7270 \t loss_train = 36294768.0 \t loss_valid = 30197106.0 \n",
      "Model_11_7280 \t loss_train = 36511756.0 \t loss_valid = 30280318.0 \n",
      "Model_11_7290 \t loss_train = 36027752.0 \t loss_valid = 29995824.0 \n",
      "Model_11_7300 \t loss_train = 36109620.0 \t loss_valid = 30028066.0 \n",
      "Model_11_7310 \t loss_train = 36308328.0 \t loss_valid = 30185836.0 \n",
      "Model_11_7320 \t loss_train = 36584996.0 \t loss_valid = 30392216.0 \n",
      "Model_11_7330 \t loss_train = 36322116.0 \t loss_valid = 30197538.0 \n",
      "Model_11_7340 \t loss_train = 36482204.0 \t loss_valid = 30321048.0 \n",
      "Model_11_7350 \t loss_train = 36032048.0 \t loss_valid = 29880272.0 \n",
      "Model_11_7360 \t loss_train = 36249412.0 \t loss_valid = 30127002.0 \n",
      "Model_11_7370 \t loss_train = 35970216.0 \t loss_valid = 29973612.0 \n",
      "Model_11_7380 \t loss_train = 37271480.0 \t loss_valid = 31000352.0 \n",
      "Model_11_7390 \t loss_train = 35914084.0 \t loss_valid = 29895076.0 \n",
      "Model_11_7400 \t loss_train = 36954428.0 \t loss_valid = 30712276.0 \n",
      "Model_11_7410 \t loss_train = 36446916.0 \t loss_valid = 30220442.0 \n",
      "Model_11_7420 \t loss_train = 36151032.0 \t loss_valid = 30109320.0 \n",
      "Model_11_7430 \t loss_train = 36289372.0 \t loss_valid = 30097000.0 \n",
      "Model_11_7440 \t loss_train = 36610812.0 \t loss_valid = 30478510.0 \n",
      "Model_11_7450 \t loss_train = 36171280.0 \t loss_valid = 30079898.0 \n",
      "Model_11_7460 \t loss_train = 36097964.0 \t loss_valid = 30017128.0 \n",
      "Model_11_7470 \t loss_train = 36060656.0 \t loss_valid = 29976282.0 \n",
      "Model_11_7480 \t loss_train = 36037788.0 \t loss_valid = 29965640.0 \n",
      "Model_11_7490 \t loss_train = 36609124.0 \t loss_valid = 30476022.0 \n",
      "Model_11_7500 \t loss_train = 35596840.0 \t loss_valid = 29649066.0 \n",
      "Model_11_7510 \t loss_train = 37071008.0 \t loss_valid = 30884538.0 \n",
      "Model_11_7520 \t loss_train = 36316464.0 \t loss_valid = 30222964.0 \n",
      "Model_11_7530 \t loss_train = 36772488.0 \t loss_valid = 30668104.0 \n",
      "Model_11_7540 \t loss_train = 36370140.0 \t loss_valid = 30256890.0 \n",
      "Model_11_7550 \t loss_train = 36308740.0 \t loss_valid = 30254756.0 \n",
      "Model_11_7560 \t loss_train = 36484148.0 \t loss_valid = 30228152.0 \n",
      "Model_11_7570 \t loss_train = 36341764.0 \t loss_valid = 30311102.0 \n",
      "Model_11_7580 \t loss_train = 36828540.0 \t loss_valid = 30618064.0 \n",
      "Model_11_7590 \t loss_train = 36344368.0 \t loss_valid = 30136952.0 \n",
      "Model_11_7600 \t loss_train = 36328588.0 \t loss_valid = 30251682.0 \n",
      "Model_11_7610 \t loss_train = 36480404.0 \t loss_valid = 30317180.0 \n",
      "Model_11_7620 \t loss_train = 36581412.0 \t loss_valid = 30354976.0 \n",
      "Model_11_7630 \t loss_train = 37057184.0 \t loss_valid = 30789538.0 \n",
      "Model_11_7640 \t loss_train = 35996484.0 \t loss_valid = 29923746.0 \n",
      "Model_11_7650 \t loss_train = 36051440.0 \t loss_valid = 29994060.0 \n",
      "Model_11_7660 \t loss_train = 37201180.0 \t loss_valid = 30897908.0 \n",
      "Model_11_7670 \t loss_train = 36258588.0 \t loss_valid = 30108612.0 \n",
      "Model_11_7680 \t loss_train = 36043952.0 \t loss_valid = 29996240.0 \n",
      "Model_11_7690 \t loss_train = 36566956.0 \t loss_valid = 30340996.0 \n",
      "Model_11_7700 \t loss_train = 36220412.0 \t loss_valid = 30096402.0 \n",
      "Model_11_7710 \t loss_train = 36323496.0 \t loss_valid = 30209830.0 \n",
      "Model_11_7720 \t loss_train = 36729052.0 \t loss_valid = 30478566.0 \n",
      "Model_11_7730 \t loss_train = 36581888.0 \t loss_valid = 30451234.0 \n",
      "Model_11_7740 \t loss_train = 36343892.0 \t loss_valid = 30211874.0 \n",
      "Model_11_7750 \t loss_train = 36659348.0 \t loss_valid = 30490220.0 \n",
      "Model_11_7760 \t loss_train = 36679760.0 \t loss_valid = 30444582.0 \n",
      "Model_11_7770 \t loss_train = 36322964.0 \t loss_valid = 30157242.0 \n",
      "Model_11_7780 \t loss_train = 36242992.0 \t loss_valid = 30105518.0 \n",
      "Model_11_7790 \t loss_train = 36810896.0 \t loss_valid = 30555844.0 \n",
      "Model_11_7800 \t loss_train = 36462084.0 \t loss_valid = 30291516.0 \n",
      "Model_11_7810 \t loss_train = 36769400.0 \t loss_valid = 30540958.0 \n",
      "Model_11_7820 \t loss_train = 36936292.0 \t loss_valid = 30679166.0 \n",
      "Model_11_7830 \t loss_train = 37021204.0 \t loss_valid = 30754980.0 \n",
      "Model_11_7840 \t loss_train = 36613600.0 \t loss_valid = 30415016.0 \n",
      "Model_11_7850 \t loss_train = 36457744.0 \t loss_valid = 30291380.0 \n",
      "Model_11_7860 \t loss_train = 36666052.0 \t loss_valid = 30556018.0 \n",
      "Model_11_7870 \t loss_train = 37158604.0 \t loss_valid = 30810870.0 \n",
      "Model_11_7880 \t loss_train = 36347752.0 \t loss_valid = 30212912.0 \n",
      "Model_11_7890 \t loss_train = 36711548.0 \t loss_valid = 30513828.0 \n",
      "Model_11_7900 \t loss_train = 36922608.0 \t loss_valid = 30718628.0 \n",
      "Model_11_7910 \t loss_train = 37188928.0 \t loss_valid = 30922664.0 \n",
      "Model_11_7920 \t loss_train = 36483404.0 \t loss_valid = 30369810.0 \n",
      "Model_11_7930 \t loss_train = 36846652.0 \t loss_valid = 30566824.0 \n",
      "Model_11_7940 \t loss_train = 36729796.0 \t loss_valid = 30537032.0 \n",
      "Model_11_7950 \t loss_train = 36709536.0 \t loss_valid = 30462950.0 \n",
      "Model_11_7960 \t loss_train = 37020992.0 \t loss_valid = 30786490.0 \n",
      "Model_11_7970 \t loss_train = 36778524.0 \t loss_valid = 30526230.0 \n",
      "Model_11_7980 \t loss_train = 36561988.0 \t loss_valid = 30381106.0 \n",
      "Model_11_7990 \t loss_train = 36999676.0 \t loss_valid = 30719886.0 \n",
      "Model_11_8000 \t loss_train = 36787888.0 \t loss_valid = 30542460.0 \n",
      "Model_11_8010 \t loss_train = 36744160.0 \t loss_valid = 30487036.0 \n",
      "Model_11_8020 \t loss_train = 36462504.0 \t loss_valid = 30399406.0 \n",
      "Model_11_8030 \t loss_train = 36952792.0 \t loss_valid = 30586816.0 \n",
      "Model_11_8040 \t loss_train = 36337616.0 \t loss_valid = 30188216.0 \n",
      "Model_11_8050 \t loss_train = 36755280.0 \t loss_valid = 30478080.0 \n",
      "Model_11_8060 \t loss_train = 36507568.0 \t loss_valid = 30311228.0 \n",
      "Model_11_8070 \t loss_train = 36638612.0 \t loss_valid = 30385572.0 \n",
      "Model_11_8080 \t loss_train = 36524628.0 \t loss_valid = 30332902.0 \n",
      "Model_11_8090 \t loss_train = 36939684.0 \t loss_valid = 30699754.0 \n",
      "Model_11_8100 \t loss_train = 36623140.0 \t loss_valid = 30443002.0 \n",
      "Model_11_8110 \t loss_train = 36710580.0 \t loss_valid = 30454888.0 \n",
      "Model_11_8120 \t loss_train = 36780716.0 \t loss_valid = 30515516.0 \n",
      "Model_11_8130 \t loss_train = 36460752.0 \t loss_valid = 30329906.0 \n",
      "Model_11_8140 \t loss_train = 36878752.0 \t loss_valid = 30549096.0 \n",
      "Model_11_8150 \t loss_train = 36280280.0 \t loss_valid = 30131964.0 \n",
      "Model_11_8160 \t loss_train = 36824752.0 \t loss_valid = 30573050.0 \n",
      "Model_11_8170 \t loss_train = 36694412.0 \t loss_valid = 30510596.0 \n",
      "Model_11_8180 \t loss_train = 36932544.0 \t loss_valid = 30676272.0 \n",
      "Model_11_8190 \t loss_train = 37025916.0 \t loss_valid = 30680190.0 \n",
      "Model_11_8200 \t loss_train = 36667300.0 \t loss_valid = 30483532.0 \n",
      "Model_11_8210 \t loss_train = 36628860.0 \t loss_valid = 30423150.0 \n",
      "Model_11_8220 \t loss_train = 36880660.0 \t loss_valid = 30584488.0 \n",
      "Model_11_8230 \t loss_train = 37045200.0 \t loss_valid = 30755438.0 \n",
      "Model_11_8240 \t loss_train = 37021124.0 \t loss_valid = 30721748.0 \n",
      "Model_11_8250 \t loss_train = 36505776.0 \t loss_valid = 30297764.0 \n",
      "Model_11_8260 \t loss_train = 36893304.0 \t loss_valid = 30723584.0 \n",
      "Model_11_8270 \t loss_train = 37270360.0 \t loss_valid = 30878988.0 \n",
      "Model_11_8280 \t loss_train = 36719212.0 \t loss_valid = 30467574.0 \n",
      "Model_11_8290 \t loss_train = 36584460.0 \t loss_valid = 30386700.0 \n",
      "Model_11_8300 \t loss_train = 37282180.0 \t loss_valid = 31038932.0 \n",
      "Model_11_8310 \t loss_train = 36754580.0 \t loss_valid = 30470548.0 \n",
      "Model_11_8320 \t loss_train = 35852092.0 \t loss_valid = 29817284.0 \n",
      "Model_11_8330 \t loss_train = 36868692.0 \t loss_valid = 30666572.0 \n",
      "Model_11_8340 \t loss_train = 37346380.0 \t loss_valid = 30871530.0 \n",
      "Model_11_8350 \t loss_train = 36447996.0 \t loss_valid = 30287806.0 \n",
      "Model_11_8360 \t loss_train = 36640520.0 \t loss_valid = 30414550.0 \n",
      "Model_11_8370 \t loss_train = 36903864.0 \t loss_valid = 30649158.0 \n",
      "Model_11_8380 \t loss_train = 37152000.0 \t loss_valid = 30852672.0 \n",
      "Model_11_8390 \t loss_train = 36555000.0 \t loss_valid = 30345348.0 \n",
      "Model_11_8400 \t loss_train = 36517776.0 \t loss_valid = 30264608.0 \n",
      "Model_11_8410 \t loss_train = 37314136.0 \t loss_valid = 30992356.0 \n",
      "Model_11_8420 \t loss_train = 36609456.0 \t loss_valid = 30438314.0 \n",
      "Model_11_8430 \t loss_train = 36690288.0 \t loss_valid = 30428950.0 \n",
      "Model_11_8440 \t loss_train = 37076992.0 \t loss_valid = 30794660.0 \n",
      "Model_11_8450 \t loss_train = 36974376.0 \t loss_valid = 30677378.0 \n",
      "Model_11_8460 \t loss_train = 36364724.0 \t loss_valid = 30278836.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_11_8470 \t loss_train = 37248100.0 \t loss_valid = 30883656.0 \n",
      "Model_11_8480 \t loss_train = 37287980.0 \t loss_valid = 30941678.0 \n",
      "Model_11_8490 \t loss_train = 37016204.0 \t loss_valid = 30703840.0 \n",
      "Model_11_8500 \t loss_train = 36751264.0 \t loss_valid = 30473422.0 \n",
      "Model_11_8510 \t loss_train = 36689584.0 \t loss_valid = 30423308.0 \n",
      "Model_11_8520 \t loss_train = 36338028.0 \t loss_valid = 30062266.0 \n",
      "Model_11_8530 \t loss_train = 36724452.0 \t loss_valid = 30487602.0 \n",
      "Model_11_8540 \t loss_train = 37287236.0 \t loss_valid = 30910482.0 \n",
      "Model_11_8550 \t loss_train = 37340592.0 \t loss_valid = 30937890.0 \n",
      "Model_11_8560 \t loss_train = 36954752.0 \t loss_valid = 30509014.0 \n",
      "Model_11_8570 \t loss_train = 36525956.0 \t loss_valid = 30345424.0 \n",
      "Model_11_8580 \t loss_train = 36708172.0 \t loss_valid = 30460716.0 \n",
      "Model_11_8590 \t loss_train = 36836992.0 \t loss_valid = 30533170.0 \n",
      "Model_11_8600 \t loss_train = 36536088.0 \t loss_valid = 30331856.0 \n",
      "Model_11_8610 \t loss_train = 36406968.0 \t loss_valid = 30208442.0 \n",
      "Model_11_8620 \t loss_train = 36690656.0 \t loss_valid = 30366654.0 \n",
      "Model_11_8630 \t loss_train = 36756676.0 \t loss_valid = 30511572.0 \n",
      "Model_11_8640 \t loss_train = 36614508.0 \t loss_valid = 30355946.0 \n",
      "Model_11_8650 \t loss_train = 36705992.0 \t loss_valid = 30444216.0 \n",
      "Model_11_8660 \t loss_train = 36991304.0 \t loss_valid = 30704330.0 \n",
      "Model_11_8670 \t loss_train = 36938476.0 \t loss_valid = 30725468.0 \n",
      "Model_11_8680 \t loss_train = 36901084.0 \t loss_valid = 30580582.0 \n",
      "Model_11_8690 \t loss_train = 36669844.0 \t loss_valid = 30403632.0 \n",
      "Model_11_8700 \t loss_train = 36959492.0 \t loss_valid = 30662346.0 \n",
      "Model_11_8710 \t loss_train = 36925636.0 \t loss_valid = 30556638.0 \n",
      "Model_11_8720 \t loss_train = 36690272.0 \t loss_valid = 30368278.0 \n",
      "Model_11_8730 \t loss_train = 37146172.0 \t loss_valid = 30860880.0 \n",
      "Model_11_8740 \t loss_train = 37063680.0 \t loss_valid = 30630192.0 \n",
      "Model_11_8750 \t loss_train = 37120032.0 \t loss_valid = 30730108.0 \n",
      "Model_11_8760 \t loss_train = 36712148.0 \t loss_valid = 30450126.0 \n",
      "Model_11_8770 \t loss_train = 37170704.0 \t loss_valid = 30815620.0 \n",
      "Model_11_8780 \t loss_train = 37554196.0 \t loss_valid = 31068596.0 \n",
      "Model_11_8790 \t loss_train = 36539964.0 \t loss_valid = 30302976.0 \n",
      "Model_11_8800 \t loss_train = 36574932.0 \t loss_valid = 30317324.0 \n",
      "Model_11_8810 \t loss_train = 37144508.0 \t loss_valid = 30709988.0 \n",
      "Model_11_8820 \t loss_train = 37022204.0 \t loss_valid = 30700092.0 \n",
      "Model_11_8830 \t loss_train = 36929328.0 \t loss_valid = 30635574.0 \n",
      "Model_11_8840 \t loss_train = 36833592.0 \t loss_valid = 30563942.0 \n",
      "Model_11_8850 \t loss_train = 37420168.0 \t loss_valid = 30951702.0 \n",
      "Model_11_8860 \t loss_train = 36574884.0 \t loss_valid = 30341398.0 \n",
      "Model_11_8870 \t loss_train = 35828708.0 \t loss_valid = 29714650.0 \n",
      "Model_11_8880 \t loss_train = 37072936.0 \t loss_valid = 30755752.0 \n",
      "Model_11_8890 \t loss_train = 37188916.0 \t loss_valid = 30919322.0 \n",
      "Model_11_8900 \t loss_train = 37209556.0 \t loss_valid = 30783130.0 \n",
      "Model_11_8910 \t loss_train = 36604484.0 \t loss_valid = 30388802.0 \n",
      "Model_11_8920 \t loss_train = 37176672.0 \t loss_valid = 30860696.0 \n",
      "Model_11_8930 \t loss_train = 37389324.0 \t loss_valid = 30885098.0 \n",
      "Model_11_8940 \t loss_train = 37446340.0 \t loss_valid = 31067086.0 \n",
      "Model_11_8950 \t loss_train = 37412588.0 \t loss_valid = 30988540.0 \n",
      "Model_11_8960 \t loss_train = 37258764.0 \t loss_valid = 30795852.0 \n",
      "Model_11_8970 \t loss_train = 37879828.0 \t loss_valid = 31426794.0 \n",
      "Model_11_8980 \t loss_train = 37012120.0 \t loss_valid = 30652498.0 \n",
      "Model_11_8990 \t loss_train = 36983596.0 \t loss_valid = 30630826.0 \n",
      "Model_11_9000 \t loss_train = 37479472.0 \t loss_valid = 31102872.0 \n",
      "Model_11_9010 \t loss_train = 37660312.0 \t loss_valid = 31234038.0 \n",
      "Model_11_9020 \t loss_train = 36671596.0 \t loss_valid = 30408344.0 \n",
      "Model_11_9030 \t loss_train = 37014724.0 \t loss_valid = 30696970.0 \n",
      "Model_11_9040 \t loss_train = 37206520.0 \t loss_valid = 30848142.0 \n",
      "Model_11_9050 \t loss_train = 37261860.0 \t loss_valid = 30954050.0 \n",
      "Model_11_9060 \t loss_train = 36579920.0 \t loss_valid = 30250082.0 \n",
      "Model_11_9070 \t loss_train = 36866752.0 \t loss_valid = 30600606.0 \n",
      "Model_11_9080 \t loss_train = 36769692.0 \t loss_valid = 30450172.0 \n",
      "Model_11_9090 \t loss_train = 37128668.0 \t loss_valid = 30797874.0 \n",
      "Model_11_9100 \t loss_train = 36887296.0 \t loss_valid = 30570326.0 \n",
      "Model_11_9110 \t loss_train = 36864676.0 \t loss_valid = 30609522.0 \n",
      "Model_11_9120 \t loss_train = 37116320.0 \t loss_valid = 30748350.0 \n",
      "Model_11_9130 \t loss_train = 37165348.0 \t loss_valid = 30847786.0 \n",
      "Model_11_9140 \t loss_train = 37166776.0 \t loss_valid = 30717636.0 \n",
      "Model_11_9150 \t loss_train = 36785176.0 \t loss_valid = 30512994.0 \n",
      "Model_11_9160 \t loss_train = 36421792.0 \t loss_valid = 30165814.0 \n",
      "Model_11_9170 \t loss_train = 37250180.0 \t loss_valid = 30913678.0 \n",
      "Model_11_9180 \t loss_train = 37262468.0 \t loss_valid = 30868872.0 \n",
      "Model_11_9190 \t loss_train = 37126296.0 \t loss_valid = 30676920.0 \n",
      "Model_11_9200 \t loss_train = 36600192.0 \t loss_valid = 30347652.0 \n",
      "Model_11_9210 \t loss_train = 36827328.0 \t loss_valid = 30518098.0 \n",
      "Model_11_9220 \t loss_train = 36565876.0 \t loss_valid = 30327692.0 \n",
      "Model_11_9230 \t loss_train = 37049960.0 \t loss_valid = 30670924.0 \n",
      "Model_11_9240 \t loss_train = 37035060.0 \t loss_valid = 30668408.0 \n",
      "Model_11_9250 \t loss_train = 37063124.0 \t loss_valid = 30708284.0 \n",
      "Model_11_9260 \t loss_train = 37296688.0 \t loss_valid = 30855986.0 \n",
      "Model_11_9270 \t loss_train = 36996472.0 \t loss_valid = 30550006.0 \n",
      "Model_11_9280 \t loss_train = 37073916.0 \t loss_valid = 30719886.0 \n",
      "Model_11_9290 \t loss_train = 37408744.0 \t loss_valid = 30943156.0 \n",
      "Model_11_9300 \t loss_train = 36921008.0 \t loss_valid = 30634952.0 \n",
      "Model_11_9310 \t loss_train = 37506936.0 \t loss_valid = 31093102.0 \n",
      "Model_11_9320 \t loss_train = 37308248.0 \t loss_valid = 30793010.0 \n",
      "Model_11_9330 \t loss_train = 37383676.0 \t loss_valid = 30990588.0 \n",
      "Model_11_9340 \t loss_train = 37156520.0 \t loss_valid = 30770682.0 \n",
      "Model_11_9350 \t loss_train = 36771332.0 \t loss_valid = 30500662.0 \n",
      "Model_11_9360 \t loss_train = 36669520.0 \t loss_valid = 30378410.0 \n",
      "Model_11_9370 \t loss_train = 37558108.0 \t loss_valid = 31128560.0 \n",
      "Model_11_9380 \t loss_train = 36873484.0 \t loss_valid = 30541240.0 \n",
      "Model_11_9390 \t loss_train = 36801360.0 \t loss_valid = 30479982.0 \n",
      "Model_11_9400 \t loss_train = 37017508.0 \t loss_valid = 30744406.0 \n",
      "Model_11_9410 \t loss_train = 37560404.0 \t loss_valid = 31108528.0 \n",
      "Model_11_9420 \t loss_train = 37396956.0 \t loss_valid = 30962056.0 \n",
      "Model_11_9430 \t loss_train = 37424392.0 \t loss_valid = 31030474.0 \n",
      "Model_11_9440 \t loss_train = 36955788.0 \t loss_valid = 30596064.0 \n",
      "Model_11_9450 \t loss_train = 36731004.0 \t loss_valid = 30481730.0 \n",
      "Model_11_9460 \t loss_train = 37345404.0 \t loss_valid = 30975778.0 \n",
      "Model_11_9470 \t loss_train = 37735284.0 \t loss_valid = 31268396.0 \n",
      "Model_11_9480 \t loss_train = 37247572.0 \t loss_valid = 30834376.0 \n",
      "Model_11_9490 \t loss_train = 36956660.0 \t loss_valid = 30642164.0 \n",
      "Model_11_9500 \t loss_train = 37081088.0 \t loss_valid = 30750512.0 \n",
      "Model_11_9510 \t loss_train = 37306008.0 \t loss_valid = 30841606.0 \n",
      "Model_11_9520 \t loss_train = 37393296.0 \t loss_valid = 30981372.0 \n",
      "Model_11_9530 \t loss_train = 36600764.0 \t loss_valid = 30355472.0 \n",
      "Model_11_9540 \t loss_train = 36692388.0 \t loss_valid = 30420040.0 \n",
      "Model_11_9550 \t loss_train = 37230404.0 \t loss_valid = 30814888.0 \n",
      "Model_11_9560 \t loss_train = 37111288.0 \t loss_valid = 30740778.0 \n",
      "Model_11_9570 \t loss_train = 37315684.0 \t loss_valid = 30928520.0 \n",
      "Model_11_9580 \t loss_train = 37368492.0 \t loss_valid = 30930634.0 \n",
      "Model_11_9590 \t loss_train = 37261172.0 \t loss_valid = 30892614.0 \n",
      "Model_11_9600 \t loss_train = 37233648.0 \t loss_valid = 30849932.0 \n",
      "Model_11_9610 \t loss_train = 36735588.0 \t loss_valid = 30410926.0 \n",
      "Model_11_9620 \t loss_train = 36786632.0 \t loss_valid = 30531566.0 \n",
      "Model_11_9630 \t loss_train = 37111512.0 \t loss_valid = 30774942.0 \n",
      "Model_11_9640 \t loss_train = 37640864.0 \t loss_valid = 31189756.0 \n",
      "Model_11_9650 \t loss_train = 37559992.0 \t loss_valid = 31062506.0 \n",
      "Model_11_9660 \t loss_train = 37257572.0 \t loss_valid = 30866414.0 \n",
      "Model_11_9670 \t loss_train = 37334196.0 \t loss_valid = 30853698.0 \n",
      "Model_11_9680 \t loss_train = 36859712.0 \t loss_valid = 30545720.0 \n",
      "Model_11_9690 \t loss_train = 37135204.0 \t loss_valid = 30758482.0 \n",
      "Model_11_9700 \t loss_train = 37525728.0 \t loss_valid = 31102022.0 \n",
      "Model_11_9710 \t loss_train = 37421224.0 \t loss_valid = 31001912.0 \n",
      "Model_11_9720 \t loss_train = 37202388.0 \t loss_valid = 30808128.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_11_9730 \t loss_train = 37398952.0 \t loss_valid = 30960260.0 \n",
      "Model_11_9740 \t loss_train = 37096308.0 \t loss_valid = 30766368.0 \n",
      "Model_11_9750 \t loss_train = 37704572.0 \t loss_valid = 31127438.0 \n",
      "Model_11_9760 \t loss_train = 37088960.0 \t loss_valid = 30661642.0 \n",
      "Model_11_9770 \t loss_train = 37015544.0 \t loss_valid = 30684090.0 \n",
      "Model_11_9780 \t loss_train = 37687244.0 \t loss_valid = 31230038.0 \n",
      "Model_11_9790 \t loss_train = 37605028.0 \t loss_valid = 31099554.0 \n",
      "Model_11_9800 \t loss_train = 37945556.0 \t loss_valid = 31325376.0 \n",
      "Model_11_9810 \t loss_train = 37011048.0 \t loss_valid = 30703966.0 \n",
      "Model_11_9820 \t loss_train = 36727392.0 \t loss_valid = 30363282.0 \n",
      "Model_11_9830 \t loss_train = 37118948.0 \t loss_valid = 30776136.0 \n",
      "Model_11_9840 \t loss_train = 37276788.0 \t loss_valid = 30850216.0 \n",
      "Model_11_9850 \t loss_train = 37129884.0 \t loss_valid = 30757774.0 \n",
      "Model_11_9860 \t loss_train = 37039968.0 \t loss_valid = 30628078.0 \n",
      "Model_11_9870 \t loss_train = 37307428.0 \t loss_valid = 30957982.0 \n",
      "Model_11_9880 \t loss_train = 36750920.0 \t loss_valid = 30517890.0 \n",
      "Model_11_9890 \t loss_train = 38105216.0 \t loss_valid = 31443422.0 \n",
      "Model_11_9900 \t loss_train = 37400504.0 \t loss_valid = 31071710.0 \n",
      "Model_11_9910 \t loss_train = 37849268.0 \t loss_valid = 31391928.0 \n",
      "Model_11_9920 \t loss_train = 37488352.0 \t loss_valid = 30917998.0 \n",
      "Model_11_9930 \t loss_train = 37233112.0 \t loss_valid = 30889934.0 \n",
      "Model_11_9940 \t loss_train = 37425976.0 \t loss_valid = 30972638.0 \n",
      "Model_11_9950 \t loss_train = 37801264.0 \t loss_valid = 31226020.0 \n",
      "Model_11_9960 \t loss_train = 37483752.0 \t loss_valid = 30985870.0 \n",
      "Model_11_9970 \t loss_train = 37376544.0 \t loss_valid = 30914702.0 \n",
      "Model_11_9980 \t loss_train = 37882536.0 \t loss_valid = 31353098.0 \n",
      "Model_11_9990 \t loss_train = 37727432.0 \t loss_valid = 31211264.0 \n",
      "Model_11_10000 \t loss_train = 37993572.0 \t loss_valid = 31352850.0 \n",
      "Model_11_10010 \t loss_train = 37844128.0 \t loss_valid = 31280846.0 \n",
      "Model_11_10020 \t loss_train = 38098680.0 \t loss_valid = 31527570.0 \n",
      "Model_11_10030 \t loss_train = 37323232.0 \t loss_valid = 30886254.0 \n",
      "Model_11_10040 \t loss_train = 36775772.0 \t loss_valid = 30499006.0 \n",
      "Model_11_10050 \t loss_train = 37374348.0 \t loss_valid = 30915154.0 \n",
      "Model_11_10060 \t loss_train = 37140272.0 \t loss_valid = 30680128.0 \n",
      "Model_11_10070 \t loss_train = 37224964.0 \t loss_valid = 30872000.0 \n",
      "Model_11_10080 \t loss_train = 37365304.0 \t loss_valid = 30984290.0 \n",
      "Model_11_10090 \t loss_train = 37770340.0 \t loss_valid = 31203688.0 \n",
      "Model_11_10100 \t loss_train = 37884084.0 \t loss_valid = 31380860.0 \n",
      "Model_11_10110 \t loss_train = 37402920.0 \t loss_valid = 30975766.0 \n",
      "Model_11_10120 \t loss_train = 37404856.0 \t loss_valid = 30950042.0 \n",
      "Model_11_10130 \t loss_train = 37678808.0 \t loss_valid = 31259472.0 \n",
      "Model_11_10140 \t loss_train = 37546668.0 \t loss_valid = 31021160.0 \n",
      "Model_11_10150 \t loss_train = 37077132.0 \t loss_valid = 30740284.0 \n",
      "Model_11_10160 \t loss_train = 36846368.0 \t loss_valid = 30501992.0 \n",
      "Model_11_10170 \t loss_train = 37833028.0 \t loss_valid = 31279370.0 \n",
      "Model_11_10180 \t loss_train = 37814696.0 \t loss_valid = 31321770.0 \n",
      "Model_11_10190 \t loss_train = 37630024.0 \t loss_valid = 31143494.0 \n",
      "Model_11_10200 \t loss_train = 37421500.0 \t loss_valid = 30954724.0 \n",
      "Model_11_10210 \t loss_train = 37932524.0 \t loss_valid = 31296998.0 \n",
      "Model_11_10220 \t loss_train = 37947280.0 \t loss_valid = 31458858.0 \n",
      "Model_11_10230 \t loss_train = 38402964.0 \t loss_valid = 31799240.0 \n",
      "Model_11_10240 \t loss_train = 37971964.0 \t loss_valid = 31459780.0 \n",
      "Model_11_10250 \t loss_train = 37571880.0 \t loss_valid = 31121436.0 \n",
      "Model_11_10260 \t loss_train = 37275296.0 \t loss_valid = 30848922.0 \n",
      "Model_11_10270 \t loss_train = 37742088.0 \t loss_valid = 31219826.0 \n",
      "Model_11_10280 \t loss_train = 37116072.0 \t loss_valid = 30712346.0 \n",
      "Model_11_10290 \t loss_train = 37476680.0 \t loss_valid = 30970940.0 \n",
      "Model_11_10300 \t loss_train = 37521760.0 \t loss_valid = 31050872.0 \n",
      "Model_11_10310 \t loss_train = 37602420.0 \t loss_valid = 31138424.0 \n",
      "Model_11_10320 \t loss_train = 37800312.0 \t loss_valid = 31287436.0 \n",
      "Model_11_10330 \t loss_train = 37896416.0 \t loss_valid = 31426434.0 \n",
      "Model_11_10340 \t loss_train = 37699888.0 \t loss_valid = 31164276.0 \n",
      "Model_11_10350 \t loss_train = 37642892.0 \t loss_valid = 31220280.0 \n",
      "Model_11_10360 \t loss_train = 38081428.0 \t loss_valid = 31495804.0 \n",
      "Model_11_10370 \t loss_train = 37285244.0 \t loss_valid = 30842700.0 \n",
      "Model_11_10380 \t loss_train = 37743332.0 \t loss_valid = 31234932.0 \n",
      "Model_11_10390 \t loss_train = 37382012.0 \t loss_valid = 30904738.0 \n",
      "Model_11_10400 \t loss_train = 37854428.0 \t loss_valid = 31318772.0 \n",
      "Model_11_10410 \t loss_train = 37577188.0 \t loss_valid = 31045562.0 \n",
      "Model_11_10420 \t loss_train = 37548532.0 \t loss_valid = 31082344.0 \n",
      "Model_11_10430 \t loss_train = 37819164.0 \t loss_valid = 31263664.0 \n",
      "Model_11_10440 \t loss_train = 37467144.0 \t loss_valid = 30993180.0 \n",
      "Model_11_10450 \t loss_train = 37698508.0 \t loss_valid = 31155760.0 \n",
      "Model_11_10460 \t loss_train = 37357272.0 \t loss_valid = 30874718.0 \n",
      "Model_11_10470 \t loss_train = 37753368.0 \t loss_valid = 31179824.0 \n",
      "Model_11_10480 \t loss_train = 37714444.0 \t loss_valid = 31139808.0 \n",
      "Model_11_10490 \t loss_train = 37199184.0 \t loss_valid = 30814416.0 \n",
      "Model_11_10500 \t loss_train = 37487020.0 \t loss_valid = 30979208.0 \n",
      "Model_11_10510 \t loss_train = 37912748.0 \t loss_valid = 31436806.0 \n",
      "Model_11_10520 \t loss_train = 36989000.0 \t loss_valid = 30561916.0 \n",
      "Model_11_10530 \t loss_train = 36862924.0 \t loss_valid = 30458394.0 \n",
      "Model_11_10540 \t loss_train = 37704732.0 \t loss_valid = 31199778.0 \n",
      "Model_11_10550 \t loss_train = 37434780.0 \t loss_valid = 31001470.0 \n",
      "Model_11_10560 \t loss_train = 37303744.0 \t loss_valid = 30869658.0 \n",
      "Model_11_10570 \t loss_train = 37889640.0 \t loss_valid = 31370878.0 \n",
      "Model_11_10580 \t loss_train = 38363920.0 \t loss_valid = 31709496.0 \n",
      "Model_11_10590 \t loss_train = 37826056.0 \t loss_valid = 31350960.0 \n",
      "Model_11_10600 \t loss_train = 37783652.0 \t loss_valid = 31267588.0 \n",
      "Model_11_10610 \t loss_train = 37550548.0 \t loss_valid = 31038716.0 \n",
      "Model_11_10620 \t loss_train = 37346644.0 \t loss_valid = 30878502.0 \n",
      "Model_11_10630 \t loss_train = 37564024.0 \t loss_valid = 31076008.0 \n",
      "Model_11_10640 \t loss_train = 37568004.0 \t loss_valid = 31073096.0 \n",
      "Model_11_10650 \t loss_train = 37472600.0 \t loss_valid = 31023274.0 \n",
      "Model_11_10660 \t loss_train = 37741328.0 \t loss_valid = 31236106.0 \n",
      "Model_11_10670 \t loss_train = 37758380.0 \t loss_valid = 31197004.0 \n",
      "Model_11_10680 \t loss_train = 37608588.0 \t loss_valid = 31104866.0 \n",
      "Model_11_10690 \t loss_train = 37391912.0 \t loss_valid = 30937710.0 \n",
      "Model_11_10700 \t loss_train = 37369028.0 \t loss_valid = 30869688.0 \n",
      "Model_11_10710 \t loss_train = 37533652.0 \t loss_valid = 31034838.0 \n",
      "Model_11_10720 \t loss_train = 37744112.0 \t loss_valid = 31218752.0 \n",
      "Model_11_10730 \t loss_train = 37922596.0 \t loss_valid = 31444126.0 \n",
      "Model_11_10740 \t loss_train = 37523636.0 \t loss_valid = 31055894.0 \n",
      "Model_11_10750 \t loss_train = 37394956.0 \t loss_valid = 30915752.0 \n",
      "Model_11_10760 \t loss_train = 37739080.0 \t loss_valid = 31260502.0 \n",
      "Model_11_10770 \t loss_train = 37667640.0 \t loss_valid = 31092992.0 \n",
      "Model_11_10780 \t loss_train = 37522016.0 \t loss_valid = 30964378.0 \n",
      "Model_11_10790 \t loss_train = 37536656.0 \t loss_valid = 31013028.0 \n",
      "Model_11_10800 \t loss_train = 37767928.0 \t loss_valid = 31183866.0 \n",
      "Model_11_10810 \t loss_train = 37886168.0 \t loss_valid = 31283150.0 \n",
      "Model_11_10820 \t loss_train = 37359580.0 \t loss_valid = 30907398.0 \n",
      "Model_11_10830 \t loss_train = 37496300.0 \t loss_valid = 30939644.0 \n",
      "Model_11_10840 \t loss_train = 37768468.0 \t loss_valid = 31163652.0 \n",
      "Model_11_10850 \t loss_train = 37695808.0 \t loss_valid = 31179132.0 \n",
      "Model_11_10860 \t loss_train = 37984424.0 \t loss_valid = 31405694.0 \n",
      "Model_11_10870 \t loss_train = 38277464.0 \t loss_valid = 31632466.0 \n",
      "Model_11_10880 \t loss_train = 37670964.0 \t loss_valid = 31168344.0 \n",
      "Model_11_10890 \t loss_train = 37617064.0 \t loss_valid = 31093280.0 \n",
      "Model_11_10900 \t loss_train = 38129464.0 \t loss_valid = 31461960.0 \n",
      "Model_11_10910 \t loss_train = 37347904.0 \t loss_valid = 30888490.0 \n",
      "Model_11_10920 \t loss_train = 37670388.0 \t loss_valid = 31113276.0 \n",
      "Model_11_10930 \t loss_train = 37906160.0 \t loss_valid = 31346916.0 \n",
      "Model_11_10940 \t loss_train = 37876204.0 \t loss_valid = 31317144.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_11_10950 \t loss_train = 37684616.0 \t loss_valid = 31139136.0 \n",
      "Model_11_10960 \t loss_train = 37114924.0 \t loss_valid = 30715582.0 \n",
      "Model_11_10970 \t loss_train = 37313372.0 \t loss_valid = 30816404.0 \n",
      "Model_11_10980 \t loss_train = 37502280.0 \t loss_valid = 30963128.0 \n",
      "Model_11_10990 \t loss_train = 37532164.0 \t loss_valid = 30939486.0 \n",
      "Model_11_11000 \t loss_train = 37902644.0 \t loss_valid = 31288082.0 \n",
      "Model_11_11010 \t loss_train = 37679812.0 \t loss_valid = 31093124.0 \n",
      "Model_11_11020 \t loss_train = 37856196.0 \t loss_valid = 31310260.0 \n",
      "Model_11_11030 \t loss_train = 37438772.0 \t loss_valid = 31018158.0 \n",
      "Model_11_11040 \t loss_train = 37903228.0 \t loss_valid = 31326198.0 \n",
      "Model_11_11050 \t loss_train = 37583628.0 \t loss_valid = 31062228.0 \n",
      "Model_11_11060 \t loss_train = 37573964.0 \t loss_valid = 31049618.0 \n",
      "Early stopping!\n",
      "CPU times: user 7min 22s, sys: 22.2 s, total: 7min 44s\n",
      "Wall time: 5min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res_start = 17\n",
    "dict_y_models_train = {}              # dict of models for y(총관중수) prediction \n",
    "# dict_reserve_models_train = {}        # dict of models for reservation prediction \n",
    "\n",
    "for day in range(0, 12):   \n",
    "    \n",
    "    # Predict y_total(총관중수) as reservation progresses. Note that features differ \n",
    "    X_train_values = np.array(X_train.iloc[:, 0:res_start+day].values, dtype=np.float32)\n",
    "    y_train_values = np.array(y_train.values, dtype=np.float32)\n",
    "    \n",
    "    X_test_values = np.array(X_test.iloc[:, 0:res_start+day].values, dtype=np.float32)\n",
    "    y_test_values = np.array(y_test.values, dtype=np.float32)\n",
    "                              \n",
    "    y_model_path = NeuralNetRegressor(X_train_values, y_train_values, \n",
    "                                      X_test_values, y_test_values,\n",
    "                                      n_epochs=100000, model_id=day)\n",
    "    \n",
    "    y_model_key = 'y_model_' + str(day)   # y_model_n : n'th day prediction of y\n",
    "    dict_y_models_train[y_model_key] = y_model_path     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y_model_0': 'models_log/y_model_0',\n",
       " 'y_model_1': 'models_log/y_model_1',\n",
       " 'y_model_2': 'models_log/y_model_2',\n",
       " 'y_model_3': 'models_log/y_model_3',\n",
       " 'y_model_4': 'models_log/y_model_4',\n",
       " 'y_model_5': 'models_log/y_model_5',\n",
       " 'y_model_6': 'models_log/y_model_6',\n",
       " 'y_model_7': 'models_log/y_model_7',\n",
       " 'y_model_8': 'models_log/y_model_8',\n",
       " 'y_model_9': 'models_log/y_model_9',\n",
       " 'y_model_10': 'models_log/y_model_10',\n",
       " 'y_model_11': 'models_log/y_model_11'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_y_models_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 총관중 예측  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def predict_total(X_in, y_in, game_idx):   \n",
    "    \"\"\"\n",
    "    dict_y_models_train : 총관중수 모델 with training set\n",
    "    X_in : games features in design matrix form (Pandas DataFrame) \n",
    "    y_in : targets  (Pandas Series)\n",
    "    game_idx : integer \n",
    "    \n",
    "    ** 학습된 모델 갖고 오기 : 모델이 저장된 디렉토리에서 직접 갖고 온다. \n",
    "    ** Tensorflow 실행 환경 : 이전 모델의 compuational graph가 전혀 없는 초기화 상태에서 시작  \n",
    "    \n",
    "    - But we know what is the model we need. We know the naming protocol.  \n",
    "    \"\"\"\n",
    "    pred_y_totals = [] \n",
    "    \n",
    "    # df = pd.DataFrame(index=range(1, 13))\n",
    "\n",
    "    for day in range(0,12):\n",
    "\n",
    "        reset_graph()   # 그래프 초기화 \n",
    "            \n",
    "        # 원하는 tensorflow 그래프를 복원해야 함 ...   예) \"./models_log/y_model_0.meta\" \n",
    "        y_model_key = 'y_model_' + str(day) \n",
    "        y_model_meta_key = y_model_key + '.meta'\n",
    "        \n",
    "        model_path = os.path.join('.', 'models_log') + os.sep + y_model_key\n",
    "        model_meta_path = os.path.join('.','models_log') + os.sep + y_model_meta_key\n",
    "        \n",
    "        restorer = tf.train.import_meta_graph(model_meta_path) # model graph restored to default graph\n",
    "        # list_nodes_in_graph()\n",
    "        \n",
    "        # -------------- 중요: 원래 그래프의 노드에 접근할 수 있는 handle을 가져와야 함 ---------------\n",
    "        # 우리가 위에서 그래프를 초기화했고, 종종 모델을 저장했다가 나중에 쓸 수도 있기에 이런 방법을 익혀야 함\n",
    "        #\n",
    "        X = tf.get_default_graph().get_tensor_by_name(\"X:0\")  # Placeholder X\n",
    "        prediction = tf.get_default_graph().get_tensor_by_name(\"output/BiasAdd:0\") # output  \n",
    "        # ---- 원래 모델의 computation graph를 복원했고, 원하는 노드(텐서)도 획득 \n",
    "        \n",
    "        with tf.Session() as sess: \n",
    "            restorer.restore(sess, model_path)   # Restored the state(weights)\n",
    "            \n",
    "            X_values = X_in.iloc[game_idx, 0:(res_start+day)].values.reshape(1,-1)\n",
    "            # X_values = np.array(X_in.iloc[game_idx, 0:res_start+day].values, dtype=np.float32)\n",
    "\n",
    "            pred_y_total = sess.run(prediction, feed_dict={X:X_values} )\n",
    "            pred_y_totals.append(pred_y_total[0][0]) \n",
    "        \n",
    "    print(pred_y_totals)\n",
    "    \n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.hlines(y=y_in.iloc[game_idx], xmin=0, xmax=11, color='r', linestyle='-', label=\"실제\")\n",
    "    plt.plot(pred_y_totals, color='green', linestyle='dashed', linewidth=3,label=\"예측\")  \n",
    "    plt.grid() \n",
    "    plt.legend(loc=\"best\", fontsize=14)\n",
    "    plt.title(\"총관중수 예측_%d\"%game_idx, fontsize=14)\n",
    "    plt.show() \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_0\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_1\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_2\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_3\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_4\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_5\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_6\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_7\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_8\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_9\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_10\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_11\n",
      "[9004.539, 8954.147, 9118.822, 8672.298, 8510.877, 8891.281, 8898.689, 8146.999, 8937.212, 8661.688, 8352.679, 8876.957]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_0\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_1\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_2\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_3\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_4\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_5\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_6\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_7\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_8\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_9\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_10\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_11\n",
      "[9050.688, 8998.067, 8928.864, 8671.601, 9180.0625, 8879.491, 8904.614, 8880.574, 9031.268, 8765.798, 8551.741, 8843.364]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_0\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_1\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_2\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_3\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_4\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_5\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_6\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_7\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_8\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_9\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_10\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_11\n",
      "[9018.61, 8994.034, 8869.288, 8763.653, 9005.754, 8883.54, 8884.466, 8738.677, 8951.384, 8755.134, 8412.324, 8792.676]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_0\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_1\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_2\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_3\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_4\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_5\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_6\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_7\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_8\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_9\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_10\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_11\n",
      "[9086.003, 8953.74, 8389.841, 9016.22, 8667.706, 8886.021, 8878.009, 8670.734, 8945.115, 8589.487, 9312.631, 8498.83]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_0\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_1\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_2\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_3\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_4\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_5\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_6\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_7\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_8\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_9\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_10\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_11\n",
      "[9037.576, 8947.992, 8844.677, 8749.454, 8984.105, 8906.242, 8897.586, 8812.104, 9053.281, 8867.501, 9150.593, 8836.924]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_0\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_1\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_2\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_3\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_4\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_5\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_6\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_7\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_8\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_9\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_10\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_11\n",
      "[9047.927, 8956.345, 8898.155, 8253.033, 9771.685, 8878.466, 8942.343, 9383.331, 8880.564, 8120.895, 8854.814, 9078.09]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_0\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_1\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_2\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_3\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_4\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_5\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_6\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_7\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_8\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_9\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_10\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_11\n",
      "[9049.35, 8981.868, 9090.212, 8998.783, 9082.327, 8903.803, 8892.408, 8845.078, 8966.181, 8766.498, 8724.707, 9410.485]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_0\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_1\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_2\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_3\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_4\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_5\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_6\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_7\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_8\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_9\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_10\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_11\n",
      "[9077.417, 8957.578, 8939.109, 8778.528, 8726.251, 8899.827, 8901.034, 8838.346, 8897.284, 9076.85, 9040.097, 9312.05]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_0\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_1\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_2\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_3\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_4\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_5\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_6\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_7\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_8\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_9\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_10\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_11\n",
      "[9026.62, 9018.068, 8824.507, 8928.381, 8987.546, 8909.897, 8907.709, 8933.013, 8924.349, 8878.8955, 8730.046, 8915.343]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_0\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_1\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_2\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_3\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_4\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_5\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_6\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_7\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_8\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_9\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_10\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_11\n",
      "[9030.804, 8987.831, 9036.593, 8468.618, 8558.829, 8864.257, 8866.268, 8535.709, 8933.221, 8633.856, 8912.537, 8442.779]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_0\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_1\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_2\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_3\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_4\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_5\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_6\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_7\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_8\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_9\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_10\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_11\n",
      "[9086.003, 8948.6045, 9008.778, 8731.434, 8618.727, 8879.298, 8893.471, 8636.582, 8790.528, 8827.964, 8548.095, 9422.665]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_0\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_1\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_2\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_3\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_4\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_5\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_6\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_7\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_8\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_9\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_10\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_11\n",
      "[8996.725, 8943.403, 9322.858, 8486.903, 8657.544, 8878.852, 8907.195, 8770.41, 8777.924, 8830.767, 8416.267, 9512.158]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_0\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_1\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_2\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_3\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_4\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_5\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_6\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_7\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_8\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_9\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_10\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_11\n",
      "[9007.855, 8951.936, 9098.852, 8429.318, 7939.735, 8859.792, 8891.646, 8083.5127, 8471.044, 8160.496, 8441.973, 9008.846]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_0\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_1\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_2\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_3\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_4\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_5\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_6\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_7\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_8\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_9\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_10\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_11\n",
      "[9058.076, 8969.625, 8894.316, 8801.155, 9781.724, 8923.077, 8923.768, 8786.976, 8792.99, 8646.547, 8657.69, 9831.884]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_0\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_1\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_2\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_3\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_4\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_5\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_6\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_7\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_8\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_9\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_10\n",
      "INFO:tensorflow:Restoring parameters from ./models_log/y_model_11\n",
      "[9027.486, 8976.408, 8937.525, 9078.339, 8860.101, 8902.899, 8890.418, 8864.975, 8892.167, 8992.732, 8566.396, 9028.224]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for game_index in range(0, len(y_test), 5) :\n",
    "    predict_total(X_test, y_test, game_index)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
